{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_1_-_Template_hand-out.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jojoayan1992/ML_CyberSec/blob/master/Project1/Project_1_ver1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "4NzyqehHjUlG"
      },
      "cell_type": "markdown",
      "source": [
        "# ML in Cybersecurity: Project I\n",
        "\n",
        "## Team\n",
        "  * **Team name**:  *fill this in*\n",
        "  * **Members**:  *fill this in. format: name1 (email1), name2 (email2), ...*\n",
        "  * **Tutor**: *fill this in after being assigned*\n",
        "\n",
        "\n",
        "## Logistics\n",
        "  * **Due date**: 11th November 2018, 23:59:59 (to email the completed notebook to your respective tutors)\n",
        "  * Complete this in **teams of 3**\n",
        "  * Write to Hossein (hossein.hajipour@cispa.saarland) by **2nd November** your team members and team-name. \n",
        "  * In case you cannot find a team, some available options: (a) Contact Hossein, who can help you out (b) Post on the [course group](https://groups.google.com/d/forum/ml-cysec-2018)\n",
        "  * Each team will be assigned a tutor. Mail the notebook (or share the collab link) to the respective TAs before the due date.\n",
        "  \n",
        "  \n",
        "## Timeline\n",
        "  * 29-Oct-2018: Project 1 hand-out\n",
        "  * 2-Nov-2018: Write to Hossein your team-name and members\n",
        "  * 5-Nov-2018: Each team is assigned a tutor\n",
        "  * **11-Nov-2018** (23:59:59): Email completed notebook to respective TAs\n",
        "  * **12-Nov-2018** (12:15-14:00, regular tutorial slot): Teams present their projects\n",
        "  * 19-Nov-2018 (12:15-14:00, regular tutorial slot): Project 1 discussion and summary\n",
        "  \n",
        "  \n",
        "## About this Project\n",
        "In this project, you'll implement a digit classifier, based on the popular [MNIST](http://yann.lecun.com/exdb/mnist/) dataset. The dataset is based on a seminal [paper](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf), which immensely popularized (convolutional) neural networks. This is a great starting point for ML research and this dataset/model has been a stepping stone numerous other tasks such as [GANs](https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf), [Adversarial Perturbations](https://arxiv.org/abs/1412.6572) and so many more!\n",
        "\n",
        "This dataset consists of data $\\mathcal{D} = \\{x_i, y_i\\}_{i=1}^N$, where $x_i$ is a 28x28 pixel grayscale image and $y_i$ is a scalar represeting digits between 0-9. The notebook will guide you to load this data, implement classifiers $\\hat{y_i} = f_w(x_i)$  and analyze results. By doing so, you'll have a ML model that works on real data!\n",
        "\n",
        "To put things into context, have a look at Slide 24 in the [second](https://cms.cispa.saarland/mlcysec/dl/2/2018-10-24_ML_overview.pdf) lecture. Within this framework, the following blocks of this project are fixed:\n",
        "  * *Real-world problem*: Digit classification\n",
        "  * *Performance metric*: Mean accuracy i.e., $ \\frac{1}{N} \\sum_{i=1}^N \\mathbb{1}[\\hat{y_i} = y_i]$, where $\\mathbb{1}[\\hat{y_i} = y_i]$ is 1 if your model predicted the right digit for the $i$-th digit and 0 otherwise.\n",
        "  * *Data*: The MNIST dataset\n",
        "\n",
        "You'll make the the following design-choices:\n",
        " * *Choice of Model*: A model family (Non-parametric methods, Linear classifiers, Neural Networks, etc.)\n",
        " * *ML Model*: Specific model (e.g., SVM with a polynomial kernel)\n",
        " * *Loss/Risk*\n",
        " * *Optimization*\n",
        "\n",
        "\n",
        "## A Note on Grading\n",
        "The grading for this project will depend on:\n",
        " 1. Functional digit classifier\n",
        "   * Following a well-defined ML pipeline\n",
        "   * Developing 3 classification models (keep them diverse and ideally of increasing complexity)\n",
        "   * Obtaining reasonable accuracies (>80%) on a held-out test set\n",
        " 1. Analysis\n",
        "   * Which methods work better than the rest and why?\n",
        "   * Which hyper-parameters and design-choices were important in each of your methods?\n",
        "   * Quantifying influence of these hyper-parameters on loss and/or validation accuracies\n",
        "   * Trade-offs between methods, hyper-parameters, design-choices\n",
        "    * Anything else you find interesting (this part is open-ended)\n",
        " \n",
        "We will evaluate this criteria in a **12-minute presentation** (9 mins for presentation + 3 mins for Q&A). This will be during the regular tutorial slot on 12th November 12:00-14:00 (Location will be conveyed soon). In case you have time restrictions during the time of the tutorial, notify us asap!  You can present on your laptops.\n",
        "\n",
        "The most interesting findings will be discussed in the tutorial slot on 19th November.\n",
        " \n",
        " A note on (1.): \n",
        "  * choose your models that aids good insights. We require at least one non-Neural Network (e.g., SVM, KNN) and one Neural Network model (e.g., MLP, CNN).\n",
        "  * We definitely don't expect all three models to achieve >99% test accuracies!\n",
        " \n",
        " \n",
        "## Filling-in the Notebook\n",
        "You'll be submitting this very notebook that is filled-in with your code and analysis. Make sure you submit one that has been previously executed in-order. (So that results/graphs are already visible upon opening it). \n",
        "\n",
        "The notebook you submit **should compile** (or should be self-contained and sufficiently commented). Check tutorial 1 on how to set up the Python3 environment.\n",
        "\n",
        "It is extremely important that you **do not** re-order the existing sections. Apart from that, the code blocks that you need to fill-in are given by:\n",
        "```\n",
        "#\n",
        "#\n",
        "# ------- Your Code -------\n",
        "#\n",
        "#\n",
        "```\n",
        "Feel free to break this into multiple-cells. It's even better if you interleave explanations and code-blocks so that the entire notebook forms a readable \"story\".\n",
        "\n",
        "\n",
        "## Code of Honor\n",
        "We encourage discussing ideas and concepts with other students to help you learn and better understand the course content. However, the work you submit and present **must be original** and demonstrate your effort in solving the presented problems. **We will not tolerate** blatantly using existing solutions (such as from the internet), improper collaboration (e.g., sharing code or experimental data between groups) and plagiarism. If the honor code is not met, no points will be awarded.\n",
        "\n",
        " \n",
        " ## Versions\n",
        "  * v1.1: Added Code of Honor\n",
        "  * v1.0: Initial notebook\n",
        "  \n",
        "  ---"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "3ewNwfFvbFaR",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time \n",
        " \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "import json \n",
        "import time \n",
        "import pickle \n",
        "import sys \n",
        "import csv \n",
        "import os \n",
        "import os.path as osp \n",
        "import shutil \n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from IPython.display import display, HTML\n",
        " \n",
        "%matplotlib inline \n",
        "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots \n",
        "plt.rcParams['image.interpolation'] = 'nearest' \n",
        "plt.rcParams['image.cmap'] = 'gray' \n",
        " \n",
        "# for auto-reloading external modules \n",
        "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython \n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "640GrzbOevr0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f869316-9a04-42d4-ff1d-b77256583d84"
      },
      "cell_type": "code",
      "source": [
        "# Load other libraries here.\n",
        "# Keep it minimal! We should be easily able to reproduce your code.\n",
        "\n",
        "# In case you want to use neural networks, we only support sklearn and keras (With a tensorflow backend).\n",
        "\n",
        "import sklearn\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import sklearn.model_selection\n",
        "import sklearn.metrics\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "import tensorflow as tf\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "nxi-lLD0mKHD"
      },
      "cell_type": "markdown",
      "source": [
        "Helpers\n",
        "\n",
        "In case you choose to have some methods you plan to reuse during the notebook, define them here. This will avoid clutter and keep rest of the notebook succinct."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "VBbigqdEmKd8",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def identity_func(foo):\n",
        "    return foo\n",
        "\n",
        "\n",
        "#\n",
        "#\n",
        "# ------- Your Code -------\n",
        "#\n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "n1pcmKkyjT7y"
      },
      "cell_type": "markdown",
      "source": [
        "# 1. Loading and Visualizing data\n",
        "\n",
        "In this section, you'll need to prepare the MNIST data for the experiments you'll be conducting for the remainder of the notebook."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "AIU9Q762fmoT"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.1. Load Data\n",
        "\n",
        "Here you'll load the MNIST data into memory. The end-goal is to two have the following variables:\n",
        "  * `x_trainval`, `x_test`: of shape $N \\times d_1 \\times d_2 \\dots$ (e.g., $N \\times 784$. 784 since you could flatten each 28x28 pixel image into a single vector)\n",
        "  * `y_trainval`, `y_test`: of shape $N \\times K$ (K = 1 or 10 depending on how you plan to represent the ground-truth digit annotation)\n",
        "\n",
        "You can either do this by:\n",
        "  1. Downloading the MNIST dataset, unpacking and preparing it yourself to have fine-grained control\n",
        "  1. Using high-level existing functions, such as the one provided by  [`keras.datasets`](https://keras.io/datasets/#mnist-database-of-handwritten-digits).\n",
        "  \n",
        "  \n",
        "  In either case, it is important that you have disjoint trainval and test splits!"
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "k52VgrWzVmIk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "10eb9b9d-a6e8-4538-cfd1-807b449a28df"
      },
      "cell_type": "code",
      "source": [
        "(x_trainval, y_trainval), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "7kYacpo_jvao",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "b15a4747-6c97-4402-847d-7ff84fe1e202"
      },
      "cell_type": "code",
      "source": [
        "#\n",
        "#\n",
        "# ------- Your Code -------\n",
        "#\n",
        "#\n",
        "\n",
        "print('x_trainval.shape = {},  y_trainval.shape = {}'.format(x_trainval.shape, y_trainval.shape))\n",
        "print('x_test.shape = {},  y_test.shape = {}'.format(x_test.shape, y_test.shape))\n",
        "\n",
        "#\n",
        "# Feel free to have multiple variables in case your models are designed for different formats\n",
        "# For instance, in case your model requires Nx28x28 inputs, declare x_trainval_3d, etc.\n",
        "\n",
        "# Tip: Set this to a tiny number (such 0.05) to aid debugging\n",
        "# After all, you do not want to train/evaluate on the entire dataset to find bugs\n",
        "DEBUG_FRAC = 0.1\n",
        "# Resample x_[], y_[]\n",
        "x = np.concatenate((x_trainval, x_test))\n",
        "#print(x.shape)\n",
        "y = np.concatenate((y_trainval, y_test))\n",
        "#print(y.shape)\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=int(DEBUG_FRAC * x_test.shape[0]), train_size=int(DEBUG_FRAC * x_trainval.shape[0]), random_state=42)\n",
        "idx = sss.split(x,y)\n",
        "for train_idx, test_idx in idx:\n",
        "    x_trainval, y_trainval = x[train_idx], y[train_idx]\n",
        "    x_test, y_test = x[test_idx], y[test_idx]\n",
        "\n",
        "print(x_trainval.shape, x_test.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_trainval.shape = (60000, 28, 28),  y_trainval.shape = (60000,)\n",
            "x_test.shape = (10000, 28, 28),  y_test.shape = (10000,)\n",
            "(6000, 28, 28) (1000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "eA6_cejNjzYw"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.2. Visualize Data\n",
        "\n",
        "To get the hang of your data you'll be training a digit classifier on, visualize it.\n",
        "\n",
        "Examples of ways to visualize it:\n",
        "  * Given a digit, display few randomly sampled images for this digit (the bare minimum)\n",
        "  * Visualize as a grid (e.g., Slide 7, [Lecture 2](https://cms.cispa.saarland/mlcysec/dl/2/2018-10-24_ML_overview.pdf)) using a combination of `plt.imshow` and `plt.subplots`\n",
        "  \n",
        "It's up to you to decide how you want to do this. The end-goal is for you to potentially give a trailer of the dataset to someone who hasn't seen it before."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "dISIbt4plyoD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "36f87871-6941-45fc-d937-b6c4998331a4"
      },
      "cell_type": "code",
      "source": [
        "#\n",
        "#\n",
        "# ------- Your Code -------\n",
        "%matplotlib inline\n",
        "fig, axes = plt.subplots(3,3)\n",
        "plt.subplots_adjust(bottom=0.01, top=1.3, right=1)\n",
        "nums = [0, 5, 8]\n",
        "for i in range(len(nums)):\n",
        "    sample_idxs = (y_trainval == nums[i])\n",
        "    sample_X = x_trainval[sample_idxs][:3]\n",
        "    for s_num in range(len(sample_X)):\n",
        "        axes[i, s_num].imshow(sample_X[s_num], cmap='gray')\n",
        "#\n",
        "#\n",
        "#plt.imshow(x_train[0], cmap='gray')\n",
        "#plt.savefig('fig1.pdf')   # Save the figures in case you want to use it in the presentation\n",
        "#plt.show()   # These should be some visualization of data at the end of this section"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAGUCAYAAAAI+TQuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fdf7d098630>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "b8sAT53jmJ8_"
      },
      "cell_type": "markdown",
      "source": [
        "# 2. Digit classifiers\n",
        "\n",
        "In this section, you'll begin developing models to perform digit classification.\n",
        "\n",
        "Each model needs to be structured like so:\n",
        "  1. Give a brief reason which model you are going to train and why you choose it\n",
        "  1. Define hyper-parameters for model and optimization procedure\n",
        "  1. Define your model\n",
        "  1. Define optimization method and fit model to data\n",
        "  1. Summarize your findings\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "xkF-7eFnpWoe"
      },
      "cell_type": "markdown",
      "source": [
        "## 2.1: Model [M1]: *fill-this-in*\n",
        "\n",
        "**Short description **: *fill this in*"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "lVyT9Oddp3GB"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.1.1: Hyper-parameters\n",
        "\n",
        "Define hyper-parameters for your method here"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "yuHt4T7Vp5NC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "6282517a-d5ad-4581-db1d-f776a8d13734"
      },
      "cell_type": "code",
      "source": [
        "#\n",
        "#\n",
        "# ------- Your Code -------\n",
        "#\n",
        "#\n",
        "\n",
        "#gamma = 0.001 # example\n",
        "num_neighbors = np.arange(1, 11)\n",
        "weights = [\"uniform\", \"distance\"]\n",
        "#norm = np.arange(1, 6)\n",
        "param_space = {\"n_neighbors\": num_neighbors, \"weights\": weights}\n",
        "print(x_trainval.shape)\n",
        "#x_trainval_knn = x_trainval.reshape(x_trainval.shape[0],-1)\n",
        "x_trainval_knn = x_trainval.reshape(x_trainval.shape[0],-1)\n",
        "print(x_trainval_knn.shape)\n",
        "y_trainval_knn = y_trainval\n",
        "x_test_knn = x_test.reshape(x_test.shape[0],-1)\n",
        "y_test_knn = y_test\n",
        "\n",
        "test_set = 'val'  #  or 'test'\n",
        "# Decide all your hyperparameters based on validation performance\n",
        "# Then, switch to 'test' for final evaluation\n",
        "if test_set == 'val':\n",
        "    train_idxs, val_idxs = ..., ...   # Fill in\n",
        "    x_train, y_train = x_trainval[train_idxs], y_trainval[train_idxs]\n",
        "    x_eval, y_eval = x_trainval[val_idxs], y_trainval[val_idxs]\n",
        "else:\n",
        "    x_train, y_train = x_trainval, y_trainval\n",
        "    x_eval, y_eval = x_test, y_test"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6000, 28, 28)\n",
            "(6000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "pkuCgPatp59X"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.1.2: Model\n",
        "\n",
        "Define your model here (all hyper-parameters in 2.1.1)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "3qV3SuPAp6XF",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#\n",
        "#\n",
        "# ------- Your Code -------\n",
        "#\n",
        "#\n",
        "knn = KNeighborsClassifier()\n",
        "#train_scores, test_scores = sklearn.model_selection.validation_curve(\n",
        "#    knn, x_trainval_knn, y_trainval_knn, param_name=\"n_neighbors\", param_range=num_neighbors,\n",
        "#    cv=5, scoring=\"accuracy\", n_jobs=1)\n",
        "grid_search = sklearn.model_selection.GridSearchCV(knn, param_space, verbose=2, n_jobs=-1, cv=3, refit=True, return_train_score=True, scoring=\"accuracy\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_dmkX74JVmJg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2218
        },
        "outputId": "b582078e-3833-42a4-c920-fcb33819fb62"
      },
      "cell_type": "code",
      "source": [
        "grid_search.fit(x_trainval_knn, y_trainval_knn)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
            "[CV] n_neighbors=1, weights=uniform ..................................\n",
            "[CV] n_neighbors=1, weights=uniform ..................................\n",
            "[CV] ................... n_neighbors=1, weights=uniform, total=  24.4s\n",
            "[CV] n_neighbors=1, weights=uniform ..................................\n",
            "[CV] ................... n_neighbors=1, weights=uniform, total=  24.3s\n",
            "[CV] n_neighbors=1, weights=distance .................................\n",
            "[CV] ................... n_neighbors=1, weights=uniform, total=  24.7s\n",
            "[CV] n_neighbors=1, weights=distance .................................\n",
            "[CV] .................. n_neighbors=1, weights=distance, total=  24.9s\n",
            "[CV] n_neighbors=1, weights=distance .................................\n",
            "[CV] .................. n_neighbors=1, weights=distance, total=  24.7s\n",
            "[CV] n_neighbors=2, weights=uniform ..................................\n",
            "[CV] .................. n_neighbors=1, weights=distance, total=  24.7s\n",
            "[CV] n_neighbors=2, weights=uniform ..................................\n",
            "[CV] ................... n_neighbors=2, weights=uniform, total=  24.8s\n",
            "[CV] n_neighbors=2, weights=uniform ..................................\n",
            "[CV] ................... n_neighbors=2, weights=uniform, total=  25.0s\n",
            "[CV] n_neighbors=2, weights=distance .................................\n",
            "[CV] ................... n_neighbors=2, weights=uniform, total=  24.6s\n",
            "[CV] n_neighbors=2, weights=distance .................................\n",
            "[CV] .................. n_neighbors=2, weights=distance, total=  24.9s\n",
            "[CV] n_neighbors=2, weights=distance .................................\n",
            "[CV] .................. n_neighbors=2, weights=distance, total=  24.8s\n",
            "[CV] n_neighbors=3, weights=uniform ..................................\n",
            "[CV] .................. n_neighbors=2, weights=distance, total=  24.6s\n",
            "[CV] n_neighbors=3, weights=uniform ..................................\n",
            "[CV] ................... n_neighbors=3, weights=uniform, total=  24.9s\n",
            "[CV] n_neighbors=3, weights=uniform ..................................\n",
            "[CV] ................... n_neighbors=3, weights=uniform, total=  24.7s\n",
            "[CV] n_neighbors=3, weights=distance .................................\n",
            "[CV] .................. n_neighbors=3, weights=distance, total=  24.7s\n",
            "[CV] n_neighbors=3, weights=distance .................................\n",
            "[CV] ................... n_neighbors=3, weights=uniform, total=  24.8s\n",
            "[CV] n_neighbors=3, weights=distance .................................\n",
            "[CV] .................. n_neighbors=3, weights=distance, total=  24.6s\n",
            "[CV] n_neighbors=4, weights=uniform ..................................\n",
            "[CV] .................. n_neighbors=3, weights=distance, total=  24.8s\n",
            "[CV] n_neighbors=4, weights=uniform ..................................\n",
            "[CV] ................... n_neighbors=4, weights=uniform, total=  24.5s\n",
            "[CV] n_neighbors=4, weights=uniform ..................................\n",
            "[CV] ................... n_neighbors=4, weights=uniform, total=  24.1s\n",
            "[CV] n_neighbors=4, weights=distance .................................\n",
            "[CV] ................... n_neighbors=4, weights=uniform, total=  24.7s\n",
            "[CV] n_neighbors=4, weights=distance .................................\n",
            "[CV] .................. n_neighbors=4, weights=distance, total=  24.9s\n",
            "[CV] n_neighbors=4, weights=distance .................................\n",
            "[CV] .................. n_neighbors=4, weights=distance, total=  24.8s\n",
            "[CV] n_neighbors=5, weights=uniform ..................................\n",
            "[CV] .................. n_neighbors=4, weights=distance, total=  24.7s\n",
            "[CV] n_neighbors=5, weights=uniform ..................................\n",
            "[CV] ................... n_neighbors=5, weights=uniform, total=  24.8s\n",
            "[CV] n_neighbors=5, weights=uniform ..................................\n",
            "[CV] ................... n_neighbors=5, weights=uniform, total=  24.9s\n",
            "[CV] n_neighbors=5, weights=distance .................................\n",
            "[CV] ................... n_neighbors=5, weights=uniform, total=  24.4s\n",
            "[CV] n_neighbors=5, weights=distance .................................\n",
            "[CV] .................. n_neighbors=5, weights=distance, total=  24.5s\n",
            "[CV] n_neighbors=5, weights=distance .................................\n",
            "[CV] .................. n_neighbors=5, weights=distance, total=  24.7s\n",
            "[CV] n_neighbors=6, weights=uniform ..................................\n",
            "[CV] .................. n_neighbors=5, weights=distance, total=  24.7s\n",
            "[CV] n_neighbors=6, weights=uniform ..................................\n",
            "[CV] ................... n_neighbors=6, weights=uniform, total=  24.7s\n",
            "[CV] n_neighbors=6, weights=uniform ..................................\n",
            "[CV] ................... n_neighbors=6, weights=uniform, total=  24.8s\n",
            "[CV] n_neighbors=6, weights=distance .................................\n",
            "[CV] ................... n_neighbors=6, weights=uniform, total=  24.7s\n",
            "[CV] n_neighbors=6, weights=distance .................................\n",
            "[CV] .................. n_neighbors=6, weights=distance, total=  24.9s\n",
            "[CV] n_neighbors=6, weights=distance .................................\n",
            "[CV] .................. n_neighbors=6, weights=distance, total=  24.5s\n",
            "[CV] n_neighbors=7, weights=uniform ..................................\n",
            "[CV] .................. n_neighbors=6, weights=distance, total=  24.1s\n",
            "[CV] n_neighbors=7, weights=uniform ..................................\n",
            "[CV] ................... n_neighbors=7, weights=uniform, total=  24.5s\n",
            "[CV] n_neighbors=7, weights=uniform ..................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed: 22.2min\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................... n_neighbors=7, weights=uniform, total=  24.3s\n",
            "[CV] n_neighbors=7, weights=distance .................................\n",
            "[CV] ................... n_neighbors=7, weights=uniform, total=  25.2s\n",
            "[CV] n_neighbors=7, weights=distance .................................\n",
            "[CV] .................. n_neighbors=7, weights=distance, total=  25.1s\n",
            "[CV] n_neighbors=7, weights=distance .................................\n",
            "[CV] .................. n_neighbors=7, weights=distance, total=  25.2s\n",
            "[CV] n_neighbors=8, weights=uniform ..................................\n",
            "[CV] .................. n_neighbors=7, weights=distance, total=  25.3s\n",
            "[CV] n_neighbors=8, weights=uniform ..................................\n",
            "[CV] ................... n_neighbors=8, weights=uniform, total=  25.1s\n",
            "[CV] n_neighbors=8, weights=uniform ..................................\n",
            "[CV] ................... n_neighbors=8, weights=uniform, total=  25.0s\n",
            "[CV] n_neighbors=8, weights=distance .................................\n",
            "[CV] ................... n_neighbors=8, weights=uniform, total=  25.0s\n",
            "[CV] n_neighbors=8, weights=distance .................................\n",
            "[CV] .................. n_neighbors=8, weights=distance, total=  25.3s\n",
            "[CV] n_neighbors=8, weights=distance .................................\n",
            "[CV] .................. n_neighbors=8, weights=distance, total=  25.1s\n",
            "[CV] n_neighbors=9, weights=uniform ..................................\n",
            "[CV] .................. n_neighbors=8, weights=distance, total=  25.0s\n",
            "[CV] n_neighbors=9, weights=uniform ..................................\n",
            "[CV] ................... n_neighbors=9, weights=uniform, total=  25.2s\n",
            "[CV] n_neighbors=9, weights=uniform ..................................\n",
            "[CV] ................... n_neighbors=9, weights=uniform, total=  25.0s\n",
            "[CV] n_neighbors=9, weights=distance .................................\n",
            "[CV] ................... n_neighbors=9, weights=uniform, total=  25.2s\n",
            "[CV] n_neighbors=9, weights=distance .................................\n",
            "[CV] .................. n_neighbors=9, weights=distance, total=  24.9s\n",
            "[CV] n_neighbors=9, weights=distance .................................\n",
            "[CV] .................. n_neighbors=9, weights=distance, total=  25.3s\n",
            "[CV] n_neighbors=10, weights=uniform .................................\n",
            "[CV] .................. n_neighbors=9, weights=distance, total=  25.3s\n",
            "[CV] n_neighbors=10, weights=uniform .................................\n",
            "[CV] .................. n_neighbors=10, weights=uniform, total=  25.2s\n",
            "[CV] n_neighbors=10, weights=uniform .................................\n",
            "[CV] .................. n_neighbors=10, weights=uniform, total=  25.2s\n",
            "[CV] n_neighbors=10, weights=distance ................................\n",
            "[CV] .................. n_neighbors=10, weights=uniform, total=  25.1s\n",
            "[CV] n_neighbors=10, weights=distance ................................\n",
            "[CV] ................. n_neighbors=10, weights=distance, total=  25.2s\n",
            "[CV] n_neighbors=10, weights=distance ................................\n",
            "[CV] ................. n_neighbors=10, weights=distance, total=  25.3s\n",
            "[CV] ................. n_neighbors=10, weights=distance, total=  25.0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed: 36.0min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score='raise',\n",
              "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
              "           weights='uniform'),\n",
              "       fit_params=None, iid=True, n_jobs=-1,\n",
              "       param_grid={'n_neighbors': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]), 'weights': ['uniform', 'distance']},\n",
              "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
              "       scoring='accuracy', verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "_lHSriqhVmJr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(grid_search.cv_results_['params'][grid_search.best_index_])\n",
        "y_pred = grid_search.predict(x_test_knn)\n",
        "\n",
        "print(sklearn.metrics.accuracy_score(y_test_knn, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OzliNCGCVmJx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(grid_search.cv_results_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "70Uev6GOVmJ3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "list_ids_distance = []\n",
        "for i, x in enumerate(grid_search.cv_results_['params']):\n",
        "    if x['weights'] == 'distance':\n",
        "        list_ids_distance.append(i) \n",
        "    \n",
        "list_ids_uniform = []\n",
        "for i, x in enumerate(grid_search.cv_results_['params']):\n",
        "    if x['weights'] == 'uniform':\n",
        "        list_ids_uniform.append(i) \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sgxYETLrVmJ7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#train_scores_mean = grid_search.cv_results_['mean_train_score'][list_ids]\n",
        "#train_scores_std = grid_search.cv_results_['std_train_score'][list_ids]\n",
        "test_scores_dist_mean = grid_search.cv_results_['mean_test_score'][list_ids_distance]\n",
        "test_scores_dist_std = grid_search.cv_results_['std_test_score'][list_ids_distance]\n",
        "test_scores_unif_mean = grid_search.cv_results_['mean_test_score'][list_ids_uniform]\n",
        "test_scores_unif_std = grid_search.cv_results_['std_test_score'][list_ids_uniform]\n",
        "\n",
        "plt.title(\"Validation Curve with KNN\")\n",
        "plt.xlabel(\"n_neighbors (k)\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.xticks(num_neighbors)\n",
        "\n",
        "plt.plot(num_neighbors, test_scores_dist_mean, label=\"Cross-Validation score distance weighting\",\n",
        "             color=\"darkorange\")\n",
        "plt.fill_between(num_neighbors, test_scores_dist_mean - test_scores_dist_std,\n",
        "                 test_scores_dist_mean + test_scores_dist_std, alpha=0.2,\n",
        "                 color=\"darkorange\")\n",
        "plt.plot(num_neighbors, test_scores_unif_mean, label=\"Cross-validation score uniform weighting\",\n",
        "             color=\"navy\")\n",
        "plt.fill_between(num_neighbors, test_scores_unif_mean - test_scores_unif_std,\n",
        "                 test_scores_unif_mean + test_scores_unif_std, alpha=0.2,\n",
        "                 color=\"navy\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5aSOFw9hVmKB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "knn_10 = KNeighborsClassifier(n_neighbors=4, weights=\"distance\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "SxE6d6OXp6sU"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.1.3: Fit Model\n",
        "\n",
        "Define optimization procedure and fit your model to the data"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "08tLwuchp68-",
        "colab": {},
        "outputId": "147ed789-a18f-4455-f36b-611910c74aef"
      },
      "cell_type": "code",
      "source": [
        "knn_10.fit(x_trainval_knn, y_trainval_knn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "           metric_params=None, n_jobs=None, n_neighbors=4, p=2,\n",
              "           weights='distance')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "metadata": {
        "id": "sV3b1xRPVmKa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred = knn_10.predict(x_trainval_knn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NTSAI7GEVmKf",
        "colab_type": "code",
        "colab": {},
        "outputId": "ca281c31-b74f-4ae0-bab6-76583d28ca78"
      },
      "cell_type": "code",
      "source": [
        "sklearn.metrics.accuracy_score(y_trainval_knn, y_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "QaJv_d_Dp7OM"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.1.4: Evaluation\n",
        "\n",
        "Evaluate your model.\n",
        "\n",
        "When possible, you should have:\n",
        "  * Loss curves: Plot epoch (# passes over training data) and loss\n",
        "  * Accuracy curves: Plot epoch and accuracy over val/test set\n",
        "  * Final numbers: Report final accuracy numbers for your model"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "kZtLgPZrp7h5",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#\n",
        "#\n",
        "# ------- Your Code -------\n",
        "#\n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "DEQrdyLHsUIu"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.1.5: Summary\n",
        "\n",
        "Summarize your findings:\n",
        " * Which hyper-parameters were important and how did they influence your results?\n",
        " * What were other design choices you faced?\n",
        " * Any other interesting insights..."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Fcq52WUUs2Mm"
      },
      "cell_type": "markdown",
      "source": [
        "# 2.2: Model [M2]: *fill-this-in*\n",
        "\n",
        "*use the same format as above. Repeat Sections 2.1.1 -- 2.1.5*\n",
        "\n",
        "# 2.3: Model [M3]: *fill-this-in*\n",
        "\n",
        "*use the same format as above. Repeat Sections 2.1.1 -- 2.1.5*"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Ex3qQp3JolD1"
      },
      "cell_type": "markdown",
      "source": [
        "# 3. Summary\n",
        "\n",
        "Enter your final summary here.\n",
        "\n",
        "You should now compare performance  on the three models [M1], [M2] and [M3]. Present this in a tabular format and/or using plots.\n",
        "\n",
        "Which model do you recommend to perform digit classification and why?\n",
        "\n",
        "Feel free to discuss other insightful observations."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "pa6rPT53LUW8",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}