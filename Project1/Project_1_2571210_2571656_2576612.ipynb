{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4NzyqehHjUlG"
   },
   "source": [
    "# ML in Cybersecurity: Project I\n",
    "\n",
    "## Team\n",
    "  * **Team name**:  *The Overestimators*\n",
    "  * **Members**:  *Anilkumar Erappanakoppal Swamy (2571210) (s8anerap@stud.uni-saarland.de) , Ayan Majumdar (2571656) (s8aymaju@stud.uni-saarland.de), Sravani Pasam (2576612) (s8srpasa@stud.uni-saarland.de)*\n",
    "  * **Tutor**: *Kathrine Grosse (kathrin.grosse@cispa.saarland)*\n",
    "\n",
    "\n",
    "## About this Project\n",
    "In this project, you'll implement a digit classifier, based on the popular [MNIST](http://yann.lecun.com/exdb/mnist/) dataset. The dataset is based on a seminal [paper](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf), which immensely popularized (convolutional) neural networks. This is a great starting point for ML research and this dataset/model has been a stepping stone numerous other tasks such as [GANs](https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf), [Adversarial Perturbations](https://arxiv.org/abs/1412.6572) and so many more!\n",
    "\n",
    "This dataset consists of data $\\mathcal{D} = \\{x_i, y_i\\}_{i=1}^N$, where $x_i$ is a 28x28 pixel grayscale image and $y_i$ is a scalar represeting digits between 0-9. The notebook will guide you to load this data, implement classifiers $\\hat{y_i} = f_w(x_i)$  and analyze results. By doing so, you'll have a ML model that works on real data!\n",
    "\n",
    "To put things into context, have a look at Slide 24 in the [second](https://cms.cispa.saarland/mlcysec/dl/2/2018-10-24_ML_overview.pdf) lecture. Within this framework, the following blocks of this project are fixed:\n",
    "  * *Real-world problem*: Digit classification\n",
    "  * *Performance metric*: Mean accuracy i.e., $ \\frac{1}{N} \\sum_{i=1}^N \\mathbb{1}[\\hat{y_i} = y_i]$, where $\\mathbb{1}[\\hat{y_i} = y_i]$ is 1 if your model predicted the right digit for the $i$-th digit and 0 otherwise.\n",
    "  * *Data*: The MNIST dataset\n",
    "\n",
    "You'll make the the following design-choices:\n",
    " * *Choice of Model*: A model family (Non-parametric methods, Linear classifiers, Neural Networks, etc.)\n",
    " * *ML Model*: Specific model (e.g., SVM with a polynomial kernel)\n",
    " * *Loss/Risk*\n",
    " * *Optimization*\n",
    "\n",
    " \n",
    " ## Versions\n",
    "  * v1.1: Added Code of Honor\n",
    "  * v1.0: Initial notebook\n",
    "  \n",
    "  ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3ewNwfFvbFaR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    " \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import json \n",
    "import time \n",
    "import pickle \n",
    "import sys \n",
    "import csv \n",
    "import os \n",
    "import os.path as osp \n",
    "import shutil \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display, HTML\n",
    " \n",
    "%matplotlib inline \n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots \n",
    "plt.rcParams['image.interpolation'] = 'nearest' \n",
    "plt.rcParams['image.cmap'] = 'gray' \n",
    " \n",
    "# for auto-reloading external modules \n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "640GrzbOevr0",
    "outputId": "9146915c-49ca-4b32-cd94-34b9cf1edcb4"
   },
   "outputs": [],
   "source": [
    "# Load other libraries here.\n",
    "# Keep it minimal! We should be easily able to reproduce your code.\n",
    "\n",
    "# In case you want to use neural networks, we only support sklearn and keras (With a tensorflow backend).\n",
    "\n",
    "import inspect\n",
    "from random import randint\n",
    "import sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import sklearn.model_selection\n",
    "from sklearn import preprocessing\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nxi-lLD0mKHD"
   },
   "source": [
    "Helpers\n",
    "\n",
    "In case you choose to have some methods you plan to reuse during the notebook, define them here. This will avoid clutter and keep rest of the notebook succinct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VBbigqdEmKd8"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "grid_search_results: dict of results.\n",
    "param_name1: Fix this value to param_name1_val.\n",
    "param_name2: Will plot this param with respect to param_name2_space.\n",
    "'''\n",
    "def plot_validation_data(grid_search_results, param_name1, param_name2, param_name1_val, param_name2_space, plt_title=\"Plot_Title\",plt_xlab=\"x_label\",plt_ylab=\"y_label\",color=\"darkblue\",label=\"Label_Plot\"):\n",
    "\n",
    "    list_ids_param2 = []\n",
    "    for i, x in enumerate(grid_search_results['params']):\n",
    "        if x[param_name1] == param_name1_val:\n",
    "            list_ids_param2.append(i)         \n",
    "\n",
    "    test_scores_mean = grid_search_results['mean_test_score'][list_ids_param2]\n",
    "    test_scores_std = grid_search_results['std_test_score'][list_ids_param2]\n",
    "\n",
    "    plt.title(plt_title)\n",
    "    plt.xlabel(plt_xlab)\n",
    "    plt.ylabel(plt_ylab)\n",
    "    \n",
    "    plt.plot(param_name2_space, test_scores_mean,'o-', label=label,\n",
    "             color=color)\n",
    "    plt.fill_between(param_name2_space, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=color)\n",
    "    \n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "    \n",
    "def display_classification_results(y_test, y_pred,title=\"Heatmap\"):\n",
    "    print(\"Test accuracy: %.2f%%\"%(sklearn.metrics.accuracy_score(y_test, y_pred)*100))\n",
    "    print(\"Classification Report:\\n\",sklearn.metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "    conf_mat = sklearn.metrics.confusion_matrix(y_test,y_pred)\n",
    "    print(\"Confidence Matrix:\\n\",conf_mat)\n",
    "    ax = sns.heatmap(conf_mat);\n",
    "    ax.set(title=title, xlabel=\"Digits\", ylabel=\"Digits\");\n",
    "    \n",
    "def LoadData_PreProcess():\n",
    "    # load the MNIST dataset using keras high-level functions\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "    # plot 6 images as gray scale from the dataset  \n",
    "    plt.subplot(231)\n",
    "    plt.imshow(X_train[np.random.randint(low=0, high = 50)], cmap=plt.get_cmap('gray'))\n",
    "    plt.subplot(232)\n",
    "    plt.imshow(X_train[np.random.randint(low=0, high = 50)], cmap=plt.get_cmap('gray'))\n",
    "    plt.subplot(233)\n",
    "    plt.imshow(X_train[np.random.randint(low=0, high = 50)], cmap=plt.get_cmap('gray'))\n",
    "    plt.subplot(234)\n",
    "    plt.imshow(X_train[np.random.randint(low=0, high = 50)], cmap=plt.get_cmap('gray'))\n",
    "    plt.subplot(235)\n",
    "    plt.imshow(X_train[np.random.randint(low=0, high = 50)], cmap=plt.get_cmap('gray'))\n",
    "    plt.subplot(236)\n",
    "    plt.imshow(X_train[np.random.randint(low=0, high = 50)], cmap=plt.get_cmap('gray'))\n",
    "    # show the plot\n",
    "    #   plt.show()\n",
    "\n",
    "\n",
    "    # PrePorcessing\n",
    "    # reshape to be [samples][pixels][width][height]\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')\n",
    "\n",
    "    print(X_train.shape)\n",
    "\n",
    "    # Normalize the pixel values from range 0-255 to 0-1\n",
    "    X_train = X_train / 255\n",
    "    X_test = X_test / 255\n",
    "\n",
    "\n",
    "    # Output value ranges from 0-9, encode them into one hot vector\n",
    "    y_train = np_utils.to_categorical(y_train)\n",
    "    y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n1pcmKkyjT7y"
   },
   "source": [
    "# 1. Loading and Visualizing data\n",
    "\n",
    "In this section, you'll need to prepare the MNIST data for the experiments you'll be conducting for the remainder of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AIU9Q762fmoT"
   },
   "source": [
    "## 1.1. Load Data\n",
    "\n",
    "Here you'll load the MNIST data into memory. The end-goal is to two have the following variables:\n",
    "  * `x_trainval`, `x_test`: of shape $N \\times d_1 \\times d_2 \\dots$ (e.g., $N \\times 784$. 784 since you could flatten each 28x28 pixel image into a single vector)\n",
    "  * `y_trainval`, `y_test`: of shape $N \\times K$ (K = 1 or 10 depending on how you plan to represent the ground-truth digit annotation)\n",
    "\n",
    "You can either do this by:\n",
    "  1. Downloading the MNIST dataset, unpacking and preparing it yourself to have fine-grained control\n",
    "  1. Using high-level existing functions, such as the one provided by  [`keras.datasets`](https://keras.io/datasets/#mnist-database-of-handwritten-digits).\n",
    "  \n",
    "  \n",
    "  In either case, it is important that you have disjoint trainval and test splits!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HYrB9ADA8vT0"
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 21\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k52VgrWzVmIk",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(x_trainval, y_trainval), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "7kYacpo_jvao",
    "outputId": "0161d440-ac41-4234-86fc-d6720e5479b7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_trainval.shape = (60000, 28, 28),  y_trainval.shape = (60000,)\n",
      "x_test.shape = (10000, 28, 28),  y_test.shape = (10000,)\n",
      "(60000, 28, 28) (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#\n",
    "# ------- Your Code -------\n",
    "#\n",
    "#\n",
    "\n",
    "print('x_trainval.shape = {},  y_trainval.shape = {}'.format(x_trainval.shape, y_trainval.shape))\n",
    "print('x_test.shape = {},  y_test.shape = {}'.format(x_test.shape, y_test.shape))\n",
    "\n",
    "#\n",
    "# Feel free to have multiple variables in case your models are designed for different formats\n",
    "# For instance, in case your model requires Nx28x28 inputs, declare x_trainval_3d, etc.\n",
    "\n",
    "# Tip: Set this to a tiny number (such 0.05) to aid debugging\n",
    "# After all, you do not want to train/evaluate on the entire dataset to find bugs\n",
    "DEBUG_FRAC = 1.0\n",
    "# Resample x_[], y_[]\n",
    "x = np.concatenate((x_trainval, x_test))\n",
    "#print(x.shape)\n",
    "y = np.concatenate((y_trainval, y_test))\n",
    "#print(y.shape)\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=int(DEBUG_FRAC * x_test.shape[0]), train_size=int(DEBUG_FRAC * x_trainval.shape[0]), random_state=42)\n",
    "idx = sss.split(x,y)\n",
    "for train_idx, test_idx in idx:\n",
    "    x_trainval, y_trainval = x[train_idx], y[train_idx]\n",
    "    x_test, y_test = x[test_idx], y[test_idx]\n",
    "\n",
    "print(x_trainval.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "GCXCh8Ic8vUA",
    "outputId": "2cb8005f-a759-4518-cd72-c8862da5de98"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\cysecml\\lib\\site-packages\\sklearn\\utils\\validation.py:590: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "D:\\Anaconda3\\envs\\cysecml\\lib\\site-packages\\sklearn\\utils\\validation.py:590: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "D:\\Anaconda3\\envs\\cysecml\\lib\\site-packages\\sklearn\\utils\\validation.py:590: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced: (60000, 332)\n",
      "Input dimension: (60000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Scaling and Normalization\n",
    "\n",
    "# Performing this for SVD\n",
    "scaler = preprocessing.StandardScaler().fit(x_trainval.reshape(x_trainval.shape[0],-1))\n",
    "x_trainval_scaled = scaler.transform(x_trainval.reshape(x_trainval.shape[0],-1))\n",
    "x_test_scaled = scaler.transform(x_test.reshape(x_test.shape[0],-1))\n",
    "\n",
    "# Do PCA\n",
    "pca = PCA(0.95)\n",
    "pca.fit(x_trainval_scaled)\n",
    "\n",
    "x_trainval_red = pca.transform(x_trainval_scaled)\n",
    "x_test_red = pca.transform(x_test_scaled)\n",
    "\n",
    "print(\"Reduced:\",x_trainval_red.shape)\n",
    "\n",
    "# Performing this normalization for MLP as this gave better results.\n",
    "x_trainval_nn = x_trainval.reshape(x_trainval.shape[0],-1)\n",
    "x_test_nn = x_test.reshape(x_test.shape[0],-1)\n",
    "\n",
    "# Make sure all values are between 0 and 1\n",
    "x_trainval_nn = x_trainval_nn / 255.0\n",
    "x_test_nn = x_test_nn / 255.0\n",
    "\n",
    "print(\"Input dimension:\", x_trainval_nn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "gO9Hg3rJ8vUE",
    "outputId": "16ddab5e-6554-4c6f-d8e2-102615c1b7a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_train Shape: (60000, 10)\n",
      "Num Classes: 10\n",
      "Input Dimension: 784\n"
     ]
    }
   ],
   "source": [
    "# one hot encode outputs\n",
    "# This format is necessary for Keras multiclass classification.\n",
    "\n",
    "y_trainval_nn = np_utils.to_categorical(y_trainval)\n",
    "num_classes = y_trainval_nn.shape[1]\n",
    "\n",
    "print(\"Y_train Shape:\",y_trainval_nn.shape)\n",
    "\n",
    "print(\"Num Classes:\", num_classes)\n",
    "INPUT_DIMENSION = x_trainval_nn.shape[1]\n",
    "print(\"Input Dimension:\", INPUT_DIMENSION)\n",
    "\n",
    "y_test_nn = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eA6_cejNjzYw"
   },
   "source": [
    "## 1.2. Visualize Data\n",
    "\n",
    "To get the hang of your data you'll be training a digit classifier on, visualize it.\n",
    "\n",
    "Examples of ways to visualize it:\n",
    "  * Given a digit, display few randomly sampled images for this digit (the bare minimum)\n",
    "  * Visualize as a grid (e.g., Slide 7, [Lecture 2](https://cms.cispa.saarland/mlcysec/dl/2/2018-10-24_ML_overview.pdf)) using a combination of `plt.imshow` and `plt.subplots`\n",
    "  \n",
    "It's up to you to decide how you want to do this. The end-goal is for you to potentially give a trailer of the dataset to someone who hasn't seen it before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 546
    },
    "colab_type": "code",
    "id": "JuqXUnB28vUJ",
    "outputId": "4792e099-29ed-4363-8deb-df2d194ad07e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution of the data\n",
    "ax = sns.countplot(y_trainval);\n",
    "ax.set(title=\"Distribution of the Labels\", xlabel=\"Digit Label\", ylabel=\"Count\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "colab_type": "code",
    "id": "KYcqQH7TJmXI",
    "outputId": "e1d0394a-4f8e-4690-e133-08ea0a46d72a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1, 28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAAFHCAYAAADgNUZ2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7effb68f5eb8>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data utilities and training images display\n",
    "X_train, y_train, X_test, y_test = LoadData_PreProcess()\n",
    "n_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b8sAT53jmJ8_"
   },
   "source": [
    "# 2. Digit classifiers\n",
    "\n",
    "In this section, you'll begin developing models to perform digit classification.\n",
    "\n",
    "Each model needs to be structured like so:\n",
    "  1. Give a brief reason which model you are going to train and why you choose it\n",
    "  1. Define hyper-parameters for model and optimization procedure\n",
    "  1. Define your model\n",
    "  1. Define optimization method and fit model to data\n",
    "  1. Summarize your findings\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xkF-7eFnpWoe"
   },
   "source": [
    "## 2.1: Model [M1]: *SVM Classifier*\n",
    "\n",
    "#### Short description : *We use an SVM Classifier with polynomial kernel to perform the multiclass classification task. We use scikit-learn grid search cross validation to perform hyperparameter selection of the hyperparameters C and gamma of SVM classifier (SVC). We feed the SVM Classifier a reduced dimensionality form of the original input after having the input properly centered and scaled and applying PCA with 95% variance of the data retained.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lVyT9Oddp3GB"
   },
   "source": [
    "### 2.1.1: Hyper-parameters\n",
    "\n",
    "Define hyper-parameters for your method here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "eIq8Zr-Eos6Q",
    "outputId": "9d893ba2-02aa-4c30-ab39-4eb5d84f698c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05, 0.1, 0.5, 1] [0.005, 0.01, 0.05, 0.1]\n",
      "(60000, 28, 28)\n",
      "(60000, 332)\n"
     ]
    }
   ],
   "source": [
    "c_space = [0.05, 0.1, 0.5, 1]\n",
    "gamma_space = [0.005, 0.01, 0.05, 0.1]\n",
    "kernels = [\"poly\"]\n",
    "param_space = {\"C\":c_space, \"gamma\":gamma_space, \"kernel\":kernels}\n",
    "print(c_space, gamma_space)\n",
    "\n",
    "print(x_trainval.shape)\n",
    "#x_trainval_knn = x_trainval.reshape(x_trainval.shape[0],-1)\n",
    "#x_trainval_svc = x_trainval.reshape(x_trainval.shape[0],-1)\n",
    "x_trainval_svc = x_trainval_red\n",
    "print(x_trainval_svc.shape)\n",
    "y_trainval_svc = y_trainval\n",
    "x_test_svc = x_test_red\n",
    "y_test_svc = y_test\n",
    "\n",
    "test_set = 'val'  #  or 'test'\n",
    "# Decide all your hyperparameters based on validation performance\n",
    "# Then, switch to 'test' for final evaluation\n",
    "if test_set == 'val':\n",
    "    train_idxs, val_idxs = ..., ...   # Fill in\n",
    "    x_train, y_train = x_trainval[train_idxs], y_trainval[train_idxs]\n",
    "    x_eval, y_eval = x_trainval[val_idxs], y_trainval[val_idxs]\n",
    "else:\n",
    "    x_train, y_train = x_trainval, y_trainval\n",
    "    x_eval, y_eval = x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pkuCgPatp59X"
   },
   "source": [
    "### 2.1.2: Model\n",
    "\n",
    "Define your model here (all hyper-parameters in 2.1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TGxwd1-ZoyAB"
   },
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "\n",
    "grid_search = sklearn.model_selection.GridSearchCV(svc, param_space, verbose=2, cv=2, refit=True, return_train_score=True, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SxE6d6OXp6sU"
   },
   "source": [
    "### 2.1.3: Fit Model\n",
    "\n",
    "Define optimization procedure and fit your model to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "024Chkuzo01B",
    "outputId": "30fdc749-c5b3-47cd-aad4-ed567a73f547",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 16 candidates, totalling 32 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] C=0.05, gamma=0.005, kernel=poly ................................\n",
      "[CV] ................. C=0.05, gamma=0.005, kernel=poly, total= 6.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 10.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] C=0.05, gamma=0.005, kernel=poly ................................\n",
      "[CV] ................. C=0.05, gamma=0.005, kernel=poly, total= 6.8min\n",
      "[CV] C=0.05, gamma=0.01, kernel=poly .................................\n",
      "[CV] .................. C=0.05, gamma=0.01, kernel=poly, total= 4.8min\n",
      "[CV] C=0.05, gamma=0.01, kernel=poly .................................\n",
      "[CV] .................. C=0.05, gamma=0.01, kernel=poly, total= 4.9min\n",
      "[CV] C=0.05, gamma=0.05, kernel=poly .................................\n",
      "[CV] .................. C=0.05, gamma=0.05, kernel=poly, total= 4.7min\n",
      "[CV] C=0.05, gamma=0.05, kernel=poly .................................\n",
      "[CV] .................. C=0.05, gamma=0.05, kernel=poly, total= 4.3min\n",
      "[CV] C=0.05, gamma=0.1, kernel=poly ..................................\n",
      "[CV] ................... C=0.05, gamma=0.1, kernel=poly, total= 4.3min\n",
      "[CV] C=0.05, gamma=0.1, kernel=poly ..................................\n",
      "[CV] ................... C=0.05, gamma=0.1, kernel=poly, total= 4.6min\n",
      "[CV] C=0.1, gamma=0.005, kernel=poly .................................\n",
      "[CV] .................. C=0.1, gamma=0.005, kernel=poly, total= 4.4min\n",
      "[CV] C=0.1, gamma=0.005, kernel=poly .................................\n",
      "[CV] .................. C=0.1, gamma=0.005, kernel=poly, total= 4.4min\n",
      "[CV] C=0.1, gamma=0.01, kernel=poly ..................................\n",
      "[CV] ................... C=0.1, gamma=0.01, kernel=poly, total= 3.4min\n",
      "[CV] C=0.1, gamma=0.01, kernel=poly ..................................\n",
      "[CV] ................... C=0.1, gamma=0.01, kernel=poly, total= 3.4min\n",
      "[CV] C=0.1, gamma=0.05, kernel=poly ..................................\n",
      "[CV] ................... C=0.1, gamma=0.05, kernel=poly, total= 3.3min\n",
      "[CV] C=0.1, gamma=0.05, kernel=poly ..................................\n",
      "[CV] ................... C=0.1, gamma=0.05, kernel=poly, total= 3.4min\n",
      "[CV] C=0.1, gamma=0.1, kernel=poly ...................................\n",
      "[CV] .................... C=0.1, gamma=0.1, kernel=poly, total= 3.4min\n",
      "[CV] C=0.1, gamma=0.1, kernel=poly ...................................\n",
      "[CV] .................... C=0.1, gamma=0.1, kernel=poly, total= 3.4min\n",
      "[CV] C=0.5, gamma=0.005, kernel=poly .................................\n",
      "[CV] .................. C=0.5, gamma=0.005, kernel=poly, total= 3.4min\n",
      "[CV] C=0.5, gamma=0.005, kernel=poly .................................\n",
      "[CV] .................. C=0.5, gamma=0.005, kernel=poly, total= 3.5min\n",
      "[CV] C=0.5, gamma=0.01, kernel=poly ..................................\n",
      "[CV] ................... C=0.5, gamma=0.01, kernel=poly, total= 3.4min\n",
      "[CV] C=0.5, gamma=0.01, kernel=poly ..................................\n",
      "[CV] ................... C=0.5, gamma=0.01, kernel=poly, total= 3.4min\n",
      "[CV] C=0.5, gamma=0.05, kernel=poly ..................................\n",
      "[CV] ................... C=0.5, gamma=0.05, kernel=poly, total= 3.4min\n",
      "[CV] C=0.5, gamma=0.05, kernel=poly ..................................\n",
      "[CV] ................... C=0.5, gamma=0.05, kernel=poly, total= 3.7min\n",
      "[CV] C=0.5, gamma=0.1, kernel=poly ...................................\n",
      "[CV] .................... C=0.5, gamma=0.1, kernel=poly, total= 3.6min\n",
      "[CV] C=0.5, gamma=0.1, kernel=poly ...................................\n",
      "[CV] .................... C=0.5, gamma=0.1, kernel=poly, total= 3.4min\n",
      "[CV] C=1, gamma=0.005, kernel=poly ...................................\n",
      "[CV] .................... C=1, gamma=0.005, kernel=poly, total= 3.6min\n",
      "[CV] C=1, gamma=0.005, kernel=poly ...................................\n",
      "[CV] .................... C=1, gamma=0.005, kernel=poly, total= 3.5min\n",
      "[CV] C=1, gamma=0.01, kernel=poly ....................................\n",
      "[CV] ..................... C=1, gamma=0.01, kernel=poly, total= 3.5min\n",
      "[CV] C=1, gamma=0.01, kernel=poly ....................................\n",
      "[CV] ..................... C=1, gamma=0.01, kernel=poly, total= 3.5min\n",
      "[CV] C=1, gamma=0.05, kernel=poly ....................................\n",
      "[CV] ..................... C=1, gamma=0.05, kernel=poly, total= 3.4min\n",
      "[CV] C=1, gamma=0.05, kernel=poly ....................................\n",
      "[CV] ..................... C=1, gamma=0.05, kernel=poly, total= 3.5min\n",
      "[CV] C=1, gamma=0.1, kernel=poly .....................................\n",
      "[CV] ...................... C=1, gamma=0.1, kernel=poly, total= 3.5min\n",
      "[CV] C=1, gamma=0.1, kernel=poly .....................................\n",
      "[CV] ...................... C=1, gamma=0.1, kernel=poly, total= 3.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed: 188.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [0.05, 0.1, 0.5, 1], 'gamma': [0.005, 0.01, 0.05, 0.1], 'kernel': ['poly']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(x_trainval_svc, y_trainval_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wMuS9JsI8vUo",
    "outputId": "f050cca0-232c-4e7c-aa59-f92f3be06299"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score after grid-search: 97.45% with the parameters: {'C': 0.1, 'gamma': 0.01, 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score after grid-search: %.2f%%\"%(grid_search.best_score_*100),\"with the parameters:\",grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([222.46703804, 146.5151571 , 133.56821263, 130.8939172 ,\n",
      "       134.43543875, 100.78715992,  99.19891131, 100.10641038,\n",
      "       103.38574457, 100.75113034, 105.91390169, 104.29768813,\n",
      "       104.26565921, 102.50301707, 102.30952096, 102.27712226]), 'std_fit_time': array([8.03081548, 0.35409606, 6.33647549, 3.67586768, 1.54967368,\n",
      "       0.3984921 , 0.21648252, 0.52860415, 0.19549632, 0.50312042,\n",
      "       4.9378022 , 2.14077675, 0.32275212, 0.30618179, 0.41188025,\n",
      "       0.08626938]), 'mean_score_time': array([184.98009515, 143.93911028, 135.5314008 , 136.55785298,\n",
      "       128.02474499, 101.61185455, 102.53985322, 102.85853124,\n",
      "       102.8784796 , 102.84359396, 105.36232185, 106.17170942,\n",
      "       107.75942969, 105.28554511, 105.15341449, 105.15589154]), 'std_score_time': array([7.20923114, 0.64839196, 5.06092846, 4.71479893, 0.40490031,\n",
      "       0.45725727, 0.73603141, 0.11618876, 1.57927787, 0.02046597,\n",
      "       2.96505547, 1.53639257, 3.2468214 , 0.47273707, 0.24686098,\n",
      "       0.23736537]), 'param_C': masked_array(data=[0.05, 0.05, 0.05, 0.05, 0.1, 0.1, 0.1, 0.1, 0.5, 0.5,\n",
      "                   0.5, 0.5, 1, 1, 1, 1],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_gamma': masked_array(data=[0.005, 0.01, 0.05, 0.1, 0.005, 0.01, 0.05, 0.1, 0.005,\n",
      "                   0.01, 0.05, 0.1, 0.005, 0.01, 0.05, 0.1],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_kernel': masked_array(data=['poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
      "                   'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
      "                   'poly', 'poly'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'C': 0.05, 'gamma': 0.005, 'kernel': 'poly'}, {'C': 0.05, 'gamma': 0.01, 'kernel': 'poly'}, {'C': 0.05, 'gamma': 0.05, 'kernel': 'poly'}, {'C': 0.05, 'gamma': 0.1, 'kernel': 'poly'}, {'C': 0.1, 'gamma': 0.005, 'kernel': 'poly'}, {'C': 0.1, 'gamma': 0.01, 'kernel': 'poly'}, {'C': 0.1, 'gamma': 0.05, 'kernel': 'poly'}, {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}, {'C': 0.5, 'gamma': 0.005, 'kernel': 'poly'}, {'C': 0.5, 'gamma': 0.01, 'kernel': 'poly'}, {'C': 0.5, 'gamma': 0.05, 'kernel': 'poly'}, {'C': 0.5, 'gamma': 0.1, 'kernel': 'poly'}, {'C': 1, 'gamma': 0.005, 'kernel': 'poly'}, {'C': 1, 'gamma': 0.01, 'kernel': 'poly'}, {'C': 1, 'gamma': 0.05, 'kernel': 'poly'}, {'C': 1, 'gamma': 0.1, 'kernel': 'poly'}], 'split0_test_score': array([0.96043729, 0.97363597, 0.97456921, 0.97456921, 0.96720328,\n",
      "       0.9746692 , 0.97456921, 0.97456921, 0.9740026 , 0.97480252,\n",
      "       0.97456921, 0.97456921, 0.97443589, 0.97460254, 0.97456921,\n",
      "       0.97456921]), 'split1_test_score': array([0.96086275, 0.97349735, 0.97396406, 0.97396406, 0.96766343,\n",
      "       0.97423076, 0.97396406, 0.97396406, 0.97376404, 0.97393073,\n",
      "       0.97396406, 0.97396406, 0.97426409, 0.97396406, 0.97396406,\n",
      "       0.97396406]), 'mean_test_score': array([0.96065   , 0.97356667, 0.97426667, 0.97426667, 0.96743333,\n",
      "       0.97445   , 0.97426667, 0.97426667, 0.97388333, 0.97436667,\n",
      "       0.97426667, 0.97426667, 0.97435   , 0.97428333, 0.97426667,\n",
      "       0.97426667]), 'std_test_score': array([2.12731668e-04, 6.93100003e-05, 3.02573335e-04, 3.02573335e-04,\n",
      "       2.30076668e-04, 2.19221668e-04, 3.02573335e-04, 3.02573335e-04,\n",
      "       1.19278334e-04, 4.35896669e-04, 3.02573335e-04, 3.02573335e-04,\n",
      "       8.58983338e-05, 3.19238335e-04, 3.02573335e-04, 3.02573335e-04]), 'rank_test_score': array([16, 14,  5,  5, 15,  1,  5,  5, 13,  2,  5,  5,  3,  4,  5,  5]), 'split0_train_score': array([0.98179818, 0.99783312, 1.        , 1.        , 0.98986565,\n",
      "       0.99926659, 1.        , 1.        , 0.99846651, 0.99996666,\n",
      "       1.        , 1.        , 0.99953329, 1.        , 1.        ,\n",
      "       1.        ]), 'split1_train_score': array([0.98163517, 0.99796687, 1.        , 1.        , 0.99010099,\n",
      "       0.9993334 , 1.        , 1.        , 0.9986668 , 1.        ,\n",
      "       1.        , 1.        , 0.99950005, 1.        , 1.        ,\n",
      "       1.        ]), 'mean_train_score': array([0.98171667, 0.99789999, 1.        , 1.        , 0.98998332,\n",
      "       0.9993    , 1.        , 1.        , 0.99856666, 0.99998333,\n",
      "       1.        , 1.        , 0.99951667, 1.        , 1.        ,\n",
      "       1.        ]), 'std_train_score': array([8.15050008e-05, 6.68766673e-05, 0.00000000e+00, 0.00000000e+00,\n",
      "       1.17668335e-04, 3.34033337e-05, 0.00000000e+00, 0.00000000e+00,\n",
      "       1.00143334e-04, 1.66683335e-05, 0.00000000e+00, 0.00000000e+00,\n",
      "       1.66183335e-05, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00])}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.cv_results_)\n",
    "\n",
    "sys.setrecursionlimit(300000)\n",
    "with open('svm_grid_search_cv_results.pickle', 'wb') as handle:\n",
    "    pickle.dump(grid_search.cv_results_, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zrn30ybf8vUr"
   },
   "source": [
    "### We fit model with best CV parameters on (train+val) and use that to test on test-data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uJFeb6kV8vUt",
    "outputId": "62740f27-4e19-43b0-ab88-d57e69a77563"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='poly',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(C=0.1, gamma=0.01, kernel=\"poly\")\n",
    "svc.fit(x_trainval_svc, y_trainval_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QaJv_d_Dp7OM"
   },
   "source": [
    "### 2.1.4: Evaluation\n",
    "\n",
    "Evaluate your model.\n",
    "\n",
    "When possible, you should have:\n",
    "  * Loss curves: Plot epoch (# passes over training data) and loss\n",
    "  * Accuracy curves: Plot epoch and accuracy over val/test set\n",
    "  * Final numbers: Report final accuracy numbers for your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Td47Eqnx8vUz"
   },
   "source": [
    "### Showing effect of some hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LT2aaSnY8vU0",
    "outputId": "75b5903e-44e3-428b-9c44-abf8de530929",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_validation_data(grid_search.cv_results_,\"gamma\",\"C\",grid_search.best_params_['gamma'],c_space,\"Validation Curve with SVM varying C\",\\\n",
    "                     \"C\",\"Score\",\"darkorange\",\"Cross-Validation score C variation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GEYl0K808vU3",
    "outputId": "9a0d7d9b-5c68-45c5-92c9-f11fb48ad365"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_validation_data(grid_search.cv_results_,\"C\",\"gamma\",grid_search.best_params_['C'],c_space,\"Validation Curve with SVM varying gamma\",\\\n",
    "                     \"gamma\",\"Score\",\"darkblue\",\"Cross-Validation score gamma variation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xVrHGCUt8vU7"
   },
   "source": [
    "### Use the model fitted on (train+val) to predict on test and show results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ahMmOSu8vU8"
   },
   "outputs": [],
   "source": [
    "y_pred = svc.predict(x_test_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lzyXsSss8vU_",
    "outputId": "24ad76d2-7c65-40e4-d694-a22f277dad69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 98.02%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       986\n",
      "           1       0.99      0.99      0.99      1125\n",
      "           2       0.98      0.98      0.98       999\n",
      "           3       0.97      0.97      0.97      1020\n",
      "           4       0.98      0.98      0.98       975\n",
      "           5       0.97      0.98      0.98       902\n",
      "           6       0.99      0.99      0.99       982\n",
      "           7       0.98      0.98      0.98      1042\n",
      "           8       0.98      0.97      0.97       975\n",
      "           9       0.97      0.97      0.97       994\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     10000\n",
      "   macro avg       0.98      0.98      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n",
      "Confidence Matrix:\n",
      " [[ 980    1    0    1    0    0    1    0    1    2]\n",
      " [   0 1117    3    0    1    1    1    1    1    0]\n",
      " [   2    0  975    6    3    1    1    8    2    1]\n",
      " [   1    1    4  990    0   10    0    5    7    2]\n",
      " [   0    0    1    0  960    0    2    1    0   11]\n",
      " [   2    0    1    8    0  880    4    0    6    1]\n",
      " [   4    0    1    1    3    3  969    0    1    0]\n",
      " [   2    3    3    0    4    0    0 1019    0   11]\n",
      " [   1    2    4    6    1    5    3    0  947    6]\n",
      " [   0    5    2    4    5    3    0    5    5  965]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_classification_results(y_test_svc, y_pred,title=\"Heatmap of Predictions of SVM Classifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DEQrdyLHsUIu"
   },
   "source": [
    "### 2.1.5: Summary\n",
    "\n",
    "Summarize your findings:\n",
    " * Which hyper-parameters were important and how did they influence your results?\n",
    " > *The hyperparameters for SVM classifier that were important were the paramaters C, and gamma. As we saw from the plots above, the C parameter and gamma both influenced our results. We can see from the cross-validation results and the validation plots that as C increases, the training accuracy for all runs go to 1.0, whereas the validation accuracy drops. This means that as C increases the model overits. On the other hand, the lowest value of C had poor validation score and a comparatively low training score, meaning that it underfit. This can be attributed to the fact that high values of C means the margins are smaller, and hence we have a higher chance to overfit on the training data.*<br>\n",
    " > *For the value of gamma as well, we see a very similar performance. For lowest gamma, we have the worst result, and then as gamma is increased, the gamma value of 0.01 gave the best validation score, while if we kept on increasing it, the score reduced again. But for highest values of gamma, the training accuracy was 1.0. This can be because for high values of gamma, the area of influence of the support vectors is reduced greatly, resulting in more overfitting.*\n",
    " * What were other design choices you faced?\n",
    " > *Other design choice we faced was the choice of a kernel. We chose the polynomial kernel, because the RBF kernel is very slow to train, and it is also a non-linear kernel. Also we perform PCA to reduce the input dimensionality that reduces it from 784 to 332. This helps to reduce the training and evaluation time, without hurting the performance much.*\n",
    " * Any other interesting insights...\n",
    " > *We see that even after dropping the dimensionality from 784 to 332 by using PCA, we still manage to get 98% accuracy. It shows how there was some redundancy in the high dimensionality. As mentioned in the website: http://yann.lecun.com/exdb/mnist/ a Gaussian kernel with no data preprocessing gives a result of 98.6%. Here we manage to get a respectable score of 98% even after reducing the data dimension and a poly kernel.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fcq52WUUs2Mm"
   },
   "source": [
    "# 2.2: Model [M2]: *2-layer Perceptron*\n",
    "\n",
    "#### Short description : *We use an Multilayered Perceptron (2 layers) to perform the multiclass classification task. We use keras to create the MLP model and scikit-learn grid search cross validation to perform hyperparameter selection of the some of the important hyperparameters.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lVyT9Oddp3GB"
   },
   "source": [
    "### 2.2.1: Hyper-parameters\n",
    "\n",
    "Define hyper-parameters for your method here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gjD2xtuZ8vVI"
   },
   "outputs": [],
   "source": [
    "### 2.1.1: Hyper-parameters\n",
    "\n",
    "Define hyper-parameters for your method here# Define the parameter space\n",
    "epochs = np.arange(10,40,10)\n",
    "#epochs = [30,]\n",
    "#batch_size = np.arange(100,250,50)\n",
    "activations = [\"sigmoid\",\"relu\"]\n",
    "optimizer_algos = [\"sgd\",\"adam\"]\n",
    "## learning_rate\n",
    "#learning_rate = [0.001, 0.01, 0.1]\n",
    "num_neurons = [256,512,INPUT_DIMENSION, 1024]\n",
    "dropout_rate = [0.0,0.3,0.5]\n",
    "\n",
    "param_space = {\"epochs\":epochs,\\\n",
    "               #\"batch_size\": batch_size,\\\n",
    "               \"activation\": activations,\\\n",
    "               \"optimizer_algo\": optimizer_algos,\\\n",
    "               #\"learning_rate\": learning_rate,\\\n",
    "               \"num_neurons\": num_neurons,\\\n",
    "               \"dropout\": dropout_rate,\n",
    "              }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pkuCgPatp59X"
   },
   "source": [
    "### 2.2.2: Model\n",
    "\n",
    "Define your model here (all hyper-parameters in 2.1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pcKqyJJV8vVP"
   },
   "outputs": [],
   "source": [
    "# Method to create a Keras model. We call it inside sklearn GridSearchCV for easy cross validation.\n",
    "def create_mlp_model(num_neurons=256,activation='relu',optimizer_algo='sgd',dropout=0.0, learning_rate=0.01):\n",
    "    # create our model\n",
    "    model = Sequential()\n",
    "    # Hidden Layer 1\n",
    "    model.add(Dense(units=num_neurons, input_dim=INPUT_DIMENSION, activation=activation))\n",
    "    # Dropout Layer\n",
    "    model.add(Dropout(dropout))\n",
    "    # Hidden Layer 2\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    if optimizer_algo == 'sgd':\n",
    "      optimizer_algo = optimizers.SGD(lr=learning_rate)\n",
    "    elif optimizer_algo == 'adam':\n",
    "      optimizer_algo = optimizers.Adam(lr=learning_rate)\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer_algo, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fjDOeyyv8vVS"
   },
   "outputs": [],
   "source": [
    "### 2.1.2: Model\n",
    "\n",
    "Define your model here (all hyper-parameters in 2.1.1)# Define the Keras Model that will be used in cross validation\n",
    "model = KerasClassifier(build_fn=create_mlp_model)\n",
    "\n",
    "# Define the parameter space\n",
    "#epochs = np.arange(20,40,10)\n",
    "\n",
    "grid_search = sklearn.model_selection.GridSearchCV(estimator=model, param_grid=param_space, verbose=2, cv=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SxE6d6OXp6sU"
   },
   "source": [
    "### 2.2.3: Fit Model\n",
    "\n",
    "Define optimization procedure and fit your model to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1646
    },
    "colab_type": "code",
    "id": "8l0JkUOC8vVZ",
    "outputId": "c0a742b5-de88-47a8-a31e-1cbb96eb2c77",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 144 candidates, totalling 288 fits\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=10, num_neurons=256, optimizer_algo=sgd \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 1.7291 - acc: 0.6266\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 2s 58us/step - loss: 0.9983 - acc: 0.8095\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 0.7160 - acc: 0.8423\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 2s 55us/step - loss: 0.5889 - acc: 0.8614\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.5178 - acc: 0.8715\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 2s 53us/step - loss: 0.4726 - acc: 0.8780\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 2s 53us/step - loss: 0.4408 - acc: 0.8840\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 2s 53us/step - loss: 0.4173 - acc: 0.8893\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 2s 53us/step - loss: 0.3995 - acc: 0.8926\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 2s 53us/step - loss: 0.3851 - acc: 0.8962\n",
      "30000/30000 [==============================] - 1s 20us/step\n",
      "30000/30000 [==============================] - 1s 24us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=10, num_neurons=256, optimizer_algo=sgd, total=  18.4s\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=10, num_neurons=256, optimizer_algo=sgd \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   19.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 3s 89us/step - loss: 1.7154 - acc: 0.6347\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 2s 57us/step - loss: 0.9852 - acc: 0.8168\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 2s 55us/step - loss: 0.7070 - acc: 0.8489\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 2s 56us/step - loss: 0.5828 - acc: 0.8647\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 2s 55us/step - loss: 0.5136 - acc: 0.8734\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 2s 57us/step - loss: 0.4699 - acc: 0.8793\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 0.4393 - acc: 0.8846\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 2s 56us/step - loss: 0.4169 - acc: 0.8881\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 2s 57us/step - loss: 0.3994 - acc: 0.8899\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.3858 - acc: 0.8933\n",
      "30000/30000 [==============================] - 1s 31us/step\n",
      "30000/30000 [==============================] - 1s 22us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=10, num_neurons=256, optimizer_algo=sgd, total=  19.7s\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=10, num_neurons=256, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 4s 121us/step - loss: 0.2698 - acc: 0.9171\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 3s 107us/step - loss: 0.1297 - acc: 0.9603\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 4s 125us/step - loss: 0.1004 - acc: 0.9689\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 4s 119us/step - loss: 0.0853 - acc: 0.9715\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 3s 107us/step - loss: 0.0672 - acc: 0.9780\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 4s 123us/step - loss: 0.0725 - acc: 0.9765\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 3s 107us/step - loss: 0.0668 - acc: 0.9776\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 3s 114us/step - loss: 0.0625 - acc: 0.9799\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 0.0522 - acc: 0.9828\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 3s 114us/step - loss: 0.0545 - acc: 0.9814\n",
      "30000/30000 [==============================] - 1s 23us/step\n",
      "30000/30000 [==============================] - 1s 21us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=10, num_neurons=256, optimizer_algo=adam, total=  35.9s\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=10, num_neurons=256, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 4s 134us/step - loss: 0.2691 - acc: 0.9181\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 4s 128us/step - loss: 0.1220 - acc: 0.9630\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 4s 148us/step - loss: 0.0992 - acc: 0.9689\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 5s 166us/step - loss: 0.0833 - acc: 0.9731\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 4s 125us/step - loss: 0.0693 - acc: 0.9767\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 4s 148us/step - loss: 0.0714 - acc: 0.9767 0s - loss: 0.0697 - acc\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 4s 128us/step - loss: 0.0691 - acc: 0.9785\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 4s 146us/step - loss: 0.0697 - acc: 0.9785\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 4s 133us/step - loss: 0.0575 - acc: 0.9817\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 4s 146us/step - loss: 0.0593 - acc: 0.9807\n",
      "30000/30000 [==============================] - 1s 35us/step\n",
      "30000/30000 [==============================] - 1s 23us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=10, num_neurons=256, optimizer_algo=adam, total=  43.5s\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=10, num_neurons=512, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 6s 190us/step - loss: 1.6705 - acc: 0.6201\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 6s 192us/step - loss: 0.9298 - acc: 0.8181\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 5s 175us/step - loss: 0.6714 - acc: 0.8505\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 6s 205us/step - loss: 0.5580 - acc: 0.8667\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 5s 166us/step - loss: 0.4952 - acc: 0.8753\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 5s 169us/step - loss: 0.4550 - acc: 0.8826\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 6s 190us/step - loss: 0.4271 - acc: 0.8870\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 6s 192us/step - loss: 0.4064 - acc: 0.8916\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 5s 175us/step - loss: 0.3903 - acc: 0.8939\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 5s 174us/step - loss: 0.3775 - acc: 0.8967\n",
      "30000/30000 [==============================] - 2s 61us/step\n",
      "30000/30000 [==============================] - 1s 48us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=10, num_neurons=512, optimizer_algo=sgd, total=  57.0s\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=10, num_neurons=512, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 5s 172us/step - loss: 1.6757 - acc: 0.6278\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 5s 182us/step - loss: 0.9373 - acc: 0.8184\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 5s 171us/step - loss: 0.6750 - acc: 0.8516\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 5s 162us/step - loss: 0.5599 - acc: 0.8662\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 5s 178us/step - loss: 0.4967 - acc: 0.8748\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 5s 177us/step - loss: 0.4563 - acc: 0.8823\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 6s 188us/step - loss: 0.4287 - acc: 0.8862\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 5s 176us/step - loss: 0.4084 - acc: 0.8903\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 5s 178us/step - loss: 0.3925 - acc: 0.8916\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 6s 191us/step - loss: 0.3801 - acc: 0.8937\n",
      "30000/30000 [==============================] - 1s 46us/step\n",
      "30000/30000 [==============================] - 1s 45us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=10, num_neurons=512, optimizer_algo=sgd, total=  55.0s\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=10, num_neurons=512, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 10s 330us/step - loss: 0.2859 - acc: 0.91350s - loss: 0.2917 - \n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 10s 325us/step - loss: 0.1298 - acc: 0.9590\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 10s 330us/step - loss: 0.1024 - acc: 0.9675\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 10s 325us/step - loss: 0.0931 - acc: 0.9713\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 10s 347us/step - loss: 0.0900 - acc: 0.9716\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 8s 269us/step - loss: 0.0778 - acc: 0.9745\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 9s 298us/step - loss: 0.0720 - acc: 0.9778\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 9s 290us/step - loss: 0.0714 - acc: 0.9773\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 9s 309us/step - loss: 0.0765 - acc: 0.9772\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 10s 330us/step - loss: 0.0762 - acc: 0.9782\n",
      "30000/30000 [==============================] - 1s 44us/step\n",
      "30000/30000 [==============================] - 1s 42us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=10, num_neurons=512, optimizer_algo=adam, total= 1.6min\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=10, num_neurons=512, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 11s 358us/step - loss: 0.2737 - acc: 0.9158\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 10s 320us/step - loss: 0.1269 - acc: 0.9607\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 10s 342us/step - loss: 0.1070 - acc: 0.9671\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 10s 319us/step - loss: 0.0952 - acc: 0.9708\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 11s 355us/step - loss: 0.0945 - acc: 0.9712\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 10s 318us/step - loss: 0.0748 - acc: 0.9777\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 10s 339us/step - loss: 0.0722 - acc: 0.9775\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 11s 359us/step - loss: 0.0792 - acc: 0.9771\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 10s 333us/step - loss: 0.0654 - acc: 0.9806\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 10s 331us/step - loss: 0.0671 - acc: 0.9800\n",
      "30000/30000 [==============================] - 1s 48us/step\n",
      "30000/30000 [==============================] - 2s 61us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=10, num_neurons=512, optimizer_algo=adam, total= 1.7min\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=10, num_neurons=784, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 8s 250us/step - loss: 1.6302 - acc: 0.6248\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 8s 251us/step - loss: 0.8949 - acc: 0.8194\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 9s 289us/step - loss: 0.6520 - acc: 0.8524\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 8s 263us/step - loss: 0.5454 - acc: 0.8667\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 7s 245us/step - loss: 0.4854 - acc: 0.8760\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 8s 257us/step - loss: 0.4479 - acc: 0.8815\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 8s 262us/step - loss: 0.4213 - acc: 0.8874\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 8s 254us/step - loss: 0.4017 - acc: 0.8919\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 8s 261us/step - loss: 0.3864 - acc: 0.8939\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 7s 245us/step - loss: 0.3741 - acc: 0.8975\n",
      "30000/30000 [==============================] - 2s 68us/step\n",
      "30000/30000 [==============================] - 2s 65us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=10, num_neurons=784, optimizer_algo=sgd, total= 1.3min\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=10, num_neurons=784, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 9s 286us/step - loss: 1.6466 - acc: 0.6177\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 8s 268us/step - loss: 0.9026 - acc: 0.8230\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 9s 296us/step - loss: 0.6535 - acc: 0.8539\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 6s 210us/step - loss: 0.5458 - acc: 0.8674\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 7s 232us/step - loss: 0.4863 - acc: 0.8758\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 6s 216us/step - loss: 0.4486 - acc: 0.8811\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 7s 229us/step - loss: 0.4226 - acc: 0.8853\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 7s 226us/step - loss: 0.4036 - acc: 0.8898\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 7s 242us/step - loss: 0.3889 - acc: 0.8914\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 8s 254us/step - loss: 0.3764 - acc: 0.8949 0s - loss: 0.3\n",
      "30000/30000 [==============================] - 2s 82us/step\n",
      "30000/30000 [==============================] - 2s 56us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=10, num_neurons=784, optimizer_algo=sgd, total= 1.3min\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=10, num_neurons=784, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 15s 485us/step - loss: 0.2958 - acc: 0.91361s - los - ETA: 0s - loss: 0.2960 - acc: 0.913\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 13s 441us/step - loss: 0.1327 - acc: 0.9585\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 14s 456us/step - loss: 0.1169 - acc: 0.9624\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 13s 433us/step - loss: 0.1094 - acc: 0.9663\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 13s 446us/step - loss: 0.1043 - acc: 0.9699\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 13s 422us/step - loss: 0.0937 - acc: 0.9731\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 13s 445us/step - loss: 0.1040 - acc: 0.9705\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 14s 459us/step - loss: 0.0944 - acc: 0.9742\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 14s 466us/step - loss: 0.1021 - acc: 0.9732\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 13s 442us/step - loss: 0.0790 - acc: 0.9781\n",
      "30000/30000 [==============================] - 2s 64us/step\n",
      "30000/30000 [==============================] - 2s 56us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=10, num_neurons=784, optimizer_algo=adam, total= 2.3min\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=10, num_neurons=784, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 14s 469us/step - loss: 0.3087 - acc: 0.9134\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 13s 449us/step - loss: 0.1306 - acc: 0.9595\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 0.1011 - acc: 0.968 - 14s 465us/step - loss: 0.1015 - acc: 0.9679\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 14s 458us/step - loss: 0.1030 - acc: 0.96661s - l\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 14s 464us/step - loss: 0.0964 - acc: 0.9709\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 16s 519us/step - loss: 0.0887 - acc: 0.9739\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 14s 469us/step - loss: 0.0848 - acc: 0.9759\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 13s 430us/step - loss: 0.0905 - acc: 0.9741\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 14s 470us/step - loss: 0.0753 - acc: 0.97891s -\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 14s 450us/step - loss: 0.0808 - acc: 0.9782\n",
      "30000/30000 [==============================] - 2s 62us/step\n",
      "30000/30000 [==============================] - 2s 66us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=10, num_neurons=784, optimizer_algo=adam, total= 2.4min\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=10, num_neurons=1024, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 10s 319us/step - loss: 1.6039 - acc: 0.61791s \n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 8s 283us/step - loss: 0.8777 - acc: 0.8209\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 9s 304us/step - loss: 0.6427 - acc: 0.8513\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 10s 319us/step - loss: 0.5402 - acc: 0.8657\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 9s 284us/step - loss: 0.4824 - acc: 0.8752\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 9s 307us/step - loss: 0.4458 - acc: 0.8829\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 10s 317us/step - loss: 0.4201 - acc: 0.8860\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 8s 275us/step - loss: 0.4008 - acc: 0.8910\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 10s 319us/step - loss: 0.3859 - acc: 0.8938\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 8s 271us/step - loss: 0.3745 - acc: 0.8960\n",
      "30000/30000 [==============================] - 2s 80us/step\n",
      "30000/30000 [==============================] - 3s 104us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=10, num_neurons=1024, optimizer_algo=sgd, total= 1.5min\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=10, num_neurons=1024, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 9s 291us/step - loss: 1.6017 - acc: 0.6278\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 9s 303us/step - loss: 0.8734 - acc: 0.8190\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 9s 309us/step - loss: 0.6403 - acc: 0.8512\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 8s 271us/step - loss: 0.5384 - acc: 0.8665\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 10s 337us/step - loss: 0.4818 - acc: 0.8739\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 10s 327us/step - loss: 0.4454 - acc: 0.8811\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 9s 309us/step - loss: 0.4208 - acc: 0.8852\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 8s 282us/step - loss: 0.4018 - acc: 0.8885\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 9s 314us/step - loss: 0.3878 - acc: 0.8911\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 9s 294us/step - loss: 0.3762 - acc: 0.8943\n",
      "30000/30000 [==============================] - 2s 74us/step\n",
      "30000/30000 [==============================] - 2s 68us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=10, num_neurons=1024, optimizer_algo=sgd, total= 1.6min\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=10, num_neurons=1024, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 19s 625us/step - loss: 0.2959 - acc: 0.9160\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 19s 644us/step - loss: 0.1338 - acc: 0.9572\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 18s 613us/step - loss: 0.1170 - acc: 0.9649\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 18s 585us/step - loss: 0.1146 - acc: 0.9673\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 18s 615us/step - loss: 0.1168 - acc: 0.9667\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 18s 601us/step - loss: 0.1095 - acc: 0.9702\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 17s 570us/step - loss: 0.1124 - acc: 0.9710\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 17s 566us/step - loss: 0.1140 - acc: 0.9712\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 17s 577us/step - loss: 0.1101 - acc: 0.9730\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 17s 564us/step - loss: 0.1021 - acc: 0.9750\n",
      "30000/30000 [==============================] - 2s 74us/step\n",
      "30000/30000 [==============================] - 2s 69us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=10, num_neurons=1024, optimizer_algo=adam, total= 3.0min\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=10, num_neurons=1024, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 18s 589us/step - loss: 0.3102 - acc: 0.9115\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 17s 572us/step - loss: 0.1324 - acc: 0.9596\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 17s 574us/step - loss: 0.1079 - acc: 0.9683\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 17s 568us/step - loss: 0.1000 - acc: 0.9689\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 17s 577us/step - loss: 0.1257 - acc: 0.9659\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 18s 592us/step - loss: 0.1093 - acc: 0.9700\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 18s 586us/step - loss: 0.0988 - acc: 0.9734\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 17s 572us/step - loss: 0.1155 - acc: 0.9710\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 17s 572us/step - loss: 0.1137 - acc: 0.9721\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 18s 587us/step - loss: 0.0845 - acc: 0.9785\n",
      "30000/30000 [==============================] - 2s 78us/step\n",
      "30000/30000 [==============================] - 2s 69us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=10, num_neurons=1024, optimizer_algo=adam, total= 2.9min\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=20, num_neurons=256, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 1.7120 - acc: 0.6321\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.9876 - acc: 0.8098\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.7096 - acc: 0.8447\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.5850 - acc: 0.8632\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.5154 - acc: 0.8720\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.4702 - acc: 0.8806\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.4388 - acc: 0.8867\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.4158 - acc: 0.8913\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.3978 - acc: 0.8941\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.3833 - acc: 0.8964\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 3s 83us/step - loss: 0.3718 - acc: 0.8988\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.3616 - acc: 0.9015\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.3533 - acc: 0.9029\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.3458 - acc: 0.9049\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.3395 - acc: 0.9062\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.3336 - acc: 0.9077\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.3286 - acc: 0.9087\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.3239 - acc: 0.9104\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.3196 - acc: 0.9110\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 2s 53us/step - loss: 0.3156 - acc: 0.9118\n",
      "30000/30000 [==============================] - 1s 28us/step\n",
      "30000/30000 [==============================] - 1s 21us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=20, num_neurons=256, optimizer_algo=sgd, total=  44.8s\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=20, num_neurons=256, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 1.7384 - acc: 0.6036\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 2s 54us/step - loss: 0.9945 - acc: 0.8105\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 2s 55us/step - loss: 0.7098 - acc: 0.8469\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 2s 54us/step - loss: 0.5835 - acc: 0.8629\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 2s 54us/step - loss: 0.5137 - acc: 0.8725\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 2s 56us/step - loss: 0.4690 - acc: 0.8797\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 2s 57us/step - loss: 0.4384 - acc: 0.8842: \n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 2s 53us/step - loss: 0.4157 - acc: 0.8886: 1s\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 2s 57us/step - loss: 0.3983 - acc: 0.8912\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 2s 54us/step - loss: 0.3845 - acc: 0.8949\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.3730 - acc: 0.8964\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 2s 53us/step - loss: 0.3636 - acc: 0.8983\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 2s 53us/step - loss: 0.3551 - acc: 0.8996\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 2s 56us/step - loss: 0.3484 - acc: 0.9006\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 2s 53us/step - loss: 0.3419 - acc: 0.9024\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 2s 54us/step - loss: 0.3364 - acc: 0.9041\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 2s 54us/step - loss: 0.3313 - acc: 0.9047\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 2s 53us/step - loss: 0.3269 - acc: 0.9058\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 2s 54us/step - loss: 0.3228 - acc: 0.9070\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 2s 55us/step - loss: 0.3188 - acc: 0.9079\n",
      "30000/30000 [==============================] - 1s 31us/step\n",
      "30000/30000 [==============================] - 1s 24us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=20, num_neurons=256, optimizer_algo=sgd, total=  34.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] activation=sigmoid, dropout=0.0, epochs=20, num_neurons=256, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 4s 129us/step - loss: 0.2742 - acc: 0.9178\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 3s 113us/step - loss: 0.1292 - acc: 0.9607\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 3s 116us/step - loss: 0.1012 - acc: 0.9674\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 3s 113us/step - loss: 0.0865 - acc: 0.9719\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 3s 112us/step - loss: 0.0842 - acc: 0.9715\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 3s 112us/step - loss: 0.0691 - acc: 0.9771\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 4s 119us/step - loss: 0.0671 - acc: 0.9787\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 3s 111us/step - loss: 0.0622 - acc: 0.9799\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 3s 113us/step - loss: 0.0554 - acc: 0.9824\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 3s 113us/step - loss: 0.0599 - acc: 0.9802\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 3s 111us/step - loss: 0.0594 - acc: 0.9805\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 3s 112us/step - loss: 0.0507 - acc: 0.9831\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 3s 111us/step - loss: 0.0566 - acc: 0.9815\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 3s 111us/step - loss: 0.0535 - acc: 0.9835\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 3s 111us/step - loss: 0.0509 - acc: 0.9839\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 3s 110us/step - loss: 0.0440 - acc: 0.9859\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 4s 117us/step - loss: 0.0398 - acc: 0.9878\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 3s 114us/step - loss: 0.0457 - acc: 0.9851\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 4s 119us/step - loss: 0.0442 - acc: 0.9864\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 3s 111us/step - loss: 0.0420 - acc: 0.9864\n",
      "30000/30000 [==============================] - 1s 32us/step\n",
      "30000/30000 [==============================] - 1s 25us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=20, num_neurons=256, optimizer_algo=adam, total= 1.2min\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=20, num_neurons=256, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 4s 135us/step - loss: 0.2683 - acc: 0.9167\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 4s 119us/step - loss: 0.1267 - acc: 0.9607\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 4s 120us/step - loss: 0.0946 - acc: 0.9705\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 4s 117us/step - loss: 0.0861 - acc: 0.9722\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 4s 117us/step - loss: 0.0750 - acc: 0.9753\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 4s 119us/step - loss: 0.0655 - acc: 0.9796\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 4s 117us/step - loss: 0.0661 - acc: 0.9778\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 4s 117us/step - loss: 0.0646 - acc: 0.9797\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 4s 125us/step - loss: 0.0575 - acc: 0.9815\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 4s 119us/step - loss: 0.0593 - acc: 0.9819\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 4s 118us/step - loss: 0.0535 - acc: 0.9825\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 4s 118us/step - loss: 0.0588 - acc: 0.9816\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 4s 120us/step - loss: 0.0518 - acc: 0.9839\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 120us/step - loss: 0.0441 - acc: 0.9863\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 4s 121us/step - loss: 0.0454 - acc: 0.9855\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 4s 119us/step - loss: 0.0436 - acc: 0.9858\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 4s 119us/step - loss: 0.0471 - acc: 0.9855\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 4s 117us/step - loss: 0.0410 - acc: 0.9863\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 4s 122us/step - loss: 0.0418 - acc: 0.9870\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 4s 127us/step - loss: 0.0385 - acc: 0.9881\n",
      "30000/30000 [==============================] - 1s 31us/step\n",
      "30000/30000 [==============================] - 1s 23us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=20, num_neurons=256, optimizer_algo=adam, total= 1.2min\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=20, num_neurons=512, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 5s 160us/step - loss: 1.6599 - acc: 0.6291\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 4s 144us/step - loss: 0.9303 - acc: 0.8202\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 4s 145us/step - loss: 0.6715 - acc: 0.8512\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 4s 144us/step - loss: 0.5575 - acc: 0.8670\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 0.4944 - acc: 0.8768\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 4s 148us/step - loss: 0.4541 - acc: 0.8827\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 0.4263 - acc: 0.8873\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 4s 145us/step - loss: 0.4057 - acc: 0.8903\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 5s 155us/step - loss: 0.3898 - acc: 0.8931\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.3772 - acc: 0.8965\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 4s 143us/step - loss: 0.3664 - acc: 0.8987\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 4s 141us/step - loss: 0.3576 - acc: 0.9005\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 4s 144us/step - loss: 0.3506 - acc: 0.9013\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 144us/step - loss: 0.3439 - acc: 0.9034\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 4s 147us/step - loss: 0.3380 - acc: 0.9054\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 0.3329 - acc: 0.9063\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 4s 143us/step - loss: 0.3283 - acc: 0.9081\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 5s 152us/step - loss: 0.3244 - acc: 0.9093\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 4s 143us/step - loss: 0.3205 - acc: 0.9094\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 4s 144us/step - loss: 0.3168 - acc: 0.9110\n",
      "30000/30000 [==============================] - 2s 52us/step\n",
      "30000/30000 [==============================] - 1s 45us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=20, num_neurons=512, optimizer_algo=sgd, total= 1.5min\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=20, num_neurons=512, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 5s 161us/step - loss: 1.6696 - acc: 0.6238\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 4s 149us/step - loss: 0.9328 - acc: 0.8145\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 4s 141us/step - loss: 0.6743 - acc: 0.8504\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 4s 149us/step - loss: 0.5603 - acc: 0.8655\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 4s 146us/step - loss: 0.4972 - acc: 0.8754\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 4s 144us/step - loss: 0.4566 - acc: 0.8802\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 4s 144us/step - loss: 0.4291 - acc: 0.8853\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 4s 144us/step - loss: 0.4081 - acc: 0.8898\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 4s 140us/step - loss: 0.3925 - acc: 0.8916\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 4s 140us/step - loss: 0.3793 - acc: 0.8942\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 4s 149us/step - loss: 0.3693 - acc: 0.8963\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 5s 157us/step - loss: 0.3607 - acc: 0.8972\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 5s 156us/step - loss: 0.3530 - acc: 0.8994\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 147us/step - loss: 0.3467 - acc: 0.9016\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 5s 152us/step - loss: 0.3409 - acc: 0.9021\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 4s 150us/step - loss: 0.3360 - acc: 0.9028\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 4s 145us/step - loss: 0.3315 - acc: 0.9048\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 0.3276 - acc: 0.9054\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 5s 156us/step - loss: 0.3238 - acc: 0.9061\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 4s 149us/step - loss: 0.3205 - acc: 0.9074\n",
      "30000/30000 [==============================] - 2s 56us/step\n",
      "30000/30000 [==============================] - 2s 58us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=20, num_neurons=512, optimizer_algo=sgd, total= 1.5min\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=20, num_neurons=512, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 11s 366us/step - loss: 0.2799 - acc: 0.91821s - lo\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 11s 353us/step - loss: 0.1359 - acc: 0.9582\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 10s 326us/step - loss: 0.1126 - acc: 0.9648\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 10s 336us/step - loss: 0.0969 - acc: 0.9696\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 9s 313us/step - loss: 0.0870 - acc: 0.9724\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 9s 315us/step - loss: 0.0816 - acc: 0.9738\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 12s 388us/step - loss: 0.0802 - acc: 0.9762\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 12s 394us/step - loss: 0.0729 - acc: 0.9770\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 11s 381us/step - loss: 0.0679 - acc: 0.9793\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 11s 379us/step - loss: 0.0754 - acc: 0.9778\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 10s 323us/step - loss: 0.0614 - acc: 0.9819\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 12s 390us/step - loss: 0.0601 - acc: 0.9830\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 11s 372us/step - loss: 0.0687 - acc: 0.9806\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 9s 308us/step - loss: 0.0597 - acc: 0.9832 0s - loss: 0.0588 - acc: 0\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 0.0629 - acc: 0.982 - 8s 283us/step - loss: 0.0630 - acc: 0.9825\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 8s 274us/step - loss: 0.0548 - acc: 0.9845\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 9s 291us/step - loss: 0.0571 - acc: 0.9840\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 12s 416us/step - loss: 0.0520 - acc: 0.9855\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 8s 273us/step - loss: 0.0511 - acc: 0.9856\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 10s 332us/step - loss: 0.0706 - acc: 0.9835\n",
      "30000/30000 [==============================] - 2s 65us/step\n",
      "30000/30000 [==============================] - 2s 54us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=20, num_neurons=512, optimizer_algo=adam, total= 3.4min\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=20, num_neurons=512, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 12s 406us/step - loss: 0.2843 - acc: 0.9157\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 13s 419us/step - loss: 0.1284 - acc: 0.9594\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 13s 430us/step - loss: 0.0946 - acc: 0.9694\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 13s 434us/step - loss: 0.1062 - acc: 0.9659\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 12s 414us/step - loss: 0.0870 - acc: 0.9736A: 0s - loss: 0.0871 - acc: 0\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 12s 413us/step - loss: 0.0786 - acc: 0.9755\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 13s 426us/step - loss: 0.0776 - acc: 0.9768\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 12s 415us/step - loss: 0.0696 - acc: 0.9787\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 13s 424us/step - loss: 0.0650 - acc: 0.9813\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 12s 416us/step - loss: 0.0642 - acc: 0.9811\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 13s 436us/step - loss: 0.0725 - acc: 0.9793\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 12s 414us/step - loss: 0.0613 - acc: 0.9823\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 15s 494us/step - loss: 0.0666 - acc: 0.9815\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 14s 458us/step - loss: 0.0714 - acc: 0.98150s - loss: 0.072\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 13s 441us/step - loss: 0.0609 - acc: 0.9837\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 13s 446us/step - loss: 0.0571 - acc: 0.9843\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 13s 435us/step - loss: 0.0609 - acc: 0.9836\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 13s 436us/step - loss: 0.0500 - acc: 0.9873\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 12s 408us/step - loss: 0.0559 - acc: 0.9856\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 13s 449us/step - loss: 0.0552 - acc: 0.9853\n",
      "30000/30000 [==============================] - 2s 73us/step\n",
      "30000/30000 [==============================] - 2s 65us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=20, num_neurons=512, optimizer_algo=adam, total= 4.4min\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=20, num_neurons=784, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 8s 271us/step - loss: 1.6253 - acc: 0.6290\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 8s 252us/step - loss: 0.8934 - acc: 0.8236\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 9s 284us/step - loss: 0.6500 - acc: 0.8529\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 8s 263us/step - loss: 0.5443 - acc: 0.8678\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 8s 256us/step - loss: 0.4855 - acc: 0.8760\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 8s 268us/step - loss: 0.4478 - acc: 0.8819\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 8s 268us/step - loss: 0.4215 - acc: 0.8873\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 8s 266us/step - loss: 0.4022 - acc: 0.8911\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 9s 288us/step - loss: 0.3871 - acc: 0.8941\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 8s 266us/step - loss: 0.3749 - acc: 0.8967\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 7s 250us/step - loss: 0.3652 - acc: 0.8993\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 8s 270us/step - loss: 0.3567 - acc: 0.9012\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 8s 264us/step - loss: 0.3493 - acc: 0.9019\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 8s 261us/step - loss: 0.3435 - acc: 0.9033\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 8s 278us/step - loss: 0.3380 - acc: 0.9049\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 8s 273us/step - loss: 0.3330 - acc: 0.9062\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 9s 284us/step - loss: 0.3286 - acc: 0.9071 0s - loss: 0.32\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 11s 360us/step - loss: 0.3244 - acc: 0.9091\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 10s 330us/step - loss: 0.3213 - acc: 0.9102\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 10s 341us/step - loss: 0.3177 - acc: 0.9105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 3s 101us/step\n",
      "30000/30000 [==============================] - 3s 90us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=20, num_neurons=784, optimizer_algo=sgd, total= 2.9min\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=20, num_neurons=784, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 11s 378us/step - loss: 1.6341 - acc: 0.6241\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 11s 353us/step - loss: 0.8903 - acc: 0.8179\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 10s 334us/step - loss: 0.6488 - acc: 0.8519\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 10s 329us/step - loss: 0.5441 - acc: 0.8654\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 11s 370us/step - loss: 0.4863 - acc: 0.8748\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 10s 329us/step - loss: 0.4489 - acc: 0.8807\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 8s 261us/step - loss: 0.4234 - acc: 0.8848\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 8s 264us/step - loss: 0.4043 - acc: 0.8883\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 8s 260us/step - loss: 0.3892 - acc: 0.8918\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 8s 270us/step - loss: 0.3778 - acc: 0.8944\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 8s 258us/step - loss: 0.3682 - acc: 0.8953\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 8s 260us/step - loss: 0.3603 - acc: 0.8974\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 8s 254us/step - loss: 0.3530 - acc: 0.8993\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 8s 259us/step - loss: 0.3467 - acc: 0.9009\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 8s 266us/step - loss: 0.3417 - acc: 0.9019\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 8s 265us/step - loss: 0.3369 - acc: 0.9027\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 8s 276us/step - loss: 0.3330 - acc: 0.9041\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 7s 250us/step - loss: 0.3290 - acc: 0.9050\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 9s 289us/step - loss: 0.3251 - acc: 0.9063\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 8s 279us/step - loss: 0.3221 - acc: 0.9078\n",
      "30000/30000 [==============================] - 2s 79us/step\n",
      "30000/30000 [==============================] - 2s 70us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=20, num_neurons=784, optimizer_algo=sgd, total= 2.9min\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=20, num_neurons=784, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 16s 534us/step - loss: 0.2938 - acc: 0.91480s - loss: 0.2952 - acc: 0\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 16s 517us/step - loss: 0.1374 - acc: 0.9580\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 15s 504us/step - loss: 0.1122 - acc: 0.9646\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 16s 538us/step - loss: 0.1121 - acc: 0.9664\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 20s 656us/step - loss: 0.1064 - acc: 0.96800s - loss: 0.1064 - acc: 0.\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 20s 679us/step - loss: 0.0920 - acc: 0.9733\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 22s 723us/step - loss: 0.0907 - acc: 0.9736\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 22s 746us/step - loss: 0.1023 - acc: 0.9722\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 20s 666us/step - loss: 0.1041 - acc: 0.9737\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 18s 605us/step - loss: 0.0779 - acc: 0.97881s - l\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 16s 529us/step - loss: 0.0897 - acc: 0.9768\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 15s 513us/step - loss: 0.0817 - acc: 0.9789\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 22s 719us/step - loss: 0.0895 - acc: 0.97841s - loss: \n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 17s 571us/step - loss: 0.0856 - acc: 0.9797\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 17s 557us/step - loss: 0.0933 - acc: 0.9785\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 19s 621us/step - loss: 0.0941 - acc: 0.9781\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 18s 590us/step - loss: 0.0758 - acc: 0.9824\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 17s 583us/step - loss: 0.0651 - acc: 0.9842\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 17s 560us/step - loss: 0.0854 - acc: 0.9815\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 18s 597us/step - loss: 0.0747 - acc: 0.9836\n",
      "30000/30000 [==============================] - 3s 110us/step\n",
      "30000/30000 [==============================] - 3s 91us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=20, num_neurons=784, optimizer_algo=adam, total= 6.1min\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=20, num_neurons=784, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 18s 595us/step - loss: 0.2833 - acc: 0.91600s - loss: 0.2869 - ac\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 16s 546us/step - loss: 0.1342 - acc: 0.9584\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 14s 462us/step - loss: 0.1086 - acc: 0.9656\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 14s 463us/step - loss: 0.1027 - acc: 0.9686\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 14s 469us/step - loss: 0.0966 - acc: 0.9709\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 14s 452us/step - loss: 0.0830 - acc: 0.9751\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 15s 488us/step - loss: 0.0885 - acc: 0.9749\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 14s 455us/step - loss: 0.0935 - acc: 0.9744\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 14s 452us/step - loss: 0.0811 - acc: 0.9786\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 14s 471us/step - loss: 0.0806 - acc: 0.9788\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 14s 454us/step - loss: 0.0850 - acc: 0.9773\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 15s 484us/step - loss: 0.0686 - acc: 0.9818\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 14s 452us/step - loss: 0.0767 - acc: 0.9806\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 15s 508us/step - loss: 0.0817 - acc: 0.9806\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 14s 480us/step - loss: 0.0754 - acc: 0.9826\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 15s 494us/step - loss: 0.1000 - acc: 0.9789\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 14s 460us/step - loss: 0.0974 - acc: 0.9800\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 14s 452us/step - loss: 0.0789 - acc: 0.98292s - loss:  - ETA: 1s - l\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 14s 458us/step - loss: 0.0922 - acc: 0.9821\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 13s 450us/step - loss: 0.0829 - acc: 0.98370s - loss: 0.0830 - acc: 0\n",
      "30000/30000 [==============================] - 2s 75us/step\n",
      "30000/30000 [==============================] - 2s 66us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=20, num_neurons=784, optimizer_algo=adam, total= 4.8min\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=20, num_neurons=1024, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 9s 314us/step - loss: 1.6136 - acc: 0.6148\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 9s 303us/step - loss: 0.8847 - acc: 0.8139\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 9s 303us/step - loss: 0.6482 - acc: 0.8496\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 10s 321us/step - loss: 0.5442 - acc: 0.8639\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 9s 284us/step - loss: 0.4854 - acc: 0.8743\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 9s 302us/step - loss: 0.4480 - acc: 0.8808\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 9s 292us/step - loss: 0.4216 - acc: 0.8867\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 9s 294us/step - loss: 0.4021 - acc: 0.8897\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 9s 285us/step - loss: 0.3869 - acc: 0.8938 0s - loss: 0.3871 - acc: 0.893\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 9s 288us/step - loss: 0.3750 - acc: 0.8954\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 9s 290us/step - loss: 0.3653 - acc: 0.8971\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 9s 289us/step - loss: 0.3569 - acc: 0.8994\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 9s 297us/step - loss: 0.3497 - acc: 0.9019\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 9s 293us/step - loss: 0.3434 - acc: 0.9035\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 9s 298us/step - loss: 0.3379 - acc: 0.9048\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 9s 288us/step - loss: 0.3332 - acc: 0.9055\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 8s 280us/step - loss: 0.3290 - acc: 0.9065\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 8s 279us/step - loss: 0.3251 - acc: 0.9084\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 9s 284us/step - loss: 0.3215 - acc: 0.9087\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 9s 307us/step - loss: 0.3179 - acc: 0.9107\n",
      "30000/30000 [==============================] - 3s 86us/step\n",
      "30000/30000 [==============================] - 2s 82us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=20, num_neurons=1024, optimizer_algo=sgd, total= 3.0min\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=20, num_neurons=1024, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 10s 338us/step - loss: 1.6164 - acc: 0.6189\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 9s 283us/step - loss: 0.8800 - acc: 0.8165\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 9s 284us/step - loss: 0.6429 - acc: 0.8509\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 9s 286us/step - loss: 0.5400 - acc: 0.8652\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 8s 283us/step - loss: 0.4826 - acc: 0.8750\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 10s 333us/step - loss: 0.4460 - acc: 0.8806\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 12s 389us/step - loss: 0.4212 - acc: 0.88491s - l\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 9s 315us/step - loss: 0.4020 - acc: 0.8887\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 10s 329us/step - loss: 0.3879 - acc: 0.8917\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 11s 376us/step - loss: 0.3764 - acc: 0.8931\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 11s 371us/step - loss: 0.3670 - acc: 0.8962\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 11s 372us/step - loss: 0.3590 - acc: 0.8981\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 11s 364us/step - loss: 0.3523 - acc: 0.8992\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 11s 376us/step - loss: 0.3462 - acc: 0.9001\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 11s 378us/step - loss: 0.3411 - acc: 0.9023\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 11s 360us/step - loss: 0.3366 - acc: 0.9029\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 11s 379us/step - loss: 0.3324 - acc: 0.9044\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 10s 349us/step - loss: 0.3285 - acc: 0.9051\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 12s 391us/step - loss: 0.3248 - acc: 0.9061\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 11s 369us/step - loss: 0.3221 - acc: 0.9070\n",
      "30000/30000 [==============================] - 3s 105us/step\n",
      "30000/30000 [==============================] - 3s 98us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=20, num_neurons=1024, optimizer_algo=sgd, total= 3.5min\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=20, num_neurons=1024, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 23s 783us/step - loss: 0.2990 - acc: 0.9123\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 22s 749us/step - loss: 0.1383 - acc: 0.9578\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 22s 743us/step - loss: 0.1185 - acc: 0.9632\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 22s 736us/step - loss: 0.1205 - acc: 0.9642\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 23s 751us/step - loss: 0.1113 - acc: 0.9683\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 22s 730us/step - loss: 0.1092 - acc: 0.9690\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 22s 729us/step - loss: 0.1029 - acc: 0.9724\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 19s 621us/step - loss: 0.0998 - acc: 0.9745\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 18s 585us/step - loss: 0.0940 - acc: 0.9764\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 18s 593us/step - loss: 0.0932 - acc: 0.9775\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 18s 593us/step - loss: 0.0911 - acc: 0.9779\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 18s 609us/step - loss: 0.0941 - acc: 0.9786\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 18s 604us/step - loss: 0.1073 - acc: 0.9774\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 20s 668us/step - loss: 0.0872 - acc: 0.9800\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 21s 703us/step - loss: 0.0859 - acc: 0.9817\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 19s 636us/step - loss: 0.0945 - acc: 0.9797\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 18s 604us/step - loss: 0.0914 - acc: 0.9817\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 18s 596us/step - loss: 0.0912 - acc: 0.9822\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 18s 597us/step - loss: 0.0772 - acc: 0.9838\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 18s 614us/step - loss: 0.0933 - acc: 0.9817\n",
      "30000/30000 [==============================] - 3s 102us/step\n",
      "30000/30000 [==============================] - 3s 96us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=20, num_neurons=1024, optimizer_algo=adam, total= 6.7min\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=20, num_neurons=1024, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 19s 640us/step - loss: 0.3066 - acc: 0.9112\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 19s 637us/step - loss: 0.1364 - acc: 0.9584\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 19s 647us/step - loss: 0.1184 - acc: 0.96330s - loss: 0.1181 - \n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 18s 600us/step - loss: 0.1193 - acc: 0.9647\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 18s 600us/step - loss: 0.1094 - acc: 0.9686\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 18s 593us/step - loss: 0.1008 - acc: 0.9713\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 18s 592us/step - loss: 0.1025 - acc: 0.9727\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 19s 617us/step - loss: 0.1017 - acc: 0.9730\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 18s 589us/step - loss: 0.0949 - acc: 0.9745\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 18s 592us/step - loss: 0.0866 - acc: 0.9790\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 18s 593us/step - loss: 0.1008 - acc: 0.9759\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 19s 625us/step - loss: 0.1023 - acc: 0.9770\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 18s 612us/step - loss: 0.0862 - acc: 0.9803\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 18s 587us/step - loss: 0.0814 - acc: 0.9816\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 19s 625us/step - loss: 0.0885 - acc: 0.9812\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 18s 598us/step - loss: 0.0876 - acc: 0.98151s\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 20s 656us/step - loss: 0.1001 - acc: 0.9793\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 17s 582us/step - loss: 0.0926 - acc: 0.9807\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 18s 584us/step - loss: 0.0928 - acc: 0.9815\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 17s 573us/step - loss: 0.0975 - acc: 0.9821\n",
      "30000/30000 [==============================] - 3s 96us/step\n",
      "30000/30000 [==============================] - 3s 90us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=20, num_neurons=1024, optimizer_algo=adam, total= 6.1min\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=30, num_neurons=256, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 4s 117us/step - loss: 1.7250 - acc: 0.6284\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 3s 89us/step - loss: 0.9883 - acc: 0.8160\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 3s 88us/step - loss: 0.7060 - acc: 0.8490\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 3s 88us/step - loss: 0.5811 - acc: 0.8648\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 3s 88us/step - loss: 0.5119 - acc: 0.8738\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 3s 89us/step - loss: 0.4678 - acc: 0.8811\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 3s 91us/step - loss: 0.4370 - acc: 0.8861\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 3s 89us/step - loss: 0.4140 - acc: 0.8905\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 3s 89us/step - loss: 0.3965 - acc: 0.8936\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 3s 91us/step - loss: 0.3822 - acc: 0.8964\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 3s 92us/step - loss: 0.3708 - acc: 0.8994\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 3s 88us/step - loss: 0.3608 - acc: 0.9006\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 3s 88us/step - loss: 0.3525 - acc: 0.9032\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.3453 - acc: 0.9043\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 3s 97us/step - loss: 0.3388 - acc: 0.9054\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 3s 89us/step - loss: 0.3330 - acc: 0.9071\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 3s 89us/step - loss: 0.3278 - acc: 0.9086\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.3233 - acc: 0.9094\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 3s 89us/step - loss: 0.3191 - acc: 0.9105\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 3s 89us/step - loss: 0.3152 - acc: 0.9117\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 3s 92us/step - loss: 0.3115 - acc: 0.9131\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 3s 91us/step - loss: 0.3083 - acc: 0.9137\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 3s 91us/step - loss: 0.3048 - acc: 0.9142\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 3s 89us/step - loss: 0.3021 - acc: 0.9154\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.2992 - acc: 0.9159\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 2s 83us/step - loss: 0.2967 - acc: 0.9174\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.2941 - acc: 0.9173\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.2918 - acc: 0.9181\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.2895 - acc: 0.9184\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 3s 90us/step - loss: 0.2872 - acc: 0.9198\n",
      "30000/30000 [==============================] - 1s 41us/step\n",
      "30000/30000 [==============================] - 1s 32us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=30, num_neurons=256, optimizer_algo=sgd, total= 1.4min\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=30, num_neurons=256, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 3s 104us/step - loss: 1.7075 - acc: 0.6435\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.9802 - acc: 0.8168\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 2s 83us/step - loss: 0.7037 - acc: 0.8487\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.5809 - acc: 0.8637\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.5123 - acc: 0.8723\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.4686 - acc: 0.8798\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.4379 - acc: 0.8841\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.4155 - acc: 0.8878\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.3982 - acc: 0.8912\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.3842 - acc: 0.8941\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.3730 - acc: 0.8959\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.3634 - acc: 0.8976\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.3551 - acc: 0.9003\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.3482 - acc: 0.9014\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.3420 - acc: 0.9029\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.3364 - acc: 0.9047\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.3314 - acc: 0.9051\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.3267 - acc: 0.9065\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.3226 - acc: 0.9078\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.3188 - acc: 0.9087\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.3152 - acc: 0.9085\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.3119 - acc: 0.9099\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.3089 - acc: 0.9108\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.3060 - acc: 0.9114\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.3029 - acc: 0.9122\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.3005 - acc: 0.9133\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.2980 - acc: 0.9137\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.2956 - acc: 0.9141\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.2931 - acc: 0.9154\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.2909 - acc: 0.9158\n",
      "30000/30000 [==============================] - 1s 40us/step\n",
      "30000/30000 [==============================] - 1s 30us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=30, num_neurons=256, optimizer_algo=sgd, total= 1.1min\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=30, num_neurons=256, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 0.2708 - acc: 0.9182\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 4s 129us/step - loss: 0.1307 - acc: 0.9585\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 4s 131us/step - loss: 0.0955 - acc: 0.9697\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 4s 123us/step - loss: 0.0828 - acc: 0.9725\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 0.0789 - acc: 0.9738\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 4s 123us/step - loss: 0.0707 - acc: 0.9763\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 0.0641 - acc: 0.9787\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 4s 132us/step - loss: 0.0528 - acc: 0.9830\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 4s 125us/step - loss: 0.0594 - acc: 0.9804\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 4s 132us/step - loss: 0.0589 - acc: 0.9809\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 0.0463 - acc: 0.9851\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 4s 133us/step - loss: 0.0501 - acc: 0.9832\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 4s 134us/step - loss: 0.0449 - acc: 0.9853\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 4s 126us/step - loss: 0.0552 - acc: 0.9820\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 0.0535 - acc: 0.9838\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 4s 123us/step - loss: 0.0314 - acc: 0.9892\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 4s 121us/step - loss: 0.0418 - acc: 0.9873\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 4s 128us/step - loss: 0.0416 - acc: 0.9876\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 4s 119us/step - loss: 0.0439 - acc: 0.9865\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 4s 125us/step - loss: 0.0368 - acc: 0.9879\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 4s 126us/step - loss: 0.0314 - acc: 0.9899\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 0.0368 - acc: 0.9882\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 4s 127us/step - loss: 0.0385 - acc: 0.9883\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 4s 145us/step - loss: 0.0342 - acc: 0.9899\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 4s 123us/step - loss: 0.0315 - acc: 0.9897\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 4s 123us/step - loss: 0.0319 - acc: 0.9908\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 4s 122us/step - loss: 0.0404 - acc: 0.9875\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 4s 120us/step - loss: 0.0444 - acc: 0.9870\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 4s 129us/step - loss: 0.0284 - acc: 0.9907\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 4s 123us/step - loss: 0.0322 - acc: 0.9904\n",
      "30000/30000 [==============================] - 1s 43us/step\n",
      "30000/30000 [==============================] - 1s 33us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=30, num_neurons=256, optimizer_algo=adam, total= 2.0min\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=30, num_neurons=256, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 5s 159us/step - loss: 0.2708 - acc: 0.9172\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 4s 134us/step - loss: 0.1254 - acc: 0.9607\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 4s 134us/step - loss: 0.0943 - acc: 0.9700\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.0754 - acc: 0.9763\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 4s 132us/step - loss: 0.0793 - acc: 0.9735\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 4s 131us/step - loss: 0.0673 - acc: 0.9781\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 4s 134us/step - loss: 0.0566 - acc: 0.9810\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 4s 134us/step - loss: 0.0506 - acc: 0.9831\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 4s 133us/step - loss: 0.0578 - acc: 0.9815\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 4s 133us/step - loss: 0.0522 - acc: 0.9835\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 4s 134us/step - loss: 0.0531 - acc: 0.9832\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 4s 134us/step - loss: 0.0512 - acc: 0.9834\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 4s 143us/step - loss: 0.0374 - acc: 0.9877\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.0426 - acc: 0.9863\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 4s 135us/step - loss: 0.0444 - acc: 0.9860\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.0478 - acc: 0.9852\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 4s 132us/step - loss: 0.0361 - acc: 0.9890\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 4s 132us/step - loss: 0.0431 - acc: 0.9866\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 4s 129us/step - loss: 0.0397 - acc: 0.9882\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 4s 130us/step - loss: 0.0388 - acc: 0.9872\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 4s 135us/step - loss: 0.0412 - acc: 0.9873\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.0421 - acc: 0.9870\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 4s 141us/step - loss: 0.0391 - acc: 0.9878\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 4s 133us/step - loss: 0.0434 - acc: 0.9872\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 4s 135us/step - loss: 0.0386 - acc: 0.9881\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 4s 134us/step - loss: 0.0390 - acc: 0.9883\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 4s 134us/step - loss: 0.0368 - acc: 0.9893\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 4s 134us/step - loss: 0.0338 - acc: 0.9898\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 0.0349 - acc: 0.9895\n",
      "30000/30000 [==============================] - 1s 44us/step\n",
      "30000/30000 [==============================] - 1s 34us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=30, num_neurons=256, optimizer_algo=adam, total= 2.1min\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=30, num_neurons=512, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 5s 178us/step - loss: 1.6658 - acc: 0.6282\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 5s 164us/step - loss: 0.9338 - acc: 0.8137\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 5s 158us/step - loss: 0.6759 - acc: 0.8469\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 0.5611 - acc: 0.8644\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 0.4970 - acc: 0.8741\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 5s 155us/step - loss: 0.4563 - acc: 0.8812\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 5s 159us/step - loss: 0.4279 - acc: 0.8872\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 5s 160us/step - loss: 0.4069 - acc: 0.8912\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 5s 154us/step - loss: 0.3909 - acc: 0.8933\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 5s 172us/step - loss: 0.3780 - acc: 0.8966\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 5s 163us/step - loss: 0.3672 - acc: 0.8984\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 0.3582 - acc: 0.8999\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 0.3506 - acc: 0.9029\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 5s 165us/step - loss: 0.3440 - acc: 0.9032\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 5s 159us/step - loss: 0.3384 - acc: 0.9048\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 5s 155us/step - loss: 0.3331 - acc: 0.9056\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 4s 148us/step - loss: 0.3284 - acc: 0.9072\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 5s 156us/step - loss: 0.3243 - acc: 0.9087\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 5s 160us/step - loss: 0.3202 - acc: 0.9099\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 5s 155us/step - loss: 0.3172 - acc: 0.9110\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 5s 152us/step - loss: 0.3138 - acc: 0.9117\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 5s 155us/step - loss: 0.3109 - acc: 0.9122\n",
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 5s 165us/step - loss: 0.3077 - acc: 0.9138\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 5s 155us/step - loss: 0.3052 - acc: 0.9134\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 5s 156us/step - loss: 0.3031 - acc: 0.9143\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 5s 157us/step - loss: 0.3008 - acc: 0.9149\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 5s 164us/step - loss: 0.2984 - acc: 0.9157\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 0.2966 - acc: 0.9165\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 4s 147us/step - loss: 0.2944 - acc: 0.9174\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 4s 146us/step - loss: 0.2924 - acc: 0.9174\n",
      "30000/30000 [==============================] - 2s 72us/step\n",
      "30000/30000 [==============================] - 2s 56us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=30, num_neurons=512, optimizer_algo=sgd, total= 2.4min\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=30, num_neurons=512, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 5s 175us/step - loss: 1.6765 - acc: 0.6317\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 4s 147us/step - loss: 0.9301 - acc: 0.8153\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 4s 146us/step - loss: 0.6708 - acc: 0.8494\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 5s 154us/step - loss: 0.5576 - acc: 0.8652\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 5s 156us/step - loss: 0.4957 - acc: 0.8736\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 4s 148us/step - loss: 0.4559 - acc: 0.8810\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 4s 150us/step - loss: 0.4285 - acc: 0.8852\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 5s 153us/step - loss: 0.4083 - acc: 0.8885\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 5s 154us/step - loss: 0.3922 - acc: 0.8904\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 4s 146us/step - loss: 0.3800 - acc: 0.8932\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 5s 155us/step - loss: 0.3697 - acc: 0.8956\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 5s 152us/step - loss: 0.3612 - acc: 0.8978\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 4s 147us/step - loss: 0.3537 - acc: 0.8992\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 4s 148us/step - loss: 0.3471 - acc: 0.9013\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 4s 147us/step - loss: 0.3416 - acc: 0.9026\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 5s 152us/step - loss: 0.3367 - acc: 0.9031\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 5s 152us/step - loss: 0.3319 - acc: 0.9045\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 4s 148us/step - loss: 0.3279 - acc: 0.9056\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 4s 146us/step - loss: 0.3243 - acc: 0.9064\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 5s 152us/step - loss: 0.3205 - acc: 0.9065\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 5s 153us/step - loss: 0.3175 - acc: 0.9089\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 5s 155us/step - loss: 0.3148 - acc: 0.9095\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 5s 157us/step - loss: 0.3117 - acc: 0.9096\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 5s 153us/step - loss: 0.3094 - acc: 0.9102\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 4s 146us/step - loss: 0.3069 - acc: 0.9113\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 4s 149us/step - loss: 0.3049 - acc: 0.9113\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 5s 152us/step - loss: 0.3026 - acc: 0.9121\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 4s 150us/step - loss: 0.3003 - acc: 0.9126\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 4s 146us/step - loss: 0.2983 - acc: 0.9130\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 4s 145us/step - loss: 0.2962 - acc: 0.9141\n",
      "30000/30000 [==============================] - 2s 63us/step\n",
      "30000/30000 [==============================] - 2s 52us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=30, num_neurons=512, optimizer_algo=sgd, total= 2.3min\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=30, num_neurons=512, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 9s 312us/step - loss: 0.2903 - acc: 0.9136\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 8s 269us/step - loss: 0.1284 - acc: 0.9601\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 9s 286us/step - loss: 0.0957 - acc: 0.9698\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 8s 270us/step - loss: 0.0955 - acc: 0.9697\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 8s 277us/step - loss: 0.0872 - acc: 0.9732\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 8s 275us/step - loss: 0.0771 - acc: 0.9754\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 8s 272us/step - loss: 0.0728 - acc: 0.9770\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 8s 276us/step - loss: 0.0721 - acc: 0.9778\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 8s 273us/step - loss: 0.0656 - acc: 0.9802\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 9s 285us/step - loss: 0.0689 - acc: 0.9786\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 8s 267us/step - loss: 0.0665 - acc: 0.9795\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 8s 269us/step - loss: 0.0641 - acc: 0.9810\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 8s 269us/step - loss: 0.0592 - acc: 0.9829\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 8s 270us/step - loss: 0.0646 - acc: 0.9813\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 8s 279us/step - loss: 0.0603 - acc: 0.9830\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 8s 274us/step - loss: 0.0624 - acc: 0.9834\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 8s 273us/step - loss: 0.0544 - acc: 0.9851\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 8s 282us/step - loss: 0.0528 - acc: 0.9850\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 8s 267us/step - loss: 0.0563 - acc: 0.9843\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 8s 282us/step - loss: 0.0672 - acc: 0.9825\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 8s 283us/step - loss: 0.0575 - acc: 0.9852\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 9s 287us/step - loss: 0.0528 - acc: 0.9863\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 8s 278us/step - loss: 0.0467 - acc: 0.9869\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 8s 281us/step - loss: 0.0448 - acc: 0.9885\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 9s 284us/step - loss: 0.0609 - acc: 0.9853\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 8s 273us/step - loss: 0.0426 - acc: 0.9884\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 8s 274us/step - loss: 0.0534 - acc: 0.9863\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 9s 285us/step - loss: 0.0511 - acc: 0.9872\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 9s 291us/step - loss: 0.0609 - acc: 0.9855\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 9s 289us/step - loss: 0.0457 - acc: 0.9885\n",
      "30000/30000 [==============================] - 2s 70us/step\n",
      "30000/30000 [==============================] - 2s 53us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=30, num_neurons=512, optimizer_algo=adam, total= 4.2min\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=30, num_neurons=512, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 9s 313us/step - loss: 0.2910 - acc: 0.9141\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 8s 267us/step - loss: 0.1294 - acc: 0.9595\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 8s 268us/step - loss: 0.1103 - acc: 0.9655\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 8s 279us/step - loss: 0.1003 - acc: 0.9681\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 8s 268us/step - loss: 0.0948 - acc: 0.9710\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 8s 276us/step - loss: 0.0752 - acc: 0.9763\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 8s 272us/step - loss: 0.0796 - acc: 0.9765\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 8s 273us/step - loss: 0.0766 - acc: 0.9774\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 9s 286us/step - loss: 0.0694 - acc: 0.9801\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 8s 270us/step - loss: 0.0619 - acc: 0.9815\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 8s 271us/step - loss: 0.0743 - acc: 0.9794\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 8s 270us/step - loss: 0.0703 - acc: 0.9810\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 8s 279us/step - loss: 0.0792 - acc: 0.9795\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 8s 272us/step - loss: 0.0658 - acc: 0.9821\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 8s 272us/step - loss: 0.0618 - acc: 0.9836\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 8s 273us/step - loss: 0.0638 - acc: 0.9827\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 8s 272us/step - loss: 0.0616 - acc: 0.9833\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 9s 284us/step - loss: 0.0722 - acc: 0.9818\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 8s 269us/step - loss: 0.0441 - acc: 0.9883\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 8s 275us/step - loss: 0.0459 - acc: 0.9879\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 8s 273us/step - loss: 0.0618 - acc: 0.9841\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 8s 271us/step - loss: 0.0721 - acc: 0.9828\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 8s 279us/step - loss: 0.0502 - acc: 0.9878\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 9s 286us/step - loss: 0.0589 - acc: 0.9852\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 8s 277us/step - loss: 0.0497 - acc: 0.9874\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 9s 288us/step - loss: 0.0505 - acc: 0.9873\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 8s 280us/step - loss: 0.0445 - acc: 0.9888\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 9s 286us/step - loss: 0.0523 - acc: 0.9880\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 8s 278us/step - loss: 0.0523 - acc: 0.9876\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 8s 273us/step - loss: 0.0583 - acc: 0.9873\n",
      "30000/30000 [==============================] - ETA:  - 2s 71us/step\n",
      "30000/30000 [==============================] - 2s 57us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=30, num_neurons=512, optimizer_algo=adam, total= 4.2min\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=30, num_neurons=784, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 8s 263us/step - loss: 1.6313 - acc: 0.6180\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 7s 234us/step - loss: 0.9013 - acc: 0.8147\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 7s 231us/step - loss: 0.6573 - acc: 0.8501\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 7s 226us/step - loss: 0.5500 - acc: 0.8642\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 7s 226us/step - loss: 0.4892 - acc: 0.8749\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 7s 231us/step - loss: 0.4511 - acc: 0.8817\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 7s 231us/step - loss: 0.4242 - acc: 0.8865\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 7s 235us/step - loss: 0.4041 - acc: 0.8910\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 7s 221us/step - loss: 0.3885 - acc: 0.8938\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 7s 219us/step - loss: 0.3763 - acc: 0.8964\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 7s 222us/step - loss: 0.3660 - acc: 0.8984\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 7s 222us/step - loss: 0.3574 - acc: 0.9004\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 7s 221us/step - loss: 0.3496 - acc: 0.9031\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 7s 227us/step - loss: 0.3440 - acc: 0.9044\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 7s 222us/step - loss: 0.3381 - acc: 0.9045\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 7s 221us/step - loss: 0.3335 - acc: 0.9068\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 7s 224us/step - loss: 0.3286 - acc: 0.9080\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 7s 220us/step - loss: 0.3245 - acc: 0.9087\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 7s 220us/step - loss: 0.3212 - acc: 0.9103\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 7s 227us/step - loss: 0.3180 - acc: 0.9102\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 7s 221us/step - loss: 0.3149 - acc: 0.9118\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 7s 222us/step - loss: 0.3121 - acc: 0.9124\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 7s 224us/step - loss: 0.3097 - acc: 0.9132\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 7s 218us/step - loss: 0.3073 - acc: 0.9135\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 7s 222us/step - loss: 0.3044 - acc: 0.9145\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 7s 238us/step - loss: 0.3024 - acc: 0.9153\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 7s 220us/step - loss: 0.3007 - acc: 0.9152\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 7s 223us/step - loss: 0.2986 - acc: 0.9163\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 7s 220us/step - loss: 0.2969 - acc: 0.9174\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 7s 221us/step - loss: 0.2949 - acc: 0.9181\n",
      "30000/30000 [==============================] - 2s 80us/step\n",
      "30000/30000 [==============================] - 2s 67us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=30, num_neurons=784, optimizer_algo=sgd, total= 3.4min\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=30, num_neurons=784, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 8s 260us/step - loss: 1.6225 - acc: 0.6323\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 7s 220us/step - loss: 0.8890 - acc: 0.8210\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 7s 220us/step - loss: 0.6474 - acc: 0.8523\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 7s 224us/step - loss: 0.5424 - acc: 0.8665\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 7s 221us/step - loss: 0.4843 - acc: 0.8758\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 7s 223us/step - loss: 0.4474 - acc: 0.8806\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 7s 228us/step - loss: 0.4217 - acc: 0.8844\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 6s 214us/step - loss: 0.4028 - acc: 0.8888\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 7s 218us/step - loss: 0.3883 - acc: 0.8915\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 7s 223us/step - loss: 0.3762 - acc: 0.8933\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 7s 222us/step - loss: 0.3666 - acc: 0.8956\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 7s 222us/step - loss: 0.3585 - acc: 0.8987\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 7s 227us/step - loss: 0.3520 - acc: 0.8992\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 7s 221us/step - loss: 0.3454 - acc: 0.9016\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 7s 222us/step - loss: 0.3402 - acc: 0.9018\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 7s 223us/step - loss: 0.3354 - acc: 0.9042\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 7s 222us/step - loss: 0.3311 - acc: 0.9048\n",
      "Epoch 18/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 7s 220us/step - loss: 0.3276 - acc: 0.9054\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 7s 229us/step - loss: 0.3240 - acc: 0.9061\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 7s 223us/step - loss: 0.3206 - acc: 0.9071\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 7s 222us/step - loss: 0.3179 - acc: 0.9081\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 7s 238us/step - loss: 0.3150 - acc: 0.9081\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 7s 223us/step - loss: 0.3126 - acc: 0.9098\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 7s 220us/step - loss: 0.3105 - acc: 0.9089\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 7s 234us/step - loss: 0.3080 - acc: 0.9109\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 7s 219us/step - loss: 0.3056 - acc: 0.9112\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 6s 215us/step - loss: 0.3039 - acc: 0.9109\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 7s 223us/step - loss: 0.3021 - acc: 0.9121\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 7s 223us/step - loss: 0.3002 - acc: 0.9124\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 7s 223us/step - loss: 0.2985 - acc: 0.9126\n",
      "30000/30000 [==============================] - 3s 95us/step\n",
      "30000/30000 [==============================] - 2s 76us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=30, num_neurons=784, optimizer_algo=sgd, total= 3.4min\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=30, num_neurons=784, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 14s 455us/step - loss: 0.3138 - acc: 0.9105\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 12s 417us/step - loss: 0.1361 - acc: 0.9583\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 13s 429us/step - loss: 0.1011 - acc: 0.9673\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 13s 425us/step - loss: 0.1059 - acc: 0.9669\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 14s 458us/step - loss: 0.0961 - acc: 0.9705\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 13s 436us/step - loss: 0.1038 - acc: 0.9703\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 13s 424us/step - loss: 0.0930 - acc: 0.9731\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 13s 425us/step - loss: 0.0824 - acc: 0.9761\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 13s 424us/step - loss: 0.0706 - acc: 0.9799\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 13s 435us/step - loss: 0.0869 - acc: 0.9764\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 13s 421us/step - loss: 0.0892 - acc: 0.9777\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 13s 419us/step - loss: 0.0771 - acc: 0.9796\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 13s 429us/step - loss: 0.0837 - acc: 0.9777\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 13s 418us/step - loss: 0.0789 - acc: 0.9810\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 12s 415us/step - loss: 0.0714 - acc: 0.9819\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 13s 425us/step - loss: 0.0728 - acc: 0.9818\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 13s 420us/step - loss: 0.0749 - acc: 0.9817\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 13s 419us/step - loss: 0.0866 - acc: 0.9803\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 13s 437us/step - loss: 0.0862 - acc: 0.9812\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 13s 425us/step - loss: 0.0730 - acc: 0.9836\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 13s 423us/step - loss: 0.0707 - acc: 0.9838\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 13s 436us/step - loss: 0.0806 - acc: 0.9838\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 13s 422us/step - loss: 0.0836 - acc: 0.9825\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 13s 436us/step - loss: 0.0834 - acc: 0.9829\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 13s 427us/step - loss: 0.0701 - acc: 0.9854\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 13s 418us/step - loss: 0.0816 - acc: 0.9842\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 13s 422us/step - loss: 0.0803 - acc: 0.9842\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 13s 433us/step - loss: 0.0834 - acc: 0.9831\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 13s 430us/step - loss: 0.0701 - acc: 0.9866\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 13s 420us/step - loss: 0.0614 - acc: 0.9881\n",
      "30000/30000 [==============================] - 3s 97us/step\n",
      "30000/30000 [==============================] - 2s 79us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=30, num_neurons=784, optimizer_algo=adam, total= 6.5min\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=30, num_neurons=784, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 14s 474us/step - loss: 0.2919 - acc: 0.9117\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 13s 426us/step - loss: 0.1251 - acc: 0.9610\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 13s 420us/step - loss: 0.1091 - acc: 0.9668\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 13s 431us/step - loss: 0.1089 - acc: 0.9665\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 12s 414us/step - loss: 0.1080 - acc: 0.9678\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 13s 422us/step - loss: 0.0872 - acc: 0.9745\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 13s 431us/step - loss: 0.0975 - acc: 0.9728\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 13s 418us/step - loss: 0.0861 - acc: 0.97600s - loss: 0.\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 12s 415us/step - loss: 0.0783 - acc: 0.9781\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 13s 425us/step - loss: 0.0919 - acc: 0.97660s - loss: 0.0886 - acc: 0. - ETA: 0s - loss: 0.0902 - acc: 0\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 13s 427us/step - loss: 0.0815 - acc: 0.9788\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 13s 422us/step - loss: 0.0790 - acc: 0.9792\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 13s 420us/step - loss: 0.0856 - acc: 0.9799\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 13s 426us/step - loss: 0.0693 - acc: 0.9833\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 13s 422us/step - loss: 0.0808 - acc: 0.98021s - lo\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 13s 427us/step - loss: 0.0784 - acc: 0.98200s - loss: 0.0788 -\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 13s 436us/step - loss: 0.0719 - acc: 0.9836\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 13s 446us/step - loss: 0.0861 - acc: 0.9815\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 13s 435us/step - loss: 0.0895 - acc: 0.9806\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 13s 435us/step - loss: 0.0885 - acc: 0.9809\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 13s 440us/step - loss: 0.0707 - acc: 0.9848\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 13s 423us/step - loss: 0.0780 - acc: 0.9838\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 13s 426us/step - loss: 0.0808 - acc: 0.98231\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 13s 425us/step - loss: 0.0793 - acc: 0.9837\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 13s 437us/step - loss: 0.0869 - acc: 0.9833\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 13s 441us/step - loss: 0.0720 - acc: 0.9857\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 13s 419us/step - loss: 0.0764 - acc: 0.9861\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 13s 419us/step - loss: 0.0651 - acc: 0.9879\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 13s 434us/step - loss: 0.0783 - acc: 0.9848\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 13s 427us/step - loss: 0.0650 - acc: 0.9879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 10s 331us/step\n",
      "30000/30000 [==============================] - 3s 88us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=30, num_neurons=784, optimizer_algo=adam, total= 6.7min\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=30, num_neurons=1024, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 11s 377us/step - loss: 1.6242 - acc: 0.6142\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 9s 288us/step - loss: 0.8820 - acc: 0.8180\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 9s 288us/step - loss: 0.6431 - acc: 0.8510\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 9s 288us/step - loss: 0.5398 - acc: 0.8655\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 8s 283us/step - loss: 0.4818 - acc: 0.8752\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 9s 284us/step - loss: 0.4454 - acc: 0.8827\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 8s 282us/step - loss: 0.4197 - acc: 0.8867\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 9s 284us/step - loss: 0.4006 - acc: 0.8903\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 9s 295us/step - loss: 0.3857 - acc: 0.8948\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 8s 282us/step - loss: 0.3741 - acc: 0.8963\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 9s 285us/step - loss: 0.3646 - acc: 0.8991\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 9s 290us/step - loss: 0.3555 - acc: 0.9006\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 9s 290us/step - loss: 0.3493 - acc: 0.9018\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 9s 285us/step - loss: 0.3429 - acc: 0.9027\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 9s 285us/step - loss: 0.3370 - acc: 0.9053\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 9s 287us/step - loss: 0.3328 - acc: 0.9067\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 8s 282us/step - loss: 0.3281 - acc: 0.9069\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 9s 296us/step - loss: 0.3244 - acc: 0.9085\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 9s 286us/step - loss: 0.3208 - acc: 0.9106\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 8s 283us/step - loss: 0.3176 - acc: 0.9109\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 9s 284us/step - loss: 0.3151 - acc: 0.9112\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 9s 284us/step - loss: 0.3122 - acc: 0.9116\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 9s 292us/step - loss: 0.3094 - acc: 0.9128\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 9s 283us/step - loss: 0.3070 - acc: 0.9147\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 8s 283us/step - loss: 0.3051 - acc: 0.9137\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 9s 284us/step - loss: 0.3029 - acc: 0.9146\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 9s 295us/step - loss: 0.3010 - acc: 0.9159\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 8s 281us/step - loss: 0.2991 - acc: 0.9160\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 9s 289us/step - loss: 0.2969 - acc: 0.9173\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 9s 291us/step - loss: 0.2954 - acc: 0.9168\n",
      "30000/30000 [==============================] - 3s 104us/step\n",
      "30000/30000 [==============================] - 3s 99us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=30, num_neurons=1024, optimizer_algo=sgd, total= 4.6min\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=30, num_neurons=1024, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 10s 330us/step - loss: 1.6031 - acc: 0.6225\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 9s 284us/step - loss: 0.8747 - acc: 0.8189\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 9s 285us/step - loss: 0.6394 - acc: 0.8514\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 8s 281us/step - loss: 0.5378 - acc: 0.8668\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 9s 286us/step - loss: 0.4812 - acc: 0.8742\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 9s 295us/step - loss: 0.4451 - acc: 0.8815\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 9s 287us/step - loss: 0.4207 - acc: 0.8852\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 9s 285us/step - loss: 0.4016 - acc: 0.8880\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 8s 282us/step - loss: 0.3878 - acc: 0.8915\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 9s 294us/step - loss: 0.3760 - acc: 0.8948\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 8s 283us/step - loss: 0.3666 - acc: 0.8962\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 9s 283us/step - loss: 0.3589 - acc: 0.8967\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 8s 283us/step - loss: 0.3517 - acc: 0.8995\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 9s 289us/step - loss: 0.3462 - acc: 0.9002\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 9s 292us/step - loss: 0.3409 - acc: 0.9011\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 8s 280us/step - loss: 0.3365 - acc: 0.9029\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 9s 302us/step - loss: 0.3321 - acc: 0.9036\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 9s 305us/step - loss: 0.3284 - acc: 0.9044\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 9s 290us/step - loss: 0.3247 - acc: 0.9054\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 9s 286us/step - loss: 0.3216 - acc: 0.9066\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 9s 286us/step - loss: 0.3186 - acc: 0.9070\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 9s 289us/step - loss: 0.3162 - acc: 0.9079\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 9s 287us/step - loss: 0.3133 - acc: 0.9091\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 9s 293us/step - loss: 0.3113 - acc: 0.9103\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 9s 288us/step - loss: 0.3094 - acc: 0.9095\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 9s 286us/step - loss: 0.3071 - acc: 0.9107\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 9s 284us/step - loss: 0.3052 - acc: 0.9115\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 9s 290us/step - loss: 0.3032 - acc: 0.9116\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 9s 297us/step - loss: 0.3016 - acc: 0.9124\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 9s 294us/step - loss: 0.2999 - acc: 0.9127\n",
      "30000/30000 [==============================] - 3s 110us/step\n",
      "30000/30000 [==============================] - 3s 91us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=30, num_neurons=1024, optimizer_algo=sgd, total= 4.4min\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=30, num_neurons=1024, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 18s 614us/step - loss: 0.3271 - acc: 0.90971s - l\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 17s 565us/step - loss: 0.1329 - acc: 0.9585\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 18s 612us/step - loss: 0.1080 - acc: 0.9659\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 17s 581us/step - loss: 0.1062 - acc: 0.9675\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 17s 581us/step - loss: 0.1034 - acc: 0.9690\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 17s 566us/step - loss: 0.1002 - acc: 0.9720\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 17s 557us/step - loss: 0.0968 - acc: 0.9738\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 18s 602us/step - loss: 0.0994 - acc: 0.9734\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 17s 579us/step - loss: 0.0925 - acc: 0.9760\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 17s 580us/step - loss: 0.0829 - acc: 0.9781\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 17s 561us/step - loss: 0.1005 - acc: 0.9761\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 17s 555us/step - loss: 0.0974 - acc: 0.9771\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 17s 569us/step - loss: 0.0935 - acc: 0.9785\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 17s 557us/step - loss: 0.1035 - acc: 0.9774\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 17s 552us/step - loss: 0.1028 - acc: 0.9777\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 17s 556us/step - loss: 0.0812 - acc: 0.9816\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 17s 552us/step - loss: 0.0917 - acc: 0.9806\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 17s 555us/step - loss: 0.0859 - acc: 0.9819\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 17s 553us/step - loss: 0.0863 - acc: 0.9818\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 17s 557us/step - loss: 0.1021 - acc: 0.9801\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 17s 552us/step - loss: 0.0762 - acc: 0.9852\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 17s 552us/step - loss: 0.0794 - acc: 0.98480s - loss: 0.0798 - acc:\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 17s 560us/step - loss: 0.0911 - acc: 0.9832\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 16s 550us/step - loss: 0.0811 - acc: 0.9846\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 17s 559us/step - loss: 0.0843 - acc: 0.9840\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 17s 557us/step - loss: 0.0989 - acc: 0.9827\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 17s 557us/step - loss: 0.0777 - acc: 0.98620s - loss: 0.0777 - acc: 0.9\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 17s 564us/step - loss: 0.0823 - acc: 0.9851\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 17s 552us/step - loss: 0.0823 - acc: 0.9854\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 17s 560us/step - loss: 0.0912 - acc: 0.9846\n",
      "30000/30000 [==============================] - 4s 131us/step\n",
      "30000/30000 [==============================] - 3s 95us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=30, num_neurons=1024, optimizer_algo=adam, total= 8.6min\n",
      "[CV] activation=sigmoid, dropout=0.0, epochs=30, num_neurons=1024, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 18s 614us/step - loss: 0.3693 - acc: 0.9091\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 17s 564us/step - loss: 0.1354 - acc: 0.9584\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 17s 553us/step - loss: 0.1136 - acc: 0.9645\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 17s 563us/step - loss: 0.1086 - acc: 0.9671\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 17s 554us/step - loss: 0.1062 - acc: 0.9691\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 17s 561us/step - loss: 0.0899 - acc: 0.9744\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 17s 559us/step - loss: 0.0932 - acc: 0.9750\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 17s 553us/step - loss: 0.0898 - acc: 0.9758\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 17s 562us/step - loss: 0.0808 - acc: 0.9782\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 17s 555us/step - loss: 0.0986 - acc: 0.9748\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 17s 563us/step - loss: 0.0923 - acc: 0.9776\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 17s 553us/step - loss: 0.0728 - acc: 0.9814\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 17s 554us/step - loss: 0.0865 - acc: 0.9784\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 17s 560us/step - loss: 0.0952 - acc: 0.9786\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 17s 555us/step - loss: 0.0851 - acc: 0.9810\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 17s 561us/step - loss: 0.0929 - acc: 0.9795\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 17s 556us/step - loss: 0.0942 - acc: 0.9801\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 17s 560us/step - loss: 0.1012 - acc: 0.9796\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 17s 557us/step - loss: 0.0805 - acc: 0.9828\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 17s 560us/step - loss: 0.0876 - acc: 0.9822\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 17s 563us/step - loss: 0.0736 - acc: 0.9850\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 17s 565us/step - loss: 0.0851 - acc: 0.9833\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 17s 564us/step - loss: 0.0942 - acc: 0.9829\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 17s 556us/step - loss: 0.0800 - acc: 0.9854\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 17s 556us/step - loss: 0.0867 - acc: 0.9845\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 17s 564us/step - loss: 0.0699 - acc: 0.9858\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 17s 555us/step - loss: 0.0808 - acc: 0.9849\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 17s 562us/step - loss: 0.0752 - acc: 0.9867\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 17s 555us/step - loss: 0.0804 - acc: 0.9857\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 17s 559us/step - loss: 0.0845 - acc: 0.9864\n",
      "30000/30000 [==============================] - 3s 108us/step\n",
      "30000/30000 [==============================] - 3s 93us/step\n",
      "[CV]  activation=sigmoid, dropout=0.0, epochs=30, num_neurons=1024, optimizer_algo=adam, total= 8.5min\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=10, num_neurons=256, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 1.8772 - acc: 0.3908\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 3s 100us/step - loss: 1.1703 - acc: 0.6812\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 3s 96us/step - loss: 0.8642 - acc: 0.7629\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 3s 96us/step - loss: 0.7233 - acc: 0.7946\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 3s 96us/step - loss: 0.6393 - acc: 0.8155\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 3s 97us/step - loss: 0.5866 - acc: 0.8314\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 3s 102us/step - loss: 0.5477 - acc: 0.8399\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 3s 100us/step - loss: 0.5188 - acc: 0.8475\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 3s 96us/step - loss: 0.4959 - acc: 0.8537\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 3s 100us/step - loss: 0.4772 - acc: 0.8598\n",
      "30000/30000 [==============================] - 2s 58us/step\n",
      "30000/30000 [==============================] - 1s 40us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=10, num_neurons=256, optimizer_algo=sgd, total=  33.0s\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=10, num_neurons=256, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 4s 148us/step - loss: 1.8519 - acc: 0.4041\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 3s 105us/step - loss: 1.1439 - acc: 0.6915\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 3s 103us/step - loss: 0.8517 - acc: 0.7646\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 3s 105us/step - loss: 0.7164 - acc: 0.7962\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 3s 105us/step - loss: 0.6390 - acc: 0.8124\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 3s 112us/step - loss: 0.5832 - acc: 0.8281\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 3s 109us/step - loss: 0.5472 - acc: 0.8396\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 3s 109us/step - loss: 0.5172 - acc: 0.8486\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 3s 102us/step - loss: 0.4944 - acc: 0.8522\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 3s 110us/step - loss: 0.4760 - acc: 0.8590\n",
      "30000/30000 [==============================] - 2s 53us/step\n",
      "30000/30000 [==============================] - 1s 39us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=10, num_neurons=256, optimizer_algo=sgd, total=  35.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] activation=sigmoid, dropout=0.3, epochs=10, num_neurons=256, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 6s 199us/step - loss: 0.3198 - acc: 0.9023\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 5s 152us/step - loss: 0.1827 - acc: 0.9447\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 5s 156us/step - loss: 0.1556 - acc: 0.9521\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 5s 152us/step - loss: 0.1458 - acc: 0.9556\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 5s 152us/step - loss: 0.1316 - acc: 0.9583\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 4s 147us/step - loss: 0.1249 - acc: 0.9607\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 4s 147us/step - loss: 0.1105 - acc: 0.9651\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 4s 145us/step - loss: 0.1102 - acc: 0.9652\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 5s 152us/step - loss: 0.1109 - acc: 0.9648\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 4s 146us/step - loss: 0.1051 - acc: 0.9667\n",
      "30000/30000 [==============================] - 2s 52us/step\n",
      "30000/30000 [==============================] - 1s 37us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=10, num_neurons=256, optimizer_algo=adam, total=  48.8s\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=10, num_neurons=256, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 6s 201us/step - loss: 0.3272 - acc: 0.8992\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 4s 140us/step - loss: 0.1841 - acc: 0.9430\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.1558 - acc: 0.9511\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 4s 141us/step - loss: 0.1449 - acc: 0.9544\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 4s 141us/step - loss: 0.1268 - acc: 0.9611\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.1250 - acc: 0.9613\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 4s 145us/step - loss: 0.1199 - acc: 0.9636\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 4s 138us/step - loss: 0.1194 - acc: 0.9629\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 4s 141us/step - loss: 0.1126 - acc: 0.9651\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.0993 - acc: 0.9691\n",
      "30000/30000 [==============================] - 2s 51us/step\n",
      "30000/30000 [==============================] - 1s 37us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=10, num_neurons=256, optimizer_algo=adam, total=  45.9s\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=10, num_neurons=512, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 7s 218us/step - loss: 1.8145 - acc: 0.4162\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 5s 179us/step - loss: 1.0861 - acc: 0.7028\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 5s 179us/step - loss: 0.8117 - acc: 0.7689\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 5s 183us/step - loss: 0.6802 - acc: 0.8035\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 5s 180us/step - loss: 0.6118 - acc: 0.8213\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 5s 179us/step - loss: 0.5573 - acc: 0.8364\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 5s 177us/step - loss: 0.5216 - acc: 0.8453\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 5s 179us/step - loss: 0.5000 - acc: 0.8519\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 5s 182us/step - loss: 0.4790 - acc: 0.8574\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 5s 179us/step - loss: 0.4646 - acc: 0.8600\n",
      "30000/30000 [==============================] - 2s 71us/step\n",
      "30000/30000 [==============================] - 2s 54us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=10, num_neurons=512, optimizer_algo=sgd, total=  57.7s\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=10, num_neurons=512, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 7s 224us/step - loss: 1.8149 - acc: 0.4157\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 5s 177us/step - loss: 1.0842 - acc: 0.7016\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 5s 176us/step - loss: 0.8031 - acc: 0.7750\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 5s 179us/step - loss: 0.6783 - acc: 0.8027\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 5s 177us/step - loss: 0.6054 - acc: 0.8217\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 5s 178us/step - loss: 0.5604 - acc: 0.8329\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 5s 174us/step - loss: 0.5224 - acc: 0.8471\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 5s 182us/step - loss: 0.4997 - acc: 0.8501\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 5s 176us/step - loss: 0.4799 - acc: 0.8576\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 5s 177us/step - loss: 0.4671 - acc: 0.8599\n",
      "30000/30000 [==============================] - 2s 71us/step\n",
      "30000/30000 [==============================] - 2s 56us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=10, num_neurons=512, optimizer_algo=sgd, total=  57.0s\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=10, num_neurons=512, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 10s 327us/step - loss: 0.3152 - acc: 0.9048\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 9s 285us/step - loss: 0.1872 - acc: 0.9426\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 9s 296us/step - loss: 0.1701 - acc: 0.9491\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 9s 288us/step - loss: 0.1414 - acc: 0.9570\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 9s 287us/step - loss: 0.1399 - acc: 0.9591\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 9s 285us/step - loss: 0.1401 - acc: 0.9581\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 9s 287us/step - loss: 0.1376 - acc: 0.9585\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 9s 296us/step - loss: 0.1220 - acc: 0.9653\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 9s 286us/step - loss: 0.1227 - acc: 0.9647\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 9s 291us/step - loss: 0.1226 - acc: 0.9661\n",
      "30000/30000 [==============================] - 2s 72us/step\n",
      "30000/30000 [==============================] - 2s 58us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=10, num_neurons=512, optimizer_algo=adam, total= 1.5min\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=10, num_neurons=512, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 10s 338us/step - loss: 0.3157 - acc: 0.9032\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 9s 293us/step - loss: 0.1823 - acc: 0.9450\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 9s 289us/step - loss: 0.1627 - acc: 0.9501\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 9s 289us/step - loss: 0.1575 - acc: 0.9546\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 9s 285us/step - loss: 0.1432 - acc: 0.9571\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 9s 296us/step - loss: 0.1474 - acc: 0.9574 1s - l\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 9s 287us/step - loss: 0.1476 - acc: 0.9611\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 9s 286us/step - loss: 0.1246 - acc: 0.9652\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 9s 288us/step - loss: 0.1126 - acc: 0.9669\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 9s 292us/step - loss: 0.1147 - acc: 0.9675\n",
      "30000/30000 [==============================] - 2s 71us/step\n",
      "30000/30000 [==============================] - 2s 65us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=10, num_neurons=512, optimizer_algo=adam, total= 1.5min\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=10, num_neurons=784, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 9s 294us/step - loss: 1.7546 - acc: 0.4420\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 8s 251us/step - loss: 1.0402 - acc: 0.7144\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 8s 251us/step - loss: 0.7845 - acc: 0.7771\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 8s 252us/step - loss: 0.6614 - acc: 0.8074\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 8s 255us/step - loss: 0.5943 - acc: 0.8242\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 8s 252us/step - loss: 0.5501 - acc: 0.8362\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 8s 252us/step - loss: 0.5151 - acc: 0.8474\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 8s 252us/step - loss: 0.4912 - acc: 0.8537\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 8s 251us/step - loss: 0.4713 - acc: 0.8595\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 8s 251us/step - loss: 0.4542 - acc: 0.8627\n",
      "30000/30000 [==============================] - 3s 98us/step\n",
      "30000/30000 [==============================] - 2s 73us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=10, num_neurons=784, optimizer_algo=sgd, total= 1.3min\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=10, num_neurons=784, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 9s 297us/step - loss: 1.7559 - acc: 0.4428\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 8s 255us/step - loss: 1.0338 - acc: 0.7176\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 8s 253us/step - loss: 0.7771 - acc: 0.7770\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 8s 252us/step - loss: 0.6598 - acc: 0.8100\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 8s 258us/step - loss: 0.5915 - acc: 0.8244\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 8s 252us/step - loss: 0.5467 - acc: 0.8364\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 8s 253us/step - loss: 0.5154 - acc: 0.8462\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 8s 256us/step - loss: 0.4889 - acc: 0.8539\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 8s 253us/step - loss: 0.4765 - acc: 0.8566\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 8s 257us/step - loss: 0.4594 - acc: 0.8605\n",
      "30000/30000 [==============================] - 3s 90us/step\n",
      "30000/30000 [==============================] - 2s 74us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=10, num_neurons=784, optimizer_algo=sgd, total= 1.3min\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=10, num_neurons=784, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 15s 486us/step - loss: 0.3407 - acc: 0.8982\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 13s 433us/step - loss: 0.2022 - acc: 0.9381\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 13s 438us/step - loss: 0.1957 - acc: 0.9445\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 13s 437us/step - loss: 0.1828 - acc: 0.9473\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 13s 433us/step - loss: 0.1773 - acc: 0.9542\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 13s 437us/step - loss: 0.1624 - acc: 0.9562\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 13s 432us/step - loss: 0.1535 - acc: 0.9602\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 13s 436us/step - loss: 0.1623 - acc: 0.9596\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 13s 437us/step - loss: 0.1597 - acc: 0.9599\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 13s 436us/step - loss: 0.1429 - acc: 0.9634\n",
      "30000/30000 [==============================] - 3s 93us/step\n",
      "30000/30000 [==============================] - 2s 73us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=10, num_neurons=784, optimizer_algo=adam, total= 2.3min\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=10, num_neurons=784, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 14s 472us/step - loss: 0.3210 - acc: 0.9037\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 13s 435us/step - loss: 0.2100 - acc: 0.9388\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 13s 427us/step - loss: 0.2058 - acc: 0.9425\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 13s 426us/step - loss: 0.1883 - acc: 0.9491\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 13s 437us/step - loss: 0.1672 - acc: 0.9544\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 13s 428us/step - loss: 0.1745 - acc: 0.9537\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 13s 428us/step - loss: 0.1644 - acc: 0.9575\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 13s 436us/step - loss: 0.1590 - acc: 0.9610\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 13s 432us/step - loss: 0.1405 - acc: 0.9638\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 13s 430us/step - loss: 0.1484 - acc: 0.9641\n",
      "30000/30000 [==============================] - 3s 94us/step\n",
      "30000/30000 [==============================] - 2s 82us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=10, num_neurons=784, optimizer_algo=adam, total= 2.2min\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=10, num_neurons=1024, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 11s 351us/step - loss: 1.7312 - acc: 0.4532\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 9s 307us/step - loss: 1.0164 - acc: 0.7148\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 9s 309us/step - loss: 0.7698 - acc: 0.7775\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 9s 309us/step - loss: 0.6532 - acc: 0.8068\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 9s 312us/step - loss: 0.5863 - acc: 0.8249\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 9s 310us/step - loss: 0.5454 - acc: 0.8356\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 9s 306us/step - loss: 0.5126 - acc: 0.8459\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 9s 311us/step - loss: 0.4910 - acc: 0.8517\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 9s 312us/step - loss: 0.4728 - acc: 0.8571\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 9s 310us/step - loss: 0.4565 - acc: 0.8637\n",
      "30000/30000 [==============================] - 3s 109us/step\n",
      "30000/30000 [==============================] - 3s 91us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=10, num_neurons=1024, optimizer_algo=sgd, total= 1.6min\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=10, num_neurons=1024, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 11s 350us/step - loss: 1.7266 - acc: 0.4544\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 10s 318us/step - loss: 1.0126 - acc: 0.7171\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 9s 312us/step - loss: 0.7613 - acc: 0.7809\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 9s 310us/step - loss: 0.6458 - acc: 0.8089\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 9s 311us/step - loss: 0.5864 - acc: 0.8235\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 9s 311us/step - loss: 0.5391 - acc: 0.8378\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 10s 319us/step - loss: 0.5128 - acc: 0.8428\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 9s 310us/step - loss: 0.4910 - acc: 0.8535\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 9s 312us/step - loss: 0.4727 - acc: 0.8565\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 9s 313us/step - loss: 0.4582 - acc: 0.8631\n",
      "30000/30000 [==============================] - 3s 110us/step\n",
      "30000/30000 [==============================] - 3s 98us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=10, num_neurons=1024, optimizer_algo=sgd, total= 1.6min\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=10, num_neurons=1024, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 18s 605us/step - loss: 0.3722 - acc: 0.8980\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 17s 556us/step - loss: 0.2063 - acc: 0.9374\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 17s 557us/step - loss: 0.2140 - acc: 0.9402\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 16s 549us/step - loss: 0.2107 - acc: 0.9452\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 17s 555us/step - loss: 0.2134 - acc: 0.9474\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 17s 554us/step - loss: 0.2068 - acc: 0.9516\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 17s 559us/step - loss: 0.1999 - acc: 0.9548\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 17s 553us/step - loss: 0.2122 - acc: 0.9553\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 17s 554us/step - loss: 0.2011 - acc: 0.9593\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 17s 562us/step - loss: 0.2074 - acc: 0.9583\n",
      "30000/30000 [==============================] - 3s 111us/step\n",
      "30000/30000 [==============================] - 3s 95us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=10, num_neurons=1024, optimizer_algo=adam, total= 2.9min\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=10, num_neurons=1024, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 18s 605us/step - loss: 0.3367 - acc: 0.9001\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 17s 562us/step - loss: 0.2223 - acc: 0.9352\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 17s 560us/step - loss: 0.2305 - acc: 0.9408\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 17s 563us/step - loss: 0.2266 - acc: 0.9444\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 17s 557us/step - loss: 0.2198 - acc: 0.9478\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 17s 564us/step - loss: 0.2006 - acc: 0.9545\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 17s 560us/step - loss: 0.2128 - acc: 0.9552\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 17s 556us/step - loss: 0.2202 - acc: 0.9548\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 17s 559us/step - loss: 0.2027 - acc: 0.9607\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 17s 559us/step - loss: 0.2109 - acc: 0.9597\n",
      "30000/30000 [==============================] - 3s 110us/step\n",
      "30000/30000 [==============================] - 3s 94us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=10, num_neurons=1024, optimizer_algo=adam, total= 2.9min\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=20, num_neurons=256, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 5s 158us/step - loss: 1.8451 - acc: 0.4045\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 4s 120us/step - loss: 1.1380 - acc: 0.6934\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 3s 113us/step - loss: 0.8483 - acc: 0.7632\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 3s 113us/step - loss: 0.7167 - acc: 0.7933\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 3s 114us/step - loss: 0.6339 - acc: 0.8169\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 3s 113us/step - loss: 0.5827 - acc: 0.8293\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 3s 116us/step - loss: 0.5446 - acc: 0.8383\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 3s 116us/step - loss: 0.5137 - acc: 0.8506\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 3s 113us/step - loss: 0.4941 - acc: 0.8540\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 3s 113us/step - loss: 0.4757 - acc: 0.8585\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 3s 112us/step - loss: 0.4596 - acc: 0.8656\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 3s 112us/step - loss: 0.4491 - acc: 0.8663\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 3s 116us/step - loss: 0.4420 - acc: 0.8686\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 122us/step - loss: 0.4251 - acc: 0.8722\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 3s 117us/step - loss: 0.4213 - acc: 0.8744\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.4093 - acc: 0.8807\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 3s 110us/step - loss: 0.4039 - acc: 0.8801\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 3s 110us/step - loss: 0.3973 - acc: 0.8836\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 3s 115us/step - loss: 0.3940 - acc: 0.8833\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 3s 116us/step - loss: 0.3866 - acc: 0.8852\n",
      "30000/30000 [==============================] - 2s 59us/step\n",
      "30000/30000 [==============================] - 1s 41us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=20, num_neurons=256, optimizer_algo=sgd, total= 1.2min\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=20, num_neurons=256, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 5s 174us/step - loss: 1.8555 - acc: 0.4076\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 3s 114us/step - loss: 1.1492 - acc: 0.6892\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 3s 113us/step - loss: 0.8503 - acc: 0.7659\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 4s 118us/step - loss: 0.7117 - acc: 0.7950\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 3s 112us/step - loss: 0.6308 - acc: 0.8200\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 3s 113us/step - loss: 0.5780 - acc: 0.8319\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 3s 113us/step - loss: 0.5448 - acc: 0.8393\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 4s 117us/step - loss: 0.5190 - acc: 0.8489\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 3s 114us/step - loss: 0.4956 - acc: 0.8523\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 3s 111us/step - loss: 0.4773 - acc: 0.8576\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 3s 114us/step - loss: 0.4629 - acc: 0.8642\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 4s 117us/step - loss: 0.4496 - acc: 0.8671\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 3s 117us/step - loss: 0.4417 - acc: 0.8686\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 120us/step - loss: 0.4310 - acc: 0.8705\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 4s 121us/step - loss: 0.4211 - acc: 0.8744\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 3s 116us/step - loss: 0.4171 - acc: 0.8773\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 3s 114us/step - loss: 0.4085 - acc: 0.8784\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 3s 114us/step - loss: 0.4035 - acc: 0.8793\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 3s 113us/step - loss: 0.3953 - acc: 0.8831\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 3s 115us/step - loss: 0.3900 - acc: 0.8833\n",
      "30000/30000 [==============================] - 2s 60us/step\n",
      "30000/30000 [==============================] - 1s 41us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=20, num_neurons=256, optimizer_algo=sgd, total= 1.2min\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=20, num_neurons=256, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 7s 227us/step - loss: 0.3195 - acc: 0.9022\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 5s 163us/step - loss: 0.1887 - acc: 0.9421\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 5s 155us/step - loss: 0.1613 - acc: 0.9493\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 5s 159us/step - loss: 0.1489 - acc: 0.9536\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 5s 155us/step - loss: 0.1424 - acc: 0.9565\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 5s 156us/step - loss: 0.1326 - acc: 0.9590\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 5s 156us/step - loss: 0.1155 - acc: 0.9646\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 5s 155us/step - loss: 0.1148 - acc: 0.9637\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 5s 156us/step - loss: 0.1033 - acc: 0.9679\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 5s 154us/step - loss: 0.1042 - acc: 0.9673\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 5s 156us/step - loss: 0.0978 - acc: 0.9699\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 5s 157us/step - loss: 0.1071 - acc: 0.9678\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 5s 160us/step - loss: 0.1044 - acc: 0.9680\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 5s 156us/step - loss: 0.0902 - acc: 0.9710\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 5s 156us/step - loss: 0.0972 - acc: 0.9696\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 5s 156us/step - loss: 0.0907 - acc: 0.9726\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 5s 155us/step - loss: 0.0897 - acc: 0.9719\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 5s 166us/step - loss: 0.0857 - acc: 0.9737\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 4s 148us/step - loss: 0.0890 - acc: 0.9735\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 0.0822 - acc: 0.9753\n",
      "30000/30000 [==============================] - 2s 61us/step\n",
      "30000/30000 [==============================] - 2s 50us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=20, num_neurons=256, optimizer_algo=adam, total= 1.6min\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=20, num_neurons=256, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 7s 234us/step - loss: 0.3189 - acc: 0.9023\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 6s 215us/step - loss: 0.1861 - acc: 0.9427\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 6s 197us/step - loss: 0.1570 - acc: 0.9520\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 6s 199us/step - loss: 0.1373 - acc: 0.9576\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 5s 157us/step - loss: 0.1296 - acc: 0.9590\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 5s 152us/step - loss: 0.1343 - acc: 0.9586\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 5s 153us/step - loss: 0.1228 - acc: 0.9625\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 0.1136 - acc: 0.9634\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 5s 168us/step - loss: 0.1094 - acc: 0.9671\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 5s 167us/step - loss: 0.1006 - acc: 0.9688\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 5s 152us/step - loss: 0.0971 - acc: 0.9702\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 5s 162us/step - loss: 0.1073 - acc: 0.9671\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 5s 152us/step - loss: 0.1027 - acc: 0.9689\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 5s 155us/step - loss: 0.0957 - acc: 0.9712\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 5s 154us/step - loss: 0.0874 - acc: 0.9743\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 6s 196us/step - loss: 0.0902 - acc: 0.9724\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 6s 188us/step - loss: 0.0839 - acc: 0.9747\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 6s 185us/step - loss: 0.0862 - acc: 0.9735\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 5s 178us/step - loss: 0.0804 - acc: 0.9754\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 8s 282us/step - loss: 0.0849 - acc: 0.9740\n",
      "30000/30000 [==============================] - 3s 108us/step\n",
      "30000/30000 [==============================] - 2s 65us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=20, num_neurons=256, optimizer_algo=adam, total= 1.9min\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=20, num_neurons=512, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 9s 305us/step - loss: 1.7891 - acc: 0.4292\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 7s 247us/step - loss: 1.0834 - acc: 0.7041\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 8s 260us/step - loss: 0.8058 - acc: 0.7737\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 8s 277us/step - loss: 0.6781 - acc: 0.8057\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 9s 309us/step - loss: 0.6039 - acc: 0.8260\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 11s 370us/step - loss: 0.5571 - acc: 0.8352\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 10s 346us/step - loss: 0.5220 - acc: 0.8466\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 8s 283us/step - loss: 0.5007 - acc: 0.8511\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 7s 249us/step - loss: 0.4786 - acc: 0.8578\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 9s 313us/step - loss: 0.4636 - acc: 0.8614\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 9s 290us/step - loss: 0.4507 - acc: 0.8655\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 8s 261us/step - loss: 0.4364 - acc: 0.8689\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 8s 274us/step - loss: 0.4278 - acc: 0.8731\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 7s 243us/step - loss: 0.4223 - acc: 0.8746\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 7s 243us/step - loss: 0.4096 - acc: 0.8783\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 7s 224us/step - loss: 0.4024 - acc: 0.8812\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 7s 243us/step - loss: 0.4030 - acc: 0.8807\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 8s 253us/step - loss: 0.3925 - acc: 0.8837\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 8s 261us/step - loss: 0.3895 - acc: 0.8852\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 8s 265us/step - loss: 0.3841 - acc: 0.8861\n",
      "30000/30000 [==============================] - 37s 1ms/step\n",
      "30000/30000 [==============================] - 3s 106us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=20, num_neurons=512, optimizer_algo=sgd, total= 3.5min\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=20, num_neurons=512, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 8s 267us/step - loss: 1.8033 - acc: 0.4265\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 5s 179us/step - loss: 1.0806 - acc: 0.7063\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 6s 193us/step - loss: 0.7989 - acc: 0.7772\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 6s 197us/step - loss: 0.6789 - acc: 0.8024\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 5s 182us/step - loss: 0.6059 - acc: 0.8202\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 6s 197us/step - loss: 0.5570 - acc: 0.8344\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 6s 193us/step - loss: 0.5285 - acc: 0.8418\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 5s 183us/step - loss: 0.4999 - acc: 0.8479\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 5s 181us/step - loss: 0.4776 - acc: 0.8561\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 6s 194us/step - loss: 0.4648 - acc: 0.8605\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 6s 192us/step - loss: 0.4504 - acc: 0.8637\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 6s 186us/step - loss: 0.4412 - acc: 0.8653\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 6s 203us/step - loss: 0.4321 - acc: 0.8699\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 7s 239us/step - loss: 0.4261 - acc: 0.8729\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 6s 213us/step - loss: 0.4169 - acc: 0.8734\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 6s 209us/step - loss: 0.4081 - acc: 0.8779\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 6s 212us/step - loss: 0.3992 - acc: 0.8807\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 6s 211us/step - loss: 0.3977 - acc: 0.8801\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 6s 213us/step - loss: 0.3886 - acc: 0.8834\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 7s 219us/step - loss: 0.3869 - acc: 0.8831\n",
      "30000/30000 [==============================] - 3s 106us/step\n",
      "30000/30000 [==============================] - 2s 82us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=20, num_neurons=512, optimizer_algo=sgd, total= 2.6min\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=20, num_neurons=512, optimizer_algo=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 14s 476us/step - loss: 0.3174 - acc: 0.9043\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 12s 405us/step - loss: 0.1956 - acc: 0.9419\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 11s 375us/step - loss: 0.1699 - acc: 0.9493\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 11s 371us/step - loss: 0.1553 - acc: 0.9529\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 12s 399us/step - loss: 0.1444 - acc: 0.9556\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 13s 440us/step - loss: 0.1368 - acc: 0.9598\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 13s 428us/step - loss: 0.1279 - acc: 0.9629\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 13s 434us/step - loss: 0.1284 - acc: 0.9634\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 14s 454us/step - loss: 0.1299 - acc: 0.96441s\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 13s 443us/step - loss: 0.1159 - acc: 0.9675\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 13s 431us/step - loss: 0.1115 - acc: 0.9690\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 13s 432us/step - loss: 0.1122 - acc: 0.9680\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 13s 418us/step - loss: 0.1130 - acc: 0.9699\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 10s 322us/step - loss: 0.1126 - acc: 0.9687\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 9s 311us/step - loss: 0.1135 - acc: 0.9711\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 9s 302us/step - loss: 0.1087 - acc: 0.9709\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 9s 293us/step - loss: 0.0922 - acc: 0.9752 1s - loss:\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 9s 310us/step - loss: 0.0896 - acc: 0.9755\n",
      "Epoch 19/20\n",
      "  640/30000 [..............................] - ETA: 2:06 - loss: 0.0903 - acc: 0.9828"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\cysecml\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.189745). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 11s 383us/step - loss: 0.1004 - acc: 0.9733\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 9s 301us/step - loss: 0.1005 - acc: 0.9743\n",
      "30000/30000 [==============================] - 26s 865us/step\n",
      "30000/30000 [==============================] - 2s 77us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=20, num_neurons=512, optimizer_algo=adam, total= 4.4min\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=20, num_neurons=512, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 16s 521us/step - loss: 0.3176 - acc: 0.90171s - loss\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 11s 360us/step - loss: 0.1914 - acc: 0.9411\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 10s 343us/step - loss: 0.1740 - acc: 0.9488\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 9s 303us/step - loss: 0.1690 - acc: 0.9502\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 10s 322us/step - loss: 0.1454 - acc: 0.9573\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 11s 375us/step - loss: 0.1433 - acc: 0.9580\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 12s 386us/step - loss: 0.1471 - acc: 0.9593\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 10s 350us/step - loss: 0.1373 - acc: 0.9618\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 13s 442us/step - loss: 0.1311 - acc: 0.9634\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 13s 421us/step - loss: 0.1255 - acc: 0.9649\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 11s 378us/step - loss: 0.1149 - acc: 0.9692\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 11s 379us/step - loss: 0.1160 - acc: 0.9689\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 11s 361us/step - loss: 0.1141 - acc: 0.9687\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 9s 310us/step - loss: 0.1102 - acc: 0.9704\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 9s 299us/step - loss: 0.1091 - acc: 0.9709\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 9s 309us/step - loss: 0.1092 - acc: 0.9710\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 9s 311us/step - loss: 0.0967 - acc: 0.9744\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 10s 321us/step - loss: 0.0952 - acc: 0.9743\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 9s 306us/step - loss: 0.0977 - acc: 0.9738\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 9s 314us/step - loss: 0.0929 - acc: 0.9750\n",
      "30000/30000 [==============================] - 6s 198us/step\n",
      "30000/30000 [==============================] - 2s 83us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=20, num_neurons=512, optimizer_algo=adam, total= 3.9min\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=20, num_neurons=784, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 14s 462us/step - loss: 1.7529 - acc: 0.4445\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 8s 281us/step - loss: 1.0438 - acc: 0.7102\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 8s 253us/step - loss: 0.7801 - acc: 0.7795\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 8s 253us/step - loss: 0.6616 - acc: 0.8087\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 8s 255us/step - loss: 0.5947 - acc: 0.8237\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 7s 246us/step - loss: 0.5491 - acc: 0.8389\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 7s 248us/step - loss: 0.5161 - acc: 0.8441\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 9s 285us/step - loss: 0.4927 - acc: 0.8550\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 9s 308us/step - loss: 0.4735 - acc: 0.8584\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 10s 326us/step - loss: 0.4590 - acc: 0.8623\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 9s 302us/step - loss: 0.4452 - acc: 0.8674\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 8s 253us/step - loss: 0.4359 - acc: 0.8691\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 8s 261us/step - loss: 0.4240 - acc: 0.8724\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 9s 294us/step - loss: 0.4217 - acc: 0.8747\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 9s 301us/step - loss: 0.4098 - acc: 0.8783\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 10s 337us/step - loss: 0.4046 - acc: 0.8805\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 14s 453us/step - loss: 0.3975 - acc: 0.8830\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 10s 336us/step - loss: 0.3938 - acc: 0.8816\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 8s 277us/step - loss: 0.3882 - acc: 0.8839\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 9s 295us/step - loss: 0.3850 - acc: 0.8857\n",
      "30000/30000 [==============================] - 33s 1ms/step\n",
      "30000/30000 [==============================] - 3s 95us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=20, num_neurons=784, optimizer_algo=sgd, total= 3.7min\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=20, num_neurons=784, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 14s 465us/step - loss: 1.7576 - acc: 0.4415\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 10s 348us/step - loss: 1.0325 - acc: 0.7154\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 8s 281us/step - loss: 0.7763 - acc: 0.7799\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 8s 256us/step - loss: 0.6581 - acc: 0.8069\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 8s 276us/step - loss: 0.5934 - acc: 0.8232\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 9s 291us/step - loss: 0.5449 - acc: 0.8383\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 8s 256us/step - loss: 0.5128 - acc: 0.8443\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 7s 243us/step - loss: 0.4932 - acc: 0.8527\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 8s 256us/step - loss: 0.4724 - acc: 0.8583\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 9s 297us/step - loss: 0.4568 - acc: 0.8634\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 10s 350us/step - loss: 0.4483 - acc: 0.8653\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 11s 362us/step - loss: 0.4349 - acc: 0.8700\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 9s 307us/step - loss: 0.4275 - acc: 0.8710\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 9s 308us/step - loss: 0.4204 - acc: 0.8734\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 10s 347us/step - loss: 0.4122 - acc: 0.8765\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 11s 378us/step - loss: 0.4070 - acc: 0.8767\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 13s 419us/step - loss: 0.3993 - acc: 0.8809\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 14s 461us/step - loss: 0.3922 - acc: 0.8838\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 15s 513us/step - loss: 0.3910 - acc: 0.8823 \n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 11s 375us/step - loss: 0.3860 - acc: 0.8837\n",
      "30000/30000 [==============================] - 41s 1ms/step\n",
      "30000/30000 [==============================] - 4s 146us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=20, num_neurons=784, optimizer_algo=sgd, total= 4.5min\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=20, num_neurons=784, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 23s 768us/step - loss: 0.3287 - acc: 0.9020\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 14s 463us/step - loss: 0.2021 - acc: 0.9394\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 14s 462us/step - loss: 0.1883 - acc: 0.94521s - loss: 0.1891 - acc: 0.945 - ETA: 1s - loss: 0.1888 - acc: 0.9 - ETA: 0s - loss: 0.188\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 14s 454us/step - loss: 0.1765 - acc: 0.9491\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 14s 473us/step - loss: 0.1638 - acc: 0.95610s - loss: 0.16\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 14s 479us/step - loss: 0.1717 - acc: 0.9566\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 14s 469us/step - loss: 0.1589 - acc: 0.9586\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 14s 459us/step - loss: 0.1730 - acc: 0.9582\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 14s 457us/step - loss: 0.1763 - acc: 0.9600\n",
      "Epoch 10/20\n",
      "  416/30000 [..............................] - ETA: 6:01 - loss: 0.1775 - acc: 0.9712"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\cysecml\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.479571). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "D:\\Anaconda3\\envs\\cysecml\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.240285). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 20s 652us/step - loss: 0.1693 - acc: 0.9615\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 16s 517us/step - loss: 0.1666 - acc: 0.9639\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 15s 490us/step - loss: 0.1714 - acc: 0.9619\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 14s 454us/step - loss: 0.1651 - acc: 0.9646\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 14s 471us/step - loss: 0.1345 - acc: 0.9702\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 14s 458us/step - loss: 0.1558 - acc: 0.9658\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 14s 472us/step - loss: 0.1356 - acc: 0.9702\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 15s 486us/step - loss: 0.1458 - acc: 0.9697\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 14s 467us/step - loss: 0.1565 - acc: 0.9690\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 14s 462us/step - loss: 0.1466 - acc: 0.9702\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 14s 451us/step - loss: 0.1389 - acc: 0.9721\n",
      "30000/30000 [==============================] - 4s 119us/step\n",
      "30000/30000 [==============================] - 3s 91us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=20, num_neurons=784, optimizer_algo=adam, total= 5.6min\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=20, num_neurons=784, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 17s 552us/step - loss: 0.3196 - acc: 0.9031\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 14s 463us/step - loss: 0.2145 - acc: 0.9364\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 14s 469us/step - loss: 0.1873 - acc: 0.9464\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 14s 477us/step - loss: 0.1740 - acc: 0.95314s - loss: 0.1623 - acc: 0.955 - ETA: 4s - loss: 0.1627 - acc: 0. - ETA:  - E\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 14s 466us/step - loss: 0.1767 - acc: 0.9536\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 15s 486us/step - loss: 0.1719 - acc: 0.9547\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 14s 480us/step - loss: 0.1668 - acc: 0.9593\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 14s 468us/step - loss: 0.1678 - acc: 0.9591\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 14s 460us/step - loss: 0.1611 - acc: 0.9609\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 14s 452us/step - loss: 0.1398 - acc: 0.9654\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 14s 465us/step - loss: 0.1488 - acc: 0.9668\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 14s 473us/step - loss: 0.1516 - acc: 0.9646\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 14s 464us/step - loss: 0.1458 - acc: 0.9678\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 14s 460us/step - loss: 0.1436 - acc: 0.9692\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 14s 479us/step - loss: 0.1580 - acc: 0.9660\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 14s 454us/step - loss: 0.1532 - acc: 0.9685\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 14s 465us/step - loss: 0.1294 - acc: 0.9729\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 15s 487us/step - loss: 0.1429 - acc: 0.9715\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 14s 460us/step - loss: 0.1433 - acc: 0.9708\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 13s 441us/step - loss: 0.1339 - acc: 0.9729\n",
      "30000/30000 [==============================] - 3s 110us/step\n",
      "30000/30000 [==============================] - 3s 96us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=20, num_neurons=784, optimizer_algo=adam, total= 4.8min\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=20, num_neurons=1024, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 13s 418us/step - loss: 1.7368 - acc: 0.44621s - loss: 1.\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 11s 381us/step - loss: 1.0197 - acc: 0.7137\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 11s 375us/step - loss: 0.7688 - acc: 0.7795\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 12s 416us/step - loss: 0.6516 - acc: 0.8093\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 11s 357us/step - loss: 0.5823 - acc: 0.8295\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 11s 355us/step - loss: 0.5403 - acc: 0.8384\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 11s 367us/step - loss: 0.5117 - acc: 0.8467\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 11s 355us/step - loss: 0.4911 - acc: 0.8531\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 11s 356us/step - loss: 0.4711 - acc: 0.8602\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 11s 365us/step - loss: 0.4508 - acc: 0.8654\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 11s 381us/step - loss: 0.4426 - acc: 0.8670\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 11s 366us/step - loss: 0.4358 - acc: 0.8694\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 11s 366us/step - loss: 0.4223 - acc: 0.8738\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 12s 386us/step - loss: 0.4161 - acc: 0.8749\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 0.4109 - acc: 0.876 - 11s 373us/step - loss: 0.4107 - acc: 0.8768\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 11s 363us/step - loss: 0.3992 - acc: 0.8808\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 11s 370us/step - loss: 0.3984 - acc: 0.8813\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 13s 422us/step - loss: 0.3913 - acc: 0.8839\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 12s 400us/step - loss: 0.3864 - acc: 0.8849\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 13s 418us/step - loss: 0.3843 - acc: 0.8844\n",
      "30000/30000 [==============================] - 4s 143us/step\n",
      "30000/30000 [==============================] - 3s 114us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=20, num_neurons=1024, optimizer_algo=sgd, total= 3.9min\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=20, num_neurons=1024, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 15s 488us/step - loss: 1.7270 - acc: 0.4510\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 11s 380us/step - loss: 1.0162 - acc: 0.7153\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 11s 364us/step - loss: 0.7667 - acc: 0.7785\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 12s 391us/step - loss: 0.6516 - acc: 0.8068\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 11s 379us/step - loss: 0.5844 - acc: 0.82690s - loss: 0.5833 - ac\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 11s 365us/step - loss: 0.5408 - acc: 0.8377\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 11s 378us/step - loss: 0.5082 - acc: 0.8479\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 11s 375us/step - loss: 0.4904 - acc: 0.8525\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 11s 367us/step - loss: 0.4712 - acc: 0.8586\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 11s 377us/step - loss: 0.4569 - acc: 0.8631\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 11s 377us/step - loss: 0.4467 - acc: 0.8645\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 13s 419us/step - loss: 0.4340 - acc: 0.8697\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 11s 359us/step - loss: 0.4269 - acc: 0.8729\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 12s 390us/step - loss: 0.4197 - acc: 0.8742\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 14s 460us/step - loss: 0.4125 - acc: 0.8753\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 13s 447us/step - loss: 0.4075 - acc: 0.8774\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 14s 455us/step - loss: 0.4021 - acc: 0.8799\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 14s 451us/step - loss: 0.3947 - acc: 0.8808\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 13s 432us/step - loss: 0.3931 - acc: 0.8814\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 13s 447us/step - loss: 0.3873 - acc: 0.8828\n",
      "30000/30000 [==============================] - 6s 209us/step\n",
      "30000/30000 [==============================] - 5s 156us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=20, num_neurons=1024, optimizer_algo=sgd, total= 4.2min\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=20, num_neurons=1024, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 28s 932us/step - loss: 0.3397 - acc: 0.9005\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 25s 846us/step - loss: 0.2246 - acc: 0.93500s - loss: 0.2241 - \n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 25s 840us/step - loss: 0.2177 - acc: 0.9409\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 25s 835us/step - loss: 0.2066 - acc: 0.9465 ETA: 1\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 28s 933us/step - loss: 0.2069 - acc: 0.9497\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 28s 942us/step - loss: 0.1868 - acc: 0.9550\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 28s 934us/step - loss: 0.1956 - acc: 0.9546\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 25s 841us/step - loss: 0.1905 - acc: 0.9580\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 28s 929us/step - loss: 0.1982 - acc: 0.9590\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 28s 919us/step - loss: 0.1931 - acc: 0.9612\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 28s 945us/step - loss: 0.1932 - acc: 0.9613\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 0.1941 - acc: 0.9625\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 23s 751us/step - loss: 0.1826 - acc: 0.96490s - loss: 0.1803\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 26s 871us/step - loss: 0.1947 - acc: 0.9648\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 28s 946us/step - loss: 0.1761 - acc: 0.9679\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 0.1870 - acc: 0.9673\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 28s 917us/step - loss: 0.1728 - acc: 0.9701\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.1734 - acc: 0.9687: 2s - los\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 21s 688us/step - loss: 0.1612 - acc: 0.9712\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 20s 670us/step - loss: 0.1819 - acc: 0.9702\n",
      "30000/30000 [==============================] - 5s 157us/step\n",
      "30000/30000 [==============================] - 4s 121us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=20, num_neurons=1024, optimizer_algo=adam, total= 9.0min\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=20, num_neurons=1024, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 22s 745us/step - loss: 0.3493 - acc: 0.8973\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 21s 688us/step - loss: 0.2004 - acc: 0.9405\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 21s 684us/step - loss: 0.2022 - acc: 0.9454\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 21s 714us/step - loss: 0.2000 - acc: 0.9484\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 21s 703us/step - loss: 0.1925 - acc: 0.9517\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 23s 779us/step - loss: 0.1993 - acc: 0.95401s \n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 21s 714us/step - loss: 0.1910 - acc: 0.9550\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 20s 671us/step - loss: 0.1699 - acc: 0.9604\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 20s 663us/step - loss: 0.1796 - acc: 0.9608\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 20s 671us/step - loss: 0.1831 - acc: 0.9609\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 20s 673us/step - loss: 0.1832 - acc: 0.9638\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 21s 696us/step - loss: 0.1803 - acc: 0.9646\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 20s 678us/step - loss: 0.1758 - acc: 0.9669\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 21s 687us/step - loss: 0.1664 - acc: 0.9679\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 20s 675us/step - loss: 0.1596 - acc: 0.9697\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 20s 678us/step - loss: 0.1823 - acc: 0.9671\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 21s 687us/step - loss: 0.1911 - acc: 0.9668\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 24s 784us/step - loss: 0.1631 - acc: 0.9711\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 25s 832us/step - loss: 0.1759 - acc: 0.9695\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 24s 816us/step - loss: 0.1613 - acc: 0.9728\n",
      "30000/30000 [==============================] - 5s 164us/step\n",
      "30000/30000 [==============================] - 4s 133us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=20, num_neurons=1024, optimizer_algo=adam, total= 7.2min\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=30, num_neurons=256, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 7s 244us/step - loss: 1.8200 - acc: 0.4151\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 5s 155us/step - loss: 1.1379 - acc: 0.6864\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 5s 164us/step - loss: 0.8539 - acc: 0.7609\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 5s 175us/step - loss: 0.7142 - acc: 0.7973\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 5s 157us/step - loss: 0.6321 - acc: 0.8175\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 5s 162us/step - loss: 0.5821 - acc: 0.8306\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 5s 156us/step - loss: 0.5481 - acc: 0.8425\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 5s 157us/step - loss: 0.5164 - acc: 0.8496\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 5s 169us/step - loss: 0.4929 - acc: 0.8572\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 5s 157us/step - loss: 0.4781 - acc: 0.8594\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 5s 159us/step - loss: 0.4622 - acc: 0.8637\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 5s 156us/step - loss: 0.4509 - acc: 0.8677\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 5s 156us/step - loss: 0.4353 - acc: 0.8714\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 5s 156us/step - loss: 0.4275 - acc: 0.8738\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 5s 159us/step - loss: 0.4224 - acc: 0.8757\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 5s 156us/step - loss: 0.4117 - acc: 0.8786\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 5s 157us/step - loss: 0.4029 - acc: 0.8804\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 5s 168us/step - loss: 0.3993 - acc: 0.8811\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 5s 156us/step - loss: 0.3946 - acc: 0.8826\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 5s 173us/step - loss: 0.3864 - acc: 0.8866\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 5s 178us/step - loss: 0.3815 - acc: 0.8882\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 5s 172us/step - loss: 0.3778 - acc: 0.8883\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 5s 158us/step - loss: 0.3739 - acc: 0.8898\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 5s 156us/step - loss: 0.3691 - acc: 0.8911\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 5s 159us/step - loss: 0.3646 - acc: 0.8935\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 5s 168us/step - loss: 0.3642 - acc: 0.8931\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 5s 158us/step - loss: 0.3599 - acc: 0.8936\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 5s 156us/step - loss: 0.3546 - acc: 0.8955\n",
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 5s 153us/step - loss: 0.3490 - acc: 0.8968\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 0.3458 - acc: 0.8975\n",
      "30000/30000 [==============================] - 3s 104us/step\n",
      "30000/30000 [==============================] - 2s 76us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=30, num_neurons=256, optimizer_algo=sgd, total= 2.5min\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=30, num_neurons=256, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 7s 223us/step - loss: 1.8201 - acc: 0.4238\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 5s 155us/step - loss: 1.1351 - acc: 0.6929\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 5s 160us/step - loss: 0.8504 - acc: 0.7640\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 0.7127 - acc: 0.7977\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 0.6327 - acc: 0.8181\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 5s 153us/step - loss: 0.5807 - acc: 0.8321\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 5s 152us/step - loss: 0.5460 - acc: 0.8408\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 0.5141 - acc: 0.8487\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 5s 169us/step - loss: 0.4955 - acc: 0.8513\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 5s 150us/step - loss: 0.4787 - acc: 0.8586\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 4s 146us/step - loss: 0.4658 - acc: 0.8604\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 4s 134us/step - loss: 0.4518 - acc: 0.8657\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 4s 128us/step - loss: 0.4422 - acc: 0.8669\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 4s 134us/step - loss: 0.4310 - acc: 0.8720\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 4s 133us/step - loss: 0.4225 - acc: 0.8728\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 4s 130us/step - loss: 0.4126 - acc: 0.8775\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 3s 113us/step - loss: 0.4071 - acc: 0.8784\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 3s 113us/step - loss: 0.3994 - acc: 0.8790\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 4s 121us/step - loss: 0.3967 - acc: 0.8807\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 3s 114us/step - loss: 0.3917 - acc: 0.8845\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 3s 109us/step - loss: 0.3856 - acc: 0.8870\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 4s 122us/step - loss: 0.3813 - acc: 0.8855\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 4s 122us/step - loss: 0.3791 - acc: 0.8856\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 3s 111us/step - loss: 0.3714 - acc: 0.8912\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 4s 117us/step - loss: 0.3656 - acc: 0.8908\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 4s 120us/step - loss: 0.3673 - acc: 0.8894\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 4s 135us/step - loss: 0.3607 - acc: 0.8923\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 4s 123us/step - loss: 0.3584 - acc: 0.8933\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 4s 127us/step - loss: 0.3545 - acc: 0.8938\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 4s 117us/step - loss: 0.3524 - acc: 0.8960\n",
      "30000/30000 [==============================] - 3s 87us/step\n",
      "30000/30000 [==============================] - 2s 69us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=30, num_neurons=256, optimizer_algo=sgd, total= 2.1min\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=30, num_neurons=256, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 8s 256us/step - loss: 0.3273 - acc: 0.8990\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 5s 175us/step - loss: 0.1865 - acc: 0.9432\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 5s 178us/step - loss: 0.1597 - acc: 0.9511\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 5s 181us/step - loss: 0.1473 - acc: 0.9536\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 5s 181us/step - loss: 0.1271 - acc: 0.9593\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 5s 175us/step - loss: 0.1327 - acc: 0.9594\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 6s 186us/step - loss: 0.1199 - acc: 0.9629\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 5s 183us/step - loss: 0.1131 - acc: 0.9654\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 5s 172us/step - loss: 0.1138 - acc: 0.9642\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 5s 177us/step - loss: 0.1059 - acc: 0.9675\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 5s 175us/step - loss: 0.0982 - acc: 0.9686\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 5s 180us/step - loss: 0.0957 - acc: 0.9704\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 5s 182us/step - loss: 0.0969 - acc: 0.9703\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 5s 183us/step - loss: 0.0973 - acc: 0.9707\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 5s 179us/step - loss: 0.0913 - acc: 0.9718\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 6s 190us/step - loss: 0.0939 - acc: 0.9714\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 5s 178us/step - loss: 0.0905 - acc: 0.9720\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 5s 174us/step - loss: 0.0835 - acc: 0.9731\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 5s 172us/step - loss: 0.0875 - acc: 0.9731\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 5s 177us/step - loss: 0.0776 - acc: 0.9762\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 5s 179us/step - loss: 0.0825 - acc: 0.9751\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 5s 183us/step - loss: 0.0748 - acc: 0.9775\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 7s 224us/step - loss: 0.0766 - acc: 0.9772\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 5s 176us/step - loss: 0.0729 - acc: 0.9782\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 6s 202us/step - loss: 0.0825 - acc: 0.9753\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 7s 226us/step - loss: 0.0817 - acc: 0.9772\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 6s 213us/step - loss: 0.0683 - acc: 0.9782\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 8s 268us/step - loss: 0.0772 - acc: 0.9772\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 8s 253us/step - loss: 0.0670 - acc: 0.9799\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 7s 247us/step - loss: 0.0692 - acc: 0.9792\n",
      "30000/30000 [==============================] - 3s 103us/step\n",
      "30000/30000 [==============================] - 2s 74us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=30, num_neurons=256, optimizer_algo=adam, total= 3.0min\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=30, num_neurons=256, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 8s 270us/step - loss: 0.3160 - acc: 0.9026\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 6s 202us/step - loss: 0.1778 - acc: 0.9453\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 6s 198us/step - loss: 0.1540 - acc: 0.9524\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 6s 207us/step - loss: 0.1441 - acc: 0.9559\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 6s 197us/step - loss: 0.1385 - acc: 0.9577\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 6s 195us/step - loss: 0.1207 - acc: 0.9619\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 6s 194us/step - loss: 0.1186 - acc: 0.9635\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 6s 196us/step - loss: 0.1163 - acc: 0.9638\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 6s 196us/step - loss: 0.1061 - acc: 0.9673\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 6s 198us/step - loss: 0.1078 - acc: 0.9672\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 6s 208us/step - loss: 0.0972 - acc: 0.9691\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 6s 193us/step - loss: 0.0952 - acc: 0.9714\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 6s 194us/step - loss: 0.0966 - acc: 0.9713\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 6s 194us/step - loss: 0.0861 - acc: 0.9733\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 6s 194us/step - loss: 0.0889 - acc: 0.9727\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 6s 208us/step - loss: 0.0872 - acc: 0.9734\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 7s 231us/step - loss: 0.0924 - acc: 0.9723\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 6s 198us/step - loss: 0.0877 - acc: 0.9732\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 6s 196us/step - loss: 0.0828 - acc: 0.9749\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 6s 198us/step - loss: 0.0796 - acc: 0.9759\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 6s 196us/step - loss: 0.0837 - acc: 0.9739\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 6s 196us/step - loss: 0.0846 - acc: 0.9748\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 6s 195us/step - loss: 0.0763 - acc: 0.9776\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 6s 206us/step - loss: 0.0788 - acc: 0.9756\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 6s 195us/step - loss: 0.0744 - acc: 0.9779\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 6s 195us/step - loss: 0.0729 - acc: 0.9783\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 6s 195us/step - loss: 0.0778 - acc: 0.9767\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 6s 195us/step - loss: 0.0749 - acc: 0.9773\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 6s 195us/step - loss: 0.0576 - acc: 0.9824\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 6s 197us/step - loss: 0.0717 - acc: 0.9793\n",
      "30000/30000 [==============================] - 3s 107us/step\n",
      "30000/30000 [==============================] - 2s 68us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=30, num_neurons=256, optimizer_algo=adam, total= 3.1min\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=30, num_neurons=512, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 9s 292us/step - loss: 1.7957 - acc: 0.4249\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 7s 222us/step - loss: 1.0784 - acc: 0.7021\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 7s 222us/step - loss: 0.8029 - acc: 0.7749\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 7s 221us/step - loss: 0.6809 - acc: 0.8026\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 7s 220us/step - loss: 0.6055 - acc: 0.8230\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 6s 208us/step - loss: 0.5555 - acc: 0.8370\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 5s 183us/step - loss: 0.5235 - acc: 0.8448\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 6s 190us/step - loss: 0.4972 - acc: 0.8518\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 6s 186us/step - loss: 0.4794 - acc: 0.8575\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 6s 189us/step - loss: 0.4623 - acc: 0.8624\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 6s 184us/step - loss: 0.4495 - acc: 0.8664\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 5s 181us/step - loss: 0.4387 - acc: 0.8694\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 6s 193us/step - loss: 0.4285 - acc: 0.8721\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 6s 189us/step - loss: 0.4199 - acc: 0.8766\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 6s 200us/step - loss: 0.4133 - acc: 0.8774\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 6s 187us/step - loss: 0.4073 - acc: 0.8801\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 5s 182us/step - loss: 0.3991 - acc: 0.8812\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 6s 191us/step - loss: 0.3925 - acc: 0.8831\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 6s 206us/step - loss: 0.3877 - acc: 0.8866\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 6s 216us/step - loss: 0.3844 - acc: 0.8865\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 6s 209us/step - loss: 0.3777 - acc: 0.8882\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 6s 189us/step - loss: 0.3772 - acc: 0.8882\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 5s 182us/step - loss: 0.3708 - acc: 0.8917\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 5s 181us/step - loss: 0.3689 - acc: 0.8914\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 6s 188us/step - loss: 0.3651 - acc: 0.8908\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 6s 186us/step - loss: 0.3613 - acc: 0.8941\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 6s 191us/step - loss: 0.3597 - acc: 0.8952\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 6s 185us/step - loss: 0.3571 - acc: 0.8940\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 6s 188us/step - loss: 0.3542 - acc: 0.8945\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 6s 187us/step - loss: 0.3487 - acc: 0.8979\n",
      "30000/30000 [==============================] - 3s 106us/step\n",
      "30000/30000 [==============================] - 2s 74us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=30, num_neurons=512, optimizer_algo=sgd, total= 3.0min\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=30, num_neurons=512, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 8s 257us/step - loss: 1.7985 - acc: 0.4240\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 6s 194us/step - loss: 1.0743 - acc: 0.7086\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 6s 206us/step - loss: 0.8051 - acc: 0.7720\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 6s 196us/step - loss: 0.6743 - acc: 0.8049\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 6s 188us/step - loss: 0.6071 - acc: 0.8216\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 6s 193us/step - loss: 0.5536 - acc: 0.8379\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 7s 227us/step - loss: 0.5278 - acc: 0.8447\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 6s 202us/step - loss: 0.5022 - acc: 0.8502\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 5s 176us/step - loss: 0.4839 - acc: 0.8549\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 7s 219us/step - loss: 0.4653 - acc: 0.8625\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 8s 262us/step - loss: 0.4541 - acc: 0.8642 1s -\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 6s 202us/step - loss: 0.4387 - acc: 0.8678\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 6s 201us/step - loss: 0.4308 - acc: 0.8718\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 7s 237us/step - loss: 0.4236 - acc: 0.8742\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 7s 225us/step - loss: 0.4155 - acc: 0.8751\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 0.4077 - acc: 0.878 - 7s 231us/step - loss: 0.4077 - acc: 0.8787\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 7s 224us/step - loss: 0.4031 - acc: 0.8791\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 7s 226us/step - loss: 0.3968 - acc: 0.8823\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 7s 233us/step - loss: 0.3907 - acc: 0.8828\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 7s 230us/step - loss: 0.3835 - acc: 0.8836\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 7s 227us/step - loss: 0.3832 - acc: 0.8850\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 7s 225us/step - loss: 0.3793 - acc: 0.8851\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 7s 222us/step - loss: 0.3741 - acc: 0.8881\n",
      "Epoch 24/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 7s 225us/step - loss: 0.3691 - acc: 0.8880\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 7s 217us/step - loss: 0.3695 - acc: 0.8897\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 5s 183us/step - loss: 0.3639 - acc: 0.8907\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 5s 180us/step - loss: 0.3652 - acc: 0.8903\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 6s 190us/step - loss: 0.3596 - acc: 0.8933\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 5s 180us/step - loss: 0.3541 - acc: 0.8943\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 5s 181us/step - loss: 0.3527 - acc: 0.8943\n",
      "30000/30000 [==============================] - 3s 99us/step\n",
      "30000/30000 [==============================] - 2s 73us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=30, num_neurons=512, optimizer_algo=sgd, total= 3.4min\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=30, num_neurons=512, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 11s 378us/step - loss: 0.3155 - acc: 0.9036\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 12s 394us/step - loss: 0.1969 - acc: 0.9421\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 11s 380us/step - loss: 0.1687 - acc: 0.9485\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 12s 400us/step - loss: 0.1545 - acc: 0.9533\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 12s 395us/step - loss: 0.1377 - acc: 0.9574\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 11s 379us/step - loss: 0.1382 - acc: 0.95830s - loss: 0.13\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 11s 378us/step - loss: 0.1220 - acc: 0.9631\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 12s 396us/step - loss: 0.1373 - acc: 0.9607\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 12s 391us/step - loss: 0.1205 - acc: 0.9663\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 11s 383us/step - loss: 0.1162 - acc: 0.96730s - loss: 0.1163 - \n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 12s 394us/step - loss: 0.1277 - acc: 0.9650\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 12s 384us/step - loss: 0.1113 - acc: 0.97060s - loss: 0.1118 - acc: 0\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 12s 395us/step - loss: 0.1100 - acc: 0.9692\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 12s 383us/step - loss: 0.1093 - acc: 0.97030s - loss: 0.1094 - acc: 0.97\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 12s 394us/step - loss: 0.1009 - acc: 0.9717TA: 0s - loss: 0.1011 - acc: 0.97\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 12s 388us/step - loss: 0.0969 - acc: 0.9739\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 10s 338us/step - loss: 0.0963 - acc: 0.9736\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 9s 305us/step - loss: 0.0999 - acc: 0.9736\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 9s 310us/step - loss: 0.1011 - acc: 0.9735\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 9s 303us/step - loss: 0.1042 - acc: 0.9718\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 9s 293us/step - loss: 0.0993 - acc: 0.9732\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 9s 298us/step - loss: 0.1078 - acc: 0.9721\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 9s 314us/step - loss: 0.0875 - acc: 0.9763\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 9s 301us/step - loss: 0.0907 - acc: 0.9761\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 9s 300us/step - loss: 0.0759 - acc: 0.9792\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 9s 293us/step - loss: 0.0777 - acc: 0.9789\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 10s 325us/step - loss: 0.0845 - acc: 0.9776\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 9s 296us/step - loss: 0.0943 - acc: 0.9762\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 9s 300us/step - loss: 0.0822 - acc: 0.9792\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 10s 335us/step - loss: 0.0794 - acc: 0.9795\n",
      "30000/30000 [==============================] - 3s 113us/step\n",
      "30000/30000 [==============================] - 2s 76us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=30, num_neurons=512, optimizer_algo=adam, total= 5.3min\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=30, num_neurons=512, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 11s 374us/step - loss: 0.3181 - acc: 0.9042\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 10s 324us/step - loss: 0.1805 - acc: 0.94411s - loss:\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 9s 314us/step - loss: 0.1670 - acc: 0.9496 0s - loss: 0\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 9s 296us/step - loss: 0.1514 - acc: 0.9550\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 10s 317us/step - loss: 0.1399 - acc: 0.95911s - loss: 0.\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 9s 305us/step - loss: 0.1295 - acc: 0.9622\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 9s 301us/step - loss: 0.1262 - acc: 0.9622\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 9s 304us/step - loss: 0.1220 - acc: 0.9643\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 10s 348us/step - loss: 0.1273 - acc: 0.9636\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 10s 320us/step - loss: 0.1285 - acc: 0.9655\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 9s 298us/step - loss: 0.1192 - acc: 0.9676\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 9s 306us/step - loss: 0.0999 - acc: 0.9725\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 9s 314us/step - loss: 0.1068 - acc: 0.9694\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 10s 322us/step - loss: 0.1018 - acc: 0.9722\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 9s 312us/step - loss: 0.1011 - acc: 0.9723\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 9s 309us/step - loss: 0.1058 - acc: 0.9714\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 10s 330us/step - loss: 0.1002 - acc: 0.9730\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 10s 322us/step - loss: 0.1045 - acc: 0.9731\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 9s 299us/step - loss: 0.0932 - acc: 0.9763\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 9s 308us/step - loss: 0.0967 - acc: 0.9746\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 9s 308us/step - loss: 0.1005 - acc: 0.9739\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 10s 318us/step - loss: 0.0884 - acc: 0.9768\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 9s 310us/step - loss: 0.0908 - acc: 0.9755\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 9s 299us/step - loss: 0.0836 - acc: 0.9781\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 9s 312us/step - loss: 0.0807 - acc: 0.9792\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 9s 312us/step - loss: 0.0854 - acc: 0.9780\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 9s 306us/step - loss: 0.0760 - acc: 0.9806\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 9s 309us/step - loss: 0.0845 - acc: 0.9784\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 10s 334us/step - loss: 0.0757 - acc: 0.9797\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 9s 313us/step - loss: 0.0785 - acc: 0.9802\n",
      "30000/30000 [==============================] - 3s 106us/step\n",
      "30000/30000 [==============================] - 2s 75us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=30, num_neurons=512, optimizer_algo=adam, total= 4.8min\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=30, num_neurons=784, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 10s 329us/step - loss: 1.7240 - acc: 0.4545\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 8s 259us/step - loss: 1.0236 - acc: 0.7181\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 9s 287us/step - loss: 0.7744 - acc: 0.7779\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 9s 289us/step - loss: 0.6585 - acc: 0.8096\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 8s 261us/step - loss: 0.5908 - acc: 0.8238\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 8s 257us/step - loss: 0.5499 - acc: 0.8362\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 8s 261us/step - loss: 0.5176 - acc: 0.8452\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 8s 282us/step - loss: 0.4926 - acc: 0.8533\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 8s 266us/step - loss: 0.4737 - acc: 0.8577\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 8s 263us/step - loss: 0.4570 - acc: 0.8643\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 8s 276us/step - loss: 0.4453 - acc: 0.8670\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 8s 264us/step - loss: 0.4328 - acc: 0.8723\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 8s 257us/step - loss: 0.4266 - acc: 0.8716\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 9s 285us/step - loss: 0.4197 - acc: 0.8718\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 9s 291us/step - loss: 0.4102 - acc: 0.8789\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 8s 258us/step - loss: 0.4020 - acc: 0.8803 0s - loss: 0.4040 - a\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 8s 257us/step - loss: 0.3980 - acc: 0.8822\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 8s 261us/step - loss: 0.3952 - acc: 0.8812\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 8s 257us/step - loss: 0.3879 - acc: 0.8839\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 8s 256us/step - loss: 0.3836 - acc: 0.8846\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 8s 253us/step - loss: 0.3799 - acc: 0.8866\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 8s 264us/step - loss: 0.3727 - acc: 0.8913\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 8s 257us/step - loss: 0.3739 - acc: 0.8904\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 8s 262us/step - loss: 0.3673 - acc: 0.8906\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 8s 273us/step - loss: 0.3633 - acc: 0.8915\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 8s 263us/step - loss: 0.3638 - acc: 0.8923\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 8s 259us/step - loss: 0.3593 - acc: 0.8939\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 8s 257us/step - loss: 0.3563 - acc: 0.8950\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 8s 275us/step - loss: 0.3529 - acc: 0.8970 1s \n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 8s 272us/step - loss: 0.3535 - acc: 0.8955\n",
      "30000/30000 [==============================] - 4s 142us/step\n",
      "30000/30000 [==============================] - 3s 102us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=30, num_neurons=784, optimizer_algo=sgd, total= 4.1min\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=30, num_neurons=784, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 10s 330us/step - loss: 1.7587 - acc: 0.4411\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 8s 264us/step - loss: 1.0423 - acc: 0.7154\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 9s 285us/step - loss: 0.7790 - acc: 0.7793\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 8s 283us/step - loss: 0.6590 - acc: 0.8081\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 8s 258us/step - loss: 0.5906 - acc: 0.8264\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 8s 261us/step - loss: 0.5445 - acc: 0.8375\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 8s 260us/step - loss: 0.5168 - acc: 0.8474\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 8s 268us/step - loss: 0.4880 - acc: 0.8543\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 8s 263us/step - loss: 0.4735 - acc: 0.8583\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 8s 264us/step - loss: 0.4609 - acc: 0.8615\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 8s 258us/step - loss: 0.4465 - acc: 0.8664\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 8s 274us/step - loss: 0.4357 - acc: 0.8685\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 8s 262us/step - loss: 0.4275 - acc: 0.8727\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 8s 254us/step - loss: 0.4190 - acc: 0.8746\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 8s 254us/step - loss: 0.4120 - acc: 0.8758\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 8s 253us/step - loss: 0.4055 - acc: 0.8773\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 8s 266us/step - loss: 0.4004 - acc: 0.8786\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 8s 265us/step - loss: 0.3941 - acc: 0.8810\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 8s 272us/step - loss: 0.3909 - acc: 0.8809\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 8s 274us/step - loss: 0.3845 - acc: 0.8847\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 8s 266us/step - loss: 0.3842 - acc: 0.8841\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 9s 289us/step - loss: 0.3801 - acc: 0.8846\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 8s 269us/step - loss: 0.3755 - acc: 0.8875\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 8s 271us/step - loss: 0.3728 - acc: 0.8872\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 8s 262us/step - loss: 0.3699 - acc: 0.8889\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 8s 257us/step - loss: 0.3637 - acc: 0.8913\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 8s 268us/step - loss: 0.3644 - acc: 0.8900\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 8s 273us/step - loss: 0.3578 - acc: 0.8926\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 8s 275us/step - loss: 0.3586 - acc: 0.8922\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 8s 267us/step - loss: 0.3570 - acc: 0.8937\n",
      "30000/30000 [==============================] - 4s 129us/step\n",
      "30000/30000 [==============================] - 3s 104us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=30, num_neurons=784, optimizer_algo=sgd, total= 4.1min\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=30, num_neurons=784, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 17s 566us/step - loss: 0.3235 - acc: 0.9022\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 16s 519us/step - loss: 0.2007 - acc: 0.9411\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 18s 606us/step - loss: 0.1935 - acc: 0.9441\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 18s 598us/step - loss: 0.1806 - acc: 0.9492\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 17s 578us/step - loss: 0.1665 - acc: 0.9539\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 18s 588us/step - loss: 0.1646 - acc: 0.9558\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 17s 581us/step - loss: 0.1626 - acc: 0.9598\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 18s 602us/step - loss: 0.1766 - acc: 0.9585\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 17s 583us/step - loss: 0.1635 - acc: 0.9615\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 17s 576us/step - loss: 0.1444 - acc: 0.9648\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 17s 583us/step - loss: 0.1562 - acc: 0.9639\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 15s 507us/step - loss: 0.1441 - acc: 0.9659\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 14s 458us/step - loss: 0.1345 - acc: 0.9679\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 14s 455us/step - loss: 0.1359 - acc: 0.9682\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 14s 481us/step - loss: 0.1409 - acc: 0.9684\n",
      "Epoch 16/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 14s 479us/step - loss: 0.1265 - acc: 0.96971s - loss:\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 14s 481us/step - loss: 0.1306 - acc: 0.9701\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 15s 501us/step - loss: 0.1298 - acc: 0.97210s - loss: 0.1304 -\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 14s 471us/step - loss: 0.1270 - acc: 0.9716\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 0.1213 - acc: 0.972 - 14s 464us/step - loss: 0.1213 - acc: 0.9726\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 14s 459us/step - loss: 0.1354 - acc: 0.9723\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 14s 467us/step - loss: 0.1480 - acc: 0.9706\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 14s 470us/step - loss: 0.1329 - acc: 0.9735\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 14s 469us/step - loss: 0.1281 - acc: 0.9753\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 14s 468us/step - loss: 0.1459 - acc: 0.9727\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 15s 504us/step - loss: 0.1377 - acc: 0.97320s - loss: 0.1394 - ac\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 15s 492us/step - loss: 0.1265 - acc: 0.9752\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 14s 464us/step - loss: 0.1305 - acc: 0.9755\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 14s 456us/step - loss: 0.1311 - acc: 0.9761\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 15s 494us/step - loss: 0.1347 - acc: 0.97540s - loss: 0.1337 - acc: \n",
      "30000/30000 [==============================] - 4s 135us/step\n",
      "30000/30000 [==============================] - 3s 107us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=30, num_neurons=784, optimizer_algo=adam, total= 7.8min\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=30, num_neurons=784, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 16s 530us/step - loss: 0.3224 - acc: 0.9027\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 15s 499us/step - loss: 0.1948 - acc: 0.94251s -\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 14s 472us/step - loss: 0.1780 - acc: 0.9479\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 14s 460us/step - loss: 0.1763 - acc: 0.9502\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 14s 475us/step - loss: 0.1795 - acc: 0.9519\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 15s 503us/step - loss: 0.1667 - acc: 0.9563\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 18s 614us/step - loss: 0.1623 - acc: 0.9578\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 18s 599us/step - loss: 0.1420 - acc: 0.9638\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 18s 597us/step - loss: 0.1505 - acc: 0.9632\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 18s 590us/step - loss: 0.1422 - acc: 0.9654\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 17s 579us/step - loss: 0.1475 - acc: 0.96541s - loss:\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 18s 590us/step - loss: 0.1459 - acc: 0.9666\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 17s 576us/step - loss: 0.1241 - acc: 0.9697\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 18s 583us/step - loss: 0.1280 - acc: 0.9700\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 17s 576us/step - loss: 0.1432 - acc: 0.9681\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 17s 558us/step - loss: 0.1544 - acc: 0.9674\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 15s 509us/step - loss: 0.1311 - acc: 0.9716\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 14s 456us/step - loss: 0.1422 - acc: 0.9698\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 14s 467us/step - loss: 0.1334 - acc: 0.9723\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 14s 454us/step - loss: 0.1262 - acc: 0.9730\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 14s 471us/step - loss: 0.1295 - acc: 0.9727\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 16s 524us/step - loss: 0.1255 - acc: 0.9739\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 16s 538us/step - loss: 0.1288 - acc: 0.9741\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 15s 509us/step - loss: 0.1303 - acc: 0.97411s - loss: 0.\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 17s 557us/step - loss: 0.1313 - acc: 0.97443s - l - ETA: 2\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 15s 507us/step - loss: 0.1297 - acc: 0.9755\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 16s 535us/step - loss: 0.1265 - acc: 0.9755\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 15s 508us/step - loss: 0.1179 - acc: 0.9769\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 16s 546us/step - loss: 0.1270 - acc: 0.9766\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 16s 549us/step - loss: 0.1132 - acc: 0.9780\n",
      "30000/30000 [==============================] - 5s 154us/step\n",
      "30000/30000 [==============================] - 3s 114us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=30, num_neurons=784, optimizer_algo=adam, total= 8.1min\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=30, num_neurons=1024, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 13s 431us/step - loss: 1.7331 - acc: 0.4469\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 11s 371us/step - loss: 1.0160 - acc: 0.7168\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 11s 355us/step - loss: 0.7663 - acc: 0.7818\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 11s 360us/step - loss: 0.6465 - acc: 0.8104\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 11s 362us/step - loss: 0.5825 - acc: 0.8260\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 11s 375us/step - loss: 0.5440 - acc: 0.8391\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 12s 394us/step - loss: 0.5135 - acc: 0.8462\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 11s 374us/step - loss: 0.4887 - acc: 0.85333s - loss: \n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 11s 361us/step - loss: 0.4688 - acc: 0.8583\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 11s 366us/step - loss: 0.4595 - acc: 0.8625\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 11s 355us/step - loss: 0.4408 - acc: 0.8672\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 11s 351us/step - loss: 0.4324 - acc: 0.8710\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 11s 372us/step - loss: 0.4227 - acc: 0.8728\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 11s 351us/step - loss: 0.4181 - acc: 0.8741\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 11s 353us/step - loss: 0.4076 - acc: 0.8784\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 11s 358us/step - loss: 0.4043 - acc: 0.8791\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 11s 367us/step - loss: 0.3976 - acc: 0.8814\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 11s 362us/step - loss: 0.3936 - acc: 0.8808\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 11s 374us/step - loss: 0.3870 - acc: 0.8833\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 12s 386us/step - loss: 0.3848 - acc: 0.88730s - loss: 0.3855 - acc: 0\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 14s 460us/step - loss: 0.3810 - acc: 0.8870\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 14s 466us/step - loss: 0.3741 - acc: 0.8885\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 14s 453us/step - loss: 0.3731 - acc: 0.8889\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 13s 439us/step - loss: 0.3691 - acc: 0.8902\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 15s 486us/step - loss: 0.3648 - acc: 0.8908\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 14s 450us/step - loss: 0.3645 - acc: 0.89201\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 11s 373us/step - loss: 0.3588 - acc: 0.8938\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 11s 357us/step - loss: 0.3561 - acc: 0.8943\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 11s 353us/step - loss: 0.3577 - acc: 0.8932\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 11s 364us/step - loss: 0.3512 - acc: 0.8960\n",
      "30000/30000 [==============================] - 5s 154us/step\n",
      "30000/30000 [==============================] - 4s 124us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=30, num_neurons=1024, optimizer_algo=sgd, total= 5.9min\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=30, num_neurons=1024, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 14s 475us/step - loss: 1.7477 - acc: 0.4409\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 14s 464us/step - loss: 1.0251 - acc: 0.71560s - loss: 1.0253 - acc: 0.715\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 12s 392us/step - loss: 0.7708 - acc: 0.7777\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 11s 350us/step - loss: 0.6521 - acc: 0.8089\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 11s 352us/step - loss: 0.5855 - acc: 0.8278\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 11s 380us/step - loss: 0.5447 - acc: 0.8352\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 10s 346us/step - loss: 0.5151 - acc: 0.8447\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 10s 347us/step - loss: 0.4874 - acc: 0.8548\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 11s 353us/step - loss: 0.4719 - acc: 0.8553\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 10s 349us/step - loss: 0.4565 - acc: 0.8628\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 11s 368us/step - loss: 0.4453 - acc: 0.8657\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 13s 446us/step - loss: 0.4360 - acc: 0.8685\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 13s 448us/step - loss: 0.4251 - acc: 0.8725\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 13s 448us/step - loss: 0.4196 - acc: 0.8733\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 13s 434us/step - loss: 0.4158 - acc: 0.8755\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 12s 396us/step - loss: 0.4054 - acc: 0.8762\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 11s 359us/step - loss: 0.3981 - acc: 0.8770\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 11s 359us/step - loss: 0.3966 - acc: 0.88060s - loss: 0.3966 - acc: 0.880\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 11s 371us/step - loss: 0.3907 - acc: 0.8816\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 11s 366us/step - loss: 0.3886 - acc: 0.8821\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 11s 365us/step - loss: 0.3825 - acc: 0.8866\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 11s 357us/step - loss: 0.3821 - acc: 0.8855\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 11s 363us/step - loss: 0.3772 - acc: 0.8863\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 11s 372us/step - loss: 0.3718 - acc: 0.8887\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 12s 404us/step - loss: 0.3717 - acc: 0.88591\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 11s 369us/step - loss: 0.3652 - acc: 0.8899\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 12s 400us/step - loss: 0.3609 - acc: 0.8921\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 12s 387us/step - loss: 0.3597 - acc: 0.8931\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 11s 373us/step - loss: 0.3598 - acc: 0.8913\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 11s 381us/step - loss: 0.3578 - acc: 0.8918\n",
      "30000/30000 [==============================] - 5s 173us/step\n",
      "30000/30000 [==============================] - 4s 126us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=30, num_neurons=1024, optimizer_algo=sgd, total= 5.9min\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=30, num_neurons=1024, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 25s 844us/step - loss: 0.3413 - acc: 0.89921s - loss: \n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 21s 706us/step - loss: 0.2207 - acc: 0.9345\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 20s 657us/step - loss: 0.2139 - acc: 0.9403\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 20s 671us/step - loss: 0.2102 - acc: 0.9463\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 20s 672us/step - loss: 0.2166 - acc: 0.9485\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 20s 658us/step - loss: 0.2082 - acc: 0.9520\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 20s 664us/step - loss: 0.2031 - acc: 0.95451s - loss: 0.1999 - acc: 0.95 - ETA: 1s \n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 20s 672us/step - loss: 0.2118 - acc: 0.9554\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 20s 670us/step - loss: 0.2273 - acc: 0.95520s - loss: 0.2268 - acc: 0.\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 20s 668us/step - loss: 0.1907 - acc: 0.9619\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 21s 699us/step - loss: 0.1899 - acc: 0.9633\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 20s 666us/step - loss: 0.1938 - acc: 0.9637\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 21s 687us/step - loss: 0.1855 - acc: 0.9647\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 21s 690us/step - loss: 0.2017 - acc: 0.9653\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 26s 878us/step - loss: 0.1910 - acc: 0.96770s - loss: 0.1910 - a\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 23s 771us/step - loss: 0.1851 - acc: 0.9691\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 23s 762us/step - loss: 0.1835 - acc: 0.9694\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 23s 777us/step - loss: 0.2019 - acc: 0.9681\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 23s 754us/step - loss: 0.1917 - acc: 0.9687\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 23s 756us/step - loss: 0.1999 - acc: 0.96871\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 23s 755us/step - loss: 0.2069 - acc: 0.9690\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 23s 758us/step - loss: 0.1875 - acc: 0.9717\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 22s 748us/step - loss: 0.1850 - acc: 0.9721\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 23s 763us/step - loss: 0.1790 - acc: 0.97231s - loss: \n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 23s 760us/step - loss: 0.1919 - acc: 0.9719\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 23s 768us/step - loss: 0.1839 - acc: 0.9733\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 22s 746us/step - loss: 0.1794 - acc: 0.9738\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 22s 750us/step - loss: 0.1787 - acc: 0.9739\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 24s 789us/step - loss: 0.1841 - acc: 0.9737\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 25s 841us/step - loss: 0.1743 - acc: 0.9755\n",
      "30000/30000 [==============================] - 7s 241us/step\n",
      "30000/30000 [==============================] - 6s 185us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=30, num_neurons=1024, optimizer_algo=adam, total=11.1min\n",
      "[CV] activation=sigmoid, dropout=0.3, epochs=30, num_neurons=1024, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 25s 820us/step - loss: 0.3441 - acc: 0.9013\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 23s 757us/step - loss: 0.2125 - acc: 0.9366\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 27s 912us/step - loss: 0.2057 - acc: 0.9417\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 22s 740us/step - loss: 0.2025 - acc: 0.9471\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 21s 694us/step - loss: 0.2002 - acc: 0.9494\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 21s 690us/step - loss: 0.1988 - acc: 0.9524\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 21s 693us/step - loss: 0.1956 - acc: 0.9558\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 21s 687us/step - loss: 0.1952 - acc: 0.9572\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 21s 714us/step - loss: 0.1913 - acc: 0.9597\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 21s 695us/step - loss: 0.2079 - acc: 0.9597\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 21s 695us/step - loss: 0.1985 - acc: 0.9632\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 21s 690us/step - loss: 0.1946 - acc: 0.9622\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 21s 691us/step - loss: 0.1699 - acc: 0.9678\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 21s 690us/step - loss: 0.1642 - acc: 0.9679\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 21s 697us/step - loss: 0.1489 - acc: 0.97030s - loss: 0.1481 - acc: 0.9\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 22s 722us/step - loss: 0.1611 - acc: 0.9696\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 21s 712us/step - loss: 0.1733 - acc: 0.9681\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 21s 686us/step - loss: 0.1825 - acc: 0.9685\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 22s 749us/step - loss: 0.1873 - acc: 0.9698\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 21s 690us/step - loss: 0.1904 - acc: 0.9696\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 21s 686us/step - loss: 0.1766 - acc: 0.9713\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 21s 692us/step - loss: 0.1719 - acc: 0.9719\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 21s 689us/step - loss: 0.1899 - acc: 0.9713\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 21s 692us/step - loss: 0.1942 - acc: 0.9704\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 21s 686us/step - loss: 0.1806 - acc: 0.9731\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 21s 689us/step - loss: 0.1880 - acc: 0.9727\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 20s 681us/step - loss: 0.1787 - acc: 0.9745\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 21s 691us/step - loss: 0.1774 - acc: 0.9748\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 21s 696us/step - loss: 0.1857 - acc: 0.9742\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 21s 703us/step - loss: 0.2032 - acc: 0.9717\n",
      "30000/30000 [==============================] - 5s 167us/step\n",
      "30000/30000 [==============================] - 4s 134us/step\n",
      "[CV]  activation=sigmoid, dropout=0.3, epochs=30, num_neurons=1024, optimizer_algo=adam, total=10.8min\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=10, num_neurons=256, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 7s 226us/step - loss: 1.9791 - acc: 0.3163\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 5s 153us/step - loss: 1.3101 - acc: 0.5961\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 4s 144us/step - loss: 0.9963 - acc: 0.6943\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 4s 141us/step - loss: 0.8425 - acc: 0.7412\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 0.7513 - acc: 0.7706\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 4s 141us/step - loss: 0.6867 - acc: 0.7904\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 4s 138us/step - loss: 0.6462 - acc: 0.8039\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 4s 135us/step - loss: 0.6051 - acc: 0.8169\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 4s 140us/step - loss: 0.5777 - acc: 0.8237\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 4s 138us/step - loss: 0.5512 - acc: 0.8324\n",
      "30000/30000 [==============================] - 3s 97us/step\n",
      "30000/30000 [==============================] - 2s 66us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=10, num_neurons=256, optimizer_algo=sgd, total=  48.8s\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=10, num_neurons=256, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 6s 199us/step - loss: 2.0001 - acc: 0.3092\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 4s 125us/step - loss: 1.3149 - acc: 0.5922\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 4s 133us/step - loss: 0.9988 - acc: 0.6955\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.8422 - acc: 0.7447\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 4s 129us/step - loss: 0.7506 - acc: 0.7716\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 4s 128us/step - loss: 0.6919 - acc: 0.7888\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 4s 132us/step - loss: 0.6439 - acc: 0.8037\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 4s 122us/step - loss: 0.5990 - acc: 0.8182\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 4s 134us/step - loss: 0.5790 - acc: 0.8259\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 4s 132us/step - loss: 0.5593 - acc: 0.8299\n",
      "30000/30000 [==============================] - 3s 95us/step\n",
      "30000/30000 [==============================] - 2s 69us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=10, num_neurons=256, optimizer_algo=sgd, total=  44.8s\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=10, num_neurons=256, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 8s 266us/step - loss: 0.3757 - acc: 0.8829\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 5s 181us/step - loss: 0.2516 - acc: 0.9225\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 5s 182us/step - loss: 0.2219 - acc: 0.9337\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 5s 181us/step - loss: 0.2073 - acc: 0.9376\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 5s 181us/step - loss: 0.1996 - acc: 0.9390\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 6s 188us/step - loss: 0.1988 - acc: 0.9413\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 5s 180us/step - loss: 0.1824 - acc: 0.9451\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 6s 187us/step - loss: 0.1752 - acc: 0.9467\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 5s 178us/step - loss: 0.1711 - acc: 0.9482\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 5s 179us/step - loss: 0.1695 - acc: 0.9497\n",
      "30000/30000 [==============================] - 3s 97us/step\n",
      "30000/30000 [==============================] - 2s 69us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=10, num_neurons=256, optimizer_algo=adam, total= 1.0min\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=10, num_neurons=256, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 7s 249us/step - loss: 0.3871 - acc: 0.8814\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 6s 186us/step - loss: 0.2455 - acc: 0.9258\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 5s 173us/step - loss: 0.2153 - acc: 0.9344\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 5s 181us/step - loss: 0.1985 - acc: 0.9394\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 5s 172us/step - loss: 0.1995 - acc: 0.9398\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 5s 172us/step - loss: 0.1831 - acc: 0.9441\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 5s 174us/step - loss: 0.1807 - acc: 0.9452\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 5s 171us/step - loss: 0.1638 - acc: 0.9494\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 5s 167us/step - loss: 0.1642 - acc: 0.9511\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 5s 165us/step - loss: 0.1588 - acc: 0.9516\n",
      "30000/30000 [==============================] - 3s 100us/step\n",
      "30000/30000 [==============================] - 2s 73us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=10, num_neurons=256, optimizer_algo=adam, total=  58.0s\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=10, num_neurons=512, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 8s 283us/step - loss: 1.9184 - acc: 0.3474\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 6s 210us/step - loss: 1.2198 - acc: 0.6209\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 6s 210us/step - loss: 0.9306 - acc: 0.7124\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 6s 209us/step - loss: 0.7881 - acc: 0.7586\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 6s 203us/step - loss: 0.7064 - acc: 0.7831\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 6s 205us/step - loss: 0.6544 - acc: 0.7958\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 6s 211us/step - loss: 0.6096 - acc: 0.8133\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 6s 202us/step - loss: 0.5765 - acc: 0.8236\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 6s 203us/step - loss: 0.5553 - acc: 0.8305\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 6s 203us/step - loss: 0.5379 - acc: 0.8361\n",
      "30000/30000 [==============================] - 4s 122us/step\n",
      "30000/30000 [==============================] - 3s 92us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=10, num_neurons=512, optimizer_algo=sgd, total= 1.1min\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=10, num_neurons=512, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 8s 281us/step - loss: 1.9042 - acc: 0.3470\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 6s 216us/step - loss: 1.2119 - acc: 0.6191\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 6s 211us/step - loss: 0.9202 - acc: 0.7127\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 6s 215us/step - loss: 0.7833 - acc: 0.7549\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 6s 214us/step - loss: 0.7042 - acc: 0.7820\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 6s 216us/step - loss: 0.6446 - acc: 0.7985\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 6s 212us/step - loss: 0.6027 - acc: 0.8156\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 7s 220us/step - loss: 0.5800 - acc: 0.8181\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 6s 211us/step - loss: 0.5522 - acc: 0.8278\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 6s 212us/step - loss: 0.5321 - acc: 0.8392\n",
      "30000/30000 [==============================] - 4s 126us/step\n",
      "30000/30000 [==============================] - 3s 93us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=10, num_neurons=512, optimizer_algo=sgd, total= 1.2min\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=10, num_neurons=512, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 13s 418us/step - loss: 0.3731 - acc: 0.8874\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 11s 352us/step - loss: 0.2511 - acc: 0.9255\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 10s 340us/step - loss: 0.2366 - acc: 0.9307\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 10s 339us/step - loss: 0.2156 - acc: 0.9353\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 10s 340us/step - loss: 0.2006 - acc: 0.9429\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 11s 352us/step - loss: 0.1923 - acc: 0.9439\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 10s 346us/step - loss: 0.1837 - acc: 0.9480\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 10s 335us/step - loss: 0.1870 - acc: 0.9479\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 10s 330us/step - loss: 0.1809 - acc: 0.9517\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 10s 337us/step - loss: 0.1660 - acc: 0.9536\n",
      "30000/30000 [==============================] - 4s 126us/step\n",
      "30000/30000 [==============================] - 3s 96us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=10, num_neurons=512, optimizer_algo=adam, total= 1.8min\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=10, num_neurons=512, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 12s 407us/step - loss: 0.3739 - acc: 0.8857\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 10s 330us/step - loss: 0.2465 - acc: 0.9244\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 10s 343us/step - loss: 0.2309 - acc: 0.9303\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 10s 331us/step - loss: 0.2256 - acc: 0.9373\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 10s 329us/step - loss: 0.1991 - acc: 0.9432\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 10s 332us/step - loss: 0.1988 - acc: 0.9443\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 10s 342us/step - loss: 0.1781 - acc: 0.9483\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 10s 330us/step - loss: 0.1859 - acc: 0.9493\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 10s 336us/step - loss: 0.1854 - acc: 0.9493\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 10s 336us/step - loss: 0.1614 - acc: 0.9532\n",
      "30000/30000 [==============================] - 4s 135us/step\n",
      "30000/30000 [==============================] - 3s 94us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=10, num_neurons=512, optimizer_algo=adam, total= 1.8min\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=10, num_neurons=784, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 11s 371us/step - loss: 1.8898 - acc: 0.3524\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 9s 293us/step - loss: 1.1879 - acc: 0.6282\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 9s 291us/step - loss: 0.9066 - acc: 0.7171\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 9s 294us/step - loss: 0.7683 - acc: 0.7580\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 9s 284us/step - loss: 0.6874 - acc: 0.7845\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 9s 284us/step - loss: 0.6383 - acc: 0.8009\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 8s 281us/step - loss: 0.5999 - acc: 0.8128\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 9s 287us/step - loss: 0.5683 - acc: 0.8235\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 9s 291us/step - loss: 0.5492 - acc: 0.8295\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 8s 283us/step - loss: 0.5261 - acc: 0.8373\n",
      "30000/30000 [==============================] - 4s 150us/step\n",
      "30000/30000 [==============================] - 4s 120us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=10, num_neurons=784, optimizer_algo=sgd, total= 1.6min\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=10, num_neurons=784, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 11s 360us/step - loss: 1.8893 - acc: 0.3505\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 9s 292us/step - loss: 1.1821 - acc: 0.6288\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 9s 283us/step - loss: 0.9080 - acc: 0.7161\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 9s 284us/step - loss: 0.7669 - acc: 0.7611\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 8s 282us/step - loss: 0.6884 - acc: 0.7834\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 9s 296us/step - loss: 0.6367 - acc: 0.8013\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 9s 294us/step - loss: 0.5987 - acc: 0.8133\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 9s 284us/step - loss: 0.5714 - acc: 0.8250\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 9s 285us/step - loss: 0.5430 - acc: 0.8311\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 9s 284us/step - loss: 0.5255 - acc: 0.8379\n",
      "30000/30000 [==============================] - 4s 149us/step\n",
      "30000/30000 [==============================] - 4s 126us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=10, num_neurons=784, optimizer_algo=sgd, total= 1.6min\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=10, num_neurons=784, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 17s 576us/step - loss: 0.3882 - acc: 0.8815\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 15s 495us/step - loss: 0.2746 - acc: 0.9199\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 15s 504us/step - loss: 0.2387 - acc: 0.9296\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 15s 504us/step - loss: 0.2395 - acc: 0.9336\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 15s 505us/step - loss: 0.2306 - acc: 0.9382\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 15s 502us/step - loss: 0.2174 - acc: 0.9429\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 15s 498us/step - loss: 0.2145 - acc: 0.94522s - loss - ETA: 0s - loss: 0.2153 \n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 15s 512us/step - loss: 0.2222 - acc: 0.9436\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 15s 498us/step - loss: 0.2064 - acc: 0.94770s - loss: 0.2067 - ac\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 15s 500us/step - loss: 0.1969 - acc: 0.9503\n",
      "30000/30000 [==============================] - 5s 157us/step\n",
      "30000/30000 [==============================] - 4s 120us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=10, num_neurons=784, optimizer_algo=adam, total= 2.7min\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=10, num_neurons=784, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 18s 587us/step - loss: 0.3837 - acc: 0.8827\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 15s 503us/step - loss: 0.2623 - acc: 0.9248\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 15s 509us/step - loss: 0.2491 - acc: 0.93040s - loss: 0.2494 - acc: 0.93\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 15s 503us/step - loss: 0.2493 - acc: 0.9328\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 15s 512us/step - loss: 0.2413 - acc: 0.9372\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 15s 510us/step - loss: 0.2098 - acc: 0.9448\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 15s 502us/step - loss: 0.2028 - acc: 0.94785s - loss: 0.19\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 15s 509us/step - loss: 0.2143 - acc: 0.9460\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 15s 504us/step - loss: 0.1881 - acc: 0.9523\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 15s 501us/step - loss: 0.1820 - acc: 0.9544\n",
      "30000/30000 [==============================] - 5s 155us/step\n",
      "30000/30000 [==============================] - 4s 120us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=10, num_neurons=784, optimizer_algo=adam, total= 2.7min\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=10, num_neurons=1024, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 13s 436us/step - loss: 1.8733 - acc: 0.3591\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 11s 357us/step - loss: 1.1607 - acc: 0.6329\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 11s 366us/step - loss: 0.8884 - acc: 0.7186\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 11s 359us/step - loss: 0.7648 - acc: 0.7585\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 11s 362us/step - loss: 0.6838 - acc: 0.7840\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 11s 356us/step - loss: 0.6335 - acc: 0.8011\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 11s 369us/step - loss: 0.5932 - acc: 0.8144\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 11s 364us/step - loss: 0.5666 - acc: 0.8259\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 11s 359us/step - loss: 0.5397 - acc: 0.8318\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 11s 362us/step - loss: 0.5223 - acc: 0.8358\n",
      "30000/30000 [==============================] - 5s 172us/step\n",
      "30000/30000 [==============================] - 4s 132us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=10, num_neurons=1024, optimizer_algo=sgd, total= 1.9min\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=10, num_neurons=1024, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 13s 438us/step - loss: 1.8694 - acc: 0.3585\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 11s 364us/step - loss: 1.1547 - acc: 0.6366\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 11s 371us/step - loss: 0.8883 - acc: 0.72301s -\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 11s 358us/step - loss: 0.7546 - acc: 0.7616\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 11s 361us/step - loss: 0.6809 - acc: 0.7840\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 11s 358us/step - loss: 0.6301 - acc: 0.8007\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 11s 369us/step - loss: 0.5939 - acc: 0.8146\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 11s 361us/step - loss: 0.5633 - acc: 0.8229\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 11s 362us/step - loss: 0.5393 - acc: 0.8336\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 11s 367us/step - loss: 0.5258 - acc: 0.8374\n",
      "30000/30000 [==============================] - 5s 173us/step\n",
      "30000/30000 [==============================] - 4s 135us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=10, num_neurons=1024, optimizer_algo=sgd, total= 1.9min\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=10, num_neurons=1024, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 22s 732us/step - loss: 0.4067 - acc: 0.8817\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 20s 666us/step - loss: 0.3330 - acc: 0.9101\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 20s 653us/step - loss: 0.3190 - acc: 0.92071s - \n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 20s 655us/step - loss: 0.3136 - acc: 0.9268\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 20s 652us/step - loss: 0.3008 - acc: 0.9331\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 20s 671us/step - loss: 0.3170 - acc: 0.9342\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 20s 653us/step - loss: 0.2808 - acc: 0.9427\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 20s 657us/step - loss: 0.3138 - acc: 0.93970s - loss: 0.3134 - acc:\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 19s 650us/step - loss: 0.2950 - acc: 0.9423\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 19s 646us/step - loss: 0.2787 - acc: 0.94802s - loss - ETA: 1s - \n",
      "30000/30000 [==============================] - 5s 179us/step\n",
      "30000/30000 [==============================] - 4s 134us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=10, num_neurons=1024, optimizer_algo=adam, total= 3.4min\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=10, num_neurons=1024, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 22s 739us/step - loss: 0.3940 - acc: 0.8818\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 20s 650us/step - loss: 0.3045 - acc: 0.9151\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 20s 653us/step - loss: 0.2728 - acc: 0.9280\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 20s 670us/step - loss: 0.2753 - acc: 0.9317\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 20s 652us/step - loss: 0.2797 - acc: 0.9320\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 20s 654us/step - loss: 0.2511 - acc: 0.93991s -\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 19s 643us/step - loss: 0.2464 - acc: 0.94360s - loss: 0.2453 -\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 20s 654us/step - loss: 0.2705 - acc: 0.9418\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 19s 645us/step - loss: 0.2574 - acc: 0.9445\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 19s 650us/step - loss: 0.2302 - acc: 0.94911s - loss: 0.2355 - acc: 0. - ETA: 1s - lo\n",
      "30000/30000 [==============================] - 5s 169us/step\n",
      "30000/30000 [==============================] - 4s 139us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=10, num_neurons=1024, optimizer_algo=adam, total= 3.4min\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=20, num_neurons=256, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 7s 230us/step - loss: 1.9491 - acc: 0.3284\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 5s 152us/step - loss: 1.2901 - acc: 0.5997\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 5s 158us/step - loss: 0.9951 - acc: 0.6956\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 4s 149us/step - loss: 0.8368 - acc: 0.7470\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 4s 149us/step - loss: 0.7451 - acc: 0.7721\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 5s 152us/step - loss: 0.6864 - acc: 0.7911\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 5s 153us/step - loss: 0.6448 - acc: 0.8032\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 5s 150us/step - loss: 0.6081 - acc: 0.8147\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 5s 150us/step - loss: 0.5824 - acc: 0.8230\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 5s 153us/step - loss: 0.5587 - acc: 0.8313\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 4s 149us/step - loss: 0.5364 - acc: 0.8359\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 5s 158us/step - loss: 0.5220 - acc: 0.8424\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 5s 159us/step - loss: 0.5081 - acc: 0.8462\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 148us/step - loss: 0.5002 - acc: 0.8492\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 4s 149us/step - loss: 0.4830 - acc: 0.8539\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 4s 149us/step - loss: 0.4765 - acc: 0.8553\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 5s 155us/step - loss: 0.4662 - acc: 0.8590\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 0.4585 - acc: 0.8608\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 5s 152us/step - loss: 0.4510 - acc: 0.8637\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 5s 159us/step - loss: 0.4445 - acc: 0.8661\n",
      "30000/30000 [==============================] - 4s 117us/step\n",
      "30000/30000 [==============================] - 2s 80us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=20, num_neurons=256, optimizer_algo=sgd, total= 1.6min\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=20, num_neurons=256, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 7s 242us/step - loss: 1.9684 - acc: 0.3204\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 5s 157us/step - loss: 1.2974 - acc: 0.5971\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 5s 152us/step - loss: 0.9933 - acc: 0.6964\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 5s 152us/step - loss: 0.8443 - acc: 0.7382\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 5s 150us/step - loss: 0.7517 - acc: 0.7679\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 5s 157us/step - loss: 0.6870 - acc: 0.7875\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 5s 161us/step - loss: 0.6437 - acc: 0.8034\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 5s 154us/step - loss: 0.6044 - acc: 0.8169\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 5s 152us/step - loss: 0.5809 - acc: 0.8219\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 5s 156us/step - loss: 0.5613 - acc: 0.8279\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 4s 149us/step - loss: 0.5386 - acc: 0.8362\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 5s 150us/step - loss: 0.5217 - acc: 0.8420\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 4s 146us/step - loss: 0.5072 - acc: 0.8446\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 5s 159us/step - loss: 0.4994 - acc: 0.8482\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 0.4888 - acc: 0.8512\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 5s 163us/step - loss: 0.4792 - acc: 0.8542\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 5s 152us/step - loss: 0.4718 - acc: 0.8573\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 5s 156us/step - loss: 0.4588 - acc: 0.8616\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 5s 153us/step - loss: 0.4534 - acc: 0.8628\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 4s 149us/step - loss: 0.4499 - acc: 0.8653\n",
      "30000/30000 [==============================] - 4s 118us/step\n",
      "30000/30000 [==============================] - 2s 80us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=20, num_neurons=256, optimizer_algo=sgd, total= 1.7min\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=20, num_neurons=256, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 9s 284us/step - loss: 0.3825 - acc: 0.8822\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 6s 201us/step - loss: 0.2515 - acc: 0.9245\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 6s 193us/step - loss: 0.2253 - acc: 0.9323\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 6s 193us/step - loss: 0.2127 - acc: 0.9362\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 6s 194us/step - loss: 0.1932 - acc: 0.9410\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 6s 192us/step - loss: 0.1927 - acc: 0.9429\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 6s 196us/step - loss: 0.1829 - acc: 0.9453\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 6s 194us/step - loss: 0.1745 - acc: 0.9480\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 6s 203us/step - loss: 0.1714 - acc: 0.9494\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 6s 194us/step - loss: 0.1644 - acc: 0.9495\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 6s 193us/step - loss: 0.1634 - acc: 0.9535\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 6s 195us/step - loss: 0.1516 - acc: 0.9541\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 6s 194us/step - loss: 0.1559 - acc: 0.9564\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 6s 194us/step - loss: 0.1571 - acc: 0.9531\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 6s 195us/step - loss: 0.1470 - acc: 0.9562\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 6s 201us/step - loss: 0.1437 - acc: 0.9584\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 6s 192us/step - loss: 0.1449 - acc: 0.9578\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 6s 196us/step - loss: 0.1462 - acc: 0.9581\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 6s 194us/step - loss: 0.1416 - acc: 0.9597\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 6s 194us/step - loss: 0.1318 - acc: 0.9623\n",
      "30000/30000 [==============================] - 4s 131us/step\n",
      "30000/30000 [==============================] - 3s 83us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=20, num_neurons=256, optimizer_algo=adam, total= 2.1min\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=20, num_neurons=256, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 9s 289us/step - loss: 0.3757 - acc: 0.8830\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 6s 198us/step - loss: 0.2421 - acc: 0.9246\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 6s 197us/step - loss: 0.2210 - acc: 0.9324\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 6s 195us/step - loss: 0.2021 - acc: 0.9375\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 6s 196us/step - loss: 0.1844 - acc: 0.9447\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 6s 195us/step - loss: 0.1866 - acc: 0.9439\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 6s 195us/step - loss: 0.1742 - acc: 0.9472\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 6s 203us/step - loss: 0.1749 - acc: 0.9472\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 6s 196us/step - loss: 0.1600 - acc: 0.9520\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 6s 199us/step - loss: 0.1587 - acc: 0.9527\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 6s 197us/step - loss: 0.1547 - acc: 0.9537\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 6s 196us/step - loss: 0.1524 - acc: 0.9542\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 6s 196us/step - loss: 0.1507 - acc: 0.9540\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 6s 202us/step - loss: 0.1494 - acc: 0.9555\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 6s 194us/step - loss: 0.1421 - acc: 0.9577\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 6s 194us/step - loss: 0.1423 - acc: 0.9589\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 6s 193us/step - loss: 0.1426 - acc: 0.9582\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 6s 193us/step - loss: 0.1399 - acc: 0.9591\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 6s 194us/step - loss: 0.1304 - acc: 0.9610\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 6s 197us/step - loss: 0.1395 - acc: 0.9582\n",
      "30000/30000 [==============================] - 4s 120us/step\n",
      "30000/30000 [==============================] - 3s 88us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=20, num_neurons=256, optimizer_algo=adam, total= 2.1min\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=20, num_neurons=512, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 9s 307us/step - loss: 1.9295 - acc: 0.3374\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 7s 225us/step - loss: 1.2210 - acc: 0.6217\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 7s 221us/step - loss: 0.9300 - acc: 0.7138\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 7s 222us/step - loss: 0.7871 - acc: 0.7543\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 7s 227us/step - loss: 0.7075 - acc: 0.7820\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 7s 231us/step - loss: 0.6493 - acc: 0.8001\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 7s 227us/step - loss: 0.6043 - acc: 0.8129\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 7s 237us/step - loss: 0.5754 - acc: 0.8210\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 6s 213us/step - loss: 0.5491 - acc: 0.8308\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 7s 217us/step - loss: 0.5333 - acc: 0.8356\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 6s 213us/step - loss: 0.5144 - acc: 0.8439\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 7s 239us/step - loss: 0.5036 - acc: 0.8448\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 7s 234us/step - loss: 0.4917 - acc: 0.8501\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 7s 219us/step - loss: 0.4737 - acc: 0.8554\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 7s 219us/step - loss: 0.4682 - acc: 0.8594\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 7s 222us/step - loss: 0.4582 - acc: 0.8603\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 7s 226us/step - loss: 0.4537 - acc: 0.8637\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 7s 226us/step - loss: 0.4435 - acc: 0.8667\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 7s 223us/step - loss: 0.4387 - acc: 0.8693\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 7s 220us/step - loss: 0.4333 - acc: 0.8692\n",
      "30000/30000 [==============================] - 4s 143us/step\n",
      "30000/30000 [==============================] - 3s 106us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=20, num_neurons=512, optimizer_algo=sgd, total= 2.4min\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=20, num_neurons=512, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 10s 322us/step - loss: 1.9176 - acc: 0.3432\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 7s 235us/step - loss: 1.2197 - acc: 0.6199\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 7s 228us/step - loss: 0.9291 - acc: 0.7137\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 7s 242us/step - loss: 0.7882 - acc: 0.7556\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 7s 229us/step - loss: 0.7036 - acc: 0.7807\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 7s 229us/step - loss: 0.6469 - acc: 0.8008\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 7s 224us/step - loss: 0.6043 - acc: 0.8122\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 7s 230us/step - loss: 0.5763 - acc: 0.8237\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 6s 217us/step - loss: 0.5531 - acc: 0.8294\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 7s 217us/step - loss: 0.5297 - acc: 0.8363\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 6s 216us/step - loss: 0.5186 - acc: 0.8399\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 6s 215us/step - loss: 0.5021 - acc: 0.8467\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 7s 218us/step - loss: 0.4869 - acc: 0.8514\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 7s 228us/step - loss: 0.4696 - acc: 0.8570\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 7s 219us/step - loss: 0.4645 - acc: 0.8588\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 6s 216us/step - loss: 0.4591 - acc: 0.8604\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 7s 218us/step - loss: 0.4482 - acc: 0.8642\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 6s 216us/step - loss: 0.4456 - acc: 0.8652\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 7s 219us/step - loss: 0.4370 - acc: 0.8673\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 7s 228us/step - loss: 0.4335 - acc: 0.8680\n",
      "30000/30000 [==============================] - 4s 143us/step\n",
      "30000/30000 [==============================] - 3s 106us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=20, num_neurons=512, optimizer_algo=sgd, total= 2.4min\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=20, num_neurons=512, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 13s 445us/step - loss: 0.3744 - acc: 0.8867\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 11s 354us/step - loss: 0.2623 - acc: 0.9236\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 11s 361us/step - loss: 0.2183 - acc: 0.9354\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 10s 343us/step - loss: 0.2169 - acc: 0.9382\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 10s 345us/step - loss: 0.1989 - acc: 0.9423\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 10s 346us/step - loss: 0.1967 - acc: 0.9426\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 11s 357us/step - loss: 0.1888 - acc: 0.9463\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 11s 351us/step - loss: 0.1779 - acc: 0.9507\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 10s 343us/step - loss: 0.1723 - acc: 0.9534\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 11s 356us/step - loss: 0.1769 - acc: 0.9510\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 10s 350us/step - loss: 0.1606 - acc: 0.9550\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 10s 347us/step - loss: 0.1621 - acc: 0.9547\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 10s 347us/step - loss: 0.1677 - acc: 0.9542\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 11s 356us/step - loss: 0.1516 - acc: 0.9579\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 10s 343us/step - loss: 0.1555 - acc: 0.9568\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 10s 344us/step - loss: 0.1517 - acc: 0.9598\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 10s 345us/step - loss: 0.1584 - acc: 0.9581\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 11s 356us/step - loss: 0.1419 - acc: 0.9620\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 10s 349us/step - loss: 0.1461 - acc: 0.9608\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 10s 342us/step - loss: 0.1421 - acc: 0.9631\n",
      "30000/30000 [==============================] - 4s 142us/step\n",
      "30000/30000 [==============================] - 3s 108us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=20, num_neurons=512, optimizer_algo=adam, total= 3.6min\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=20, num_neurons=512, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 14s 462us/step - loss: 0.3721 - acc: 0.8864\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 11s 356us/step - loss: 0.2439 - acc: 0.9269\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 12s 400us/step - loss: 0.2278 - acc: 0.9332\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 12s 399us/step - loss: 0.2076 - acc: 0.9384\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 12s 397us/step - loss: 0.2022 - acc: 0.9418\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 11s 363us/step - loss: 0.2029 - acc: 0.9434\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 11s 358us/step - loss: 0.1925 - acc: 0.9465\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 11s 363us/step - loss: 0.1793 - acc: 0.9502\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 11s 358us/step - loss: 0.1777 - acc: 0.9507\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 10s 346us/step - loss: 0.1751 - acc: 0.9523\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 10s 347us/step - loss: 0.1647 - acc: 0.9552\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 11s 357us/step - loss: 0.1711 - acc: 0.9534\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 10s 346us/step - loss: 0.1678 - acc: 0.95500s - loss: 0.1667 - a\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 10s 344us/step - loss: 0.1533 - acc: 0.9595\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 11s 352us/step - loss: 0.1601 - acc: 0.9591\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 10s 350us/step - loss: 0.1620 - acc: 0.9581\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 11s 361us/step - loss: 0.1516 - acc: 0.9608\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 10s 347us/step - loss: 0.1604 - acc: 0.9591\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 11s 358us/step - loss: 0.1419 - acc: 0.96251s - loss: 0.1401 - ac - ETA: 0s - loss: 0.1\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 10s 348us/step - loss: 0.1456 - acc: 0.9615\n",
      "30000/30000 [==============================] - 4s 143us/step\n",
      "30000/30000 [==============================] - 3s 106us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=20, num_neurons=512, optimizer_algo=adam, total= 3.7min\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=20, num_neurons=784, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 12s 398us/step - loss: 1.8985 - acc: 0.3512\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 9s 310us/step - loss: 1.1903 - acc: 0.6271\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 9s 301us/step - loss: 0.9100 - acc: 0.7168\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 9s 300us/step - loss: 0.7738 - acc: 0.7578\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 9s 305us/step - loss: 0.6968 - acc: 0.7809\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 9s 307us/step - loss: 0.6420 - acc: 0.7998\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 10s 332us/step - loss: 0.5994 - acc: 0.8137\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 9s 312us/step - loss: 0.5702 - acc: 0.8227\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 9s 304us/step - loss: 0.5447 - acc: 0.8321\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 9s 300us/step - loss: 0.5256 - acc: 0.8385\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 9s 312us/step - loss: 0.5109 - acc: 0.8453\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 9s 302us/step - loss: 0.5010 - acc: 0.8448\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 9s 303us/step - loss: 0.4865 - acc: 0.8497\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 9s 303us/step - loss: 0.4786 - acc: 0.8533\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 9s 307us/step - loss: 0.4685 - acc: 0.8592 0s - loss: 0.4688 - acc: 0.85\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 9s 301us/step - loss: 0.4572 - acc: 0.8610 1\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 9s 302us/step - loss: 0.4517 - acc: 0.8639\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 9s 300us/step - loss: 0.4414 - acc: 0.8673\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 9s 313us/step - loss: 0.4358 - acc: 0.8665\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 10s 319us/step - loss: 0.4330 - acc: 0.8706\n",
      "30000/30000 [==============================] - 5s 179us/step\n",
      "30000/30000 [==============================] - 4s 131us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=20, num_neurons=784, optimizer_algo=sgd, total= 3.2min\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=20, num_neurons=784, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 12s 395us/step - loss: 1.8636 - acc: 0.3652\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 9s 306us/step - loss: 1.1662 - acc: 0.6345\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 9s 312us/step - loss: 0.8980 - acc: 0.7170\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 9s 308us/step - loss: 0.7632 - acc: 0.7615\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 9s 302us/step - loss: 0.6892 - acc: 0.7838\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 9s 306us/step - loss: 0.6331 - acc: 0.8019\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 9s 315us/step - loss: 0.5978 - acc: 0.8139\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 9s 305us/step - loss: 0.5696 - acc: 0.8225\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 9s 306us/step - loss: 0.5453 - acc: 0.8308 0s - loss: 0.549\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 9s 307us/step - loss: 0.5238 - acc: 0.8387\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 9s 315us/step - loss: 0.5098 - acc: 0.8438\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 9s 316us/step - loss: 0.4970 - acc: 0.8473\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 9s 313us/step - loss: 0.4842 - acc: 0.8519\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 9s 314us/step - loss: 0.4730 - acc: 0.8549\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 9s 307us/step - loss: 0.4645 - acc: 0.8570\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 9s 316us/step - loss: 0.4589 - acc: 0.8593\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 9s 308us/step - loss: 0.4517 - acc: 0.8622\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 9s 311us/step - loss: 0.4439 - acc: 0.8634\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 9s 304us/step - loss: 0.4383 - acc: 0.8668\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 9s 315us/step - loss: 0.4352 - acc: 0.8679\n",
      "30000/30000 [==============================] - 5s 171us/step\n",
      "30000/30000 [==============================] - 4s 134us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=20, num_neurons=784, optimizer_algo=sgd, total= 3.2min\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=20, num_neurons=784, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 18s 613us/step - loss: 0.3845 - acc: 0.8841\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 16s 528us/step - loss: 0.2573 - acc: 0.9246\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 16s 520us/step - loss: 0.2458 - acc: 0.9307\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 16s 532us/step - loss: 0.2524 - acc: 0.9323\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 16s 528us/step - loss: 0.2405 - acc: 0.9373\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 16s 520us/step - loss: 0.2456 - acc: 0.9402\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 16s 527us/step - loss: 0.2415 - acc: 0.9404\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 16s 521us/step - loss: 0.2363 - acc: 0.9443\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 16s 523us/step - loss: 0.2399 - acc: 0.9444\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 16s 527us/step - loss: 0.2196 - acc: 0.95080s - loss: 0.2196 \n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 16s 523us/step - loss: 0.2119 - acc: 0.9518\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 16s 527us/step - loss: 0.2106 - acc: 0.9522\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 16s 521us/step - loss: 0.1991 - acc: 0.95370s - loss: 0.1987 - acc: 0.9\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 16s 523us/step - loss: 0.2046 - acc: 0.9545\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 16s 536us/step - loss: 0.1989 - acc: 0.95633s - lo -\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 16s 525us/step - loss: 0.1939 - acc: 0.9572\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 16s 531us/step - loss: 0.2055 - acc: 0.9577\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 16s 522us/step - loss: 0.2087 - acc: 0.9570\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 16s 520us/step - loss: 0.2086 - acc: 0.9572\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 16s 534us/step - loss: 0.2059 - acc: 0.9596\n",
      "30000/30000 [==============================] - 5s 169us/step\n",
      "30000/30000 [==============================] - 4s 133us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=20, num_neurons=784, optimizer_algo=adam, total= 5.4min\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=20, num_neurons=784, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 19s 629us/step - loss: 0.3839 - acc: 0.8852\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 16s 524us/step - loss: 0.2648 - acc: 0.92220s - loss: 0.2659 - ac\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 16s 532us/step - loss: 0.2561 - acc: 0.9271\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 16s 542us/step - loss: 0.2333 - acc: 0.9356\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 16s 525us/step - loss: 0.2412 - acc: 0.9371\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 16s 544us/step - loss: 0.2217 - acc: 0.94180s - loss: 0.2221 - \n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 16s 526us/step - loss: 0.2209 - acc: 0.9438\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 16s 525us/step - loss: 0.2014 - acc: 0.9491\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 16s 534us/step - loss: 0.2130 - acc: 0.9492\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 16s 526us/step - loss: 0.2241 - acc: 0.9480\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 16s 538us/step - loss: 0.2062 - acc: 0.9518\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 16s 526us/step - loss: 0.2118 - acc: 0.9530\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 16s 530us/step - loss: 0.2146 - acc: 0.95339s - los - \n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 16s 534us/step - loss: 0.2061 - acc: 0.9557\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 16s 521us/step - loss: 0.1944 - acc: 0.95741s - loss: 0\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 16s 536us/step - loss: 0.1915 - acc: 0.9578\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 16s 528us/step - loss: 0.1863 - acc: 0.9588\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 16s 543us/step - loss: 0.1935 - acc: 0.9582\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 16s 542us/step - loss: 0.1833 - acc: 0.9605\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 16s 531us/step - loss: 0.1816 - acc: 0.9607\n",
      "30000/30000 [==============================] - 6s 192us/step\n",
      "30000/30000 [==============================] - 4s 137us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=20, num_neurons=784, optimizer_algo=adam, total= 5.5min\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=20, num_neurons=1024, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 15s 486us/step - loss: 1.8484 - acc: 0.36700s - loss: 1.8597 - acc:\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 12s 384us/step - loss: 1.1509 - acc: 0.6376\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 11s 376us/step - loss: 0.8865 - acc: 0.7235\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 11s 383us/step - loss: 0.7542 - acc: 0.7637\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 11s 375us/step - loss: 0.6836 - acc: 0.78540s - loss: 0.6857 - acc\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 11s 375us/step - loss: 0.6290 - acc: 0.8028\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 11s 376us/step - loss: 0.5912 - acc: 0.8161\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 12s 384us/step - loss: 0.5667 - acc: 0.8224\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 11s 375us/step - loss: 0.5421 - acc: 0.8320\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 11s 379us/step - loss: 0.5201 - acc: 0.8382\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 12s 384us/step - loss: 0.5059 - acc: 0.8452\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 11s 371us/step - loss: 0.4957 - acc: 0.8468\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 11s 374us/step - loss: 0.4857 - acc: 0.8494\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 11s 373us/step - loss: 0.4713 - acc: 0.8550\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 12s 386us/step - loss: 0.4667 - acc: 0.8564\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 11s 374us/step - loss: 0.4561 - acc: 0.8627\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 11s 375us/step - loss: 0.4456 - acc: 0.8637\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 12s 389us/step - loss: 0.4431 - acc: 0.8644\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 12s 385us/step - loss: 0.4327 - acc: 0.8693\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 11s 375us/step - loss: 0.4283 - acc: 0.8701\n",
      "30000/30000 [==============================] - 6s 187us/step\n",
      "30000/30000 [==============================] - 4s 146us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=20, num_neurons=1024, optimizer_algo=sgd, total= 3.9min\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=20, num_neurons=1024, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 14s 472us/step - loss: 1.8816 - acc: 0.3521\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 11s 379us/step - loss: 1.1703 - acc: 0.6311\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 11s 378us/step - loss: 0.8925 - acc: 0.72011s - loss: \n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 12s 388us/step - loss: 0.7580 - acc: 0.7615\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 12s 385us/step - loss: 0.6783 - acc: 0.7867\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 11s 375us/step - loss: 0.6334 - acc: 0.8020\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 12s 400us/step - loss: 0.5975 - acc: 0.8108\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 11s 379us/step - loss: 0.5660 - acc: 0.8219\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 11s 376us/step - loss: 0.5459 - acc: 0.8292\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 11s 376us/step - loss: 0.5229 - acc: 0.83682s - loss: 0.5230 - a - ETA: 1s\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 12s 387us/step - loss: 0.5046 - acc: 0.8453\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 11s 379us/step - loss: 0.4997 - acc: 0.8453\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 12s 393us/step - loss: 0.4816 - acc: 0.8524\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 12s 387us/step - loss: 0.4711 - acc: 0.8534\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 11s 380us/step - loss: 0.4614 - acc: 0.8590\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 11s 378us/step - loss: 0.4574 - acc: 0.8596\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 11s 378us/step - loss: 0.4507 - acc: 0.8612\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 12s 389us/step - loss: 0.4470 - acc: 0.8640\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 11s 377us/step - loss: 0.4384 - acc: 0.8654\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 11s 378us/step - loss: 0.4322 - acc: 0.8679\n",
      "30000/30000 [==============================] - 6s 185us/step\n",
      "30000/30000 [==============================] - 5s 151us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=20, num_neurons=1024, optimizer_algo=sgd, total= 4.0min\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=20, num_neurons=1024, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 23s 766us/step - loss: 0.4037 - acc: 0.8839\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 20s 677us/step - loss: 0.3002 - acc: 0.9167\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 20s 670us/step - loss: 0.2991 - acc: 0.9234\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 20s 676us/step - loss: 0.2747 - acc: 0.9314\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 20s 667us/step - loss: 0.2718 - acc: 0.9354\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 20s 675us/step - loss: 0.2690 - acc: 0.9390\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 20s 671us/step - loss: 0.2889 - acc: 0.9383\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 20s 672us/step - loss: 0.2796 - acc: 0.9415\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 20s 668us/step - loss: 0.2663 - acc: 0.9458\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 20s 673us/step - loss: 0.2662 - acc: 0.9481\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 20s 665us/step - loss: 0.2565 - acc: 0.94980s - loss: 0.2574 - acc\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 20s 672us/step - loss: 0.2472 - acc: 0.9514\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 20s 673us/step - loss: 0.2423 - acc: 0.9531\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 20s 673us/step - loss: 0.2363 - acc: 0.9563\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 20s 667us/step - loss: 0.2473 - acc: 0.9532\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 20s 679us/step - loss: 0.2357 - acc: 0.9555\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 20s 666us/step - loss: 0.2362 - acc: 0.9583\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 20s 671us/step - loss: 0.2422 - acc: 0.9578\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 20s 662us/step - loss: 0.2534 - acc: 0.9568\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 20s 666us/step - loss: 0.2439 - acc: 0.9585\n",
      "30000/30000 [==============================] - 6s 189us/step\n",
      "30000/30000 [==============================] - 4s 148us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=20, num_neurons=1024, optimizer_algo=adam, total= 6.9min\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=20, num_neurons=1024, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 23s 774us/step - loss: 0.4041 - acc: 0.8800\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 20s 680us/step - loss: 0.3245 - acc: 0.9146\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 20s 677us/step - loss: 0.3257 - acc: 0.92060s - loss: 0.3239 -\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 20s 674us/step - loss: 0.3044 - acc: 0.9289\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 20s 676us/step - loss: 0.2895 - acc: 0.9357\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 20s 668us/step - loss: 0.2776 - acc: 0.9377\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 20s 673us/step - loss: 0.2972 - acc: 0.9390\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 21s 696us/step - loss: 0.2866 - acc: 0.94160s - loss: 0.2868 - ac\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 21s 684us/step - loss: 0.2916 - acc: 0.9435\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 20s 675us/step - loss: 0.3007 - acc: 0.94500s - loss: 0.3002 - ac\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 20s 680us/step - loss: 0.2726 - acc: 0.9495\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 20s 671us/step - loss: 0.2917 - acc: 0.9485\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 20s 676us/step - loss: 0.2719 - acc: 0.9511\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 20s 666us/step - loss: 0.2741 - acc: 0.9521\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 20s 681us/step - loss: 0.2659 - acc: 0.9542\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 21s 687us/step - loss: 0.2565 - acc: 0.95710s - loss: 0.2576 - acc: \n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 20s 679us/step - loss: 0.2809 - acc: 0.9553\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 20s 674us/step - loss: 0.2896 - acc: 0.9554\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 20s 682us/step - loss: 0.3053 - acc: 0.9547\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 20s 668us/step - loss: 0.2759 - acc: 0.9582\n",
      "30000/30000 [==============================] - 6s 189us/step\n",
      "30000/30000 [==============================] - 5s 151us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=20, num_neurons=1024, optimizer_algo=adam, total= 6.9min\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=30, num_neurons=256, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 8s 267us/step - loss: 1.9724 - acc: 0.3198\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 5s 171us/step - loss: 1.2988 - acc: 0.5994\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 5s 174us/step - loss: 0.9989 - acc: 0.6932\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 5s 175us/step - loss: 0.8412 - acc: 0.7423\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 5s 169us/step - loss: 0.7490 - acc: 0.7712\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 5s 172us/step - loss: 0.6854 - acc: 0.7905\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 5s 172us/step - loss: 0.6423 - acc: 0.8056\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 5s 180us/step - loss: 0.6081 - acc: 0.8159\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 5s 172us/step - loss: 0.5735 - acc: 0.8257\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 5s 172us/step - loss: 0.5548 - acc: 0.8303\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 5s 173us/step - loss: 0.5390 - acc: 0.8383\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 5s 175us/step - loss: 0.5203 - acc: 0.8425\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 5s 174us/step - loss: 0.5072 - acc: 0.8472\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 5s 170us/step - loss: 0.4960 - acc: 0.8499\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 5s 172us/step - loss: 0.4805 - acc: 0.8551\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 5s 177us/step - loss: 0.4733 - acc: 0.8569\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 5s 172us/step - loss: 0.4652 - acc: 0.8608\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 5s 173us/step - loss: 0.4561 - acc: 0.8649\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 5s 173us/step - loss: 0.4503 - acc: 0.8663\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 5s 177us/step - loss: 0.4388 - acc: 0.8692\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 5s 171us/step - loss: 0.4384 - acc: 0.8690\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 5s 173us/step - loss: 0.4273 - acc: 0.8736\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 5s 171us/step - loss: 0.4233 - acc: 0.8739\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 5s 178us/step - loss: 0.4164 - acc: 0.8763\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 5s 172us/step - loss: 0.4103 - acc: 0.8777\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 5s 173us/step - loss: 0.4089 - acc: 0.8760\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 5s 173us/step - loss: 0.4038 - acc: 0.8811\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 5s 173us/step - loss: 0.4005 - acc: 0.8801\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 5s 174us/step - loss: 0.3987 - acc: 0.8823\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 5s 174us/step - loss: 0.3934 - acc: 0.8832\n",
      "30000/30000 [==============================] - 4s 135us/step\n",
      "30000/30000 [==============================] - 3s 98us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=30, num_neurons=256, optimizer_algo=sgd, total= 2.7min\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=30, num_neurons=256, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 8s 278us/step - loss: 1.9900 - acc: 0.3130\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 5s 176us/step - loss: 1.2993 - acc: 0.5961\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 5s 175us/step - loss: 1.0017 - acc: 0.6934\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 5s 175us/step - loss: 0.8358 - acc: 0.7454\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 5s 176us/step - loss: 0.7474 - acc: 0.7686\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 5s 176us/step - loss: 0.6885 - acc: 0.7871\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 5s 180us/step - loss: 0.6426 - acc: 0.8027\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 5s 174us/step - loss: 0.6073 - acc: 0.8120\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 5s 175us/step - loss: 0.5742 - acc: 0.8258\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 5s 174us/step - loss: 0.5544 - acc: 0.8302\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 5s 176us/step - loss: 0.5403 - acc: 0.8358\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 5s 180us/step - loss: 0.5236 - acc: 0.8388\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 5s 176us/step - loss: 0.5093 - acc: 0.8450\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 5s 178us/step - loss: 0.4967 - acc: 0.8488\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 5s 173us/step - loss: 0.4845 - acc: 0.8523\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 5s 175us/step - loss: 0.4723 - acc: 0.8562\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 5s 177us/step - loss: 0.4650 - acc: 0.8582\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 5s 175us/step - loss: 0.4567 - acc: 0.8610\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 5s 176us/step - loss: 0.4542 - acc: 0.8617\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 5s 175us/step - loss: 0.4425 - acc: 0.8666\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 5s 175us/step - loss: 0.4388 - acc: 0.8671\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 5s 179us/step - loss: 0.4313 - acc: 0.8691\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 5s 176us/step - loss: 0.4288 - acc: 0.8700\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 5s 175us/step - loss: 0.4219 - acc: 0.8713\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 5s 175us/step - loss: 0.4140 - acc: 0.8754\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 5s 172us/step - loss: 0.4123 - acc: 0.8749\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 5s 175us/step - loss: 0.4038 - acc: 0.8796\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 5s 176us/step - loss: 0.4018 - acc: 0.8800\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 5s 179us/step - loss: 0.3975 - acc: 0.8799\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 5s 182us/step - loss: 0.3975 - acc: 0.8813\n",
      "30000/30000 [==============================] - 4s 132us/step\n",
      "30000/30000 [==============================] - 3s 93us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=30, num_neurons=256, optimizer_algo=sgd, total= 2.8min\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=30, num_neurons=256, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 10s 321us/step - loss: 0.3777 - acc: 0.8814\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 6s 213us/step - loss: 0.2435 - acc: 0.9253\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 6s 215us/step - loss: 0.2154 - acc: 0.9349\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 7s 223us/step - loss: 0.1972 - acc: 0.9400\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 6s 216us/step - loss: 0.1909 - acc: 0.9421\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 7s 218us/step - loss: 0.1866 - acc: 0.9445\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 6s 212us/step - loss: 0.1865 - acc: 0.9434\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 6s 212us/step - loss: 0.1686 - acc: 0.9486\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 6s 214us/step - loss: 0.1725 - acc: 0.9491\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 6s 213us/step - loss: 0.1626 - acc: 0.9530\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 7s 221us/step - loss: 0.1605 - acc: 0.9511\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 6s 215us/step - loss: 0.1597 - acc: 0.9524\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 7s 218us/step - loss: 0.1508 - acc: 0.9546\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 6s 216us/step - loss: 0.1530 - acc: 0.9540\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 7s 217us/step - loss: 0.1483 - acc: 0.9552\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 6s 214us/step - loss: 0.1498 - acc: 0.9562\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 7s 224us/step - loss: 0.1354 - acc: 0.9596\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 6s 215us/step - loss: 0.1379 - acc: 0.9585\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 6s 215us/step - loss: 0.1321 - acc: 0.9602\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 6s 216us/step - loss: 0.1405 - acc: 0.9601\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 6s 213us/step - loss: 0.1376 - acc: 0.9618\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 6s 215us/step - loss: 0.1290 - acc: 0.9617\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 7s 226us/step - loss: 0.1292 - acc: 0.9619\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 7s 231us/step - loss: 0.1296 - acc: 0.9625\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 7s 217us/step - loss: 0.1323 - acc: 0.9608\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 6s 213us/step - loss: 0.1264 - acc: 0.9618\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 6s 213us/step - loss: 0.1267 - acc: 0.9641\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 6s 211us/step - loss: 0.1213 - acc: 0.9654\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 7s 221us/step - loss: 0.1202 - acc: 0.9656\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 6s 210us/step - loss: 0.1190 - acc: 0.9653\n",
      "30000/30000 [==============================] - 4s 137us/step\n",
      "30000/30000 [==============================] - 3s 103us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=30, num_neurons=256, optimizer_algo=adam, total= 3.4min\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=30, num_neurons=256, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 9s 306us/step - loss: 0.3821 - acc: 0.8819\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 6s 208us/step - loss: 0.2382 - acc: 0.9271\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 6s 209us/step - loss: 0.2221 - acc: 0.9337\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 6s 216us/step - loss: 0.1987 - acc: 0.9407\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 6s 214us/step - loss: 0.1912 - acc: 0.9432\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 6s 207us/step - loss: 0.1821 - acc: 0.9465\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 6s 209us/step - loss: 0.1750 - acc: 0.9469\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 6s 208us/step - loss: 0.1732 - acc: 0.9485\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 6s 206us/step - loss: 0.1733 - acc: 0.9483\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 6s 215us/step - loss: 0.1576 - acc: 0.9527\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 6s 207us/step - loss: 0.1546 - acc: 0.9525\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 7s 224us/step - loss: 0.1513 - acc: 0.9540\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 6s 207us/step - loss: 0.1444 - acc: 0.9567\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 6s 208us/step - loss: 0.1431 - acc: 0.9575\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 6s 207us/step - loss: 0.1446 - acc: 0.9578\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 6s 216us/step - loss: 0.1553 - acc: 0.9539\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 6s 207us/step - loss: 0.1427 - acc: 0.9585\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 6s 207us/step - loss: 0.1354 - acc: 0.9592\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 6s 207us/step - loss: 0.1273 - acc: 0.9618\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 6s 208us/step - loss: 0.1382 - acc: 0.9596\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 6s 210us/step - loss: 0.1350 - acc: 0.9613\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 6s 206us/step - loss: 0.1310 - acc: 0.9614\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 7s 227us/step - loss: 0.1251 - acc: 0.9635\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 6s 209us/step - loss: 0.1162 - acc: 0.9657\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 6s 206us/step - loss: 0.1268 - acc: 0.9621\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 6s 205us/step - loss: 0.1242 - acc: 0.9647\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 6s 206us/step - loss: 0.1189 - acc: 0.9647\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 6s 206us/step - loss: 0.1102 - acc: 0.9669\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 6s 213us/step - loss: 0.1164 - acc: 0.9659\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 6s 207us/step - loss: 0.1242 - acc: 0.9642\n",
      "30000/30000 [==============================] - 4s 139us/step\n",
      "30000/30000 [==============================] - 3s 95us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=30, num_neurons=256, optimizer_algo=adam, total= 3.3min\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=30, num_neurons=512, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 10s 330us/step - loss: 1.8901 - acc: 0.3540\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 7s 232us/step - loss: 1.2080 - acc: 0.6236\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 7s 240us/step - loss: 0.9278 - acc: 0.7103\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 7s 231us/step - loss: 0.7851 - acc: 0.7574\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 7s 231us/step - loss: 0.7051 - acc: 0.7785\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 7s 230us/step - loss: 0.6493 - acc: 0.7999\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 7s 233us/step - loss: 0.6052 - acc: 0.8132\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 7s 244us/step - loss: 0.5781 - acc: 0.8217\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 7s 245us/step - loss: 0.5520 - acc: 0.8312\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 7s 235us/step - loss: 0.5335 - acc: 0.8348\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 7s 230us/step - loss: 0.5144 - acc: 0.8427\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 7s 230us/step - loss: 0.5010 - acc: 0.8473\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 7s 231us/step - loss: 0.4897 - acc: 0.8483\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 7s 234us/step - loss: 0.4730 - acc: 0.8585\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 7s 242us/step - loss: 0.4653 - acc: 0.8585\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 7s 232us/step - loss: 0.4585 - acc: 0.8610\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 7s 236us/step - loss: 0.4520 - acc: 0.8645\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 7s 233us/step - loss: 0.4404 - acc: 0.8677\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 7s 235us/step - loss: 0.4368 - acc: 0.8674\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 7s 244us/step - loss: 0.4322 - acc: 0.8700\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 7s 232us/step - loss: 0.4291 - acc: 0.8690\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 7s 232us/step - loss: 0.4210 - acc: 0.8750\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 7s 232us/step - loss: 0.4157 - acc: 0.8754\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 7s 231us/step - loss: 0.4094 - acc: 0.8762\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 7s 232us/step - loss: 0.4096 - acc: 0.8782\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 7s 241us/step - loss: 0.3992 - acc: 0.8820\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 7s 236us/step - loss: 0.3991 - acc: 0.8805\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 7s 235us/step - loss: 0.3954 - acc: 0.8841\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 7s 233us/step - loss: 0.3948 - acc: 0.8809\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 7s 236us/step - loss: 0.3882 - acc: 0.8830\n",
      "30000/30000 [==============================] - 5s 165us/step\n",
      "30000/30000 [==============================] - 4s 127us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=30, num_neurons=512, optimizer_algo=sgd, total= 3.7min\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=30, num_neurons=512, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 10s 336us/step - loss: 1.9200 - acc: 0.3405\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 7s 239us/step - loss: 1.2193 - acc: 0.6205\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 7s 233us/step - loss: 0.9331 - acc: 0.7129\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 7s 237us/step - loss: 0.7878 - acc: 0.7562\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 7s 237us/step - loss: 0.7064 - acc: 0.7791\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 7s 243us/step - loss: 0.6504 - acc: 0.7984\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 7s 235us/step - loss: 0.6139 - acc: 0.8106\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 7s 240us/step - loss: 0.5775 - acc: 0.8204\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 7s 238us/step - loss: 0.5528 - acc: 0.8296\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 7s 236us/step - loss: 0.5322 - acc: 0.8369\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 7s 246us/step - loss: 0.5202 - acc: 0.8426\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 7s 237us/step - loss: 0.5039 - acc: 0.8469\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 7s 233us/step - loss: 0.4894 - acc: 0.8501\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 7s 236us/step - loss: 0.4816 - acc: 0.8535\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 7s 233us/step - loss: 0.4713 - acc: 0.8587\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 7s 236us/step - loss: 0.4615 - acc: 0.8583\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 7s 240us/step - loss: 0.4529 - acc: 0.8614\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 7s 241us/step - loss: 0.4488 - acc: 0.8643\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 7s 241us/step - loss: 0.4428 - acc: 0.8655\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 7s 242us/step - loss: 0.4369 - acc: 0.8667\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 7s 236us/step - loss: 0.4259 - acc: 0.8698\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 7s 241us/step - loss: 0.4246 - acc: 0.8721\n",
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 7s 234us/step - loss: 0.4152 - acc: 0.8742\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 7s 231us/step - loss: 0.4123 - acc: 0.8782\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 7s 233us/step - loss: 0.4105 - acc: 0.8762\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 7s 231us/step - loss: 0.4076 - acc: 0.8760\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 7s 229us/step - loss: 0.3944 - acc: 0.8828\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 7s 240us/step - loss: 0.3985 - acc: 0.8808\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 7s 236us/step - loss: 0.3964 - acc: 0.8814\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 7s 231us/step - loss: 0.3904 - acc: 0.8814\n",
      "30000/30000 [==============================] - 5s 157us/step\n",
      "30000/30000 [==============================] - 3s 116us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=30, num_neurons=512, optimizer_algo=sgd, total= 3.7min\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=30, num_neurons=512, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 14s 463us/step - loss: 0.3759 - acc: 0.8864\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 11s 366us/step - loss: 0.2551 - acc: 0.9234\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 11s 361us/step - loss: 0.2391 - acc: 0.9322\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 11s 360us/step - loss: 0.2199 - acc: 0.9368\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 11s 365us/step - loss: 0.1998 - acc: 0.9420\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 11s 359us/step - loss: 0.2009 - acc: 0.9428\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 11s 356us/step - loss: 0.1838 - acc: 0.9485\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 11s 360us/step - loss: 0.1848 - acc: 0.9483\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 11s 373us/step - loss: 0.1714 - acc: 0.9524\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 11s 378us/step - loss: 0.1746 - acc: 0.9532\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 11s 360us/step - loss: 0.1686 - acc: 0.9525\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 11s 371us/step - loss: 0.1574 - acc: 0.9563\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 11s 368us/step - loss: 0.1714 - acc: 0.9549\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 11s 358us/step - loss: 0.1704 - acc: 0.9567\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 11s 360us/step - loss: 0.1509 - acc: 0.9587\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 11s 367us/step - loss: 0.1539 - acc: 0.9595\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 11s 361us/step - loss: 0.1521 - acc: 0.9601\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 11s 360us/step - loss: 0.1498 - acc: 0.9601\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 11s 371us/step - loss: 0.1437 - acc: 0.9610\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 11s 378us/step - loss: 0.1457 - acc: 0.9629\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 11s 362us/step - loss: 0.1382 - acc: 0.9631\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 11s 357us/step - loss: 0.1382 - acc: 0.9636\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 11s 367us/step - loss: 0.1330 - acc: 0.9639\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 0.1284 - acc: 0.966 - 11s 359us/step - loss: 0.1284 - acc: 0.9666\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 11s 359us/step - loss: 0.1390 - acc: 0.9646\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 11s 358us/step - loss: 0.1360 - acc: 0.9658\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 11s 370us/step - loss: 0.1370 - acc: 0.9644\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 11s 358us/step - loss: 0.1340 - acc: 0.96680s - loss: 0.1340 - acc: 0.9\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 11s 354us/step - loss: 0.1402 - acc: 0.9670\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 11s 360us/step - loss: 0.1204 - acc: 0.9681\n",
      "30000/30000 [==============================] - 5s 166us/step\n",
      "30000/30000 [==============================] - 4s 133us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=30, num_neurons=512, optimizer_algo=adam, total= 5.6min\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=30, num_neurons=512, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 14s 475us/step - loss: 0.3802 - acc: 0.8834\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 11s 373us/step - loss: 0.2508 - acc: 0.9254\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 11s 378us/step - loss: 0.2294 - acc: 0.9322\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 11s 367us/step - loss: 0.2047 - acc: 0.93921s - l - ETA: 0s - loss: 0.2034 - acc: 0.93\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 11s 368us/step - loss: 0.2167 - acc: 0.9379\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 11s 370us/step - loss: 0.1872 - acc: 0.9455\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 11s 370us/step - loss: 0.1903 - acc: 0.9471\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 11s 363us/step - loss: 0.1765 - acc: 0.9517\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 11s 363us/step - loss: 0.1778 - acc: 0.9495\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 11s 361us/step - loss: 0.1702 - acc: 0.95190s - loss: 0.1697\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 11s 372us/step - loss: 0.1800 - acc: 0.9516\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 11s 362us/step - loss: 0.1595 - acc: 0.9558\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 11s 366us/step - loss: 0.1610 - acc: 0.9548\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 11s 374us/step - loss: 0.1508 - acc: 0.9574\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 11s 371us/step - loss: 0.1540 - acc: 0.9597\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 11s 376us/step - loss: 0.1475 - acc: 0.95910s - loss: 0.1467\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 11s 368us/step - loss: 0.1426 - acc: 0.9599\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 11s 370us/step - loss: 0.1527 - acc: 0.9588\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 11s 360us/step - loss: 0.1498 - acc: 0.9613\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 11s 361us/step - loss: 0.1351 - acc: 0.9617\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 11s 371us/step - loss: 0.1415 - acc: 0.9619\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 11s 364us/step - loss: 0.1290 - acc: 0.9650\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 11s 365us/step - loss: 0.1307 - acc: 0.9632\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 11s 362us/step - loss: 0.1262 - acc: 0.9657\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 11s 370us/step - loss: 0.1305 - acc: 0.9656\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 11s 362us/step - loss: 0.1233 - acc: 0.9677\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 11s 361us/step - loss: 0.1191 - acc: 0.9685\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 11s 360us/step - loss: 0.1230 - acc: 0.9692\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 11s 373us/step - loss: 0.1198 - acc: 0.9692\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 11s 359us/step - loss: 0.1248 - acc: 0.9682\n",
      "30000/30000 [==============================] - 5s 161us/step\n",
      "30000/30000 [==============================] - 4s 118us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=30, num_neurons=512, optimizer_algo=adam, total= 5.6min\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=30, num_neurons=784, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 13s 429us/step - loss: 1.8761 - acc: 0.3560\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 10s 318us/step - loss: 1.1805 - acc: 0.6338\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 10s 318us/step - loss: 0.9066 - acc: 0.7184\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 10s 318us/step - loss: 0.7662 - acc: 0.7628\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 10s 322us/step - loss: 0.6888 - acc: 0.7831\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 10s 338us/step - loss: 0.6395 - acc: 0.8003\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 10s 331us/step - loss: 0.5970 - acc: 0.8132\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 10s 319us/step - loss: 0.5663 - acc: 0.8228\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 9s 316us/step - loss: 0.5487 - acc: 0.8305\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 10s 325us/step - loss: 0.5292 - acc: 0.8383\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 10s 321us/step - loss: 0.5054 - acc: 0.8440\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 10s 319us/step - loss: 0.4930 - acc: 0.8473\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 10s 330us/step - loss: 0.4859 - acc: 0.8520\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 10s 333us/step - loss: 0.4769 - acc: 0.8550\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 10s 318us/step - loss: 0.4686 - acc: 0.8565\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 10s 318us/step - loss: 0.4581 - acc: 0.8605\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 10s 333us/step - loss: 0.4509 - acc: 0.8625\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 11s 368us/step - loss: 0.4427 - acc: 0.8668\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 10s 320us/step - loss: 0.4339 - acc: 0.8690\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 10s 317us/step - loss: 0.4335 - acc: 0.8694\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 10s 319us/step - loss: 0.4223 - acc: 0.8737\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 10s 325us/step - loss: 0.4189 - acc: 0.8745\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 10s 319us/step - loss: 0.4140 - acc: 0.8747\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 10s 318us/step - loss: 0.4104 - acc: 0.8756\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 10s 317us/step - loss: 0.4087 - acc: 0.8767\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 10s 329us/step - loss: 0.4009 - acc: 0.8803\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 10s 320us/step - loss: 0.3979 - acc: 0.8811\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 9s 314us/step - loss: 0.3980 - acc: 0.8810\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 10s 318us/step - loss: 0.3938 - acc: 0.8813\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 10s 330us/step - loss: 0.3897 - acc: 0.8822\n",
      "30000/30000 [==============================] - 6s 188us/step\n",
      "30000/30000 [==============================] - 4s 146us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=30, num_neurons=784, optimizer_algo=sgd, total= 5.0min\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=30, num_neurons=784, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 13s 428us/step - loss: 1.8739 - acc: 0.3560\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 10s 327us/step - loss: 1.1755 - acc: 0.6278\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 10s 335us/step - loss: 0.9019 - acc: 0.7196\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 10s 328us/step - loss: 0.7647 - acc: 0.7618\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 10s 328us/step - loss: 0.6889 - acc: 0.7842\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 10s 326us/step - loss: 0.6391 - acc: 0.8006\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 10s 336us/step - loss: 0.5973 - acc: 0.8136\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 10s 324us/step - loss: 0.5656 - acc: 0.8239\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 10s 320us/step - loss: 0.5431 - acc: 0.8309\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 10s 326us/step - loss: 0.5250 - acc: 0.8365\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 10s 339us/step - loss: 0.5096 - acc: 0.8428\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 10s 333us/step - loss: 0.4971 - acc: 0.8476\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 10s 324us/step - loss: 0.4857 - acc: 0.8508\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 10s 325us/step - loss: 0.4762 - acc: 0.85341s - l\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 10s 331us/step - loss: 0.4680 - acc: 0.8558\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 10s 322us/step - loss: 0.4595 - acc: 0.8583\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 10s 321us/step - loss: 0.4516 - acc: 0.8613\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 10s 320us/step - loss: 0.4440 - acc: 0.8651\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 10s 328us/step - loss: 0.4394 - acc: 0.8670\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 10s 320us/step - loss: 0.4327 - acc: 0.8680\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 10s 322us/step - loss: 0.4291 - acc: 0.8707\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 10s 324us/step - loss: 0.4255 - acc: 0.8714\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 10s 329us/step - loss: 0.4177 - acc: 0.8751\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 10s 321us/step - loss: 0.4146 - acc: 0.8730\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 10s 324us/step - loss: 0.4077 - acc: 0.8772\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 10s 320us/step - loss: 0.4082 - acc: 0.8760\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 10s 331us/step - loss: 0.4015 - acc: 0.8781\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 10s 322us/step - loss: 0.4007 - acc: 0.87911s \n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 10s 322us/step - loss: 0.3967 - acc: 0.8808\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 10s 323us/step - loss: 0.3921 - acc: 0.8822\n",
      "30000/30000 [==============================] - 6s 191us/step\n",
      "30000/30000 [==============================] - 4s 148us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=30, num_neurons=784, optimizer_algo=sgd, total= 5.0min\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=30, num_neurons=784, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 20s 666us/step - loss: 0.3956 - acc: 0.8808\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 16s 546us/step - loss: 0.2918 - acc: 0.9179\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 17s 558us/step - loss: 0.2850 - acc: 0.9242\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 16s 547us/step - loss: 0.2596 - acc: 0.9318\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 17s 554us/step - loss: 0.2268 - acc: 0.9405\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 16s 534us/step - loss: 0.2303 - acc: 0.9431\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 17s 550us/step - loss: 0.2218 - acc: 0.9448\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 17s 551us/step - loss: 0.2225 - acc: 0.9449\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 16s 540us/step - loss: 0.2227 - acc: 0.9478\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 16s 547us/step - loss: 0.2170 - acc: 0.9480\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 16s 538us/step - loss: 0.2022 - acc: 0.9531\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 17s 553us/step - loss: 0.2031 - acc: 0.9528\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 16s 537us/step - loss: 0.2057 - acc: 0.95333s \n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 16s 537us/step - loss: 0.2016 - acc: 0.9562\n",
      "Epoch 15/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 16s 548us/step - loss: 0.1869 - acc: 0.9585\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 16s 537us/step - loss: 0.1728 - acc: 0.9608\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 17s 554us/step - loss: 0.1765 - acc: 0.9580\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 16s 538us/step - loss: 0.1613 - acc: 0.9630\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 16s 537us/step - loss: 0.1817 - acc: 0.9601\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 17s 551us/step - loss: 0.1901 - acc: 0.9588\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 16s 542us/step - loss: 0.2014 - acc: 0.9592\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 16s 548us/step - loss: 0.1826 - acc: 0.9609\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 16s 540us/step - loss: 0.1939 - acc: 0.9606\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 16s 543us/step - loss: 0.1791 - acc: 0.9636\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 16s 550us/step - loss: 0.1752 - acc: 0.9635\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 16s 539us/step - loss: 0.1689 - acc: 0.9654\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 17s 553us/step - loss: 0.1553 - acc: 0.9660\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 16s 540us/step - loss: 0.1603 - acc: 0.9660\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 16s 548us/step - loss: 0.1950 - acc: 0.96320s - loss: 0.1974 \n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 17s 554us/step - loss: 0.1739 - acc: 0.9663\n",
      "30000/30000 [==============================] - 6s 189us/step\n",
      "30000/30000 [==============================] - 4s 146us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=30, num_neurons=784, optimizer_algo=adam, total= 8.3min\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=30, num_neurons=784, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 20s 659us/step - loss: 0.3853 - acc: 0.8865\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 16s 536us/step - loss: 0.2764 - acc: 0.9192\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 16s 542us/step - loss: 0.2588 - acc: 0.9284\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 16s 548us/step - loss: 0.2567 - acc: 0.9334\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 16s 539us/step - loss: 0.2424 - acc: 0.9379\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 17s 552us/step - loss: 0.2271 - acc: 0.9426\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 16s 539us/step - loss: 0.2178 - acc: 0.9461\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 16s 541us/step - loss: 0.2055 - acc: 0.9480\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 16s 548us/step - loss: 0.2037 - acc: 0.9495\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 16s 544us/step - loss: 0.2040 - acc: 0.9508\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 17s 552us/step - loss: 0.1918 - acc: 0.9547\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 16s 538us/step - loss: 0.2050 - acc: 0.9521\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 17s 560us/step - loss: 0.1966 - acc: 0.9558\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 16s 550us/step - loss: 0.1949 - acc: 0.9561\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 16s 539us/step - loss: 0.1929 - acc: 0.9579\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 17s 561us/step - loss: 0.2007 - acc: 0.9560\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 17s 551us/step - loss: 0.1952 - acc: 0.9577\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 17s 553us/step - loss: 0.1769 - acc: 0.9617\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 16s 538us/step - loss: 0.1714 - acc: 0.96182s - loss: 0.1716 - acc - ETA: 1s\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 16s 540us/step - loss: 0.1783 - acc: 0.9613\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 17s 561us/step - loss: 0.1858 - acc: 0.9613\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 16s 543us/step - loss: 0.1892 - acc: 0.9634\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 17s 558us/step - loss: 0.1795 - acc: 0.9629\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 16s 545us/step - loss: 0.1679 - acc: 0.9652\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 16s 545us/step - loss: 0.1689 - acc: 0.9642\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 17s 554us/step - loss: 0.1618 - acc: 0.96631s - loss: 0.\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 16s 539us/step - loss: 0.1732 - acc: 0.9645\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 16s 550us/step - loss: 0.1614 - acc: 0.9680\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 16s 539us/step - loss: 0.1607 - acc: 0.9658\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 16s 547us/step - loss: 0.1587 - acc: 0.9673\n",
      "30000/30000 [==============================] - 6s 193us/step\n",
      "30000/30000 [==============================] - 5s 156us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=30, num_neurons=784, optimizer_algo=adam, total= 8.4min\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=30, num_neurons=1024, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 15s 502us/step - loss: 1.8636 - acc: 0.3608\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 12s 398us/step - loss: 1.1609 - acc: 0.6329\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 12s 408us/step - loss: 0.8937 - acc: 0.7180\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 12s 395us/step - loss: 0.7637 - acc: 0.76131s - loss\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 12s 396us/step - loss: 0.6803 - acc: 0.78710s - loss: 0.6809 - acc:\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 12s 406us/step - loss: 0.6290 - acc: 0.8024\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 12s 399us/step - loss: 0.5930 - acc: 0.8137\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 12s 398us/step - loss: 0.5667 - acc: 0.82081s - loss: \n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 12s 405us/step - loss: 0.5459 - acc: 0.8295\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 12s 400us/step - loss: 0.5288 - acc: 0.8370\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 12s 398us/step - loss: 0.5139 - acc: 0.8418\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 12s 396us/step - loss: 0.4921 - acc: 0.8471\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 12s 407us/step - loss: 0.4819 - acc: 0.8520\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 12s 395us/step - loss: 0.4696 - acc: 0.8555\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 12s 401us/step - loss: 0.4644 - acc: 0.8585\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 12s 405us/step - loss: 0.4618 - acc: 0.8571\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 12s 398us/step - loss: 0.4494 - acc: 0.8636\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 12s 397us/step - loss: 0.4405 - acc: 0.8650\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 12s 415us/step - loss: 0.4376 - acc: 0.8667\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 12s 394us/step - loss: 0.4313 - acc: 0.8698\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 12s 399us/step - loss: 0.4263 - acc: 0.8710\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 12s 397us/step - loss: 0.4236 - acc: 0.8731\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 12s 405us/step - loss: 0.4164 - acc: 0.8731\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 12s 398us/step - loss: 0.4114 - acc: 0.87531s -\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 12s 403us/step - loss: 0.4103 - acc: 0.87450s - loss: 0.4094 -\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 12s 411us/step - loss: 0.4008 - acc: 0.87751s - \n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 12s 400us/step - loss: 0.3996 - acc: 0.8802\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 12s 407us/step - loss: 0.3961 - acc: 0.8820\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 12s 409us/step - loss: 0.3989 - acc: 0.8813\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 12s 398us/step - loss: 0.3876 - acc: 0.8834\n",
      "30000/30000 [==============================] - 6s 199us/step\n",
      "30000/30000 [==============================] - 5s 157us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=30, num_neurons=1024, optimizer_algo=sgd, total= 6.2min\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=30, num_neurons=1024, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 15s 514us/step - loss: 1.8760 - acc: 0.3589\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 12s 404us/step - loss: 1.1633 - acc: 0.6335\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 12s 404us/step - loss: 0.8919 - acc: 0.7196\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 12s 398us/step - loss: 0.7604 - acc: 0.7627\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 12s 409us/step - loss: 0.6800 - acc: 0.7845\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 12s 399us/step - loss: 0.6309 - acc: 0.8030\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 12s 404us/step - loss: 0.5934 - acc: 0.81320s - loss: 0.5934 - acc: \n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 12s 403us/step - loss: 0.5635 - acc: 0.8231\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 12s 399us/step - loss: 0.5452 - acc: 0.8291\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 12s 398us/step - loss: 0.5275 - acc: 0.8354\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 12s 408us/step - loss: 0.5050 - acc: 0.8455\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 12s 397us/step - loss: 0.4953 - acc: 0.8478\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 12s 396us/step - loss: 0.4826 - acc: 0.8498\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 12s 400us/step - loss: 0.4728 - acc: 0.8549\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 12s 408us/step - loss: 0.4657 - acc: 0.8576\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 12s 399us/step - loss: 0.4539 - acc: 0.8604\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 12s 399us/step - loss: 0.4485 - acc: 0.86221s - loss\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 12s 411us/step - loss: 0.4429 - acc: 0.86380s - loss: 0\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 12s 404us/step - loss: 0.4342 - acc: 0.8665\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 12s 400us/step - loss: 0.4309 - acc: 0.8704\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 12s 411us/step - loss: 0.4293 - acc: 0.8693\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 12s 409us/step - loss: 0.4206 - acc: 0.87160s - loss: 0.4207 - acc: 0.871\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 12s 413us/step - loss: 0.4159 - acc: 0.8736\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 12s 407us/step - loss: 0.4126 - acc: 0.8744\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 12s 403us/step - loss: 0.4075 - acc: 0.8753\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 12s 399us/step - loss: 0.4059 - acc: 0.8767\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 12s 396us/step - loss: 0.4008 - acc: 0.8779\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 13s 422us/step - loss: 0.3999 - acc: 0.8768\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 12s 405us/step - loss: 0.3955 - acc: 0.8801\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 12s 394us/step - loss: 0.3947 - acc: 0.8813\n",
      "30000/30000 [==============================] - 6s 214us/step\n",
      "30000/30000 [==============================] - 5s 162us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=30, num_neurons=1024, optimizer_algo=sgd, total= 6.2min\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=30, num_neurons=1024, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 24s 804us/step - loss: 0.4062 - acc: 0.8800\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 21s 706us/step - loss: 0.3109 - acc: 0.9142\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 21s 685us/step - loss: 0.3290 - acc: 0.9194\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 21s 687us/step - loss: 0.3145 - acc: 0.9281\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 20s 681us/step - loss: 0.2806 - acc: 0.9339\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 21s 687us/step - loss: 0.2988 - acc: 0.9353\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 20s 677us/step - loss: 0.2901 - acc: 0.9404\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 21s 687us/step - loss: 0.2905 - acc: 0.9410\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 20s 680us/step - loss: 0.2948 - acc: 0.9433\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 21s 699us/step - loss: 0.2715 - acc: 0.9461\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 20s 681us/step - loss: 0.2583 - acc: 0.9490\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 21s 687us/step - loss: 0.2793 - acc: 0.9494\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 20s 681us/step - loss: 0.2735 - acc: 0.9524\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 21s 688us/step - loss: 0.2685 - acc: 0.9499\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 20s 678us/step - loss: 0.2513 - acc: 0.9549\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 21s 687us/step - loss: 0.2444 - acc: 0.95632s - - ETA: 1s - loss: 0.\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 20s 678us/step - loss: 0.2386 - acc: 0.95701s - l\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 21s 689us/step - loss: 0.2537 - acc: 0.9577\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 20s 682us/step - loss: 0.2574 - acc: 0.9558\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 21s 714us/step - loss: 0.2449 - acc: 0.95861s -\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 21s 690us/step - loss: 0.2387 - acc: 0.9603\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 21s 691us/step - loss: 0.2424 - acc: 0.9601\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 21s 685us/step - loss: 0.2417 - acc: 0.9605\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 20s 674us/step - loss: 0.2316 - acc: 0.9624\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 21s 683us/step - loss: 0.2243 - acc: 0.9641\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 21s 688us/step - loss: 0.2567 - acc: 0.9599\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 21s 692us/step - loss: 0.2364 - acc: 0.9623\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 21s 685us/step - loss: 0.2405 - acc: 0.9633\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 21s 686us/step - loss: 0.2434 - acc: 0.9639\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 20s 674us/step - loss: 0.2502 - acc: 0.9624\n",
      "30000/30000 [==============================] - 6s 208us/step\n",
      "30000/30000 [==============================] - 5s 164us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=30, num_neurons=1024, optimizer_algo=adam, total=10.5min\n",
      "[CV] activation=sigmoid, dropout=0.5, epochs=30, num_neurons=1024, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 25s 820us/step - loss: 0.4325 - acc: 0.8820\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 21s 691us/step - loss: 0.2921 - acc: 0.9197\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 20s 680us/step - loss: 0.3109 - acc: 0.9235\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 21s 696us/step - loss: 0.2801 - acc: 0.9313\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 21s 686us/step - loss: 0.2843 - acc: 0.9357\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 21s 710us/step - loss: 0.2842 - acc: 0.9366\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 21s 688us/step - loss: 0.2593 - acc: 0.9442\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 21s 691us/step - loss: 0.2465 - acc: 0.94551s - loss: 0\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 20s 681us/step - loss: 0.2567 - acc: 0.9462\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 21s 692us/step - loss: 0.2615 - acc: 0.9478\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 20s 682us/step - loss: 0.2603 - acc: 0.9487\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 21s 696us/step - loss: 0.2488 - acc: 0.9510\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 20s 682us/step - loss: 0.2620 - acc: 0.9527\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 21s 695us/step - loss: 0.2443 - acc: 0.9549\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 21s 685us/step - loss: 0.2527 - acc: 0.9539\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 21s 695us/step - loss: 0.2234 - acc: 0.9579\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 20s 683us/step - loss: 0.2420 - acc: 0.9578\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 21s 700us/step - loss: 0.2488 - acc: 0.9566\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 21s 696us/step - loss: 0.2414 - acc: 0.9585\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 22s 719us/step - loss: 0.2489 - acc: 0.9587\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 22s 721us/step - loss: 0.2602 - acc: 0.9586\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 22s 729us/step - loss: 0.2444 - acc: 0.9601\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 22s 726us/step - loss: 0.2416 - acc: 0.9622\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 22s 722us/step - loss: 0.2470 - acc: 0.9609\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 22s 725us/step - loss: 0.2411 - acc: 0.9627\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 22s 724us/step - loss: 0.2306 - acc: 0.9640\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 23s 764us/step - loss: 0.2572 - acc: 0.9626\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 22s 722us/step - loss: 0.2274 - acc: 0.9662\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 21s 709us/step - loss: 0.2175 - acc: 0.9667\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 21s 707us/step - loss: 0.2257 - acc: 0.9667\n",
      "30000/30000 [==============================] - 7s 221us/step\n",
      "30000/30000 [==============================] - 5s 174us/step\n",
      "[CV]  activation=sigmoid, dropout=0.5, epochs=30, num_neurons=1024, optimizer_algo=adam, total=10.7min\n",
      "[CV] activation=relu, dropout=0.0, epochs=10, num_neurons=256, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 9s 295us/step - loss: 0.8561 - acc: 0.7973\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 5s 182us/step - loss: 0.4039 - acc: 0.8938\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 5s 182us/step - loss: 0.3383 - acc: 0.9086\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 6s 183us/step - loss: 0.3049 - acc: 0.9179\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 5s 181us/step - loss: 0.2811 - acc: 0.9243\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 6s 190us/step - loss: 0.2634 - acc: 0.9289\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 7s 231us/step - loss: 0.2489 - acc: 0.9322\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 6s 191us/step - loss: 0.2355 - acc: 0.9369\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 5s 181us/step - loss: 0.2243 - acc: 0.9406\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 5s 182us/step - loss: 0.2140 - acc: 0.9428\n",
      "30000/30000 [==============================] - 5s 162us/step\n",
      "30000/30000 [==============================] - 3s 105us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=10, num_neurons=256, optimizer_algo=sgd, total= 1.1min\n",
      "[CV] activation=relu, dropout=0.0, epochs=10, num_neurons=256, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 9s 289us/step - loss: 0.8527 - acc: 0.7962\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 5s 178us/step - loss: 0.4097 - acc: 0.8902\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 5s 175us/step - loss: 0.3449 - acc: 0.9042\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 5s 178us/step - loss: 0.3111 - acc: 0.9108\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 5s 176us/step - loss: 0.2869 - acc: 0.9183\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 6s 187us/step - loss: 0.2677 - acc: 0.9232\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 5s 179us/step - loss: 0.2515 - acc: 0.9286\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 5s 183us/step - loss: 0.2376 - acc: 0.9326\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 5s 178us/step - loss: 0.2254 - acc: 0.9362\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 5s 178us/step - loss: 0.2141 - acc: 0.9396\n",
      "30000/30000 [==============================] - 5s 155us/step\n",
      "30000/30000 [==============================] - 3s 105us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=10, num_neurons=256, optimizer_algo=sgd, total= 1.0min\n",
      "[CV] activation=relu, dropout=0.0, epochs=10, num_neurons=256, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 10s 331us/step - loss: 0.2875 - acc: 0.9163\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 7s 219us/step - loss: 0.1773 - acc: 0.9487\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 7s 230us/step - loss: 0.1504 - acc: 0.9588\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 6s 216us/step - loss: 0.1370 - acc: 0.9630\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 6s 215us/step - loss: 0.1214 - acc: 0.9671\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 6s 214us/step - loss: 0.1173 - acc: 0.9708\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 6s 216us/step - loss: 0.1065 - acc: 0.9732\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 6s 216us/step - loss: 0.1031 - acc: 0.9757\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 7s 225us/step - loss: 0.0996 - acc: 0.9781\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 6s 214us/step - loss: 0.0790 - acc: 0.9820\n",
      "30000/30000 [==============================] - 5s 161us/step\n",
      "30000/30000 [==============================] - 3s 107us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=10, num_neurons=256, optimizer_algo=adam, total= 1.2min\n",
      "[CV] activation=relu, dropout=0.0, epochs=10, num_neurons=256, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 10s 333us/step - loss: 0.2861 - acc: 0.9144\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 7s 219us/step - loss: 0.1770 - acc: 0.9501\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 7s 225us/step - loss: 0.1470 - acc: 0.9598\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 7s 217us/step - loss: 0.1325 - acc: 0.9651\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 7s 218us/step - loss: 0.1265 - acc: 0.9677\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 7s 218us/step - loss: 0.1107 - acc: 0.9736\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 7s 217us/step - loss: 0.1055 - acc: 0.9736\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 7s 219us/step - loss: 0.0919 - acc: 0.9767\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 7s 227us/step - loss: 0.1005 - acc: 0.9774\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 7s 219us/step - loss: 0.0941 - acc: 0.9799\n",
      "30000/30000 [==============================] - 5s 157us/step\n",
      "30000/30000 [==============================] - 4s 121us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=10, num_neurons=256, optimizer_algo=adam, total= 1.2min\n",
      "[CV] activation=relu, dropout=0.0, epochs=10, num_neurons=512, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 11s 356us/step - loss: 0.8033 - acc: 0.8118\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 7s 240us/step - loss: 0.3948 - acc: 0.8963\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 7s 243us/step - loss: 0.3327 - acc: 0.9093\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 7s 240us/step - loss: 0.2995 - acc: 0.9184\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 7s 236us/step - loss: 0.2764 - acc: 0.9244\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 7s 240us/step - loss: 0.2580 - acc: 0.9312\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 7s 240us/step - loss: 0.2431 - acc: 0.9340\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 7s 241us/step - loss: 0.2300 - acc: 0.9383\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 7s 248us/step - loss: 0.2184 - acc: 0.9413\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 7s 246us/step - loss: 0.2080 - acc: 0.9440\n",
      "30000/30000 [==============================] - 5s 174us/step\n",
      "30000/30000 [==============================] - 4s 126us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=10, num_neurons=512, optimizer_algo=sgd, total= 1.4min\n",
      "[CV] activation=relu, dropout=0.0, epochs=10, num_neurons=512, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 11s 364us/step - loss: 0.8204 - acc: 0.8124\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 8s 253us/step - loss: 0.3948 - acc: 0.8947\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 7s 240us/step - loss: 0.3319 - acc: 0.9078\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 7s 242us/step - loss: 0.2982 - acc: 0.9169\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 7s 242us/step - loss: 0.2743 - acc: 0.9229\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 7s 240us/step - loss: 0.2557 - acc: 0.9279\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 7s 239us/step - loss: 0.2403 - acc: 0.9325\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 8s 250us/step - loss: 0.2270 - acc: 0.9363\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 7s 240us/step - loss: 0.2149 - acc: 0.9400\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 7s 241us/step - loss: 0.2043 - acc: 0.9429\n",
      "30000/30000 [==============================] - 5s 180us/step\n",
      "30000/30000 [==============================] - 4s 127us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=10, num_neurons=512, optimizer_algo=sgd, total= 1.4min\n",
      "[CV] activation=relu, dropout=0.0, epochs=10, num_neurons=512, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 15s 509us/step - loss: 0.2985 - acc: 0.9148\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 11s 368us/step - loss: 0.1857 - acc: 0.9504\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 11s 367us/step - loss: 0.1647 - acc: 0.9569\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 11s 365us/step - loss: 0.1449 - acc: 0.9623\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 11s 382us/step - loss: 0.1276 - acc: 0.9692\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 11s 367us/step - loss: 0.1256 - acc: 0.9710\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 11s 368us/step - loss: 0.1144 - acc: 0.97421s -\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 11s 381us/step - loss: 0.1214 - acc: 0.9739\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 11s 376us/step - loss: 0.0946 - acc: 0.9790\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 11s 380us/step - loss: 0.1002 - acc: 0.9791\n",
      "30000/30000 [==============================] - 5s 172us/step\n",
      "30000/30000 [==============================] - 4s 127us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=10, num_neurons=512, optimizer_algo=adam, total= 2.0min\n",
      "[CV] activation=relu, dropout=0.0, epochs=10, num_neurons=512, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 15s 506us/step - loss: 0.2928 - acc: 0.9144\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 11s 372us/step - loss: 0.1867 - acc: 0.9503\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 11s 379us/step - loss: 0.1552 - acc: 0.9583\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 12s 384us/step - loss: 0.1399 - acc: 0.96461s - l\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 11s 380us/step - loss: 0.1327 - acc: 0.9680\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 11s 377us/step - loss: 0.1119 - acc: 0.9721\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 12s 388us/step - loss: 0.1065 - acc: 0.9759\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 12s 383us/step - loss: 0.1008 - acc: 0.9776\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 11s 365us/step - loss: 0.1112 - acc: 0.9766\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 11s 370us/step - loss: 0.1066 - acc: 0.9789\n",
      "30000/30000 [==============================] - 6s 191us/step\n",
      "30000/30000 [==============================] - 4s 136us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=10, num_neurons=512, optimizer_algo=adam, total= 2.1min\n",
      "[CV] activation=relu, dropout=0.0, epochs=10, num_neurons=784, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 13s 437us/step - loss: 0.8027 - acc: 0.8138\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 10s 324us/step - loss: 0.3916 - acc: 0.8977\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 10s 323us/step - loss: 0.3295 - acc: 0.9108\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 10s 336us/step - loss: 0.2962 - acc: 0.9201\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 10s 328us/step - loss: 0.2734 - acc: 0.9266\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 10s 322us/step - loss: 0.2554 - acc: 0.9312\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 10s 324us/step - loss: 0.2405 - acc: 0.9364\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 10s 332us/step - loss: 0.2272 - acc: 0.9391\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 10s 321us/step - loss: 0.2157 - acc: 0.9414\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 10s 324us/step - loss: 0.2049 - acc: 0.9444\n",
      "30000/30000 [==============================] - 6s 204us/step\n",
      "30000/30000 [==============================] - 5s 156us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=10, num_neurons=784, optimizer_algo=sgd, total= 1.8min\n",
      "[CV] activation=relu, dropout=0.0, epochs=10, num_neurons=784, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 14s 466us/step - loss: 0.7792 - acc: 0.8206\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 10s 328us/step - loss: 0.3904 - acc: 0.8957\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 10s 328us/step - loss: 0.3285 - acc: 0.9085\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 10s 324us/step - loss: 0.2955 - acc: 0.9170\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 10s 334us/step - loss: 0.2718 - acc: 0.9239\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 10s 329us/step - loss: 0.2535 - acc: 0.9294\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 10s 329us/step - loss: 0.2374 - acc: 0.9340\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 10s 331us/step - loss: 0.2236 - acc: 0.9379\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 10s 335us/step - loss: 0.2122 - acc: 0.9405\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 10s 326us/step - loss: 0.2011 - acc: 0.9436\n",
      "30000/30000 [==============================] - 6s 201us/step\n",
      "30000/30000 [==============================] - 5s 158us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=10, num_neurons=784, optimizer_algo=sgd, total= 1.8min\n",
      "[CV] activation=relu, dropout=0.0, epochs=10, num_neurons=784, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 20s 670us/step - loss: 0.3076 - acc: 0.91060s - loss: 0.3091 - a\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 17s 553us/step - loss: 0.1745 - acc: 0.9515\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 16s 548us/step - loss: 0.1567 - acc: 0.9582\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 16s 536us/step - loss: 0.1300 - acc: 0.9647\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 16s 531us/step - loss: 0.1245 - acc: 0.9700\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 15s 491us/step - loss: 0.1089 - acc: 0.9724\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 15s 492us/step - loss: 0.1035 - acc: 0.9740\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 15s 493us/step - loss: 0.1067 - acc: 0.97521s - l\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 14s 481us/step - loss: 0.0922 - acc: 0.9786\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 14s 473us/step - loss: 0.0906 - acc: 0.9796\n",
      "30000/30000 [==============================] - 6s 194us/step\n",
      "30000/30000 [==============================] - 4s 134us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=10, num_neurons=784, optimizer_algo=adam, total= 2.8min\n",
      "[CV] activation=relu, dropout=0.0, epochs=10, num_neurons=784, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 18s 598us/step - loss: 0.2986 - acc: 0.9130\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 14s 480us/step - loss: 0.1777 - acc: 0.9506\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 15s 488us/step - loss: 0.1551 - acc: 0.9597 ETA: 1s - los\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 14s 477us/step - loss: 0.1363 - acc: 0.96437s - l  - ETA: 3s - lo\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 14s 478us/step - loss: 0.1192 - acc: 0.9697\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 15s 489us/step - loss: 0.1361 - acc: 0.96912s - loss: 0.1305 - acc: 0.9 - ETA\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 14s 475us/step - loss: 0.1036 - acc: 0.9761\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 14s 478us/step - loss: 0.1155 - acc: 0.9753\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 14s 483us/step - loss: 0.0978 - acc: 0.97902s - loss: 0. - ETA: 0s - loss: 0.097\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 14s 483us/step - loss: 0.1013 - acc: 0.9792\n",
      "30000/30000 [==============================] - 6s 193us/step\n",
      "30000/30000 [==============================] - 4s 149us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=10, num_neurons=784, optimizer_algo=adam, total= 2.6min\n",
      "[CV] activation=relu, dropout=0.0, epochs=10, num_neurons=1024, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 15s 493us/step - loss: 0.7909 - acc: 0.8224\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 11s 355us/step - loss: 0.3842 - acc: 0.8998\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 11s 356us/step - loss: 0.3247 - acc: 0.9125\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 11s 363us/step - loss: 0.2919 - acc: 0.9212\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 11s 356us/step - loss: 0.2695 - acc: 0.9273\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 11s 355us/step - loss: 0.2517 - acc: 0.9332\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 11s 356us/step - loss: 0.2367 - acc: 0.9376\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 11s 360us/step - loss: 0.2231 - acc: 0.9406\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 11s 354us/step - loss: 0.2113 - acc: 0.9436\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 11s 352us/step - loss: 0.2009 - acc: 0.9461\n",
      "30000/30000 [==============================] - 6s 196us/step\n",
      "30000/30000 [==============================] - 4s 148us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=10, num_neurons=1024, optimizer_algo=sgd, total= 2.0min\n",
      "[CV] activation=relu, dropout=0.0, epochs=10, num_neurons=1024, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 15s 499us/step - loss: 0.7749 - acc: 0.8257\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 11s 357us/step - loss: 0.3860 - acc: 0.8968\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 11s 356us/step - loss: 0.3260 - acc: 0.9099\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 11s 358us/step - loss: 0.2928 - acc: 0.9175\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 11s 351us/step - loss: 0.2688 - acc: 0.9254\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 11s 353us/step - loss: 0.2508 - acc: 0.9303\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 11s 356us/step - loss: 0.2348 - acc: 0.9349\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 11s 359us/step - loss: 0.2208 - acc: 0.9385\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 11s 352us/step - loss: 0.2087 - acc: 0.9414\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 11s 354us/step - loss: 0.1983 - acc: 0.9444\n",
      "30000/30000 [==============================] - 6s 198us/step\n",
      "30000/30000 [==============================] - 4s 149us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=10, num_neurons=1024, optimizer_algo=sgd, total= 2.0min\n",
      "[CV] activation=relu, dropout=0.0, epochs=10, num_neurons=1024, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 22s 747us/step - loss: 0.3099 - acc: 0.9133\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 19s 621us/step - loss: 0.1939 - acc: 0.94741s \n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 19s 627us/step - loss: 0.1582 - acc: 0.9587\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 19s 618us/step - loss: 0.1437 - acc: 0.9650\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 19s 624us/step - loss: 0.1296 - acc: 0.96840s - loss: 0.1296 - acc: 0.96\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 18s 613us/step - loss: 0.1255 - acc: 0.9704\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 19s 623us/step - loss: 0.1113 - acc: 0.9733\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 18s 614us/step - loss: 0.1078 - acc: 0.9752 - ETA\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 19s 623us/step - loss: 0.1090 - acc: 0.9776\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 18s 613us/step - loss: 0.1031 - acc: 0.9785\n",
      "30000/30000 [==============================] - 6s 202us/step\n",
      "30000/30000 [==============================] - 5s 156us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=10, num_neurons=1024, optimizer_algo=adam, total= 3.3min\n",
      "[CV] activation=relu, dropout=0.0, epochs=10, num_neurons=1024, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 23s 771us/step - loss: 0.3070 - acc: 0.91392s - loss: 0 - ETA: 1s - loss: 0.3\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 0.1788 - acc: 0.951 - 19s 630us/step - loss: 0.1792 - acc: 0.9515\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 19s 624us/step - loss: 0.1391 - acc: 0.9627\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 19s 629us/step - loss: 0.1345 - acc: 0.9652\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 19s 626us/step - loss: 0.1236 - acc: 0.9696\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 19s 624us/step - loss: 0.1099 - acc: 0.97340s - loss: 0.1102 - acc: 0.\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 19s 632us/step - loss: 0.1163 - acc: 0.9739\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 19s 628us/step - loss: 0.1045 - acc: 0.9768\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 19s 622us/step - loss: 0.0856 - acc: 0.9810\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 19s 629us/step - loss: 0.0839 - acc: 0.9817\n",
      "30000/30000 [==============================] - 6s 206us/step\n",
      "30000/30000 [==============================] - 5s 159us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=10, num_neurons=1024, optimizer_algo=adam, total= 3.3min\n",
      "[CV] activation=relu, dropout=0.0, epochs=20, num_neurons=256, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 9s 293us/step - loss: 0.8452 - acc: 0.7970\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 5s 173us/step - loss: 0.4049 - acc: 0.8931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 5s 173us/step - loss: 0.3399 - acc: 0.9081\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 5s 172us/step - loss: 0.3060 - acc: 0.9176\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 5s 171us/step - loss: 0.2829 - acc: 0.9229\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 5s 171us/step - loss: 0.2646 - acc: 0.9281\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 5s 175us/step - loss: 0.2498 - acc: 0.9320\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 5s 162us/step - loss: 0.2366 - acc: 0.9355\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 5s 163us/step - loss: 0.2251 - acc: 0.9397\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 5s 163us/step - loss: 0.2146 - acc: 0.9424\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 5s 162us/step - loss: 0.2052 - acc: 0.9449\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 5s 161us/step - loss: 0.1966 - acc: 0.9471\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 5s 161us/step - loss: 0.1887 - acc: 0.9498\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 5s 162us/step - loss: 0.1812 - acc: 0.9514\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 5s 167us/step - loss: 0.1747 - acc: 0.9524\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 5s 162us/step - loss: 0.1681 - acc: 0.9547\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 5s 162us/step - loss: 0.1618 - acc: 0.9559\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 5s 161us/step - loss: 0.1564 - acc: 0.9575\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 5s 162us/step - loss: 0.1512 - acc: 0.9584\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 5s 162us/step - loss: 0.1461 - acc: 0.9599\n",
      "30000/30000 [==============================] - 4s 149us/step\n",
      "30000/30000 [==============================] - 3s 102us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=20, num_neurons=256, optimizer_algo=sgd, total= 1.8min\n",
      "[CV] activation=relu, dropout=0.0, epochs=20, num_neurons=256, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 9s 290us/step - loss: 0.8212 - acc: 0.8030\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 5s 170us/step - loss: 0.4073 - acc: 0.8903\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 5s 172us/step - loss: 0.3436 - acc: 0.9045\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 5s 161us/step - loss: 0.3098 - acc: 0.9125\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 5s 161us/step - loss: 0.2855 - acc: 0.9190\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 5s 162us/step - loss: 0.2667 - acc: 0.9247\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 5s 162us/step - loss: 0.2501 - acc: 0.9295\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 5s 161us/step - loss: 0.2365 - acc: 0.9332\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 5s 168us/step - loss: 0.2237 - acc: 0.9377\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 5s 162us/step - loss: 0.2122 - acc: 0.9409\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 5s 163us/step - loss: 0.2020 - acc: 0.9437\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 5s 161us/step - loss: 0.1929 - acc: 0.9459\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 5s 163us/step - loss: 0.1845 - acc: 0.9486\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 5s 162us/step - loss: 0.1766 - acc: 0.9510\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 5s 161us/step - loss: 0.1694 - acc: 0.9526\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 5s 161us/step - loss: 0.1630 - acc: 0.9545\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 5s 168us/step - loss: 0.1569 - acc: 0.9569\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 5s 162us/step - loss: 0.1511 - acc: 0.9576\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 5s 162us/step - loss: 0.1456 - acc: 0.9598\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 5s 162us/step - loss: 0.1406 - acc: 0.9611\n",
      "30000/30000 [==============================] - 4s 149us/step\n",
      "30000/30000 [==============================] - 3s 99us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=20, num_neurons=256, optimizer_algo=sgd, total= 1.8min\n",
      "[CV] activation=relu, dropout=0.0, epochs=20, num_neurons=256, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 10s 341us/step - loss: 0.2891 - acc: 0.9154\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 7s 223us/step - loss: 0.1838 - acc: 0.9486\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 7s 219us/step - loss: 0.1468 - acc: 0.9596\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 7s 221us/step - loss: 0.1267 - acc: 0.9661\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 6s 215us/step - loss: 0.1138 - acc: 0.9679\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 7s 220us/step - loss: 0.1134 - acc: 0.9712\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 6s 212us/step - loss: 0.1075 - acc: 0.9744\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 7s 222us/step - loss: 0.1078 - acc: 0.9741\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 7s 218us/step - loss: 0.0850 - acc: 0.9796\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 6s 214us/step - loss: 0.0871 - acc: 0.9801\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 7s 225us/step - loss: 0.0960 - acc: 0.9804\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 6s 212us/step - loss: 0.0912 - acc: 0.9815\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 6s 207us/step - loss: 0.0901 - acc: 0.9821\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 7s 218us/step - loss: 0.0854 - acc: 0.9837\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 7s 231us/step - loss: 0.0806 - acc: 0.9844\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 7s 222us/step - loss: 0.0734 - acc: 0.9861\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 6s 215us/step - loss: 0.0711 - acc: 0.9864\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 6s 215us/step - loss: 0.1007 - acc: 0.9838\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 7s 217us/step - loss: 0.0726 - acc: 0.9868\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 7s 222us/step - loss: 0.0758 - acc: 0.9873\n",
      "30000/30000 [==============================] - 5s 153us/step\n",
      "30000/30000 [==============================] - 3s 101us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=20, num_neurons=256, optimizer_algo=adam, total= 2.3min\n",
      "[CV] activation=relu, dropout=0.0, epochs=20, num_neurons=256, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 10s 335us/step - loss: 0.2820 - acc: 0.9149\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 6s 213us/step - loss: 0.1771 - acc: 0.9511\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 6s 216us/step - loss: 0.1566 - acc: 0.9567 0s - loss: 0.1561 - acc: 0\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 7s 221us/step - loss: 0.1387 - acc: 0.9645\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 7s 222us/step - loss: 0.1232 - acc: 0.9696\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 7s 217us/step - loss: 0.1085 - acc: 0.9726\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 7s 217us/step - loss: 0.1080 - acc: 0.9737\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 7s 218us/step - loss: 0.1125 - acc: 0.9751\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 6s 216us/step - loss: 0.1123 - acc: 0.9757\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 6s 215us/step - loss: 0.0994 - acc: 0.9790\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 7s 222us/step - loss: 0.0797 - acc: 0.9818\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 6s 214us/step - loss: 0.1067 - acc: 0.9791\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 6s 212us/step - loss: 0.0948 - acc: 0.9817\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 6s 214us/step - loss: 0.0910 - acc: 0.9829\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 6s 210us/step - loss: 0.0759 - acc: 0.9857\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 6s 213us/step - loss: 0.0761 - acc: 0.9862\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 7s 218us/step - loss: 0.0838 - acc: 0.9861\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 6s 207us/step - loss: 0.0809 - acc: 0.9855\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 6s 207us/step - loss: 0.0771 - acc: 0.9872\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 6s 207us/step - loss: 0.0849 - acc: 0.9857\n",
      "30000/30000 [==============================] - 5s 155us/step\n",
      "30000/30000 [==============================] - 3s 102us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=20, num_neurons=256, optimizer_algo=adam, total= 2.3min\n",
      "[CV] activation=relu, dropout=0.0, epochs=20, num_neurons=512, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 11s 351us/step - loss: 0.8010 - acc: 0.8207\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 7s 238us/step - loss: 0.3927 - acc: 0.8964\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 7s 235us/step - loss: 0.3308 - acc: 0.9107\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 7s 231us/step - loss: 0.2980 - acc: 0.9188\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 7s 231us/step - loss: 0.2752 - acc: 0.9252\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 7s 239us/step - loss: 0.2575 - acc: 0.9302\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 7s 239us/step - loss: 0.2424 - acc: 0.9350\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 7s 240us/step - loss: 0.2291 - acc: 0.9387\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 7s 234us/step - loss: 0.2176 - acc: 0.9412\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 7s 230us/step - loss: 0.2076 - acc: 0.9444\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 7s 240us/step - loss: 0.1979 - acc: 0.9469\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 7s 240us/step - loss: 0.1891 - acc: 0.9492\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 7s 247us/step - loss: 0.1814 - acc: 0.9501\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 7s 240us/step - loss: 0.1741 - acc: 0.9521\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 7s 230us/step - loss: 0.1669 - acc: 0.9543\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 7s 235us/step - loss: 0.1604 - acc: 0.9554\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 7s 234us/step - loss: 0.1546 - acc: 0.9567\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 7s 237us/step - loss: 0.1489 - acc: 0.9590\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 7s 238us/step - loss: 0.1432 - acc: 0.9601\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 7s 237us/step - loss: 0.1387 - acc: 0.9622\n",
      "30000/30000 [==============================] - 5s 171us/step\n",
      "30000/30000 [==============================] - 4s 120us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=20, num_neurons=512, optimizer_algo=sgd, total= 2.5min\n",
      "[CV] activation=relu, dropout=0.0, epochs=20, num_neurons=512, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 11s 358us/step - loss: 0.8229 - acc: 0.8067\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 7s 241us/step - loss: 0.3942 - acc: 0.8924\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 7s 235us/step - loss: 0.3307 - acc: 0.9081\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 7s 234us/step - loss: 0.2967 - acc: 0.9175\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 7s 232us/step - loss: 0.2727 - acc: 0.9231\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 7s 232us/step - loss: 0.2540 - acc: 0.9279\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 7s 234us/step - loss: 0.2381 - acc: 0.9334\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 8s 254us/step - loss: 0.2244 - acc: 0.9371\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 8s 253us/step - loss: 0.2121 - acc: 0.9405\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 7s 244us/step - loss: 0.2014 - acc: 0.9427\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 7s 242us/step - loss: 0.1920 - acc: 0.9457\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 7s 239us/step - loss: 0.1829 - acc: 0.9488\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 8s 253us/step - loss: 0.1750 - acc: 0.9508\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 7s 242us/step - loss: 0.1678 - acc: 0.9527\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 7s 248us/step - loss: 0.1610 - acc: 0.9546\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 7s 245us/step - loss: 0.1543 - acc: 0.9570\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 7s 244us/step - loss: 0.1489 - acc: 0.9579\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 7s 240us/step - loss: 0.1432 - acc: 0.9599\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 7s 246us/step - loss: 0.1380 - acc: 0.9612\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 7s 240us/step - loss: 0.1332 - acc: 0.9629\n",
      "30000/30000 [==============================] - 6s 193us/step\n",
      "30000/30000 [==============================] - 4s 124us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=20, num_neurons=512, optimizer_algo=sgd, total= 2.6min\n",
      "[CV] activation=relu, dropout=0.0, epochs=20, num_neurons=512, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 14s 473us/step - loss: 0.2850 - acc: 0.9154\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 11s 352us/step - loss: 0.1923 - acc: 0.9470\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 11s 352us/step - loss: 0.1553 - acc: 0.9581\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 10s 338us/step - loss: 0.1308 - acc: 0.9640\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 10s 337us/step - loss: 0.1312 - acc: 0.9660\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 10s 345us/step - loss: 0.1143 - acc: 0.9704\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 10s 338us/step - loss: 0.1101 - acc: 0.9721\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 10s 337us/step - loss: 0.0959 - acc: 0.9749\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 10s 332us/step - loss: 0.0980 - acc: 0.9766\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 10s 345us/step - loss: 0.0941 - acc: 0.9795\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 10s 335us/step - loss: 0.0974 - acc: 0.9780\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 10s 335us/step - loss: 0.0893 - acc: 0.9816\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 10s 339us/step - loss: 0.0749 - acc: 0.9838\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 10s 344us/step - loss: 0.0941 - acc: 0.9811\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 10s 337us/step - loss: 0.0902 - acc: 0.9827\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 10s 335us/step - loss: 0.0722 - acc: 0.9862\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 10s 335us/step - loss: 0.0764 - acc: 0.9862\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 10s 344us/step - loss: 0.0954 - acc: 0.9828\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 10s 336us/step - loss: 0.0955 - acc: 0.9854\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 10s 337us/step - loss: 0.0975 - acc: 0.9857\n",
      "30000/30000 [==============================] - 5s 177us/step\n",
      "30000/30000 [==============================] - 4s 120us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=20, num_neurons=512, optimizer_algo=adam, total= 3.6min\n",
      "[CV] activation=relu, dropout=0.0, epochs=20, num_neurons=512, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 15s 503us/step - loss: 0.2934 - acc: 0.91522s -\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 10s 344us/step - loss: 0.1778 - acc: 0.9516\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 10s 341us/step - loss: 0.1583 - acc: 0.9575\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 11s 351us/step - loss: 0.1296 - acc: 0.9661\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 10s 339us/step - loss: 0.1166 - acc: 0.9702\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 10s 336us/step - loss: 0.1119 - acc: 0.9711\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 10s 337us/step - loss: 0.1111 - acc: 0.9722\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 10s 346us/step - loss: 0.1002 - acc: 0.9749\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 10s 338us/step - loss: 0.0958 - acc: 0.9775\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 10s 338us/step - loss: 0.1027 - acc: 0.9769\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 11s 354us/step - loss: 0.1020 - acc: 0.9792\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 11s 358us/step - loss: 0.0905 - acc: 0.9809\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 10s 338us/step - loss: 0.0925 - acc: 0.9820\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 10s 341us/step - loss: 0.0797 - acc: 0.9839\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 10s 341us/step - loss: 0.0851 - acc: 0.9833\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 10s 347us/step - loss: 0.0933 - acc: 0.9834\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 10s 339us/step - loss: 0.0754 - acc: 0.9859\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 10s 339us/step - loss: 0.0671 - acc: 0.9872\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 10s 344us/step - loss: 0.0934 - acc: 0.9851\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 10s 342us/step - loss: 0.1001 - acc: 0.9846\n",
      "30000/30000 [==============================] - 6s 188us/step\n",
      "30000/30000 [==============================] - 4s 123us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=20, num_neurons=512, optimizer_algo=adam, total= 3.6min\n",
      "[CV] activation=relu, dropout=0.0, epochs=20, num_neurons=784, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 13s 437us/step - loss: 0.8057 - acc: 0.8159\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 9s 311us/step - loss: 0.3881 - acc: 0.8987\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 10s 321us/step - loss: 0.3277 - acc: 0.9112\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 9s 309us/step - loss: 0.2951 - acc: 0.9195\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 9s 303us/step - loss: 0.2724 - acc: 0.9254\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 9s 315us/step - loss: 0.2542 - acc: 0.9313 0s - loss: 0.252\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 9s 306us/step - loss: 0.2392 - acc: 0.9354 1s - lo\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 9s 309us/step - loss: 0.2262 - acc: 0.9396\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 9s 309us/step - loss: 0.2147 - acc: 0.9429\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 9s 310us/step - loss: 0.2038 - acc: 0.9453 0s - loss: 0.2039\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 9s 315us/step - loss: 0.1944 - acc: 0.9480\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 9s 306us/step - loss: 0.1857 - acc: 0.9493\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 9s 304us/step - loss: 0.1776 - acc: 0.9526 1s - loss:\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 9s 301us/step - loss: 0.1702 - acc: 0.9536\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 9s 310us/step - loss: 0.1631 - acc: 0.9564\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 9s 303us/step - loss: 0.1568 - acc: 0.9573\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 9s 302us/step - loss: 0.1504 - acc: 0.9593\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 9s 300us/step - loss: 0.1449 - acc: 0.9606\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 9s 306us/step - loss: 0.1398 - acc: 0.9624\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 9s 306us/step - loss: 0.1347 - acc: 0.9638\n",
      "30000/30000 [==============================] - 6s 211us/step\n",
      "30000/30000 [==============================] - 4s 146us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=20, num_neurons=784, optimizer_algo=sgd, total= 3.3min\n",
      "[CV] activation=relu, dropout=0.0, epochs=20, num_neurons=784, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 13s 435us/step - loss: 0.7848 - acc: 0.8251\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 9s 308us/step - loss: 0.3864 - acc: 0.8963\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 9s 297us/step - loss: 0.3268 - acc: 0.9094\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 9s 301us/step - loss: 0.2937 - acc: 0.9176\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 9s 298us/step - loss: 0.2702 - acc: 0.9248\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 9s 300us/step - loss: 0.2514 - acc: 0.9298\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 9s 309us/step - loss: 0.2359 - acc: 0.9346\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 9s 302us/step - loss: 0.2225 - acc: 0.9375\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 9s 298us/step - loss: 0.2102 - acc: 0.9416\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 9s 300us/step - loss: 0.1995 - acc: 0.9441\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 9s 307us/step - loss: 0.1899 - acc: 0.9461\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 9s 301us/step - loss: 0.1811 - acc: 0.9494\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 9s 298us/step - loss: 0.1727 - acc: 0.9518\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 9s 299us/step - loss: 0.1655 - acc: 0.9537\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 9s 302us/step - loss: 0.1584 - acc: 0.9560\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 9s 303us/step - loss: 0.1520 - acc: 0.9576\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 9s 299us/step - loss: 0.1459 - acc: 0.9590\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 9s 299us/step - loss: 0.1404 - acc: 0.9617\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 9s 298us/step - loss: 0.1353 - acc: 0.9622\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 9s 306us/step - loss: 0.1304 - acc: 0.9641\n",
      "30000/30000 [==============================] - 6s 209us/step\n",
      "30000/30000 [==============================] - 4s 144us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=20, num_neurons=784, optimizer_algo=sgd, total= 3.2min\n",
      "[CV] activation=relu, dropout=0.0, epochs=20, num_neurons=784, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 19s 645us/step - loss: 0.3117 - acc: 0.91318s - loss: \n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 15s 499us/step - loss: 0.1861 - acc: 0.9491\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 15s 493us/step - loss: 0.1581 - acc: 0.9583\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 15s 493us/step - loss: 0.1360 - acc: 0.9653\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 15s 506us/step - loss: 0.1182 - acc: 0.9711\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 15s 499us/step - loss: 0.1176 - acc: 0.97156s - loss: 0 - ETA: 5s - loss: 0.1110 - acc: 0 - ETA: 4s - loss: 0.1141 - acc: 0.9\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 16s 529us/step - loss: 0.1235 - acc: 0.9723- ET\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 15s 490us/step - loss: 0.1106 - acc: 0.9761\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 15s 505us/step - loss: 0.1044 - acc: 0.9786\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 15s 503us/step - loss: 0.0999 - acc: 0.9789\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 15s 488us/step - loss: 0.1057 - acc: 0.9808\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 15s 492us/step - loss: 0.0804 - acc: 0.9831\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 15s 496us/step - loss: 0.0939 - acc: 0.9823\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 15s 490us/step - loss: 0.0940 - acc: 0.98270s - loss: 0.0945 - acc: 0\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 15s 497us/step - loss: 0.1030 - acc: 0.9828\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 15s 490us/step - loss: 0.0980 - acc: 0.98441s - loss: 0.0972  - ETA: 0s - loss: 0.0975 - \n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 15s 493us/step - loss: 0.0790 - acc: 0.9864\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 15s 499us/step - loss: 0.0882 - acc: 0.98521s\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 0.0881 - acc: 0.9868- ETA: - 15s 490us/step - loss: 0.0883 - acc: 0.9868\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 15s 488us/step - loss: 0.1115 - acc: 0.98580s - loss: 0.1119 - ac\n",
      "30000/30000 [==============================] - 6s 213us/step\n",
      "30000/30000 [==============================] - 4s 147us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=20, num_neurons=784, optimizer_algo=adam, total= 5.2min\n",
      "[CV] activation=relu, dropout=0.0, epochs=20, num_neurons=784, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 19s 633us/step - loss: 0.3108 - acc: 0.9103\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 15s 501us/step - loss: 0.1814 - acc: 0.9501\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 15s 491us/step - loss: 0.1581 - acc: 0.9588: 1s - los\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 15s 494us/step - loss: 0.1423 - acc: 0.9645\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 15s 500us/step - loss: 0.1244 - acc: 0.9687\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 15s 507us/step - loss: 0.1296 - acc: 0.9697\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 15s 495us/step - loss: 0.1067 - acc: 0.9749\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 15s 502us/step - loss: 0.1242 - acc: 0.9737\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 15s 493us/step - loss: 0.1105 - acc: 0.97743s - loss: 0.102 - ETA: 3s -  - ETA: 1s - loss: 0.1115 - acc: - ETA: 1s - loss: 0.1\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 15s 498us/step - loss: 0.1055 - acc: 0.97900s - loss: 0.1052 - acc: \n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 15s 491us/step - loss: 0.1074 - acc: 0.9795\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 15s 495us/step - loss: 0.1005 - acc: 0.9806\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 15s 500us/step - loss: 0.0813 - acc: 0.9846\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 15s 495us/step - loss: 0.1135 - acc: 0.98260s - loss: 0.1134 - acc: 0.98\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 15s 491us/step - loss: 0.1110 - acc: 0.98235 - ETA: 1s - lo\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 15s 500us/step - loss: 0.1055 - acc: 0.98450s - loss: 0.1010 - ac\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 15s 492us/step - loss: 0.1013 - acc: 0.9851\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 15s 499us/step - loss: 0.1069 - acc: 0.9843\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 15s 505us/step - loss: 0.0995 - acc: 0.9861\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 15s 497us/step - loss: 0.0995 - acc: 0.985911s - lo - ETA: 11s - loss: 0.0722 - - ETA: 10s - loss:\n",
      "30000/30000 [==============================] - 6s 201us/step\n",
      "30000/30000 [==============================] - 5s 155us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=20, num_neurons=784, optimizer_algo=adam, total= 5.1min\n",
      "[CV] activation=relu, dropout=0.0, epochs=20, num_neurons=1024, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 15s 516us/step - loss: 0.7818 - acc: 0.8266\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 11s 366us/step - loss: 0.3846 - acc: 0.90050s - loss: 0.3866 - acc\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 11s 372us/step - loss: 0.3239 - acc: 0.9139\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 11s 369us/step - loss: 0.2912 - acc: 0.9218\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 11s 369us/step - loss: 0.2687 - acc: 0.9283\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 11s 374us/step - loss: 0.2508 - acc: 0.9326\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 11s 375us/step - loss: 0.2361 - acc: 0.9365\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 11s 370us/step - loss: 0.2228 - acc: 0.9401\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 11s 365us/step - loss: 0.2115 - acc: 0.9438\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 11s 368us/step - loss: 0.2011 - acc: 0.9460\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 11s 372us/step - loss: 0.1919 - acc: 0.9486\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 11s 367us/step - loss: 0.1831 - acc: 0.9508\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 11s 367us/step - loss: 0.1752 - acc: 0.9527\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 11s 375us/step - loss: 0.1679 - acc: 0.9548\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 11s 368us/step - loss: 0.1612 - acc: 0.9563\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 11s 366us/step - loss: 0.1547 - acc: 0.9580\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 11s 365us/step - loss: 0.1489 - acc: 0.9598\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 11s 371us/step - loss: 0.1431 - acc: 0.96161s - loss:\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 11s 362us/step - loss: 0.1379 - acc: 0.96301s - loss: \n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 11s 365us/step - loss: 0.1328 - acc: 0.9647\n",
      "30000/30000 [==============================] - 7s 220us/step\n",
      "30000/30000 [==============================] - 5s 167us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=20, num_neurons=1024, optimizer_algo=sgd, total= 3.9min\n",
      "[CV] activation=relu, dropout=0.0, epochs=20, num_neurons=1024, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 15s 502us/step - loss: 0.7635 - acc: 0.8314\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 11s 364us/step - loss: 0.3834 - acc: 0.8960\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 11s 366us/step - loss: 0.3250 - acc: 0.9094\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 11s 374us/step - loss: 0.2922 - acc: 0.9178\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 11s 369us/step - loss: 0.2689 - acc: 0.9245\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 11s 370us/step - loss: 0.2500 - acc: 0.9293\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 11s 371us/step - loss: 0.2338 - acc: 0.9346\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 11s 367us/step - loss: 0.2205 - acc: 0.9389\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 11s 363us/step - loss: 0.2084 - acc: 0.9419\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 11s 366us/step - loss: 0.1973 - acc: 0.9450\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 11s 374us/step - loss: 0.1874 - acc: 0.9484\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 11s 374us/step - loss: 0.1786 - acc: 0.9503\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 11s 367us/step - loss: 0.1705 - acc: 0.9532\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 11s 366us/step - loss: 0.1628 - acc: 0.9550\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 11s 372us/step - loss: 0.1560 - acc: 0.9571\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 11s 365us/step - loss: 0.1498 - acc: 0.9584\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 11s 370us/step - loss: 0.1439 - acc: 0.96060s - loss: 0.1444 - acc:  - ETA: 0s - loss: 0.1441 - acc: 0.9\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 11s 376us/step - loss: 0.1381 - acc: 0.9624\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 11s 368us/step - loss: 0.1331 - acc: 0.9637\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 11s 363us/step - loss: 0.1282 - acc: 0.96551s - lo\n",
      "30000/30000 [==============================] - 7s 219us/step\n",
      "30000/30000 [==============================] - 5s 160us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=20, num_neurons=1024, optimizer_algo=sgd, total= 3.9min\n",
      "[CV] activation=relu, dropout=0.0, epochs=20, num_neurons=1024, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 23s 769us/step - loss: 0.3048 - acc: 0.91200s - loss: 0.3072 - acc: \n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 19s 619us/step - loss: 0.1935 - acc: 0.9482\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 19s 627us/step - loss: 0.1580 - acc: 0.9577\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 19s 625us/step - loss: 0.1282 - acc: 0.9673\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 19s 628us/step - loss: 0.1272 - acc: 0.9687\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 19s 621us/step - loss: 0.1137 - acc: 0.9733\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 19s 628us/step - loss: 0.1096 - acc: 0.9742\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 19s 619us/step - loss: 0.1069 - acc: 0.9755\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 19s 627us/step - loss: 0.0973 - acc: 0.9784\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 19s 624us/step - loss: 0.1151 - acc: 0.97761s - loss:  - ETA: 0s - loss: 0.1152 - acc: \n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 19s 637us/step - loss: 0.0831 - acc: 0.9828\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 19s 620us/step - loss: 0.1039 - acc: 0.9800\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 19s 624us/step - loss: 0.0967 - acc: 0.9819\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 18s 616us/step - loss: 0.0689 - acc: 0.98602s - loss: 0.0697 - - ETA: 1s - los\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 19s 623us/step - loss: 0.0996 - acc: 0.98330s - loss: 0.099\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 19s 619us/step - loss: 0.0867 - acc: 0.9841\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 19s 620us/step - loss: 0.0854 - acc: 0.9859\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 19s 633us/step - loss: 0.0990 - acc: 0.9843\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 19s 626us/step - loss: 0.0874 - acc: 0.9871\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 19s 628us/step - loss: 0.0913 - acc: 0.98611s \n",
      "30000/30000 [==============================] - 7s 230us/step\n",
      "30000/30000 [==============================] - 5s 162us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=20, num_neurons=1024, optimizer_algo=adam, total= 6.4min\n",
      "[CV] activation=relu, dropout=0.0, epochs=20, num_neurons=1024, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 24s 791us/step - loss: 0.3110 - acc: 0.91166s - loss: 0. - ETA: 1s - los\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 19s 628us/step - loss: 0.1867 - acc: 0.9499\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 19s 636us/step - loss: 0.1490 - acc: 0.9615\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 19s 630us/step - loss: 0.1298 - acc: 0.9661\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 19s 635us/step - loss: 0.1224 - acc: 0.96810s - loss: 0.12\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 19s 648us/step - loss: 0.1090 - acc: 0.9723\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 19s 632us/step - loss: 0.1194 - acc: 0.9736\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 19s 634us/step - loss: 0.1051 - acc: 0.97697s - loss: 0.1002 - ETA: 6s\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 19s 643us/step - loss: 0.1085 - acc: 0.97751s - loss\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 19s 635us/step - loss: 0.0824 - acc: 0.9817\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 19s 637us/step - loss: 0.0987 - acc: 0.9812\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 19s 627us/step - loss: 0.1058 - acc: 0.9804\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 19s 630us/step - loss: 0.0946 - acc: 0.9829\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 19s 627us/step - loss: 0.0861 - acc: 0.98451s - loss: 0.0846 - acc: 0.98 - ETA: 1s\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 19s 628us/step - loss: 0.1160 - acc: 0.9823A: 2s - loss: 0.1147 -  - ETA: 1\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 19s 648us/step - loss: 0.0946 - acc: 0.9852\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 19s 637us/step - loss: 0.1002 - acc: 0.9845\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 19s 632us/step - loss: 0.0766 - acc: 0.9882\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 19s 623us/step - loss: 0.1143 - acc: 0.9853\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 19s 632us/step - loss: 0.0954 - acc: 0.98750s - loss: 0.0918 \n",
      "30000/30000 [==============================] - 7s 222us/step\n",
      "30000/30000 [==============================] - 5s 163us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=20, num_neurons=1024, optimizer_algo=adam, total= 6.5min\n",
      "[CV] activation=relu, dropout=0.0, epochs=30, num_neurons=256, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 10s 343us/step - loss: 0.8430 - acc: 0.7991\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 6s 194us/step - loss: 0.4048 - acc: 0.8926\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 6s 186us/step - loss: 0.3402 - acc: 0.9072\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 6s 185us/step - loss: 0.3059 - acc: 0.9165\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 5s 181us/step - loss: 0.2827 - acc: 0.9221\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 5s 182us/step - loss: 0.2646 - acc: 0.9279\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 6s 191us/step - loss: 0.2496 - acc: 0.9322\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 5s 176us/step - loss: 0.2364 - acc: 0.9359\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 5s 182us/step - loss: 0.2250 - acc: 0.9392\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 5s 176us/step - loss: 0.2149 - acc: 0.9423\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 5s 175us/step - loss: 0.2052 - acc: 0.9450\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 5s 176us/step - loss: 0.1969 - acc: 0.9473\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 5s 176us/step - loss: 0.1888 - acc: 0.9498\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 5s 176us/step - loss: 0.1814 - acc: 0.9512\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 5s 176us/step - loss: 0.1751 - acc: 0.9521\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 5s 175us/step - loss: 0.1687 - acc: 0.9544\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 5s 181us/step - loss: 0.1623 - acc: 0.9561\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 5s 175us/step - loss: 0.1569 - acc: 0.9571\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 5s 178us/step - loss: 0.1518 - acc: 0.9593\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 5s 175us/step - loss: 0.1468 - acc: 0.9602\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 5s 176us/step - loss: 0.1420 - acc: 0.9618\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 5s 175us/step - loss: 0.1376 - acc: 0.9624\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 5s 175us/step - loss: 0.1333 - acc: 0.9640\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 5s 182us/step - loss: 0.1293 - acc: 0.9650\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 5s 176us/step - loss: 0.1255 - acc: 0.9670\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 5s 175us/step - loss: 0.1218 - acc: 0.9674\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 5s 175us/step - loss: 0.1183 - acc: 0.9687\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 5s 175us/step - loss: 0.1151 - acc: 0.9696\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 5s 176us/step - loss: 0.1119 - acc: 0.9710\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 5s 177us/step - loss: 0.1089 - acc: 0.9717\n",
      "30000/30000 [==============================] - 5s 166us/step\n",
      "30000/30000 [==============================] - 4s 118us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=30, num_neurons=256, optimizer_algo=sgd, total= 2.8min\n",
      "[CV] activation=relu, dropout=0.0, epochs=30, num_neurons=256, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 10s 321us/step - loss: 0.8348 - acc: 0.7995\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 6s 184us/step - loss: 0.4081 - acc: 0.8888\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 5s 182us/step - loss: 0.3434 - acc: 0.9040\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 5s 180us/step - loss: 0.3085 - acc: 0.9124\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 5s 182us/step - loss: 0.2843 - acc: 0.9206\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 5s 180us/step - loss: 0.2656 - acc: 0.9259\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 6s 187us/step - loss: 0.2498 - acc: 0.9295\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 5s 181us/step - loss: 0.2362 - acc: 0.9338\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 5s 183us/step - loss: 0.2239 - acc: 0.9368\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 5s 181us/step - loss: 0.2133 - acc: 0.9404\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 5s 181us/step - loss: 0.2034 - acc: 0.9432\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 5s 182us/step - loss: 0.1943 - acc: 0.9464\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 5s 181us/step - loss: 0.1862 - acc: 0.9481\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 6s 187us/step - loss: 0.1785 - acc: 0.9506\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 5s 181us/step - loss: 0.1714 - acc: 0.9524\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 5s 182us/step - loss: 0.1649 - acc: 0.9545\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 5s 182us/step - loss: 0.1587 - acc: 0.9569\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 5s 182us/step - loss: 0.1531 - acc: 0.9579\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 5s 181us/step - loss: 0.1477 - acc: 0.9595\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 5s 182us/step - loss: 0.1427 - acc: 0.9608\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 6s 186us/step - loss: 0.1378 - acc: 0.9623\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 6s 185us/step - loss: 0.1334 - acc: 0.9635\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 5s 183us/step - loss: 0.1292 - acc: 0.9645\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 6s 183us/step - loss: 0.1251 - acc: 0.9659\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 6s 184us/step - loss: 0.1211 - acc: 0.9675\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 5s 182us/step - loss: 0.1177 - acc: 0.9676\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 5s 182us/step - loss: 0.1140 - acc: 0.9690\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 5s 181us/step - loss: 0.1107 - acc: 0.9701\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 6s 186us/step - loss: 0.1074 - acc: 0.9716\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 5s 181us/step - loss: 0.1046 - acc: 0.9720\n",
      "30000/30000 [==============================] - 6s 185us/step\n",
      "30000/30000 [==============================] - 4s 127us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=30, num_neurons=256, optimizer_algo=sgd, total= 2.9min\n",
      "[CV] activation=relu, dropout=0.0, epochs=30, num_neurons=256, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 11s 377us/step - loss: 0.2858 - acc: 0.9152\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 7s 238us/step - loss: 0.1841 - acc: 0.9476\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 7s 242us/step - loss: 0.1461 - acc: 0.9597\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 7s 234us/step - loss: 0.1331 - acc: 0.9640\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 7s 235us/step - loss: 0.1098 - acc: 0.9702\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 7s 237us/step - loss: 0.1020 - acc: 0.9730\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 7s 238us/step - loss: 0.1045 - acc: 0.9734\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 7s 241us/step - loss: 0.0991 - acc: 0.9752 0s - loss: 0.0954 - ac\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 7s 234us/step - loss: 0.0977 - acc: 0.9767\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 7s 232us/step - loss: 0.0922 - acc: 0.9786\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 7s 233us/step - loss: 0.0992 - acc: 0.9777\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 7s 235us/step - loss: 0.0845 - acc: 0.9812\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 7s 232us/step - loss: 0.0763 - acc: 0.9831\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 7s 238us/step - loss: 0.0763 - acc: 0.9837\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 7s 234us/step - loss: 0.0972 - acc: 0.9815\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 7s 235us/step - loss: 0.0890 - acc: 0.9832\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 7s 247us/step - loss: 0.0756 - acc: 0.9862\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 7s 234us/step - loss: 0.0872 - acc: 0.9852\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 7s 242us/step - loss: 0.0976 - acc: 0.9830\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 7s 247us/step - loss: 0.0596 - acc: 0.9884\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 7s 237us/step - loss: 0.0904 - acc: 0.9858\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 7s 239us/step - loss: 0.0707 - acc: 0.9881\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 7s 240us/step - loss: 0.0763 - acc: 0.9881\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 7s 236us/step - loss: 0.0775 - acc: 0.9871\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 7s 241us/step - loss: 0.0586 - acc: 0.9903\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 7s 240us/step - loss: 0.0749 - acc: 0.9885\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 7s 235us/step - loss: 0.0741 - acc: 0.9895\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 7s 234us/step - loss: 0.0989 - acc: 0.9874\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 7s 237us/step - loss: 0.0851 - acc: 0.9892\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 7s 236us/step - loss: 0.0752 - acc: 0.9897\n",
      "30000/30000 [==============================] - 6s 191us/step\n",
      "30000/30000 [==============================] - 3s 115us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=30, num_neurons=256, optimizer_algo=adam, total= 3.7min\n",
      "[CV] activation=relu, dropout=0.0, epochs=30, num_neurons=256, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 11s 378us/step - loss: 0.2841 - acc: 0.9144\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 7s 231us/step - loss: 0.1743 - acc: 0.9501\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 7s 242us/step - loss: 0.1542 - acc: 0.9584\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 7s 243us/step - loss: 0.1353 - acc: 0.9637\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 7s 250us/step - loss: 0.1168 - acc: 0.9696\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 8s 253us/step - loss: 0.1144 - acc: 0.9699\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 7s 239us/step - loss: 0.1081 - acc: 0.9737\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 7s 240us/step - loss: 0.1026 - acc: 0.9759\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 7s 240us/step - loss: 0.0893 - acc: 0.9784\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 8s 250us/step - loss: 0.0875 - acc: 0.9797\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 7s 240us/step - loss: 0.1065 - acc: 0.9786\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 7s 241us/step - loss: 0.0910 - acc: 0.9807\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 7s 240us/step - loss: 0.0943 - acc: 0.9813\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 7s 242us/step - loss: 0.0844 - acc: 0.9841\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 7s 243us/step - loss: 0.0826 - acc: 0.9850\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 7s 245us/step - loss: 0.0956 - acc: 0.9835\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 7s 242us/step - loss: 0.0991 - acc: 0.9839\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 7s 240us/step - loss: 0.0732 - acc: 0.9874\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 0.0970 - acc: 0.985 - 7s 239us/step - loss: 0.0969 - acc: 0.9858\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 7s 241us/step - loss: 0.0858 - acc: 0.9867\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 7s 247us/step - loss: 0.0844 - acc: 0.9875\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 7s 244us/step - loss: 0.0693 - acc: 0.9887\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 7s 240us/step - loss: 0.0871 - acc: 0.9875\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 7s 243us/step - loss: 0.0873 - acc: 0.9877\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 7s 239us/step - loss: 0.0957 - acc: 0.9878\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 7s 245us/step - loss: 0.0970 - acc: 0.9884\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 7s 248us/step - loss: 0.0865 - acc: 0.9892\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 7s 243us/step - loss: 0.0925 - acc: 0.9894\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 7s 241us/step - loss: 0.1167 - acc: 0.9873\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 7s 240us/step - loss: 0.1119 - acc: 0.9881\n",
      "30000/30000 [==============================] - 5s 180us/step\n",
      "30000/30000 [==============================] - 4s 117us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=30, num_neurons=256, optimizer_algo=adam, total= 3.8min\n",
      "[CV] activation=relu, dropout=0.0, epochs=30, num_neurons=512, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 12s 405us/step - loss: 0.8070 - acc: 0.8137\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 8s 253us/step - loss: 0.3942 - acc: 0.8981\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 8s 252us/step - loss: 0.3325 - acc: 0.9095\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 7s 249us/step - loss: 0.3003 - acc: 0.9179\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 8s 259us/step - loss: 0.2773 - acc: 0.9234\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 7s 248us/step - loss: 0.2591 - acc: 0.9303\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 8s 254us/step - loss: 0.2442 - acc: 0.9345\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 8s 258us/step - loss: 0.2312 - acc: 0.9379\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 8s 256us/step - loss: 0.2196 - acc: 0.9411\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 8s 259us/step - loss: 0.2092 - acc: 0.9436\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 8s 256us/step - loss: 0.1995 - acc: 0.9462\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 8s 256us/step - loss: 0.1909 - acc: 0.9485\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 8s 252us/step - loss: 0.1833 - acc: 0.9507\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 8s 252us/step - loss: 0.1758 - acc: 0.9524\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 7s 249us/step - loss: 0.1690 - acc: 0.9543\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 8s 257us/step - loss: 0.1624 - acc: 0.9556\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 7s 248us/step - loss: 0.1563 - acc: 0.9582\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 7s 249us/step - loss: 0.1507 - acc: 0.9591\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 7s 249us/step - loss: 0.1453 - acc: 0.9611\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 7s 248us/step - loss: 0.1402 - acc: 0.9619\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 8s 256us/step - loss: 0.1354 - acc: 0.9633\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 7s 249us/step - loss: 0.1309 - acc: 0.9650\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 8s 251us/step - loss: 0.1264 - acc: 0.9660\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 7s 247us/step - loss: 0.1224 - acc: 0.9679\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 8s 263us/step - loss: 0.1186 - acc: 0.9687\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 8s 258us/step - loss: 0.1151 - acc: 0.9693\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 7s 248us/step - loss: 0.1115 - acc: 0.9712\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 7s 249us/step - loss: 0.1081 - acc: 0.9714\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 7s 248us/step - loss: 0.1049 - acc: 0.9729\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 8s 251us/step - loss: 0.1019 - acc: 0.9734\n",
      "30000/30000 [==============================] - 6s 188us/step\n",
      "30000/30000 [==============================] - 4s 135us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=30, num_neurons=512, optimizer_algo=sgd, total= 4.0min\n",
      "[CV] activation=relu, dropout=0.0, epochs=30, num_neurons=512, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 12s 404us/step - loss: 0.8067 - acc: 0.8123\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 8s 257us/step - loss: 0.3974 - acc: 0.8941\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 8s 257us/step - loss: 0.3352 - acc: 0.9077\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 8s 261us/step - loss: 0.3025 - acc: 0.9156\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 8s 269us/step - loss: 0.2793 - acc: 0.9217\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 8s 273us/step - loss: 0.2605 - acc: 0.9263\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 8s 264us/step - loss: 0.2453 - acc: 0.9312\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 8s 252us/step - loss: 0.2315 - acc: 0.9353\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 8s 255us/step - loss: 0.2194 - acc: 0.9388\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 8s 256us/step - loss: 0.2083 - acc: 0.9419 1s - los\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 8s 253us/step - loss: 0.1986 - acc: 0.9437\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 8s 252us/step - loss: 0.1895 - acc: 0.9468\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 8s 253us/step - loss: 0.1811 - acc: 0.9496\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 8s 252us/step - loss: 0.1734 - acc: 0.9513\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 8s 259us/step - loss: 0.1663 - acc: 0.9546\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 8s 250us/step - loss: 0.1595 - acc: 0.9553\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 8s 253us/step - loss: 0.1534 - acc: 0.9569\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 8s 252us/step - loss: 0.1476 - acc: 0.9588\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 8s 255us/step - loss: 0.1422 - acc: 0.9606\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 8s 264us/step - loss: 0.1373 - acc: 0.9624\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 8s 271us/step - loss: 0.1324 - acc: 0.9643\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 8s 255us/step - loss: 0.1279 - acc: 0.9652\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 8s 254us/step - loss: 0.1237 - acc: 0.9663\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 8s 252us/step - loss: 0.1197 - acc: 0.9678\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 8s 253us/step - loss: 0.1158 - acc: 0.9695\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 8s 258us/step - loss: 0.1121 - acc: 0.9700\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 8s 253us/step - loss: 0.1088 - acc: 0.9705\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 8s 252us/step - loss: 0.1056 - acc: 0.9719\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 8s 250us/step - loss: 0.1024 - acc: 0.9722\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 8s 253us/step - loss: 0.0994 - acc: 0.9736\n",
      "30000/30000 [==============================] - 6s 211us/step\n",
      "30000/30000 [==============================] - 4s 131us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=30, num_neurons=512, optimizer_algo=sgd, total= 4.0min\n",
      "[CV] activation=relu, dropout=0.0, epochs=30, num_neurons=512, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 16s 520us/step - loss: 0.3011 - acc: 0.9137\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 11s 354us/step - loss: 0.1927 - acc: 0.9478\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 11s 358us/step - loss: 0.1615 - acc: 0.9559\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 11s 366us/step - loss: 0.1374 - acc: 0.9644\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 11s 365us/step - loss: 0.1388 - acc: 0.9666\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 11s 362us/step - loss: 0.1103 - acc: 0.9729\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 11s 374us/step - loss: 0.1169 - acc: 0.9733\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 11s 371us/step - loss: 0.1135 - acc: 0.9749\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 11s 361us/step - loss: 0.1139 - acc: 0.9757\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 11s 356us/step - loss: 0.1034 - acc: 0.9787\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 11s 362us/step - loss: 0.0975 - acc: 0.9790\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 11s 358us/step - loss: 0.0968 - acc: 0.9812\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 11s 352us/step - loss: 0.0993 - acc: 0.9815\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 11s 361us/step - loss: 0.0928 - acc: 0.9833\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 11s 352us/step - loss: 0.0996 - acc: 0.9824\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 11s 353us/step - loss: 0.0988 - acc: 0.9838\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 11s 353us/step - loss: 0.0810 - acc: 0.9861\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 11s 359us/step - loss: 0.0997 - acc: 0.9840\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 11s 367us/step - loss: 0.1034 - acc: 0.9855\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 11s 356us/step - loss: 0.0919 - acc: 0.9851\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 11s 353us/step - loss: 0.0864 - acc: 0.9876\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 11s 362us/step - loss: 0.0806 - acc: 0.9885\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 11s 353us/step - loss: 0.0887 - acc: 0.9881\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 11s 352us/step - loss: 0.1058 - acc: 0.9858\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 11s 356us/step - loss: 0.0885 - acc: 0.9878\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 11s 354us/step - loss: 0.0819 - acc: 0.9889\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 11s 354us/step - loss: 0.1013 - acc: 0.9878\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 11s 353us/step - loss: 0.0831 - acc: 0.9889\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 11s 362us/step - loss: 0.0830 - acc: 0.9894\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 11s 352us/step - loss: 0.1040 - acc: 0.9885\n",
      "30000/30000 [==============================] - 6s 189us/step\n",
      "30000/30000 [==============================] - 4s 132us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=30, num_neurons=512, optimizer_algo=adam, total= 5.6min\n",
      "[CV] activation=relu, dropout=0.0, epochs=30, num_neurons=512, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 15s 495us/step - loss: 0.3006 - acc: 0.9116\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 11s 366us/step - loss: 0.1790 - acc: 0.9518\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 11s 360us/step - loss: 0.1461 - acc: 0.9603\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 11s 357us/step - loss: 0.1320 - acc: 0.9648\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 11s 368us/step - loss: 0.1334 - acc: 0.9683\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 11s 357us/step - loss: 0.1180 - acc: 0.9719\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 11s 357us/step - loss: 0.1117 - acc: 0.9746\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 11s 360us/step - loss: 0.1196 - acc: 0.9746\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 11s 367us/step - loss: 0.0910 - acc: 0.9786\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 11s 359us/step - loss: 0.0965 - acc: 0.9792\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 11s 357us/step - loss: 0.1061 - acc: 0.9799\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 11s 356us/step - loss: 0.1130 - acc: 0.9801\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 11s 364us/step - loss: 0.0842 - acc: 0.9836\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 11s 358us/step - loss: 0.0783 - acc: 0.9846\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 11s 360us/step - loss: 0.0785 - acc: 0.9853\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 11s 380us/step - loss: 0.0874 - acc: 0.9855\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 11s 362us/step - loss: 0.1027 - acc: 0.9850\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 11s 357us/step - loss: 0.1039 - acc: 0.9859\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 11s 371us/step - loss: 0.0952 - acc: 0.9861\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 11s 367us/step - loss: 0.0941 - acc: 0.9859\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 11s 358us/step - loss: 0.0942 - acc: 0.9863\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 11s 355us/step - loss: 0.0989 - acc: 0.9878\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 11s 356us/step - loss: 0.0800 - acc: 0.9892\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 11s 365us/step - loss: 0.0899 - acc: 0.9895\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 11s 359us/step - loss: 0.1101 - acc: 0.9872\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 11s 359us/step - loss: 0.0968 - acc: 0.9884\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 11s 370us/step - loss: 0.0971 - acc: 0.9886\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 11s 356us/step - loss: 0.0977 - acc: 0.9884\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 11s 357us/step - loss: 0.1101 - acc: 0.9880\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 11s 359us/step - loss: 0.1047 - acc: 0.9888\n",
      "30000/30000 [==============================] - 6s 203us/step\n",
      "30000/30000 [==============================] - 4s 142us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=30, num_neurons=512, optimizer_algo=adam, total= 5.6min\n",
      "[CV] activation=relu, dropout=0.0, epochs=30, num_neurons=784, optimizer_algo=sgd \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 14s 481us/step - loss: 0.7874 - acc: 0.8223\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 10s 333us/step - loss: 0.3886 - acc: 0.8987\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 10s 333us/step - loss: 0.3262 - acc: 0.9139\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 10s 346us/step - loss: 0.2932 - acc: 0.9218\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 10s 338us/step - loss: 0.2703 - acc: 0.9276\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 10s 327us/step - loss: 0.2521 - acc: 0.9333\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 10s 332us/step - loss: 0.2372 - acc: 0.9371\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 10s 343us/step - loss: 0.2241 - acc: 0.9401\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 10s 335us/step - loss: 0.2127 - acc: 0.9434\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 10s 327us/step - loss: 0.2024 - acc: 0.9460\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 10s 331us/step - loss: 0.1931 - acc: 0.9489\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 0.1845 - acc: 0.950 - 10s 335us/step - loss: 0.1846 - acc: 0.9508\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 10s 338us/step - loss: 0.1768 - acc: 0.9526\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 10s 330us/step - loss: 0.1693 - acc: 0.9538\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 10s 331us/step - loss: 0.1628 - acc: 0.9553\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 10s 336us/step - loss: 0.1566 - acc: 0.9571\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 10s 326us/step - loss: 0.1505 - acc: 0.9590\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 10s 333us/step - loss: 0.1451 - acc: 0.9603\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 10s 332us/step - loss: 0.1398 - acc: 0.9620\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 10s 337us/step - loss: 0.1350 - acc: 0.9635\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 10s 333us/step - loss: 0.1301 - acc: 0.9655\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 10s 330us/step - loss: 0.1258 - acc: 0.9666\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 10s 347us/step - loss: 0.1216 - acc: 0.9683\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 10s 336us/step - loss: 0.1178 - acc: 0.9691\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 10s 341us/step - loss: 0.1140 - acc: 0.9701\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 10s 334us/step - loss: 0.1104 - acc: 0.9716\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 10s 327us/step - loss: 0.1069 - acc: 0.9722\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 0.1040 - acc: 0.973 - 10s 336us/step - loss: 0.1040 - acc: 0.9733\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 10s 334us/step - loss: 0.1008 - acc: 0.9742\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 10s 341us/step - loss: 0.0977 - acc: 0.9750\n",
      "30000/30000 [==============================] - 7s 220us/step\n",
      "30000/30000 [==============================] - 5s 164us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=30, num_neurons=784, optimizer_algo=sgd, total= 5.2min\n",
      "[CV] activation=relu, dropout=0.0, epochs=30, num_neurons=784, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 15s 496us/step - loss: 0.7887 - acc: 0.8190\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 10s 339us/step - loss: 0.3881 - acc: 0.8950\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 10s 333us/step - loss: 0.3265 - acc: 0.9094\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 10s 342us/step - loss: 0.2931 - acc: 0.9190\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 10s 332us/step - loss: 0.2694 - acc: 0.9242\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 10s 330us/step - loss: 0.2506 - acc: 0.9293\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 10s 329us/step - loss: 0.2351 - acc: 0.9339\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 10s 337us/step - loss: 0.2213 - acc: 0.9378\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 10s 333us/step - loss: 0.2094 - acc: 0.9417\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 10s 337us/step - loss: 0.1983 - acc: 0.9451\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 10s 337us/step - loss: 0.1891 - acc: 0.9474\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 10s 341us/step - loss: 0.1799 - acc: 0.9496\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 10s 336us/step - loss: 0.1720 - acc: 0.9520\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 10s 330us/step - loss: 0.1641 - acc: 0.9544\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 0.1574 - acc: 0.956 - 10s 332us/step - loss: 0.1577 - acc: 0.9566\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 10s 342us/step - loss: 0.1512 - acc: 0.9584\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 10s 335us/step - loss: 0.1452 - acc: 0.9604\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 10s 336us/step - loss: 0.1398 - acc: 0.9618\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 10s 333us/step - loss: 0.1344 - acc: 0.9633\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 10s 335us/step - loss: 0.1295 - acc: 0.9650\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 10s 332us/step - loss: 0.1250 - acc: 0.9658\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 10s 336us/step - loss: 0.1208 - acc: 0.9672\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 10s 334us/step - loss: 0.1167 - acc: 0.9684\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 10s 338us/step - loss: 0.1129 - acc: 0.9694\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 10s 325us/step - loss: 0.1091 - acc: 0.9711\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 10s 333us/step - loss: 0.1058 - acc: 0.9721\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 10s 340us/step - loss: 0.1026 - acc: 0.9727\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 10s 343us/step - loss: 0.0993 - acc: 0.9735\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 10s 341us/step - loss: 0.0965 - acc: 0.9748\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 10s 337us/step - loss: 0.0937 - acc: 0.9755\n",
      "30000/30000 [==============================] - 7s 226us/step\n",
      "30000/30000 [==============================] - 5s 165us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=30, num_neurons=784, optimizer_algo=sgd, total= 5.2min\n",
      "[CV] activation=relu, dropout=0.0, epochs=30, num_neurons=784, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 20s 681us/step - loss: 0.3082 - acc: 0.9112\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 16s 528us/step - loss: 0.1890 - acc: 0.9464\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 16s 536us/step - loss: 0.1551 - acc: 0.9587\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 16s 520us/step - loss: 0.1220 - acc: 0.96761s \n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 17s 570us/step - loss: 0.1283 - acc: 0.9667\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 17s 578us/step - loss: 0.1222 - acc: 0.9713\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 16s 533us/step - loss: 0.1204 - acc: 0.9727\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 16s 525us/step - loss: 0.1078 - acc: 0.9749\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 15s 517us/step - loss: 0.0968 - acc: 0.9782\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 16s 521us/step - loss: 0.1029 - acc: 0.97770s - loss: 0.101\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 16s 517us/step - loss: 0.0968 - acc: 0.97960s - loss: 0.0970 - acc: 0.97\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 16s 518us/step - loss: 0.0990 - acc: 0.9813\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 16s 524us/step - loss: 0.1021 - acc: 0.9818\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 16s 518us/step - loss: 0.1158 - acc: 0.9796\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 16s 522us/step - loss: 0.1027 - acc: 0.9825\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 16s 519us/step - loss: 0.0919 - acc: 0.9845\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 15s 493us/step - loss: 0.0977 - acc: 0.98431s - loss: 0.0895 - acc: 0.985 - ETA:\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 15s 493us/step - loss: 0.0878 - acc: 0.9849\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 15s 488us/step - loss: 0.0950 - acc: 0.9865\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 15s 487us/step - loss: 0.0964 - acc: 0.98683s - loss: - ETA: 0s - loss: 0.0963 - acc: 0.98\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 15s 487us/step - loss: 0.0837 - acc: 0.9884\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 15s 487us/step - loss: 0.1046 - acc: 0.9866\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 15s 491us/step - loss: 0.1037 - acc: 0.987110s  - E - ETA: 5s - loss: 0 -  - ETA: 2s - loss: 0.105 - ETA: 1s - lo\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 15s 504us/step - loss: 0.1010 - acc: 0.9875\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 11636s 388ms/step0.0830 - acc: 0.9911 E\n",
      "30000/30000 [==============================] - 8s 282us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=30, num_neurons=784, optimizer_algo=adam, total=201.7min\n",
      "[CV] activation=relu, dropout=0.0, epochs=30, num_neurons=784, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 0.3065 - acc: 0.9121\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 22s 725us/step - loss: 0.1808 - acc: 0.9508\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 22s 726us/step - loss: 0.1472 - acc: 0.9586\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 21s 711us/step - loss: 0.1582 - acc: 0.9631\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 21s 692us/step - loss: 0.1228 - acc: 0.9694\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 21s 704us/step - loss: 0.1205 - acc: 0.9701\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 21s 688us/step - loss: 0.1211 - acc: 0.9726\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 21s 691us/step - loss: 0.1123 - acc: 0.9769\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 20s 682us/step - loss: 0.1180 - acc: 0.9761\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 21s 694us/step - loss: 0.1057 - acc: 0.9805\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 21s 706us/step - loss: 0.1001 - acc: 0.9815\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 21s 697us/step - loss: 0.1319 - acc: 0.9794\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 21s 696us/step - loss: 0.1006 - acc: 0.9828\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 21s 703us/step - loss: 0.0874 - acc: 0.9839\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 21s 696us/step - loss: 0.0896 - acc: 0.9849\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 21s 690us/step - loss: 0.1098 - acc: 0.9853\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 20s 681us/step - loss: 0.1118 - acc: 0.9847\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 21s 692us/step - loss: 0.1145 - acc: 0.9844\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 21s 685us/step - loss: 0.1082 - acc: 0.9863\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 20s 681us/step - loss: 0.1172 - acc: 0.98626s - loss - ETA:\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 20s 681us/step - loss: 0.1081 - acc: 0.9869\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 21s 706us/step - loss: 0.1117 - acc: 0.9867\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 21s 687us/step - loss: 0.1022 - acc: 0.9876\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 21s 690us/step - loss: 0.1184 - acc: 0.9871\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 20s 680us/step - loss: 0.1427 - acc: 0.9857\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 21s 698us/step - loss: 0.1168 - acc: 0.98730s - loss: 0.1175 - acc: \n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 20s 678us/step - loss: 0.1163 - acc: 0.9884\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 21s 700us/step - loss: 0.0981 - acc: 0.9901\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 21s 700us/step - loss: 0.1055 - acc: 0.9892\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 21s 685us/step - loss: 0.1243 - acc: 0.9880\n",
      "30000/30000 [==============================] - 8s 279us/step\n",
      "30000/30000 [==============================] - 6s 205us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=30, num_neurons=784, optimizer_algo=adam, total=10.9min\n",
      "[CV] activation=relu, dropout=0.0, epochs=30, num_neurons=1024, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 20s 675us/step - loss: 0.7851 - acc: 0.8213\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 15s 507us/step - loss: 0.3836 - acc: 0.89991s - loss: 0.\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 15s 508us/step - loss: 0.3233 - acc: 0.9139 - ETA: - ETA: 2s - loss: 0.3294 - acc: 0  - ETA: 0s - loss: 0.3233 - acc: 0.913\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 15s 503us/step - loss: 0.2910 - acc: 0.9210- ETA: 3s - \n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 15s 508us/step - loss: 0.2683 - acc: 0.92690s - loss: 0.2686 - acc: 0.\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 16s 517us/step - loss: 0.2504 - acc: 0.9321\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 15s 503us/step - loss: 0.2360 - acc: 0.9364\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 15s 515us/step - loss: 0.2229 - acc: 0.9394\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 15s 507us/step - loss: 0.2118 - acc: 0.94332s - loss: 0.2134 - ac\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 15s 498us/step - loss: 0.2012 - acc: 0.9458\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 15s 509us/step - loss: 0.1920 - acc: 0.9486\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 15s 496us/step - loss: 0.1832 - acc: 0.9505- ETA: 1s - lo - ETA: 0s - loss: 0.1826 - acc: 0.9\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 15s 504us/step - loss: 0.1751 - acc: 0.9530\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 15s 499us/step - loss: 0.1675 - acc: 0.9546\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 15s 501us/step - loss: 0.1607 - acc: 0.95631s - l\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 15s 510us/step - loss: 0.1538 - acc: 0.9589\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 0.1479 - acc: 0.960 - 15s 510us/step - loss: 0.1479 - acc: 0.9602\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 15s 499us/step - loss: 0.1421 - acc: 0.9615\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 16s 523us/step - loss: 0.1370 - acc: 0.9635\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 15s 503us/step - loss: 0.1320 - acc: 0.9645\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 15s 510us/step - loss: 0.1271 - acc: 0.96673s - loss: 0.1 - ETA: 0s - loss: 0.1265 -\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 15s 498us/step - loss: 0.1225 - acc: 0.96765s - loss: 0.\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 15s 496us/step - loss: 0.1186 - acc: 0.9692\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 15s 506us/step - loss: 0.1145 - acc: 0.97060s - loss: 0.1149 - acc: \n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 15s 493us/step - loss: 0.1108 - acc: 0.971710\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 15s 495us/step - loss: 0.1073 - acc: 0.97210s - loss: 0.10\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 15s 484us/step - loss: 0.1039 - acc: 0.9735\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 15s 484us/step - loss: 0.1006 - acc: 0.9748\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 15s 486us/step - loss: 0.0976 - acc: 0.9754\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 14s 475us/step - loss: 0.0946 - acc: 0.9758\n",
      "30000/30000 [==============================] - 8s 280us/step\n",
      "30000/30000 [==============================] - 6s 204us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=30, num_neurons=1024, optimizer_algo=sgd, total= 7.8min\n",
      "[CV] activation=relu, dropout=0.0, epochs=30, num_neurons=1024, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 20s 655us/step - loss: 0.7915 - acc: 0.82285s - ETA: 0s - loss: 0.7942 - acc: 0.8\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 15s 485us/step - loss: 0.3835 - acc: 0.8969A: 3s -  - ETA: 1s\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 15s 502us/step - loss: 0.3238 - acc: 0.9099\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 15s 490us/step - loss: 0.2914 - acc: 0.9196\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 15s 488us/step - loss: 0.2682 - acc: 0.9250\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 15s 500us/step - loss: 0.2494 - acc: 0.9299\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 14s 474us/step - loss: 0.2339 - acc: 0.9348\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 13s 445us/step - loss: 0.2204 - acc: 0.9387\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 13s 446us/step - loss: 0.2085 - acc: 0.9422\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 13s 437us/step - loss: 0.1975 - acc: 0.9456\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 13s 436us/step - loss: 0.1881 - acc: 0.9475\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 14s 451us/step - loss: 0.1793 - acc: 0.9502\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 13s 437us/step - loss: 0.1711 - acc: 0.9530\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 13s 440us/step - loss: 0.1638 - acc: 0.9541\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 13s 447us/step - loss: 0.1568 - acc: 0.9566\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 13s 434us/step - loss: 0.1505 - acc: 0.9581\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 13s 438us/step - loss: 0.1445 - acc: 0.9601\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 13s 446us/step - loss: 0.1391 - acc: 0.9618\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 13s 440us/step - loss: 0.1340 - acc: 0.9631\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 13s 438us/step - loss: 0.1292 - acc: 0.9643: 1s - loss\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 13s 443us/step - loss: 0.1247 - acc: 0.9657\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 13s 440us/step - loss: 0.1204 - acc: 0.9672\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 13s 437us/step - loss: 0.1164 - acc: 0.9684\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 13s 446us/step - loss: 0.1127 - acc: 0.9698\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 13s 433us/step - loss: 0.1089 - acc: 0.9700\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 13s 444us/step - loss: 0.1055 - acc: 0.9719\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 13s 449us/step - loss: 0.1024 - acc: 0.9728\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 13s 443us/step - loss: 0.0991 - acc: 0.9731\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 13s 439us/step - loss: 0.0961 - acc: 0.9746\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 13s 448us/step - loss: 0.0934 - acc: 0.9751\n",
      "30000/30000 [==============================] - 9s 291us/step\n",
      "30000/30000 [==============================] - 6s 214us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=30, num_neurons=1024, optimizer_algo=sgd, total= 7.0min\n",
      "[CV] activation=relu, dropout=0.0, epochs=30, num_neurons=1024, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 28s 927us/step - loss: 0.3137 - acc: 0.9103\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 22s 741us/step - loss: 0.1983 - acc: 0.9465\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 23s 752us/step - loss: 0.1482 - acc: 0.9597\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 22s 741us/step - loss: 0.1347 - acc: 0.9653\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 23s 774us/step - loss: 0.1333 - acc: 0.9675\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 23s 757us/step - loss: 0.1146 - acc: 0.97190s - loss: 0.1144 - acc: 0.\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 22s 744us/step - loss: 0.1181 - acc: 0.9738\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 23s 753us/step - loss: 0.0975 - acc: 0.9775\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 22s 740us/step - loss: 0.1183 - acc: 0.9762\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 24s 817us/step - loss: 0.0985 - acc: 0.9797\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 22s 732us/step - loss: 0.1219 - acc: 0.9777\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 22s 742us/step - loss: 0.1071 - acc: 0.9809\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 22s 726us/step - loss: 0.1004 - acc: 0.9826\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 22s 737us/step - loss: 0.0963 - acc: 0.9825\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 22s 738us/step - loss: 0.1084 - acc: 0.9826\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 22s 737us/step - loss: 0.1018 - acc: 0.98410s - loss: 0.1009 -\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 23s 753us/step - loss: 0.0999 - acc: 0.9850\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 22s 744us/step - loss: 0.0934 - acc: 0.9860\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 22s 748us/step - loss: 0.0912 - acc: 0.9871\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 22s 749us/step - loss: 0.0893 - acc: 0.9871\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 23s 762us/step - loss: 0.0991 - acc: 0.9870\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 23s 754us/step - loss: 0.0964 - acc: 0.9878\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 22s 749us/step - loss: 0.0980 - acc: 0.9871\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 22s 743us/step - loss: 0.1157 - acc: 0.9874\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 22s 730us/step - loss: 0.1360 - acc: 0.9856\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 22s 735us/step - loss: 0.0918 - acc: 0.9887\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 22s 727us/step - loss: 0.0835 - acc: 0.9897\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 22s 737us/step - loss: 0.1080 - acc: 0.9884\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 22s 725us/step - loss: 0.1198 - acc: 0.9877\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 22s 732us/step - loss: 0.1054 - acc: 0.9891\n",
      "30000/30000 [==============================] - 8s 269us/step\n",
      "30000/30000 [==============================] - 6s 199us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=30, num_neurons=1024, optimizer_algo=adam, total=11.4min\n",
      "[CV] activation=relu, dropout=0.0, epochs=30, num_neurons=1024, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 27s 889us/step - loss: 0.3051 - acc: 0.9123\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 22s 731us/step - loss: 0.1763 - acc: 0.9509\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 22s 724us/step - loss: 0.1573 - acc: 0.9591\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 22s 735us/step - loss: 0.1380 - acc: 0.9650\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 22s 723us/step - loss: 0.1227 - acc: 0.9685\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 23s 751us/step - loss: 0.1166 - acc: 0.9711\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 22s 739us/step - loss: 0.1089 - acc: 0.97480s - loss: 0.1079 - ac\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 22s 731us/step - loss: 0.0985 - acc: 0.9778\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 22s 725us/step - loss: 0.1041 - acc: 0.9791\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 22s 732us/step - loss: 0.1169 - acc: 0.9786\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 22s 726us/step - loss: 0.0953 - acc: 0.9816\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 22s 734us/step - loss: 0.1016 - acc: 0.9812\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 22s 738us/step - loss: 0.0869 - acc: 0.9838\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 22s 727us/step - loss: 0.1041 - acc: 0.9820\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 22s 733us/step - loss: 0.0842 - acc: 0.9853\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 22s 722us/step - loss: 0.0800 - acc: 0.9872\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 22s 729us/step - loss: 0.1041 - acc: 0.9851\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 22s 723us/step - loss: 0.0928 - acc: 0.9859\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 22s 734us/step - loss: 0.1171 - acc: 0.9847\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 22s 724us/step - loss: 0.0895 - acc: 0.9871\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 22s 732us/step - loss: 0.0898 - acc: 0.9884\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 22s 737us/step - loss: 0.0869 - acc: 0.9888\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 22s 728us/step - loss: 0.1035 - acc: 0.9871\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 22s 745us/step - loss: 0.1114 - acc: 0.98750s - loss: 0.1124\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 22s 723us/step - loss: 0.1186 - acc: 0.98741s - lo\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 22s 733us/step - loss: 0.1010 - acc: 0.98920s - loss: 0.1000 - \n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 22s 726us/step - loss: 0.0994 - acc: 0.9888\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 22s 738us/step - loss: 0.1251 - acc: 0.98760s - loss: 0.1231 -\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 22s 732us/step - loss: 0.1158 - acc: 0.9888\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 22s 737us/step - loss: 0.1010 - acc: 0.9902\n",
      "30000/30000 [==============================] - 8s 268us/step\n",
      "30000/30000 [==============================] - 6s 199us/step\n",
      "[CV]  activation=relu, dropout=0.0, epochs=30, num_neurons=1024, optimizer_algo=adam, total=11.2min\n",
      "[CV] activation=relu, dropout=0.3, epochs=10, num_neurons=256, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 12s 414us/step - loss: 0.9175 - acc: 0.7549\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 7s 242us/step - loss: 0.4602 - acc: 0.8724\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 7s 232us/step - loss: 0.3844 - acc: 0.8929\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 7s 245us/step - loss: 0.3412 - acc: 0.9025\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 7s 234us/step - loss: 0.3139 - acc: 0.9117\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 8s 271us/step - loss: 0.2901 - acc: 0.9173\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 8s 272us/step - loss: 0.2762 - acc: 0.9219\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 8s 252us/step - loss: 0.2575 - acc: 0.9262\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 8s 250us/step - loss: 0.2452 - acc: 0.9317\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 7s 249us/step - loss: 0.2330 - acc: 0.9354\n",
      "30000/30000 [==============================] - 7s 231us/step\n",
      "30000/30000 [==============================] - 5s 173us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=10, num_neurons=256, optimizer_algo=sgd, total= 1.5min\n",
      "[CV] activation=relu, dropout=0.3, epochs=10, num_neurons=256, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 13s 432us/step - loss: 0.9122 - acc: 0.7581\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 8s 278us/step - loss: 0.4694 - acc: 0.8652\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 8s 276us/step - loss: 0.3889 - acc: 0.8907\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 8s 283us/step - loss: 0.3521 - acc: 0.8991\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 8s 259us/step - loss: 0.3204 - acc: 0.9071\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 8s 262us/step - loss: 0.2961 - acc: 0.9152\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 8s 259us/step - loss: 0.2764 - acc: 0.9201\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 8s 260us/step - loss: 0.2621 - acc: 0.9246\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 8s 269us/step - loss: 0.2474 - acc: 0.9285\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 8s 260us/step - loss: 0.2344 - acc: 0.9333\n",
      "30000/30000 [==============================] - 7s 237us/step\n",
      "30000/30000 [==============================] - 5s 165us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=10, num_neurons=256, optimizer_algo=sgd, total= 1.6min\n",
      "[CV] activation=relu, dropout=0.3, epochs=10, num_neurons=256, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 15s 506us/step - loss: 0.4050 - acc: 0.8795\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 11s 351us/step - loss: 0.2989 - acc: 0.9149\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 10s 344us/step - loss: 0.2729 - acc: 0.9256\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 10s 338us/step - loss: 0.2690 - acc: 0.9292\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 11s 352us/step - loss: 0.2558 - acc: 0.9351\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 10s 340us/step - loss: 0.2539 - acc: 0.9359\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 10s 342us/step - loss: 0.2479 - acc: 0.9384\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 10s 340us/step - loss: 0.2356 - acc: 0.9425\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 11s 352us/step - loss: 0.2217 - acc: 0.9478\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 10s 347us/step - loss: 0.2224 - acc: 0.9479\n",
      "30000/30000 [==============================] - 7s 234us/step\n",
      "30000/30000 [==============================] - 5s 169us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=10, num_neurons=256, optimizer_algo=adam, total= 1.9min\n",
      "[CV] activation=relu, dropout=0.3, epochs=10, num_neurons=256, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 15s 511us/step - loss: 0.3792 - acc: 0.88571s - loss: 0\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 10s 344us/step - loss: 0.3018 - acc: 0.9170\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 10s 344us/step - loss: 0.2738 - acc: 0.9275\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 10s 341us/step - loss: 0.2752 - acc: 0.9298\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 10s 349us/step - loss: 0.2515 - acc: 0.9347\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 10s 340us/step - loss: 0.2451 - acc: 0.9390\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 10s 344us/step - loss: 0.2409 - acc: 0.9393\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 10s 339us/step - loss: 0.2444 - acc: 0.9427\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 11s 351us/step - loss: 0.2314 - acc: 0.9438\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 10s 339us/step - loss: 0.2154 - acc: 0.9480\n",
      "30000/30000 [==============================] - 7s 241us/step\n",
      "30000/30000 [==============================] - 5s 173us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=10, num_neurons=256, optimizer_algo=adam, total= 1.9min\n",
      "[CV] activation=relu, dropout=0.3, epochs=10, num_neurons=512, optimizer_algo=sgd \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 15s 507us/step - loss: 0.8706 - acc: 0.7734\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 10s 336us/step - loss: 0.4322 - acc: 0.8805\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 10s 335us/step - loss: 0.3648 - acc: 0.8972\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 10s 337us/step - loss: 0.3263 - acc: 0.9079\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 10s 345us/step - loss: 0.3000 - acc: 0.9158\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 10s 336us/step - loss: 0.2770 - acc: 0.9223\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 10s 340us/step - loss: 0.2599 - acc: 0.9276\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 10s 335us/step - loss: 0.2449 - acc: 0.9340\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 10s 345us/step - loss: 0.2309 - acc: 0.9354\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 11s 354us/step - loss: 0.2213 - acc: 0.9383\n",
      "30000/30000 [==============================] - 8s 250us/step\n",
      "30000/30000 [==============================] - 5s 179us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=10, num_neurons=512, optimizer_algo=sgd, total= 1.9min\n",
      "[CV] activation=relu, dropout=0.3, epochs=10, num_neurons=512, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 15s 506us/step - loss: 0.8603 - acc: 0.7773\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 10s 345us/step - loss: 0.4402 - acc: 0.8753\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 10s 345us/step - loss: 0.3718 - acc: 0.8932\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 10s 345us/step - loss: 0.3343 - acc: 0.9046\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 11s 356us/step - loss: 0.3053 - acc: 0.9124\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 10s 343us/step - loss: 0.2841 - acc: 0.9190\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 10s 345us/step - loss: 0.2658 - acc: 0.9244\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 10s 343us/step - loss: 0.2477 - acc: 0.9296\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 11s 356us/step - loss: 0.2361 - acc: 0.9322\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 10s 335us/step - loss: 0.2233 - acc: 0.9366\n",
      "30000/30000 [==============================] - 7s 233us/step\n",
      "30000/30000 [==============================] - 5s 166us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=10, num_neurons=512, optimizer_algo=sgd, total= 1.9min\n",
      "[CV] activation=relu, dropout=0.3, epochs=10, num_neurons=512, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 19s 628us/step - loss: 0.4002 - acc: 0.8870\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 16s 530us/step - loss: 0.3122 - acc: 0.91712s - loss - ETA: 0s - loss: 0.3117 -\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 15s 510us/step - loss: 0.2797 - acc: 0.92839s - loss: 0. - ETA: - ETA: 6s - lo - ETA: 0s - loss: 0.2797 - acc: 0.9\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 15s 511us/step - loss: 0.2649 - acc: 0.9341\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 15s 503us/step - loss: 0.2720 - acc: 0.9382\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 16s 518us/step - loss: 0.2544 - acc: 0.94160s - loss: 0.2527 - a\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 15s 503us/step - loss: 0.2640 - acc: 0.9404\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 15s 507us/step - loss: 0.2392 - acc: 0.9461\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 15s 513us/step - loss: 0.2392 - acc: 0.9467\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 15s 505us/step - loss: 0.2303 - acc: 0.9505\n",
      "30000/30000 [==============================] - 7s 250us/step\n",
      "30000/30000 [==============================] - 6s 193us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=10, num_neurons=512, optimizer_algo=adam, total= 2.8min\n",
      "[CV] activation=relu, dropout=0.3, epochs=10, num_neurons=512, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 20s 668us/step - loss: 0.3991 - acc: 0.8865\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 15s 508us/step - loss: 0.3121 - acc: 0.9170\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 15s 516us/step - loss: 0.2765 - acc: 0.9277\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 15s 510us/step - loss: 0.2694 - acc: 0.9341\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 15s 516us/step - loss: 0.2676 - acc: 0.9359\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 15s 513us/step - loss: 0.2434 - acc: 0.94063s - los\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 16s 538us/step - loss: 0.2454 - acc: 0.9422\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 15s 515us/step - loss: 0.2447 - acc: 0.9437\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 15s 511us/step - loss: 0.2371 - acc: 0.94571\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 15s 511us/step - loss: 0.2508 - acc: 0.9465\n",
      "30000/30000 [==============================] - 8s 261us/step\n",
      "30000/30000 [==============================] - 6s 188us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=10, num_neurons=512, optimizer_algo=adam, total= 2.8min\n",
      "[CV] activation=relu, dropout=0.3, epochs=10, num_neurons=784, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 20s 659us/step - loss: 0.8330 - acc: 0.7949\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 16s 535us/step - loss: 0.4188 - acc: 0.8861\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 15s 495us/step - loss: 0.3510 - acc: 0.90391s - loss: 0.3535 - - ETA: 1s - loss: \n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 15s 494us/step - loss: 0.3155 - acc: 0.9115\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 15s 493us/step - loss: 0.2917 - acc: 0.91900s - loss: 0.2917 - acc: 0.919\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 15s 486us/step - loss: 0.2704 - acc: 0.9246\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 15s 500us/step - loss: 0.2533 - acc: 0.92990s - loss: 0.2538 - \n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 15s 497us/step - loss: 0.2377 - acc: 0.9348\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 15s 496us/step - loss: 0.2261 - acc: 0.9379\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 15s 508us/step - loss: 0.2123 - acc: 0.94271s - \n",
      "30000/30000 [==============================] - 9s 287us/step\n",
      "30000/30000 [==============================] - 7s 219us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=10, num_neurons=784, optimizer_algo=sgd, total= 2.7min\n",
      "[CV] activation=relu, dropout=0.3, epochs=10, num_neurons=784, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 20s 671us/step - loss: 0.8402 - acc: 0.7857\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 15s 502us/step - loss: 0.4216 - acc: 0.8832\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 15s 511us/step - loss: 0.3552 - acc: 0.8978\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 15s 513us/step - loss: 0.3183 - acc: 0.9091\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 15s 496us/step - loss: 0.2902 - acc: 0.9173\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 15s 512us/step - loss: 0.2711 - acc: 0.92240s - loss: 0.2712 - acc: 0.922\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 15s 496us/step - loss: 0.2523 - acc: 0.9277\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 13s 449us/step - loss: 0.2356 - acc: 0.9338\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 13s 450us/step - loss: 0.2237 - acc: 0.9359\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 13s 442us/step - loss: 0.2132 - acc: 0.9400\n",
      "30000/30000 [==============================] - 8s 264us/step\n",
      "30000/30000 [==============================] - 6s 201us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=10, num_neurons=784, optimizer_algo=sgd, total= 2.7min\n",
      "[CV] activation=relu, dropout=0.3, epochs=10, num_neurons=784, optimizer_algo=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 26s 876us/step - loss: 0.4136 - acc: 0.88272\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 20s 652us/step - loss: 0.3103 - acc: 0.9167\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 20s 664us/step - loss: 0.2897 - acc: 0.9263\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 20s 656us/step - loss: 0.2704 - acc: 0.9324\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 20s 660us/step - loss: 0.2560 - acc: 0.93850s - loss: 0.2559 - acc: 0.938\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 20s 660us/step - loss: 0.2543 - acc: 0.9407\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 20s 659us/step - loss: 0.2481 - acc: 0.9431\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 20s 661us/step - loss: 0.2341 - acc: 0.9455\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 20s 651us/step - loss: 0.2312 - acc: 0.9460\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 20s 672us/step - loss: 0.2332 - acc: 0.9475\n",
      "30000/30000 [==============================] - 8s 267us/step\n",
      "30000/30000 [==============================] - 6s 197us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=10, num_neurons=784, optimizer_algo=adam, total= 3.6min\n",
      "[CV] activation=relu, dropout=0.3, epochs=10, num_neurons=784, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 24s 812us/step - loss: 0.4178 - acc: 0.8805\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 20s 668us/step - loss: 0.3191 - acc: 0.9188\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 20s 657us/step - loss: 0.2819 - acc: 0.9268\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 20s 669us/step - loss: 0.2845 - acc: 0.9311\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 20s 657us/step - loss: 0.2497 - acc: 0.9395\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 20s 660us/step - loss: 0.2620 - acc: 0.9408\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 20s 662us/step - loss: 0.2681 - acc: 0.9414\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 20s 669us/step - loss: 0.2479 - acc: 0.9466\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 20s 657us/step - loss: 0.2486 - acc: 0.9481\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 20s 663us/step - loss: 0.2310 - acc: 0.9507\n",
      "30000/30000 [==============================] - 8s 268us/step\n",
      "30000/30000 [==============================] - 6s 200us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=10, num_neurons=784, optimizer_algo=adam, total= 3.5min\n",
      "[CV] activation=relu, dropout=0.3, epochs=10, num_neurons=1024, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 20s 651us/step - loss: 0.8098 - acc: 0.8012\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 14s 483us/step - loss: 0.4116 - acc: 0.8878\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 15s 488us/step - loss: 0.3454 - acc: 0.9056\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 15s 497us/step - loss: 0.3127 - acc: 0.9128\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 15s 484us/step - loss: 0.2871 - acc: 0.92060s - loss: 0.2867 - acc: 0.921 - ETA: 0s - loss: 0.2868 - acc: \n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 15s 494us/step - loss: 0.2687 - acc: 0.9263\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 15s 486us/step - loss: 0.2503 - acc: 0.9323\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 15s 487us/step - loss: 0.2375 - acc: 0.9355\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 15s 494us/step - loss: 0.2237 - acc: 0.9392\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 14s 483us/step - loss: 0.2134 - acc: 0.9415\n",
      "30000/30000 [==============================] - 8s 275us/step\n",
      "30000/30000 [==============================] - 6s 210us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=10, num_neurons=1024, optimizer_algo=sgd, total= 2.7min\n",
      "[CV] activation=relu, dropout=0.3, epochs=10, num_neurons=1024, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 20s 658us/step - loss: 0.8093 - acc: 0.8000\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 15s 493us/step - loss: 0.4136 - acc: 0.8862\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 15s 506us/step - loss: 0.3511 - acc: 0.9003\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 15s 501us/step - loss: 0.3121 - acc: 0.9112\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 15s 500us/step - loss: 0.2861 - acc: 0.9205\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 15s 508us/step - loss: 0.2663 - acc: 0.9249\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 15s 499us/step - loss: 0.2494 - acc: 0.92880s - loss: 0.2498 - acc:\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 15s 513us/step - loss: 0.2346 - acc: 0.9337\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 15s 495us/step - loss: 0.2229 - acc: 0.9369\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 15s 491us/step - loss: 0.2099 - acc: 0.9416\n",
      "30000/30000 [==============================] - 9s 291us/step\n",
      "30000/30000 [==============================] - 7s 219us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=10, num_neurons=1024, optimizer_algo=sgd, total= 2.7min\n",
      "[CV] activation=relu, dropout=0.3, epochs=10, num_neurons=1024, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 29s 980us/step - loss: 0.4171 - acc: 0.8836\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 24s 811us/step - loss: 0.3181 - acc: 0.9159\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 25s 830us/step - loss: 0.2828 - acc: 0.92751s - loss: 0.\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 25s 828us/step - loss: 0.2592 - acc: 0.9362\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 25s 836us/step - loss: 0.2642 - acc: 0.9385\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 25s 824us/step - loss: 0.2551 - acc: 0.9385\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 24s 807us/step - loss: 0.2484 - acc: 0.94321s - loss: 0. - ETA: 0s - loss: 0.24\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 24s 813us/step - loss: 0.2363 - acc: 0.9480\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 24s 804us/step - loss: 0.2515 - acc: 0.9480\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 25s 820us/step - loss: 0.2391 - acc: 0.9494\n",
      "30000/30000 [==============================] - 9s 285us/step\n",
      "30000/30000 [==============================] - 7s 218us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=10, num_neurons=1024, optimizer_algo=adam, total= 4.3min\n",
      "[CV] activation=relu, dropout=0.3, epochs=10, num_neurons=1024, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 0.4275 - acc: 0.8824: 3s  - ETA: 0s - loss: 0.4304\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 26s 860us/step - loss: 0.2980 - acc: 0.91871\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 0.2880 - acc: 0.9282 - 24s 810us/step - loss: 0.2879 - acc: 0.9282\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 25s 824us/step - loss: 0.2777 - acc: 0.93490s - loss: 0.2775 - acc: 0.93\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 25s 817us/step - loss: 0.2537 - acc: 0.94070s - loss: 0.2537 - acc: 0.94\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 24s 810us/step - loss: 0.2498 - acc: 0.9442\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 29s 951us/step - loss: 0.2753 - acc: 0.94175s - loss:\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 29s 961us/step - loss: 0.2428 - acc: 0.94897s  - ETA: 6s - los\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 29s 953us/step - loss: 0.2457 - acc: 0.9512\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 28s 950us/step - loss: 0.2560 - acc: 0.94956s - - ETA: 4s - loss - ETA: 3s - lo - ETA: 1s - loss: 0.2538 - ac - ETA: 1s - los\n",
      "30000/30000 [==============================] - 9s 315us/step\n",
      "30000/30000 [==============================] - 7s 244us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=10, num_neurons=1024, optimizer_algo=adam, total= 4.6min\n",
      "[CV] activation=relu, dropout=0.3, epochs=20, num_neurons=256, optimizer_algo=sgd \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 13s 429us/step - loss: 0.8922 - acc: 0.7672\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 8s 262us/step - loss: 0.4622 - acc: 0.8702\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 8s 262us/step - loss: 0.3883 - acc: 0.8907\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 8s 262us/step - loss: 0.3467 - acc: 0.9006\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 8s 270us/step - loss: 0.3177 - acc: 0.9101\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 8s 265us/step - loss: 0.2962 - acc: 0.9162\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 8s 266us/step - loss: 0.2801 - acc: 0.9218\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 8s 262us/step - loss: 0.2633 - acc: 0.9259\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 8s 262us/step - loss: 0.2484 - acc: 0.9303\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 8s 270us/step - loss: 0.2379 - acc: 0.9347\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 8s 262us/step - loss: 0.2287 - acc: 0.9367\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 8s 265us/step - loss: 0.2190 - acc: 0.9391\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 8s 265us/step - loss: 0.2116 - acc: 0.9399\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 8s 264us/step - loss: 0.2043 - acc: 0.9447\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 8s 270us/step - loss: 0.1961 - acc: 0.9444\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 8s 263us/step - loss: 0.1889 - acc: 0.9465\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 8s 270us/step - loss: 0.1851 - acc: 0.9496\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 8s 274us/step - loss: 0.1769 - acc: 0.9503\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 8s 262us/step - loss: 0.1707 - acc: 0.9524\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 8s 271us/step - loss: 0.1681 - acc: 0.9518\n",
      "30000/30000 [==============================] - 8s 259us/step\n",
      "30000/30000 [==============================] - 5s 178us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=20, num_neurons=256, optimizer_algo=sgd, total= 2.9min\n",
      "[CV] activation=relu, dropout=0.3, epochs=20, num_neurons=256, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 13s 424us/step - loss: 0.9031 - acc: 0.7598\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 8s 267us/step - loss: 0.4689 - acc: 0.8655\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 8s 276us/step - loss: 0.3937 - acc: 0.8873\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 8s 268us/step - loss: 0.3524 - acc: 0.8973\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 8s 268us/step - loss: 0.3229 - acc: 0.9061\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 8s 267us/step - loss: 0.3005 - acc: 0.9151\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 8s 268us/step - loss: 0.2816 - acc: 0.9186\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 8s 276us/step - loss: 0.2657 - acc: 0.9220\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 8s 273us/step - loss: 0.2513 - acc: 0.9273\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 8s 270us/step - loss: 0.2383 - acc: 0.9324\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 8s 266us/step - loss: 0.2292 - acc: 0.9347\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 8s 272us/step - loss: 0.2199 - acc: 0.9382\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 8s 274us/step - loss: 0.2100 - acc: 0.9407\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 8s 268us/step - loss: 0.2020 - acc: 0.9410\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 8s 268us/step - loss: 0.1959 - acc: 0.9442\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 8s 267us/step - loss: 0.1899 - acc: 0.9460\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 8s 276us/step - loss: 0.1819 - acc: 0.9476\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 8s 270us/step - loss: 0.1777 - acc: 0.9481\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 8s 270us/step - loss: 0.1714 - acc: 0.9520\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 8s 270us/step - loss: 0.1655 - acc: 0.9524\n",
      "30000/30000 [==============================] - 7s 248us/step\n",
      "30000/30000 [==============================] - 6s 186us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=20, num_neurons=256, optimizer_algo=sgd, total= 2.9min\n",
      "[CV] activation=relu, dropout=0.3, epochs=20, num_neurons=256, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 17s 555us/step - loss: 0.3967 - acc: 0.8823\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 11s 357us/step - loss: 0.3018 - acc: 0.9139\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 10s 335us/step - loss: 0.2698 - acc: 0.9245\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 10s 337us/step - loss: 0.2593 - acc: 0.9297\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 10s 335us/step - loss: 0.2497 - acc: 0.9330\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 10s 345us/step - loss: 0.2399 - acc: 0.9372\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 10s 335us/step - loss: 0.2383 - acc: 0.9381\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 10s 338us/step - loss: 0.2513 - acc: 0.9406\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 10s 334us/step - loss: 0.2201 - acc: 0.9454\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 10s 345us/step - loss: 0.2299 - acc: 0.9456\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 10s 330us/step - loss: 0.2300 - acc: 0.9474\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 9s 316us/step - loss: 0.2189 - acc: 0.9492\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 9s 312us/step - loss: 0.2183 - acc: 0.9500\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 10s 321us/step - loss: 0.2261 - acc: 0.9504\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 9s 310us/step - loss: 0.1978 - acc: 0.9557\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 9s 317us/step - loss: 0.2116 - acc: 0.9553\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 9s 308us/step - loss: 0.2121 - acc: 0.9532\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 10s 323us/step - loss: 0.2085 - acc: 0.9572\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 10s 344us/step - loss: 0.2049 - acc: 0.9575\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 10s 348us/step - loss: 0.1969 - acc: 0.9577\n",
      "30000/30000 [==============================] - 8s 269us/step\n",
      "30000/30000 [==============================] - 6s 189us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=20, num_neurons=256, optimizer_algo=adam, total= 3.9min\n",
      "[CV] activation=relu, dropout=0.3, epochs=20, num_neurons=256, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 16s 532us/step - loss: 0.3930 - acc: 0.8840\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 11s 367us/step - loss: 0.2953 - acc: 0.9168\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 11s 360us/step - loss: 0.2737 - acc: 0.9260\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 11s 376us/step - loss: 0.2595 - acc: 0.9321\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 11s 370us/step - loss: 0.2474 - acc: 0.93491s - l\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 11s 361us/step - loss: 0.2241 - acc: 0.9434\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 11s 361us/step - loss: 0.2408 - acc: 0.9420\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 11s 364us/step - loss: 0.2335 - acc: 0.9441\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 11s 354us/step - loss: 0.2269 - acc: 0.9457\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 11s 353us/step - loss: 0.2305 - acc: 0.9474\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 11s 359us/step - loss: 0.2300 - acc: 0.9479\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 10s 337us/step - loss: 0.2240 - acc: 0.9496\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 10s 338us/step - loss: 0.2164 - acc: 0.9517\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 10s 345us/step - loss: 0.2150 - acc: 0.9517\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 10s 348us/step - loss: 0.2094 - acc: 0.9548\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 10s 337us/step - loss: 0.2226 - acc: 0.9542\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 10s 337us/step - loss: 0.2245 - acc: 0.9534\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 10s 338us/step - loss: 0.2055 - acc: 0.9570\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 10s 347us/step - loss: 0.2035 - acc: 0.9564\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 10s 333us/step - loss: 0.2043 - acc: 0.9561\n",
      "30000/30000 [==============================] - 8s 253us/step\n",
      "30000/30000 [==============================] - 5s 181us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=20, num_neurons=256, optimizer_algo=adam, total= 3.7min\n",
      "[CV] activation=relu, dropout=0.3, epochs=20, num_neurons=512, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 16s 537us/step - loss: 0.8475 - acc: 0.7843\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 10s 346us/step - loss: 0.4390 - acc: 0.8792\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 10s 347us/step - loss: 0.3674 - acc: 0.8973\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 11s 374us/step - loss: 0.3307 - acc: 0.9071\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 11s 362us/step - loss: 0.3027 - acc: 0.9162\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 11s 353us/step - loss: 0.2836 - acc: 0.9215\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 11s 372us/step - loss: 0.2653 - acc: 0.9253\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 11s 355us/step - loss: 0.2505 - acc: 0.9302\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 11s 366us/step - loss: 0.2377 - acc: 0.9332\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 11s 359us/step - loss: 0.2240 - acc: 0.9385\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 11s 358us/step - loss: 0.2122 - acc: 0.94271s - lo\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 11s 375us/step - loss: 0.2031 - acc: 0.94440s - loss: 0.20\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 11s 362us/step - loss: 0.1971 - acc: 0.9450\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 11s 355us/step - loss: 0.1876 - acc: 0.9484\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 11s 356us/step - loss: 0.1799 - acc: 0.9492\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 11s 365us/step - loss: 0.1741 - acc: 0.9514\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 11s 356us/step - loss: 0.1691 - acc: 0.9537\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 11s 358us/step - loss: 0.1617 - acc: 0.9552\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 11s 358us/step - loss: 0.1573 - acc: 0.9561\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 11s 364us/step - loss: 0.1528 - acc: 0.9571\n",
      "30000/30000 [==============================] - 9s 285us/step\n",
      "30000/30000 [==============================] - 6s 200us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=20, num_neurons=512, optimizer_algo=sgd, total= 3.8min\n",
      "[CV] activation=relu, dropout=0.3, epochs=20, num_neurons=512, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 16s 538us/step - loss: 0.8456 - acc: 0.7817\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 11s 368us/step - loss: 0.4404 - acc: 0.8775\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 11s 366us/step - loss: 0.3714 - acc: 0.8942\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 11s 363us/step - loss: 0.3320 - acc: 0.9059\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 12s 397us/step - loss: 0.3060 - acc: 0.9136\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 11s 359us/step - loss: 0.2817 - acc: 0.9200\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 11s 375us/step - loss: 0.2641 - acc: 0.9248\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 11s 381us/step - loss: 0.2495 - acc: 0.9287\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 11s 382us/step - loss: 0.2352 - acc: 0.9331\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 11s 374us/step - loss: 0.2222 - acc: 0.93471s - loss\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 11s 375us/step - loss: 0.2123 - acc: 0.9407\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 11s 383us/step - loss: 0.2031 - acc: 0.94301s - los\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 11s 383us/step - loss: 0.1930 - acc: 0.9459\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 11s 371us/step - loss: 0.1840 - acc: 0.94762s - loss: 0.1 - ETA: 1s -\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 11s 376us/step - loss: 0.1768 - acc: 0.9499\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 12s 385us/step - loss: 0.1703 - acc: 0.9524\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 11s 376us/step - loss: 0.1635 - acc: 0.95421s - loss: 0.1649 - acc: - ETA: 1s - loss: 0\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 11s 380us/step - loss: 0.1591 - acc: 0.9561\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 11s 375us/step - loss: 0.1531 - acc: 0.9563\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 11s 365us/step - loss: 0.1482 - acc: 0.9592\n",
      "30000/30000 [==============================] - 9s 287us/step\n",
      "30000/30000 [==============================] - 6s 202us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=20, num_neurons=512, optimizer_algo=sgd, total= 4.0min\n",
      "[CV] activation=relu, dropout=0.3, epochs=20, num_neurons=512, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 21s 709us/step - loss: 0.4051 - acc: 0.8845\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 16s 524us/step - loss: 0.2994 - acc: 0.9201\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 16s 535us/step - loss: 0.2914 - acc: 0.9254\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 16s 529us/step - loss: 0.2871 - acc: 0.9297\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 16s 525us/step - loss: 0.2568 - acc: 0.93750s - loss: 0.2\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 16s 539us/step - loss: 0.2490 - acc: 0.9398\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 16s 520us/step - loss: 0.2434 - acc: 0.9431\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 16s 531us/step - loss: 0.2353 - acc: 0.9446\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 16s 526us/step - loss: 0.2143 - acc: 0.95030s - loss: 0.2104 - ac\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 16s 524us/step - loss: 0.2367 - acc: 0.9489\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 16s 538us/step - loss: 0.2295 - acc: 0.9492\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 15s 494us/step - loss: 0.2283 - acc: 0.9514\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 14s 464us/step - loss: 0.2445 - acc: 0.95030s - loss: 0.2389 - acc: 0.950 - ETA: 0s - loss: 0.239\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 14s 463us/step - loss: 0.2306 - acc: 0.9519\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 14s 455us/step - loss: 0.2074 - acc: 0.9584\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 15s 484us/step - loss: 0.2204 - acc: 0.9561\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 15s 489us/step - loss: 0.1979 - acc: 0.9581\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 14s 464us/step - loss: 0.2146 - acc: 0.9579\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 14s 472us/step - loss: 0.2228 - acc: 0.95772s - los - ETA: 1s - loss: 0.2262 - ETA: 0s - loss: 0.2257  - ETA: 0s - loss: 0.2228 - acc: 0.\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 14s 466us/step - loss: 0.2159 - acc: 0.95840s - loss: 0.2148\n",
      "30000/30000 [==============================] - 8s 259us/step\n",
      "30000/30000 [==============================] - 5s 178us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=20, num_neurons=512, optimizer_algo=adam, total= 5.3min\n",
      "[CV] activation=relu, dropout=0.3, epochs=20, num_neurons=512, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 19s 630us/step - loss: 0.4095 - acc: 0.8819\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 13s 447us/step - loss: 0.3103 - acc: 0.91564s - loss: 0.3128 - ETA: 3s - los - E\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 14s 451us/step - loss: 0.2713 - acc: 0.92891s - lo\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 14s 454us/step - loss: 0.2654 - acc: 0.9339\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 14s 453us/step - loss: 0.2499 - acc: 0.9367\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 14s 455us/step - loss: 0.2585 - acc: 0.9394\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 14s 459us/step - loss: 0.2485 - acc: 0.9411\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 14s 452us/step - loss: 0.2413 - acc: 0.9465\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 14s 452us/step - loss: 0.2386 - acc: 0.9461\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 14s 459us/step - loss: 0.2539 - acc: 0.9476\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 15s 495us/step - loss: 0.2307 - acc: 0.9503\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 17s 552us/step - loss: 0.2171 - acc: 0.9527\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 16s 533us/step - loss: 0.2232 - acc: 0.95311\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 0.2249 - acc: 0.9543- ETA: 1s - loss: 0 - 17s 558us/step - loss: 0.2246 - acc: 0.9543\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 16s 536us/step - loss: 0.2176 - acc: 0.9551\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 16s 524us/step - loss: 0.2184 - acc: 0.9560\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 16s 533us/step - loss: 0.2121 - acc: 0.9573\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 16s 522us/step - loss: 0.2250 - acc: 0.9585\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 16s 520us/step - loss: 0.2183 - acc: 0.9582\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 16s 549us/step - loss: 0.2177 - acc: 0.95966s - lo - ETA: 0s - loss: 0.2179 - acc: \n",
      "30000/30000 [==============================] - 8s 280us/step\n",
      "30000/30000 [==============================] - 6s 205us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=20, num_neurons=512, optimizer_algo=adam, total= 5.2min\n",
      "[CV] activation=relu, dropout=0.3, epochs=20, num_neurons=784, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 21s 711us/step - loss: 0.8310 - acc: 0.7931\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 15s 512us/step - loss: 0.4226 - acc: 0.88312s - loss: - ETA: 1s - \n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 16s 522us/step - loss: 0.3552 - acc: 0.9006\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 16s 521us/step - loss: 0.3192 - acc: 0.9108\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 15s 514us/step - loss: 0.2928 - acc: 0.91920s - loss: 0.2929 - acc: 0.919\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 16s 539us/step - loss: 0.2712 - acc: 0.9245\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 16s 522us/step - loss: 0.2529 - acc: 0.9299\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 15s 515us/step - loss: 0.2399 - acc: 0.9348\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 16s 521us/step - loss: 0.2255 - acc: 0.9379\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 15s 513us/step - loss: 0.2147 - acc: 0.9403\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 16s 524us/step - loss: 0.2046 - acc: 0.94333s - loss: - ET\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 16s 517us/step - loss: 0.1948 - acc: 0.9463\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 16s 525us/step - loss: 0.1860 - acc: 0.9488\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 16s 537us/step - loss: 0.1778 - acc: 0.9501\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 16s 519us/step - loss: 0.1711 - acc: 0.9531\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 16s 523us/step - loss: 0.1658 - acc: 0.95450s - loss: 0.1658 -\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 15s 512us/step - loss: 0.1594 - acc: 0.9560\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 16s 536us/step - loss: 0.1539 - acc: 0.9567\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 16s 525us/step - loss: 0.1470 - acc: 0.9597\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 15s 511us/step - loss: 0.1442 - acc: 0.9610\n",
      "30000/30000 [==============================] - 10s 329us/step\n",
      "30000/30000 [==============================] - 8s 251us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=20, num_neurons=784, optimizer_algo=sgd, total= 5.5min\n",
      "[CV] activation=relu, dropout=0.3, epochs=20, num_neurons=784, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 21s 694us/step - loss: 0.8324 - acc: 0.79302\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 16s 521us/step - loss: 0.4224 - acc: 0.8844\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 15s 506us/step - loss: 0.3553 - acc: 0.89840s - loss: 0.3553 - acc: 0.8\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 15s 503us/step - loss: 0.3197 - acc: 0.9096\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 16s 543us/step - loss: 0.2915 - acc: 0.9161\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 15s 511us/step - loss: 0.2691 - acc: 0.9228\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 16s 519us/step - loss: 0.2519 - acc: 0.9272\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 16s 519us/step - loss: 0.2404 - acc: 0.9323\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 15s 511us/step - loss: 0.2233 - acc: 0.9364\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 16s 519us/step - loss: 0.2116 - acc: 0.93872s - loss: 0.2107 - - ETA:\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 15s 507us/step - loss: 0.2019 - acc: 0.94381s - loss: 0.2\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 15s 500us/step - loss: 0.1922 - acc: 0.9445\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 15s 511us/step - loss: 0.1822 - acc: 0.9479\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 16s 517us/step - loss: 0.1753 - acc: 0.9510\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 15s 512us/step - loss: 0.1681 - acc: 0.9527\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 15s 504us/step - loss: 0.1622 - acc: 0.9548\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 15s 507us/step - loss: 0.1573 - acc: 0.95591\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 16s 518us/step - loss: 0.1507 - acc: 0.9582\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 15s 514us/step - loss: 0.1451 - acc: 0.9601\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 15s 506us/step - loss: 0.1410 - acc: 0.9602\n",
      "30000/30000 [==============================] - 9s 315us/step\n",
      "30000/30000 [==============================] - 7s 237us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=20, num_neurons=784, optimizer_algo=sgd, total= 5.4min\n",
      "[CV] activation=relu, dropout=0.3, epochs=20, num_neurons=784, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 28s 931us/step - loss: 0.4106 - acc: 0.8841\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 23s 760us/step - loss: 0.3213 - acc: 0.9188\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 23s 767us/step - loss: 0.2919 - acc: 0.9275\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 22s 740us/step - loss: 0.2671 - acc: 0.93361s - loss: 0.2696 - a - ETA: 1s - loss: 0.\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 24s 784us/step - loss: 0.2734 - acc: 0.9363\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 23s 767us/step - loss: 0.2557 - acc: 0.9414\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 23s 768us/step - loss: 0.2616 - acc: 0.9427\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 23s 765us/step - loss: 0.2530 - acc: 0.9457\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 23s 755us/step - loss: 0.2471 - acc: 0.94780s - loss: 0.2453 - acc: \n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 23s 761us/step - loss: 0.2431 - acc: 0.9500\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 22s 748us/step - loss: 0.2320 - acc: 0.9508\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 23s 755us/step - loss: 0.2442 - acc: 0.9519\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 23s 756us/step - loss: 0.2366 - acc: 0.9541\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 23s 757us/step - loss: 0.2287 - acc: 0.9556\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 23s 753us/step - loss: 0.2212 - acc: 0.9585\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 22s 747us/step - loss: 0.2302 - acc: 0.9561ETA: 1s - loss: 0.2325 - acc: 0 - ETA: 1s - l\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 23s 760us/step - loss: 0.2430 - acc: 0.9589\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 23s 751us/step - loss: 0.2556 - acc: 0.95720s - loss: 0.2549 - acc: 0\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 22s 749us/step - loss: 0.2401 - acc: 0.9586\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 23s 756us/step - loss: 0.2195 - acc: 0.9617\n",
      "30000/30000 [==============================] - 9s 304us/step\n",
      "30000/30000 [==============================] - 6s 209us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=20, num_neurons=784, optimizer_algo=adam, total= 7.8min\n",
      "[CV] activation=relu, dropout=0.3, epochs=20, num_neurons=784, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 25s 839us/step - loss: 0.4053 - acc: 0.8834\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 20s 679us/step - loss: 0.3169 - acc: 0.9181\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 20s 664us/step - loss: 0.2899 - acc: 0.9265\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 20s 672us/step - loss: 0.2681 - acc: 0.9348\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 20s 674us/step - loss: 0.2607 - acc: 0.9388\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 20s 671us/step - loss: 0.2663 - acc: 0.9376\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 20s 663us/step - loss: 0.2531 - acc: 0.9414\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 20s 674us/step - loss: 0.2544 - acc: 0.9440\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 20s 669us/step - loss: 0.2271 - acc: 0.9486\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 21s 686us/step - loss: 0.2276 - acc: 0.9482\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 20s 663us/step - loss: 0.2435 - acc: 0.9495\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 20s 680us/step - loss: 0.2200 - acc: 0.9545\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 22s 750us/step - loss: 0.2450 - acc: 0.9521\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 21s 704us/step - loss: 0.2150 - acc: 0.9556\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 20s 675us/step - loss: 0.2194 - acc: 0.9560\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 20s 665us/step - loss: 0.2375 - acc: 0.9547\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 20s 671us/step - loss: 0.2146 - acc: 0.9570\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 20s 666us/step - loss: 0.2119 - acc: 0.9581\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 20s 673us/step - loss: 0.2180 - acc: 0.9590\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 20s 668us/step - loss: 0.2136 - acc: 0.9593\n",
      "30000/30000 [==============================] - 9s 298us/step\n",
      "30000/30000 [==============================] - 6s 212us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=20, num_neurons=784, optimizer_algo=adam, total= 7.0min\n",
      "[CV] activation=relu, dropout=0.3, epochs=20, num_neurons=1024, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 21s 696us/step - loss: 0.8225 - acc: 0.79850s - loss: 0.8315 - a\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 16s 521us/step - loss: 0.4128 - acc: 0.88891s - los\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 16s 531us/step - loss: 0.3482 - acc: 0.9029\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 16s 524us/step - loss: 0.3125 - acc: 0.91372s - loss: 0.3111 - acc: 0 - ET\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 16s 527us/step - loss: 0.2857 - acc: 0.92060s - loss: 0.2853 - acc: 0.9\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 16s 546us/step - loss: 0.2669 - acc: 0.9270\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 16s 522us/step - loss: 0.2516 - acc: 0.9307\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 16s 530us/step - loss: 0.2365 - acc: 0.9359\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 16s 524us/step - loss: 0.2224 - acc: 0.9397\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 16s 533us/step - loss: 0.2106 - acc: 0.94250s - loss: 0.2096 - \n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 16s 523us/step - loss: 0.1999 - acc: 0.9457\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 16s 519us/step - loss: 0.1911 - acc: 0.9475\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 16s 532us/step - loss: 0.1820 - acc: 0.9513\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 16s 520us/step - loss: 0.1761 - acc: 0.9518\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 16s 530us/step - loss: 0.1689 - acc: 0.9534\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 16s 523us/step - loss: 0.1616 - acc: 0.9556\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 16s 520us/step - loss: 0.1565 - acc: 0.9570\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 16s 529us/step - loss: 0.1511 - acc: 0.9584\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 16s 524us/step - loss: 0.1450 - acc: 0.96120s - loss: 0.1455 - acc: \n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 16s 534us/step - loss: 0.1385 - acc: 0.9634\n",
      "30000/30000 [==============================] - 9s 299us/step\n",
      "30000/30000 [==============================] - 7s 225us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=20, num_neurons=1024, optimizer_algo=sgd, total= 5.5min\n",
      "[CV] activation=relu, dropout=0.3, epochs=20, num_neurons=1024, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 21s 706us/step - loss: 0.8113 - acc: 0.80311s - lo\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 16s 541us/step - loss: 0.4100 - acc: 0.8876\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 16s 533us/step - loss: 0.3478 - acc: 0.90171s - loss\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 16s 539us/step - loss: 0.3101 - acc: 0.9130\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 16s 529us/step - loss: 0.2852 - acc: 0.9198\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 16s 539us/step - loss: 0.2631 - acc: 0.9254\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 16s 540us/step - loss: 0.2457 - acc: 0.9306\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 16s 528us/step - loss: 0.2321 - acc: 0.9330\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 16s 541us/step - loss: 0.2191 - acc: 0.9385\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 16s 524us/step - loss: 0.2074 - acc: 0.9413\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 16s 527us/step - loss: 0.1965 - acc: 0.9451\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 16s 543us/step - loss: 0.1890 - acc: 0.9457\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 16s 527us/step - loss: 0.1796 - acc: 0.94970s - loss: 0.1789 - acc: 0.9\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 16s 538us/step - loss: 0.1708 - acc: 0.9508\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 16s 527us/step - loss: 0.1645 - acc: 0.9546\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 16s 529us/step - loss: 0.1593 - acc: 0.9550\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 17s 561us/step - loss: 0.1535 - acc: 0.9565\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 16s 546us/step - loss: 0.1459 - acc: 0.9592\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 17s 556us/step - loss: 0.1409 - acc: 0.9604\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 17s 551us/step - loss: 0.1364 - acc: 0.9622\n",
      "30000/30000 [==============================] - 9s 298us/step\n",
      "30000/30000 [==============================] - 7s 236us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=20, num_neurons=1024, optimizer_algo=sgd, total= 5.6min\n",
      "[CV] activation=relu, dropout=0.3, epochs=20, num_neurons=1024, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 30s 985us/step - loss: 0.4156 - acc: 0.8853\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 25s 822us/step - loss: 0.3195 - acc: 0.9172\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 25s 817us/step - loss: 0.3009 - acc: 0.9255\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 24s 795us/step - loss: 0.2623 - acc: 0.9368\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 24s 806us/step - loss: 0.2729 - acc: 0.9360\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 0.2649 - acc: 0.940 - 24s 795us/step - loss: 0.2651 - acc: 0.9400\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 24s 795us/step - loss: 0.2541 - acc: 0.9440\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 24s 799us/step - loss: 0.2381 - acc: 0.9483\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 24s 794us/step - loss: 0.2341 - acc: 0.94820s - loss: 0.2349 - acc: 0.\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 24s 802us/step - loss: 0.2441 - acc: 0.9472\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 24s 800us/step - loss: 0.2574 - acc: 0.94681s - loss: \n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 24s 816us/step - loss: 0.2171 - acc: 0.95450s - loss: 0.2\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 24s 809us/step - loss: 0.2393 - acc: 0.9540\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 24s 798us/step - loss: 0.2321 - acc: 0.9544ETA: 0s - loss: 0.2329 - acc\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 24s 815us/step - loss: 0.2315 - acc: 0.9545\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 24s 797us/step - loss: 0.2077 - acc: 0.95900s - loss: 0.2080 - acc: 0.958\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 24s 799us/step - loss: 0.2180 - acc: 0.9598\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 24s 797us/step - loss: 0.2136 - acc: 0.9597\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 24s 794us/step - loss: 0.2257 - acc: 0.9582\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 24s 799us/step - loss: 0.2158 - acc: 0.9600\n",
      "30000/30000 [==============================] - 9s 305us/step\n",
      "30000/30000 [==============================] - 7s 223us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=20, num_neurons=1024, optimizer_algo=adam, total= 8.3min\n",
      "[CV] activation=relu, dropout=0.3, epochs=20, num_neurons=1024, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 0.4081 - acc: 0.8862\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 26s 858us/step - loss: 0.3022 - acc: 0.9193\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 26s 863us/step - loss: 0.2719 - acc: 0.9291\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 26s 860us/step - loss: 0.2695 - acc: 0.9345\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 25s 849us/step - loss: 0.2690 - acc: 0.9374\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 26s 858us/step - loss: 0.2553 - acc: 0.9410\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 25s 843us/step - loss: 0.2314 - acc: 0.9455\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 25s 831us/step - loss: 0.2445 - acc: 0.94550s - loss: 0.2442 - acc: 0.9\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 25s 841us/step - loss: 0.2407 - acc: 0.9498\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 25s 846us/step - loss: 0.2453 - acc: 0.9481\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 25s 835us/step - loss: 0.2496 - acc: 0.9487\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 25s 841us/step - loss: 0.2284 - acc: 0.9541\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 25s 848us/step - loss: 0.2144 - acc: 0.95561s - loss:\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 25s 831us/step - loss: 0.2430 - acc: 0.9536\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 25s 843us/step - loss: 0.2333 - acc: 0.9546\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 25s 835us/step - loss: 0.2215 - acc: 0.9577\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 25s 842us/step - loss: 0.2100 - acc: 0.9580\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 26s 870us/step - loss: 0.2305 - acc: 0.9571\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 26s 859us/step - loss: 0.2121 - acc: 0.9596\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 26s 863us/step - loss: 0.2184 - acc: 0.9593\n",
      "30000/30000 [==============================] - 9s 308us/step\n",
      "30000/30000 [==============================] - 8s 253us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=20, num_neurons=1024, optimizer_algo=adam, total= 8.7min\n",
      "[CV] activation=relu, dropout=0.3, epochs=30, num_neurons=256, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 14s 458us/step - loss: 0.9042 - acc: 0.7568\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 8s 279us/step - loss: 0.4636 - acc: 0.8704\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 8s 279us/step - loss: 0.3879 - acc: 0.8897\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 8s 278us/step - loss: 0.3493 - acc: 0.9009\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 9s 287us/step - loss: 0.3191 - acc: 0.9106\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 8s 278us/step - loss: 0.2990 - acc: 0.9157\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 8s 281us/step - loss: 0.2814 - acc: 0.9218\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 9s 286us/step - loss: 0.2679 - acc: 0.9246\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 8s 283us/step - loss: 0.2537 - acc: 0.9286\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 9s 285us/step - loss: 0.2421 - acc: 0.9323\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 8s 279us/step - loss: 0.2289 - acc: 0.9349\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 8s 278us/step - loss: 0.2220 - acc: 0.9374\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 8s 278us/step - loss: 0.2129 - acc: 0.9408\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 9s 285us/step - loss: 0.2034 - acc: 0.9430\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 8s 280us/step - loss: 0.1972 - acc: 0.9442\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 8s 276us/step - loss: 0.1911 - acc: 0.9461\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 8s 279us/step - loss: 0.1844 - acc: 0.9470\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 8s 283us/step - loss: 0.1777 - acc: 0.9496\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 9s 285us/step - loss: 0.1744 - acc: 0.9516\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 8s 274us/step - loss: 0.1696 - acc: 0.9512\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 8s 272us/step - loss: 0.1622 - acc: 0.9546\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 8s 282us/step - loss: 0.1607 - acc: 0.9544\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 8s 272us/step - loss: 0.1556 - acc: 0.9562\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 8s 280us/step - loss: 0.1512 - acc: 0.9564\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 8s 275us/step - loss: 0.1474 - acc: 0.9585\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 9s 299us/step - loss: 0.1424 - acc: 0.9598\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 9s 285us/step - loss: 0.1409 - acc: 0.9603\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 8s 272us/step - loss: 0.1384 - acc: 0.9603\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 8s 279us/step - loss: 0.1333 - acc: 0.9626\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 8s 273us/step - loss: 0.1300 - acc: 0.9635\n",
      "30000/30000 [==============================] - 8s 254us/step\n",
      "30000/30000 [==============================] - 5s 178us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=30, num_neurons=256, optimizer_algo=sgd, total= 4.4min\n",
      "[CV] activation=relu, dropout=0.3, epochs=30, num_neurons=256, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 14s 464us/step - loss: 0.9265 - acc: 0.7522\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 9s 284us/step - loss: 0.4726 - acc: 0.8663\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 9s 287us/step - loss: 0.3921 - acc: 0.8868\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 9s 289us/step - loss: 0.3526 - acc: 0.8984\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 9s 284us/step - loss: 0.3226 - acc: 0.9071\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 9s 293us/step - loss: 0.2998 - acc: 0.9142\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 9s 284us/step - loss: 0.2799 - acc: 0.9202\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 9s 288us/step - loss: 0.2644 - acc: 0.9250\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 9s 288us/step - loss: 0.2485 - acc: 0.9287\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 9s 295us/step - loss: 0.2379 - acc: 0.9321\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 9s 286us/step - loss: 0.2283 - acc: 0.9344\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 9s 287us/step - loss: 0.2160 - acc: 0.9381\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 9s 289us/step - loss: 0.2066 - acc: 0.9422\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 9s 285us/step - loss: 0.1995 - acc: 0.9422\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 9s 293us/step - loss: 0.1933 - acc: 0.9440\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 9s 287us/step - loss: 0.1832 - acc: 0.9482\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 9s 287us/step - loss: 0.1769 - acc: 0.9503\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 9s 286us/step - loss: 0.1730 - acc: 0.9515\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 9s 287us/step - loss: 0.1712 - acc: 0.9504\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 9s 295us/step - loss: 0.1650 - acc: 0.9527\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 9s 289us/step - loss: 0.1595 - acc: 0.9549\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 9s 287us/step - loss: 0.1545 - acc: 0.9558\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 9s 288us/step - loss: 0.1504 - acc: 0.9572\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 9s 295us/step - loss: 0.1498 - acc: 0.9574\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 9s 287us/step - loss: 0.1440 - acc: 0.9598\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 9s 302us/step - loss: 0.1413 - acc: 0.9600\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 9s 294us/step - loss: 0.1360 - acc: 0.9620\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 9s 295us/step - loss: 0.1350 - acc: 0.9606\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 9s 298us/step - loss: 0.1316 - acc: 0.9625\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 9s 291us/step - loss: 0.1272 - acc: 0.9640\n",
      "30000/30000 [==============================] - 8s 260us/step\n",
      "30000/30000 [==============================] - 6s 186us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=30, num_neurons=256, optimizer_algo=sgd, total= 4.6min\n",
      "[CV] activation=relu, dropout=0.3, epochs=30, num_neurons=256, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 16s 537us/step - loss: 0.3959 - acc: 0.8836\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 11s 361us/step - loss: 0.3004 - acc: 0.9161\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 11s 360us/step - loss: 0.2840 - acc: 0.9241\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 11s 361us/step - loss: 0.2774 - acc: 0.9287\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 11s 368us/step - loss: 0.2543 - acc: 0.9342\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 11s 363us/step - loss: 0.2588 - acc: 0.9370\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 11s 361us/step - loss: 0.2444 - acc: 0.9410\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 11s 367us/step - loss: 0.2449 - acc: 0.9434\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 11s 364us/step - loss: 0.2367 - acc: 0.9434\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 11s 362us/step - loss: 0.2204 - acc: 0.9488\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 11s 362us/step - loss: 0.2315 - acc: 0.9468TA: 0s - loss: 0.2320 - acc: 0\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 11s 371us/step - loss: 0.2233 - acc: 0.9493\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 11s 363us/step - loss: 0.2067 - acc: 0.9517\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 11s 363us/step - loss: 0.2325 - acc: 0.9494\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 11s 361us/step - loss: 0.2205 - acc: 0.9513\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 11s 370us/step - loss: 0.2174 - acc: 0.9537\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 11s 363us/step - loss: 0.2117 - acc: 0.9561\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 11s 362us/step - loss: 0.2136 - acc: 0.9545\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 11s 371us/step - loss: 0.2053 - acc: 0.9596\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 11s 365us/step - loss: 0.2108 - acc: 0.9569\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 11s 364us/step - loss: 0.2104 - acc: 0.9581\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 11s 363us/step - loss: 0.2064 - acc: 0.9583\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 11s 370us/step - loss: 0.1997 - acc: 0.9586\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 11s 368us/step - loss: 0.1978 - acc: 0.9592\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 11s 368us/step - loss: 0.2046 - acc: 0.9607\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 11s 365us/step - loss: 0.1980 - acc: 0.9628\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 11s 369us/step - loss: 0.2164 - acc: 0.9579\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 11s 366us/step - loss: 0.1966 - acc: 0.9615\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 11s 362us/step - loss: 0.2007 - acc: 0.9610\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 11s 371us/step - loss: 0.2070 - acc: 0.9588\n",
      "30000/30000 [==============================] - 8s 267us/step\n",
      "30000/30000 [==============================] - 6s 189us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=30, num_neurons=256, optimizer_algo=adam, total= 5.7min\n",
      "[CV] activation=relu, dropout=0.3, epochs=30, num_neurons=256, optimizer_algo=adam \n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 17s 554us/step - loss: 0.3941 - acc: 0.8814\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 11s 367us/step - loss: 0.2966 - acc: 0.9149\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 11s 359us/step - loss: 0.2803 - acc: 0.9242\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 11s 360us/step - loss: 0.2609 - acc: 0.9307\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 11s 361us/step - loss: 0.2689 - acc: 0.9333\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 11s 366us/step - loss: 0.2464 - acc: 0.9364\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 11s 362us/step - loss: 0.2400 - acc: 0.9417\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 11s 360us/step - loss: 0.2376 - acc: 0.9427\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 11s 367us/step - loss: 0.2312 - acc: 0.9465\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 11s 361us/step - loss: 0.2289 - acc: 0.94780s - loss: 0.\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 11s 364us/step - loss: 0.2263 - acc: 0.9503\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 11s 371us/step - loss: 0.2338 - acc: 0.9507\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 11s 369us/step - loss: 0.2262 - acc: 0.9509\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 11s 359us/step - loss: 0.2152 - acc: 0.9520\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 11s 363us/step - loss: 0.2117 - acc: 0.9551\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 11s 363us/step - loss: 0.2185 - acc: 0.9540\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 11s 370us/step - loss: 0.2069 - acc: 0.9566\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 11s 364us/step - loss: 0.2201 - acc: 0.9563\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 11s 362us/step - loss: 0.2219 - acc: 0.9570\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 11s 378us/step - loss: 0.2120 - acc: 0.9552\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 11s 361us/step - loss: 0.1977 - acc: 0.9592\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 11s 364us/step - loss: 0.2108 - acc: 0.9592\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 11s 361us/step - loss: 0.1948 - acc: 0.9605\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 11s 371us/step - loss: 0.2067 - acc: 0.9597\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 11s 364us/step - loss: 0.2063 - acc: 0.9615\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 11s 364us/step - loss: 0.2115 - acc: 0.9598\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 11s 363us/step - loss: 0.1983 - acc: 0.9613\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 11s 368us/step - loss: 0.1872 - acc: 0.9627\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 11s 364us/step - loss: 0.1982 - acc: 0.9628\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 11s 363us/step - loss: 0.1862 - acc: 0.9634\n",
      "30000/30000 [==============================] - 8s 260us/step\n",
      "30000/30000 [==============================] - 6s 195us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=30, num_neurons=256, optimizer_algo=adam, total= 5.7min\n",
      "[CV] activation=relu, dropout=0.3, epochs=30, num_neurons=512, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 16s 543us/step - loss: 0.8699 - acc: 0.7765\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 11s 362us/step - loss: 0.4406 - acc: 0.8795\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 11s 367us/step - loss: 0.3665 - acc: 0.8983\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 11s 359us/step - loss: 0.3270 - acc: 0.9092\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 11s 361us/step - loss: 0.2988 - acc: 0.9166\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 11s 357us/step - loss: 0.2773 - acc: 0.9238\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 11s 368us/step - loss: 0.2600 - acc: 0.9273\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 11s 358us/step - loss: 0.2463 - acc: 0.9321\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 11s 361us/step - loss: 0.2330 - acc: 0.9357\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 11s 363us/step - loss: 0.2215 - acc: 0.9384\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 11s 366us/step - loss: 0.2095 - acc: 0.9433\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 11s 363us/step - loss: 0.2015 - acc: 0.9453\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 11s 363us/step - loss: 0.1945 - acc: 0.9464\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 11s 370us/step - loss: 0.1858 - acc: 0.9495\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 11s 363us/step - loss: 0.1780 - acc: 0.9513\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 11s 372us/step - loss: 0.1728 - acc: 0.9534\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 11s 362us/step - loss: 0.1656 - acc: 0.9544\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 11s 371us/step - loss: 0.1605 - acc: 0.9557\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 11s 366us/step - loss: 0.1564 - acc: 0.9566\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 11s 366us/step - loss: 0.1501 - acc: 0.9577\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 11s 371us/step - loss: 0.1455 - acc: 0.9592\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 11s 363us/step - loss: 0.1433 - acc: 0.9602\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 11s 361us/step - loss: 0.1384 - acc: 0.9610\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 11s 366us/step - loss: 0.1349 - acc: 0.9621\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 11s 369us/step - loss: 0.1302 - acc: 0.9646\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 11s 363us/step - loss: 0.1260 - acc: 0.9653\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 11s 362us/step - loss: 0.1219 - acc: 0.9659\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 11s 363us/step - loss: 0.1196 - acc: 0.9666\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 11s 371us/step - loss: 0.1165 - acc: 0.9690\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 11s 366us/step - loss: 0.1159 - acc: 0.9686\n",
      "30000/30000 [==============================] - 9s 299us/step\n",
      "30000/30000 [==============================] - 6s 203us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=30, num_neurons=512, optimizer_algo=sgd, total= 5.7min\n",
      "[CV] activation=relu, dropout=0.3, epochs=30, num_neurons=512, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 17s 569us/step - loss: 0.8569 - acc: 0.7760\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 11s 369us/step - loss: 0.4384 - acc: 0.8779\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 11s 370us/step - loss: 0.3665 - acc: 0.8956\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 11s 376us/step - loss: 0.3311 - acc: 0.9074\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 11s 372us/step - loss: 0.3002 - acc: 0.9139\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 11s 366us/step - loss: 0.2794 - acc: 0.9195\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 11s 373us/step - loss: 0.2624 - acc: 0.9256\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 11s 378us/step - loss: 0.2480 - acc: 0.9292\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 11s 372us/step - loss: 0.2327 - acc: 0.93470s - loss: 0.2331 \n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 11s 373us/step - loss: 0.2215 - acc: 0.9365\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 12s 395us/step - loss: 0.2103 - acc: 0.9404\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 11s 374us/step - loss: 0.1997 - acc: 0.9428\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 11s 373us/step - loss: 0.1917 - acc: 0.9456\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 11s 368us/step - loss: 0.1846 - acc: 0.9481\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 11s 374us/step - loss: 0.1771 - acc: 0.9500\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 11s 363us/step - loss: 0.1710 - acc: 0.9511\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 11s 361us/step - loss: 0.1648 - acc: 0.9527\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 11s 372us/step - loss: 0.1585 - acc: 0.9560\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 11s 365us/step - loss: 0.1528 - acc: 0.9567\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 11s 362us/step - loss: 0.1479 - acc: 0.9577\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 11s 360us/step - loss: 0.1454 - acc: 0.9596\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 11s 372us/step - loss: 0.1388 - acc: 0.9615\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 11s 365us/step - loss: 0.1364 - acc: 0.9618\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 11s 372us/step - loss: 0.1343 - acc: 0.9625\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 11s 372us/step - loss: 0.1290 - acc: 0.9631\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 11s 375us/step - loss: 0.1241 - acc: 0.9649\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 11s 371us/step - loss: 0.1221 - acc: 0.9651\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 11s 367us/step - loss: 0.1173 - acc: 0.9681\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 11s 372us/step - loss: 0.1140 - acc: 0.9689\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 11s 365us/step - loss: 0.1112 - acc: 0.9685\n",
      "30000/30000 [==============================] - 8s 279us/step\n",
      "30000/30000 [==============================] - 6s 201us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=30, num_neurons=512, optimizer_algo=sgd, total= 5.8min\n",
      "[CV] activation=relu, dropout=0.3, epochs=30, num_neurons=512, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 20s 673us/step - loss: 0.4035 - acc: 0.88618s - loss: - ET - ETA: 3s - loss: 0.4179 - acc:  - ETA\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 15s 486us/step - loss: 0.3123 - acc: 0.9177 4s - ETA: 2s - loss: 0.3106 -\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 15s 486us/step - loss: 0.2874 - acc: 0.9270\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 15s 502us/step - loss: 0.2654 - acc: 0.9367\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 15s 493us/step - loss: 0.2679 - acc: 0.9365\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 15s 499us/step - loss: 0.2667 - acc: 0.93819s - loss: 0.2625 - a - ETA: 8\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 15s 490us/step - loss: 0.2502 - acc: 0.9406\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 15s 486us/step - loss: 0.2395 - acc: 0.94512s - loss: 0.2447 - acc:\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 15s 495us/step - loss: 0.2360 - acc: 0.9462\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 15s 484us/step - loss: 0.2291 - acc: 0.94780s - loss: 0.2\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 15s 486us/step - loss: 0.2164 - acc: 0.95041s - \n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 15s 500us/step - loss: 0.2250 - acc: 0.9497\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 15s 486us/step - loss: 0.2241 - acc: 0.9520\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 15s 500us/step - loss: 0.2201 - acc: 0.9527\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 15s 488us/step - loss: 0.2154 - acc: 0.9566\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 15s 489us/step - loss: 0.2161 - acc: 0.95554s - loss: - ETA: 0s - loss: 0.21\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 15s 492us/step - loss: 0.2151 - acc: 0.9565\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 15s 487us/step - loss: 0.2156 - acc: 0.9580\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 15s 487us/step - loss: 0.2210 - acc: 0.95822s - loss: 0.2197 - a\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 15s 501us/step - loss: 0.2060 - acc: 0.9595\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 15s 489us/step - loss: 0.2135 - acc: 0.9610\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 15s 489us/step - loss: 0.2131 - acc: 0.96010s - loss: 0.2122 - ac\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 15s 498us/step - loss: 0.1914 - acc: 0.9633\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 15s 488us/step - loss: 0.2238 - acc: 0.9616\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 15s 513us/step - loss: 0.2009 - acc: 0.96433s - loss: 0.2 - ETA: 1s - loss - ETA: 0s - loss: 0.2022 - \n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 15s 494us/step - loss: 0.2153 - acc: 0.96311s - los - ETA: 0s - loss: 0.2155 - acc: 0.963\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 15s 487us/step - loss: 0.2063 - acc: 0.96390s - loss: 0.20\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 15s 504us/step - loss: 0.2222 - acc: 0.96270s - loss: 0.2\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 15s 490us/step - loss: 0.2111 - acc: 0.96232s - lo - ETA: 0s - loss: 0.2069 - a\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 15s 486us/step - loss: 0.1824 - acc: 0.96890s - loss: 0.1835 - acc: 0.9\n",
      "30000/30000 [==============================] - 8s 279us/step\n",
      "30000/30000 [==============================] - 6s 206us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=30, num_neurons=512, optimizer_algo=adam, total= 7.6min\n",
      "[CV] activation=relu, dropout=0.3, epochs=30, num_neurons=512, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 20s 674us/step - loss: 0.3963 - acc: 0.88604s - - ETA: 1s - loss\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 15s 502us/step - loss: 0.3033 - acc: 0.9201\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 15s 492us/step - loss: 0.2815 - acc: 0.9292\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 15s 495us/step - loss: 0.2815 - acc: 0.93222s - loss:  - ETA: \n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 15s 499us/step - loss: 0.2574 - acc: 0.9384\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 15s 492us/step - loss: 0.2453 - acc: 0.94275s - l - ETA: 3s -\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 15s 499us/step - loss: 0.2363 - acc: 0.9431\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 15s 493us/step - loss: 0.2283 - acc: 0.9457\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 15s 493us/step - loss: 0.2323 - acc: 0.94881s - loss:\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 15s 508us/step - loss: 0.2277 - acc: 0.9514\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 15s 488us/step - loss: 0.2449 - acc: 0.94740s - loss: 0.24\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 15s 490us/step - loss: 0.2140 - acc: 0.9555\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 15s 502us/step - loss: 0.2287 - acc: 0.9539\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 15s 497us/step - loss: 0.2189 - acc: 0.9551\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 15s 502us/step - loss: 0.2155 - acc: 0.9570\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 15s 493us/step - loss: 0.2286 - acc: 0.9560\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 15s 489us/step - loss: 0.2304 - acc: 0.9564\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 15s 505us/step - loss: 0.2245 - acc: 0.9582\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 15s 490us/step - loss: 0.2112 - acc: 0.9581\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 15s 493us/step - loss: 0.2191 - acc: 0.9578\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 15s 499us/step - loss: 0.1930 - acc: 0.9621\n",
      "Epoch 22/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 15s 484us/step - loss: 0.2125 - acc: 0.96063s - loss: \n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 15s 495us/step - loss: 0.2003 - acc: 0.96220s - loss:\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 15s 494us/step - loss: 0.2059 - acc: 0.9607\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 15s 487us/step - loss: 0.2283 - acc: 0.9620\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 15s 496us/step - loss: 0.1995 - acc: 0.96427s - loss: 0.19 - ETA:  - ETA: 5s - loss: 0.1979 - acc: - ETA: 4s - loss: 0.197 - ETA: 3s - loss: - ETA: 2s - loss: 0.1994 - acc: 0.964 - ETA: 2s - loss: 0 - ETA: 1s - loss: 0. - ETA: 0s - loss: 0.1999 - acc: \n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 15s 487us/step - loss: 0.1886 - acc: 0.9649\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 15s 483us/step - loss: 0.2203 - acc: 0.9626\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 15s 495us/step - loss: 0.2029 - acc: 0.9646\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 15s 485us/step - loss: 0.2119 - acc: 0.9642\n",
      "30000/30000 [==============================] - 8s 280us/step\n",
      "30000/30000 [==============================] - 6s 202us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=30, num_neurons=512, optimizer_algo=adam, total= 7.7min\n",
      "[CV] activation=relu, dropout=0.3, epochs=30, num_neurons=784, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 20s 675us/step - loss: 0.8264 - acc: 0.7963\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 15s 492us/step - loss: 0.4231 - acc: 0.8839\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 15s 504us/step - loss: 0.3569 - acc: 0.9016\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 15s 492us/step - loss: 0.3171 - acc: 0.9112\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 15s 487us/step - loss: 0.2925 - acc: 0.9185\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 16s 517us/step - loss: 0.2721 - acc: 0.9246\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 15s 510us/step - loss: 0.2543 - acc: 0.9278\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 15s 513us/step - loss: 0.2415 - acc: 0.9320\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 15s 506us/step - loss: 0.2272 - acc: 0.9373\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 15s 509us/step - loss: 0.2158 - acc: 0.9405\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 15s 507us/step - loss: 0.2065 - acc: 0.9437\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 15s 492us/step - loss: 0.1978 - acc: 0.9443\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 15s 499us/step - loss: 0.1883 - acc: 0.9472\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 15s 494us/step - loss: 0.1794 - acc: 0.9503\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 15s 494us/step - loss: 0.1732 - acc: 0.9523\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 15s 502us/step - loss: 0.1661 - acc: 0.9532- ETA: 0s - loss: 0.1658 - ac\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 15s 499us/step - loss: 0.1595 - acc: 0.9566: 0s - loss: 0.1585 - acc: \n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 15s 500us/step - loss: 0.1552 - acc: 0.9559\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 16s 517us/step - loss: 0.1499 - acc: 0.9582\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 16s 519us/step - loss: 0.1460 - acc: 0.95960s - loss: 0.1460 - acc: 0.959\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 16s 517us/step - loss: 0.1398 - acc: 0.96140s - loss: 0.1\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 15s 511us/step - loss: 0.1346 - acc: 0.9642\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 15s 514us/step - loss: 0.1318 - acc: 0.9634\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 15s 502us/step - loss: 0.1279 - acc: 0.9651\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 15s 496us/step - loss: 0.1250 - acc: 0.9647\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 15s 493us/step - loss: 0.1203 - acc: 0.9656\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 15s 501us/step - loss: 0.1182 - acc: 0.96752s - loss: 0.1193  - ETA: 1s - loss: 0.11 - ETA: 0s - loss: 0.1178\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 15s 489us/step - loss: 0.1140 - acc: 0.9696\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 15s 507us/step - loss: 0.1102 - acc: 0.9691\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 15s 494us/step - loss: 0.1074 - acc: 0.9704\n",
      "30000/30000 [==============================] - 9s 308us/step\n",
      "30000/30000 [==============================] - 7s 230us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=30, num_neurons=784, optimizer_algo=sgd, total= 7.8min\n",
      "[CV] activation=relu, dropout=0.3, epochs=30, num_neurons=784, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 21s 700us/step - loss: 0.8291 - acc: 0.7946\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 15s 500us/step - loss: 0.4227 - acc: 0.88261s - loss: 0.4242  - ETA: 0s - loss: 0.4236 - acc: \n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 15s 511us/step - loss: 0.3552 - acc: 0.89965s - lo\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 15s 499us/step - loss: 0.3198 - acc: 0.9093\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 15s 500us/step - loss: 0.2923 - acc: 0.9155\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 15s 512us/step - loss: 0.2714 - acc: 0.92223s - \n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 15s 500us/step - loss: 0.2521 - acc: 0.9291\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 15s 513us/step - loss: 0.2383 - acc: 0.9325\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 15s 499us/step - loss: 0.2247 - acc: 0.93571s - \n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 15s 504us/step - loss: 0.2126 - acc: 0.9384\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 16s 530us/step - loss: 0.2025 - acc: 0.9431\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 16s 527us/step - loss: 0.1931 - acc: 0.9457\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 15s 504us/step - loss: 0.1859 - acc: 0.9479\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 16s 542us/step - loss: 0.1762 - acc: 0.9505\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 15s 502us/step - loss: 0.1687 - acc: 0.9522\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 15s 514us/step - loss: 0.1624 - acc: 0.95470s - loss: 0.1629 - - ETA: 0s - loss: 0.1624 - acc: 0.\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 15s 506us/step - loss: 0.1581 - acc: 0.9550\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 15s 505us/step - loss: 0.1516 - acc: 0.9572\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 15s 509us/step - loss: 0.1457 - acc: 0.9593\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 15s 511us/step - loss: 0.1403 - acc: 0.96010s - loss: 0.139\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 16s 519us/step - loss: 0.1371 - acc: 0.9618\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 16s 523us/step - loss: 0.1330 - acc: 0.9624\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 15s 504us/step - loss: 0.1285 - acc: 0.9637\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 15s 509us/step - loss: 0.1239 - acc: 0.9646\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 15s 503us/step - loss: 0.1224 - acc: 0.9658\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 15s 499us/step - loss: 0.1170 - acc: 0.96701s - lo\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 15s 505us/step - loss: 0.1138 - acc: 0.9677\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 16s 529us/step - loss: 0.1130 - acc: 0.96802s - loss: 0.11 - ET\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 16s 533us/step - loss: 0.1090 - acc: 0.9699\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 15s 510us/step - loss: 0.1049 - acc: 0.9715\n",
      "30000/30000 [==============================] - 9s 300us/step\n",
      "30000/30000 [==============================] - 7s 226us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=30, num_neurons=784, optimizer_algo=sgd, total= 7.9min\n",
      "[CV] activation=relu, dropout=0.3, epochs=30, num_neurons=784, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 26s 878us/step - loss: 0.4061 - acc: 0.8844\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 22s 719us/step - loss: 0.3187 - acc: 0.91625s - - ETA: 3s - l\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 21s 690us/step - loss: 0.2842 - acc: 0.9282\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 21s 695us/step - loss: 0.2814 - acc: 0.93117s - loss: 0.  - ETA:  \n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 21s 686us/step - loss: 0.2551 - acc: 0.9379\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 21s 694us/step - loss: 0.2515 - acc: 0.94135s - loss: 0.2521 -  - E\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 21s 688us/step - loss: 0.2391 - acc: 0.9444\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 21s 701us/step - loss: 0.2351 - acc: 0.94883s - lo - ET\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 20s 682us/step - loss: 0.2522 - acc: 0.94680s - loss: 0.2540 - ac\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 21s 706us/step - loss: 0.2374 - acc: 0.94935s - loss: 0.2354 - acc - ET - ETA: 0s - loss: 0.2371 - acc: 0.949\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 20s 682us/step - loss: 0.2341 - acc: 0.9514 ETA: 0s - loss: 0.2319 - acc\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 21s 708us/step - loss: 0.2271 - acc: 0.95121s - loss:\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 21s 699us/step - loss: 0.2247 - acc: 0.9542\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 21s 713us/step - loss: 0.2327 - acc: 0.9553\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 21s 687us/step - loss: 0.2120 - acc: 0.9574\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 21s 693us/step - loss: 0.2236 - acc: 0.9575\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 21s 687us/step - loss: 0.2220 - acc: 0.9577\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 21s 697us/step - loss: 0.2172 - acc: 0.9573\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 21s 686us/step - loss: 0.2120 - acc: 0.95952s - loss: 0.2084 - acc:  - ETA: 2s - los - ETA: 0s - loss: 0.2113 - acc: - ETA: 0s - loss: 0.2111 - acc: 0.9\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 21s 690us/step - loss: 0.2203 - acc: 0.9595\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 20s 681us/step - loss: 0.2065 - acc: 0.96193s -  - ETA: 1s - loss: 0.2073  - ETA: 0s - loss: 0.2072  - ETA: 0s - loss: 0.2056 - acc: 0.9\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 21s 694us/step - loss: 0.2216 - acc: 0.9605\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 20s 680us/step - loss: 0.2125 - acc: 0.96074s - l - ETA: 2s - loss:  - ETA: 1\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 21s 685us/step - loss: 0.2076 - acc: 0.9610\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 21s 692us/step - loss: 0.2094 - acc: 0.96483s - loss: 0.2049 - acc: 0.96 - ETA: 3s - loss: 0\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 20s 679us/step - loss: 0.2047 - acc: 0.96631s - l\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 21s 687us/step - loss: 0.2260 - acc: 0.9638\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 21s 692us/step - loss: 0.2242 - acc: 0.9645\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 21s 694us/step - loss: 0.2092 - acc: 0.96583s - loss: \n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 21s 684us/step - loss: 0.2243 - acc: 0.9639: 1\n",
      "30000/30000 [==============================] - 10s 317us/step\n",
      "30000/30000 [==============================] - 7s 237us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=30, num_neurons=784, optimizer_algo=adam, total=10.6min\n",
      "[CV] activation=relu, dropout=0.3, epochs=30, num_neurons=784, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 27s 897us/step - loss: 0.4221 - acc: 0.8854\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 21s 716us/step - loss: 0.3172 - acc: 0.9177\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 21s 705us/step - loss: 0.2755 - acc: 0.9287\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 21s 716us/step - loss: 0.2638 - acc: 0.9327\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 21s 703us/step - loss: 0.2683 - acc: 0.93541s -\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 21s 715us/step - loss: 0.2592 - acc: 0.9394\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 22s 732us/step - loss: 0.2526 - acc: 0.9431\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 21s 715us/step - loss: 0.2265 - acc: 0.9497\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 21s 706us/step - loss: 0.2442 - acc: 0.9480\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 21s 710us/step - loss: 0.2536 - acc: 0.9495\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 22s 726us/step - loss: 0.2415 - acc: 0.9505\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 21s 710us/step - loss: 0.2299 - acc: 0.9521 - ETA: 0s - loss: 0.2287 - acc: 0.\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 21s 712us/step - loss: 0.2257 - acc: 0.9539\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 21s 696us/step - loss: 0.2224 - acc: 0.9557\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 21s 708us/step - loss: 0.2360 - acc: 0.9560\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 21s 699us/step - loss: 0.2312 - acc: 0.9565\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 21s 711us/step - loss: 0.2447 - acc: 0.9573\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 22s 724us/step - loss: 0.2226 - acc: 0.9601\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 22s 717us/step - loss: 0.2307 - acc: 0.9599 - ETA: 0s - loss: 0.23\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 21s 702us/step - loss: 0.2315 - acc: 0.9609\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 24s 788us/step - loss: 0.2321 - acc: 0.9601\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 24s 816us/step - loss: 0.2346 - acc: 0.96170s - loss: 0.2354 - acc: \n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 21s 710us/step - loss: 0.2213 - acc: 0.9629\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 22s 723us/step - loss: 0.2313 - acc: 0.9606\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 21s 714us/step - loss: 0.2129 - acc: 0.9628\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 22s 720us/step - loss: 0.2236 - acc: 0.9625\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 21s 702us/step - loss: 0.2052 - acc: 0.9655\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 21s 713us/step - loss: 0.2390 - acc: 0.9626\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 21s 707us/step - loss: 0.2187 - acc: 0.9662\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 21s 715us/step - loss: 0.2247 - acc: 0.9649\n",
      "30000/30000 [==============================] - 10s 318us/step\n",
      "30000/30000 [==============================] - 7s 239us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=30, num_neurons=784, optimizer_algo=adam, total=11.0min\n",
      "[CV] activation=relu, dropout=0.3, epochs=30, num_neurons=1024, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 22s 742us/step - loss: 0.8064 - acc: 0.80510s - loss: 0.8221\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 16s 538us/step - loss: 0.4116 - acc: 0.8892\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 16s 541us/step - loss: 0.3489 - acc: 0.9029\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 16s 532us/step - loss: 0.3128 - acc: 0.9127\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 16s 541us/step - loss: 0.2881 - acc: 0.9199\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 17s 562us/step - loss: 0.2668 - acc: 0.92652s - loss: 0. - ETA: 1s - los\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 16s 539us/step - loss: 0.2509 - acc: 0.9313\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 0.2362 - acc: 0.935 - 16s 547us/step - loss: 0.2361 - acc: 0.9355\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 16s 538us/step - loss: 0.2239 - acc: 0.9388\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 17s 570us/step - loss: 0.2137 - acc: 0.9410\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 19s 634us/step - loss: 0.2029 - acc: 0.94349s - loss: 0.2040 - acc: 0.9 - ETA:  - ETA: 4s - - ETA: 2s - loss: 0.2024 - \n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 17s 559us/step - loss: 0.1924 - acc: 0.9472\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 16s 544us/step - loss: 0.1850 - acc: 0.9497\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 16s 533us/step - loss: 0.1779 - acc: 0.9511\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 16s 542us/step - loss: 0.1703 - acc: 0.9526\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 16s 529us/step - loss: 0.1625 - acc: 0.9556\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 16s 538us/step - loss: 0.1570 - acc: 0.9562\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 16s 544us/step - loss: 0.1519 - acc: 0.9579\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 16s 549us/step - loss: 0.1477 - acc: 0.9589\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 17s 551us/step - loss: 0.1417 - acc: 0.96231s - loss: \n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 16s 542us/step - loss: 0.1373 - acc: 0.9621\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 16s 536us/step - loss: 0.1330 - acc: 0.9634\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 16s 545us/step - loss: 0.1287 - acc: 0.9650\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 16s 533us/step - loss: 0.1240 - acc: 0.9660\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 16s 544us/step - loss: 0.1210 - acc: 0.9678\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 16s 532us/step - loss: 0.1173 - acc: 0.9676\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 16s 530us/step - loss: 0.1137 - acc: 0.9691\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 16s 544us/step - loss: 0.1109 - acc: 0.96930s - loss: 0.1110 - a\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 16s 548us/step - loss: 0.1079 - acc: 0.97033s - los\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 16s 542us/step - loss: 0.1048 - acc: 0.97101\n",
      "30000/30000 [==============================] - 10s 332us/step\n",
      "30000/30000 [==============================] - 7s 249us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=30, num_neurons=1024, optimizer_algo=sgd, total= 8.5min\n",
      "[CV] activation=relu, dropout=0.3, epochs=30, num_neurons=1024, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 23s 767us/step - loss: 0.8158 - acc: 0.8003\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 17s 577us/step - loss: 0.4128 - acc: 0.88690s - loss: 0.4137 - acc: 0\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 18s 592us/step - loss: 0.3505 - acc: 0.9008\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 17s 583us/step - loss: 0.3132 - acc: 0.9110\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 17s 577us/step - loss: 0.2863 - acc: 0.9177\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 18s 586us/step - loss: 0.2644 - acc: 0.9260\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 17s 577us/step - loss: 0.2491 - acc: 0.9287\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 18s 587us/step - loss: 0.2332 - acc: 0.9346\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 17s 576us/step - loss: 0.2209 - acc: 0.93674s - loss: 0.2215 - acc: 0.9 \n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 18s 586us/step - loss: 0.2077 - acc: 0.9410\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 17s 574us/step - loss: 0.1991 - acc: 0.94341s - loss:\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 18s 586us/step - loss: 0.1886 - acc: 0.9473\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 17s 579us/step - loss: 0.1811 - acc: 0.9493\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 17s 582us/step - loss: 0.1724 - acc: 0.9511\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 18s 588us/step - loss: 0.1663 - acc: 0.9526\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 17s 574us/step - loss: 0.1597 - acc: 0.9550\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 17s 582us/step - loss: 0.1535 - acc: 0.95640s - loss: 0.1530 - acc\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 17s 574us/step - loss: 0.1482 - acc: 0.95790s - loss: 0.1487 - acc: 0.957 - ETA: 0s - loss: 0.1487 - acc\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 17s 581us/step - loss: 0.1434 - acc: 0.9594\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 17s 572us/step - loss: 0.1377 - acc: 0.9616\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 17s 572us/step - loss: 0.1337 - acc: 0.96190s - loss: 0.1344 - acc: \n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 17s 580us/step - loss: 0.1285 - acc: 0.9643\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 17s 572us/step - loss: 0.1249 - acc: 0.9657\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 18s 586us/step - loss: 0.1204 - acc: 0.9659\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 17s 570us/step - loss: 0.1176 - acc: 0.96791s - l\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 0.1149 - acc: 0.967 - 18s 585us/step - loss: 0.1148 - acc: 0.9677\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 17s 575us/step - loss: 0.1108 - acc: 0.9699\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 17s 578us/step - loss: 0.1072 - acc: 0.9702\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 18s 584us/step - loss: 0.1051 - acc: 0.9711\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 17s 575us/step - loss: 0.1004 - acc: 0.9727\n",
      "30000/30000 [==============================] - 10s 349us/step\n",
      "30000/30000 [==============================] - 7s 248us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=30, num_neurons=1024, optimizer_algo=sgd, total= 9.0min\n",
      "[CV] activation=relu, dropout=0.3, epochs=30, num_neurons=1024, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 0.4265 - acc: 0.8829: 4s - loss\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 27s 900us/step - loss: 0.3193 - acc: 0.91830s - loss: 0.3184 - acc: 0 - ETA: 0s - loss: 0.3192 - acc: 0\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 27s 900us/step - loss: 0.2811 - acc: 0.9300\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 27s 913us/step - loss: 0.2898 - acc: 0.93075s - lo - ETA: 2s  - ETA: 0s - loss: 0.2860 - acc:\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 27s 894us/step - loss: 0.2704 - acc: 0.93740s - loss: 0.2\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 27s 906us/step - loss: 0.2516 - acc: 0.9445\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 27s 903us/step - loss: 0.2604 - acc: 0.9455\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 27s 907us/step - loss: 0.2450 - acc: 0.9462\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 27s 910us/step - loss: 0.2418 - acc: 0.9485\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 27s 903us/step - loss: 0.2495 - acc: 0.94916s -  - ETA: 5s - - ETA: 3s - loss: 0.2456 - acc: 0. - ETA: 3s - loss: 0. - ETA: 2s - loss: 0.2480 - acc: 0. - ETA: 2s - lo - ETA: 0s - loss: 0.2495 -\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 27s 902us/step - loss: 0.2480 - acc: 0.95220s - loss: 0.2482 - acc: 0.9\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 28s 938us/step - loss: 0.2188 - acc: 0.95548s -  - ETA: 7s - loss: 0.2152 - - ETA: 6s -\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 28s 924us/step - loss: 0.2420 - acc: 0.9559\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 27s 916us/step - loss: 0.2344 - acc: 0.9590: 9s - loss: 0.2241 - acc: 0.961 - ETA: 9s - loss: 0.2251 - ETA: 8s - loss: 0.2 - ETA: 7s - loss: 0. - ETA: 4s - loss: 0.2362 - acc: 0.959 - ETA: 4s - loss: 0.2359 - acc: 0.959 - ETA: 4s\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 27s 912us/step - loss: 0.2318 - acc: 0.9577\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 27s 908us/step - loss: 0.2448 - acc: 0.9553\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 27s 914us/step - loss: 0.2286 - acc: 0.95810s - loss: 0.2280 - \n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 27s 901us/step - loss: 0.2307 - acc: 0.9593\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 28s 918us/step - loss: 0.2390 - acc: 0.95910s - loss: 0.2398 - ac\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 28s 923us/step - loss: 0.2381 - acc: 0.9588\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 27s 917us/step - loss: 0.2371 - acc: 0.9579\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 28s 927us/step - loss: 0.2138 - acc: 0.9620\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 28s 921us/step - loss: 0.2355 - acc: 0.9622\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 27s 905us/step - loss: 0.2185 - acc: 0.9638\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 27s 913us/step - loss: 0.2126 - acc: 0.9647\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 28s 921us/step - loss: 0.2197 - acc: 0.9634\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 27s 906us/step - loss: 0.2200 - acc: 0.96606\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 27s 913us/step - loss: 0.2442 - acc: 0.9636\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 27s 915us/step - loss: 0.2217 - acc: 0.9644\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 27s 909us/step - loss: 0.2162 - acc: 0.9643\n",
      "30000/30000 [==============================] - 10s 332us/step\n",
      "30000/30000 [==============================] - 8s 250us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=30, num_neurons=1024, optimizer_algo=adam, total=13.9min\n",
      "[CV] activation=relu, dropout=0.3, epochs=30, num_neurons=1024, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.4107 - acc: 0.8826: 8s - loss: 0.4344 -  - ETA: 8\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 28s 945us/step - loss: 0.3240 - acc: 0.91565s - loss:\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 29s 981us/step - loss: 0.2762 - acc: 0.9296\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 28s 941us/step - loss: 0.2747 - acc: 0.93141s - los\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 28s 929us/step - loss: 0.2600 - acc: 0.9363\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 28s 930us/step - loss: 0.2514 - acc: 0.94040s - loss: 0.2512 - acc: 0.940 - ETA: 0s - loss: 0.2514 - acc: 0.940\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 28s 929us/step - loss: 0.2482 - acc: 0.9439ETA: 1s - loss: 0.2491 - acc: 0 - ETA: 1s \n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 28s 949us/step - loss: 0.2294 - acc: 0.9499\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 28s 929us/step - loss: 0.2394 - acc: 0.94838s - loss: 0.2290 - acc - ETA: 5s - loss: 0.2329 - - ETA: 4s - loss: 0.2341 - acc: 0. - ETA: 4s - l - ETA: 2s - - ETA: 1s - loss:\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 28s 945us/step - loss: 0.2325 - acc: 0.94980s - loss: 0.2317 - acc: 0. - ETA: 0s - loss: 0.2323 - a\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 28s 931us/step - loss: 0.2306 - acc: 0.9510\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 28s 918us/step - loss: 0.2240 - acc: 0.952610s - loss: 0.22 \n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 28s 935us/step - loss: 0.2426 - acc: 0.9515\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 28s 928us/step - loss: 0.2293 - acc: 0.9567\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 28s 930us/step - loss: 0.2348 - acc: 0.95470s - loss: 0.232\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 28s 919us/step - loss: 0.2281 - acc: 0.95582s - loss: 0. - ETA: 1s - los\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 28s 950us/step - loss: 0.2449 - acc: 0.95694 -\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 28s 920us/step - loss: 0.2212 - acc: 0.95881s - loss: - ETA: 0s - loss: 0.2216 - acc: 0.95\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 28s 918us/step - loss: 0.2238 - acc: 0.9590\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 28s 917us/step - loss: 0.2270 - acc: 0.95918s\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 28s 917us/step - loss: 0.2182 - acc: 0.9609\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 28s 917us/step - loss: 0.2416 - acc: 0.96023s - loss: 0.2382 - ac - ETA: 2s - loss:  - ETA: 1s - loss: 0. - ETA: 0s - loss: 0.2387 - acc:\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 28s 931us/step - loss: 0.2444 - acc: 0.9605\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 28s 927us/step - loss: 0.2245 - acc: 0.96275s - loss: 0.2177 - acc: - ETA: 5s  - ETA: 1s - lo\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 27s 916us/step - loss: 0.2165 - acc: 0.9646\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 27s 912us/step - loss: 0.2091 - acc: 0.96505s -  - ETA: \n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 27s 909us/step - loss: 0.2272 - acc: 0.9624\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 27s 910us/step - loss: 0.2111 - acc: 0.9641\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 27s 906us/step - loss: 0.2186 - acc: 0.9656\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 27s 908us/step - loss: 0.2295 - acc: 0.96365s - lo - ETA:\n",
      "30000/30000 [==============================] - 10s 335us/step\n",
      "30000/30000 [==============================] - 8s 254us/step\n",
      "[CV]  activation=relu, dropout=0.3, epochs=30, num_neurons=1024, optimizer_algo=adam, total=14.2min\n",
      "[CV] activation=relu, dropout=0.5, epochs=10, num_neurons=256, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 16s 522us/step - loss: 1.0035 - acc: 0.7108\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 10s 319us/step - loss: 0.5239 - acc: 0.8492\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 10s 318us/step - loss: 0.4330 - acc: 0.8755\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 10s 324us/step - loss: 0.3798 - acc: 0.89160s - loss: 0.3812\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 9s 314us/step - loss: 0.3530 - acc: 0.9001\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 9s 316us/step - loss: 0.3286 - acc: 0.9068\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 10s 318us/step - loss: 0.3076 - acc: 0.9124\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 9s 316us/step - loss: 0.2909 - acc: 0.9183\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 10s 326us/step - loss: 0.2770 - acc: 0.9212\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 10s 318us/step - loss: 0.2620 - acc: 0.9249\n",
      "30000/30000 [==============================] - 9s 291us/step\n",
      "30000/30000 [==============================] - 6s 208us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=10, num_neurons=256, optimizer_algo=sgd, total= 1.8min\n",
      "[CV] activation=relu, dropout=0.5, epochs=10, num_neurons=256, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 15s 510us/step - loss: 0.9667 - acc: 0.7175\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 9s 309us/step - loss: 0.5113 - acc: 0.8545\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 9s 308us/step - loss: 0.4288 - acc: 0.8768\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 9s 308us/step - loss: 0.3780 - acc: 0.8923\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 9s 315us/step - loss: 0.3488 - acc: 0.9009\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 9s 309us/step - loss: 0.3252 - acc: 0.9069\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 9s 307us/step - loss: 0.3010 - acc: 0.9143\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 9s 309us/step - loss: 0.2874 - acc: 0.9182\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 9s 316us/step - loss: 0.2737 - acc: 0.9204\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 9s 305us/step - loss: 0.2615 - acc: 0.9261\n",
      "30000/30000 [==============================] - 9s 286us/step\n",
      "30000/30000 [==============================] - 6s 208us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=10, num_neurons=256, optimizer_algo=sgd, total= 1.8min\n",
      "[CV] activation=relu, dropout=0.5, epochs=10, num_neurons=256, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 18s 594us/step - loss: 0.5156 - acc: 0.8449\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 12s 405us/step - loss: 0.4313 - acc: 0.8810\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 12s 393us/step - loss: 0.4191 - acc: 0.8888\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 12s 401us/step - loss: 0.3946 - acc: 0.8975\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 12s 393us/step - loss: 0.3911 - acc: 0.9015\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 12s 402us/step - loss: 0.4012 - acc: 0.9028\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 12s 398us/step - loss: 0.3759 - acc: 0.9092\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 12s 402us/step - loss: 0.3801 - acc: 0.9097\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 12s 396us/step - loss: 0.3544 - acc: 0.9182\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 12s 398us/step - loss: 0.3493 - acc: 0.9206\n",
      "30000/30000 [==============================] - 9s 284us/step\n",
      "30000/30000 [==============================] - 6s 192us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=10, num_neurons=256, optimizer_algo=adam, total= 2.2min\n",
      "[CV] activation=relu, dropout=0.5, epochs=10, num_neurons=256, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 18s 598us/step - loss: 0.5113 - acc: 0.8462\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 13s 419us/step - loss: 0.4184 - acc: 0.8829\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 12s 416us/step - loss: 0.4035 - acc: 0.8915\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 12s 411us/step - loss: 0.3822 - acc: 0.8987\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 12s 408us/step - loss: 0.3840 - acc: 0.9012\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 13s 417us/step - loss: 0.3722 - acc: 0.9052\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 12s 409us/step - loss: 0.3641 - acc: 0.9082\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 12s 411us/step - loss: 0.3603 - acc: 0.9126\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 12s 416us/step - loss: 0.3538 - acc: 0.9157\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 12s 405us/step - loss: 0.3746 - acc: 0.9137\n",
      "30000/30000 [==============================] - 9s 299us/step\n",
      "30000/30000 [==============================] - 6s 217us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=10, num_neurons=256, optimizer_algo=adam, total= 2.3min\n",
      "[CV] activation=relu, dropout=0.5, epochs=10, num_neurons=512, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 18s 594us/step - loss: 0.9231 - acc: 0.7435\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 12s 389us/step - loss: 0.4766 - acc: 0.8650\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 12s 389us/step - loss: 0.3949 - acc: 0.8888\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 12s 402us/step - loss: 0.3535 - acc: 0.8995\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 12s 391us/step - loss: 0.3262 - acc: 0.9073\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 12s 392us/step - loss: 0.2996 - acc: 0.9145\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 12s 399us/step - loss: 0.2793 - acc: 0.9209\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 12s 391us/step - loss: 0.2671 - acc: 0.9248\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 12s 396us/step - loss: 0.2494 - acc: 0.9303\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 12s 398us/step - loss: 0.2402 - acc: 0.9321\n",
      "30000/30000 [==============================] - 9s 305us/step\n",
      "30000/30000 [==============================] - 7s 219us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=10, num_neurons=512, optimizer_algo=sgd, total= 2.2min\n",
      "[CV] activation=relu, dropout=0.5, epochs=10, num_neurons=512, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 18s 599us/step - loss: 0.9056 - acc: 0.7530\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 12s 414us/step - loss: 0.4747 - acc: 0.8642\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 12s 405us/step - loss: 0.3996 - acc: 0.8844\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 13s 420us/step - loss: 0.3539 - acc: 0.8986\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 12s 413us/step - loss: 0.3239 - acc: 0.9061\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 12s 401us/step - loss: 0.2997 - acc: 0.9150\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 12s 402us/step - loss: 0.2837 - acc: 0.9191\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 12s 401us/step - loss: 0.2639 - acc: 0.9238\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 12s 413us/step - loss: 0.2504 - acc: 0.9279\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 12s 404us/step - loss: 0.2381 - acc: 0.9318\n",
      "30000/30000 [==============================] - 9s 316us/step\n",
      "30000/30000 [==============================] - 7s 223us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=10, num_neurons=512, optimizer_algo=sgd, total= 2.3min\n",
      "[CV] activation=relu, dropout=0.5, epochs=10, num_neurons=512, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 22s 724us/step - loss: 0.5216 - acc: 0.8507\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 16s 521us/step - loss: 0.4380 - acc: 0.8843\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 16s 526us/step - loss: 0.4171 - acc: 0.8948\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 16s 530us/step - loss: 0.3940 - acc: 0.9022\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 16s 533us/step - loss: 0.3876 - acc: 0.9056\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 16s 523us/step - loss: 0.4037 - acc: 0.9091\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 15s 516us/step - loss: 0.3835 - acc: 0.9133\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 16s 528us/step - loss: 0.3653 - acc: 0.91841s - loss: 0.\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 16s 517us/step - loss: 0.3758 - acc: 0.9195\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 16s 529us/step - loss: 0.3760 - acc: 0.9179\n",
      "30000/30000 [==============================] - 9s 305us/step\n",
      "30000/30000 [==============================] - 7s 225us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=10, num_neurons=512, optimizer_algo=adam, total= 2.9min\n",
      "[CV] activation=relu, dropout=0.5, epochs=10, num_neurons=512, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 23s 763us/step - loss: 0.5225 - acc: 0.8474\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 16s 524us/step - loss: 0.4258 - acc: 0.8844\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 15s 516us/step - loss: 0.4061 - acc: 0.8942\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 16s 528us/step - loss: 0.4000 - acc: 0.8995\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 16s 517us/step - loss: 0.3805 - acc: 0.9044\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 16s 529us/step - loss: 0.3859 - acc: 0.9073\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 15s 513us/step - loss: 0.3691 - acc: 0.91285s - los - ETA: 3s -  - ETA: 2s - los - ETA: 0s - loss: 0.3691\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 16s 517us/step - loss: 0.3728 - acc: 0.9145: 1s - loss:  - ETA: 0s - loss: 0.3726 \n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 16s 522us/step - loss: 0.3639 - acc: 0.9182\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 16s 525us/step - loss: 0.3596 - acc: 0.9208\n",
      "30000/30000 [==============================] - 9s 313us/step\n",
      "30000/30000 [==============================] - 7s 220us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=10, num_neurons=512, optimizer_algo=adam, total= 2.9min\n",
      "[CV] activation=relu, dropout=0.5, epochs=10, num_neurons=784, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 22s 743us/step - loss: 0.8825 - acc: 0.7637\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 15s 507us/step - loss: 0.4475 - acc: 0.8746: 0s - loss: 0.449\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 15s 510us/step - loss: 0.3746 - acc: 0.8932\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 15s 500us/step - loss: 0.3362 - acc: 0.9061\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 15s 507us/step - loss: 0.3077 - acc: 0.91351s - lo\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 15s 497us/step - loss: 0.2869 - acc: 0.9192\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 15s 500us/step - loss: 0.2686 - acc: 0.9251\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 15s 511us/step - loss: 0.2530 - acc: 0.92850s - loss: 0.2\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 15s 510us/step - loss: 0.2371 - acc: 0.9337\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 15s 510us/step - loss: 0.2257 - acc: 0.9384\n",
      "30000/30000 [==============================] - 10s 348us/step\n",
      "30000/30000 [==============================] - 7s 249us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=10, num_neurons=784, optimizer_algo=sgd, total= 2.8min\n",
      "[CV] activation=relu, dropout=0.5, epochs=10, num_neurons=784, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 22s 742us/step - loss: 0.8796 - acc: 0.7649\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 16s 547us/step - loss: 0.4537 - acc: 0.8710\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 16s 546us/step - loss: 0.3779 - acc: 0.8935\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 17s 558us/step - loss: 0.3383 - acc: 0.9030\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 17s 550us/step - loss: 0.3077 - acc: 0.9117\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 0.2869 - acc: 0.917 - 17s 560us/step - loss: 0.2868 - acc: 0.9178\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 18s 588us/step - loss: 0.2678 - acc: 0.9225\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 18s 598us/step - loss: 0.2505 - acc: 0.9269\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 17s 570us/step - loss: 0.2374 - acc: 0.9314\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 17s 552us/step - loss: 0.2250 - acc: 0.9357\n",
      "30000/30000 [==============================] - 10s 344us/step\n",
      "30000/30000 [==============================] - 7s 249us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=10, num_neurons=784, optimizer_algo=sgd, total= 3.1min\n",
      "[CV] activation=relu, dropout=0.5, epochs=10, num_neurons=784, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 29s 962us/step - loss: 0.5294 - acc: 0.85375s - loss: 0.5525 - ETA: 3s - loss: 0 - ETA: 2s - loss: 0.5427 - ac - ETA: 1s - loss:\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 23s 775us/step - loss: 0.4386 - acc: 0.8889\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 23s 780us/step - loss: 0.4147 - acc: 0.8980\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 23s 762us/step - loss: 0.3990 - acc: 0.9044\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 23s 756us/step - loss: 0.4027 - acc: 0.9104\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 22s 747us/step - loss: 0.3962 - acc: 0.9121\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 23s 761us/step - loss: 0.3687 - acc: 0.9177\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 23s 752us/step - loss: 0.3793 - acc: 0.9230\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 23s 752us/step - loss: 0.3612 - acc: 0.92370s - loss: 0.3603 - acc:\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 23s 758us/step - loss: 0.3838 - acc: 0.9196\n",
      "30000/30000 [==============================] - 10s 334us/step\n",
      "30000/30000 [==============================] - 8s 252us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=10, num_neurons=784, optimizer_algo=adam, total= 4.1min\n",
      "[CV] activation=relu, dropout=0.5, epochs=10, num_neurons=784, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 29s 972us/step - loss: 0.5197 - acc: 0.8540\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 23s 758us/step - loss: 0.4364 - acc: 0.8854\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 23s 765us/step - loss: 0.4053 - acc: 0.8973\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 23s 761us/step - loss: 0.3924 - acc: 0.9032\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 23s 760us/step - loss: 0.3774 - acc: 0.9096\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 23s 764us/step - loss: 0.3723 - acc: 0.91162s - loss: 0.3749 - acc: 0.91 - ETA:\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 22s 745us/step - loss: 0.3743 - acc: 0.91255s - loss: 0.3686 - - ETA: 4s - loss: 0.37 - ETA - ETA: 1s - loss\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 23s 757us/step - loss: 0.3905 - acc: 0.9131\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 22s 744us/step - loss: 0.3698 - acc: 0.9174\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 24s 784us/step - loss: 0.3898 - acc: 0.91994s - loss: 0.3893 - ac\n",
      "30000/30000 [==============================] - 10s 342us/step\n",
      "30000/30000 [==============================] - 8s 252us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=10, num_neurons=784, optimizer_algo=adam, total= 4.1min\n",
      "[CV] activation=relu, dropout=0.5, epochs=10, num_neurons=1024, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 25s 821us/step - loss: 0.8575 - acc: 0.7741\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 18s 603us/step - loss: 0.4428 - acc: 0.87700s - loss: 0.4440 - acc: \n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 19s 620us/step - loss: 0.3727 - acc: 0.8968\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 18s 614us/step - loss: 0.3323 - acc: 0.90731s - lo\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 19s 618us/step - loss: 0.3042 - acc: 0.91510s - loss: 0.3037 - acc: 0.9\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 18s 609us/step - loss: 0.2826 - acc: 0.9208\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 18s 616us/step - loss: 0.2655 - acc: 0.92462s - loss: 0.265 - ETA: 1s - l\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 18s 611us/step - loss: 0.2471 - acc: 0.9302\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 19s 623us/step - loss: 0.2349 - acc: 0.9341\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 18s 616us/step - loss: 0.2230 - acc: 0.9380\n",
      "30000/30000 [==============================] - 10s 349us/step\n",
      "30000/30000 [==============================] - 8s 274us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=10, num_neurons=1024, optimizer_algo=sgd, total= 3.4min\n",
      "[CV] activation=relu, dropout=0.5, epochs=10, num_neurons=1024, optimizer_algo=sgd \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 24s 810us/step - loss: 0.8476 - acc: 0.7788\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 19s 630us/step - loss: 0.4407 - acc: 0.87451s \n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 19s 624us/step - loss: 0.3704 - acc: 0.8937\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 19s 635us/step - loss: 0.3325 - acc: 0.90471s - loss: - ETA: 0s - loss: 0.3335 - a\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 19s 624us/step - loss: 0.3014 - acc: 0.91411s - lo\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 19s 634us/step - loss: 0.2802 - acc: 0.9203\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 19s 622us/step - loss: 0.2642 - acc: 0.9243\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 19s 625us/step - loss: 0.2474 - acc: 0.92970s - loss: 0.247\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 18s 616us/step - loss: 0.2308 - acc: 0.9343\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 19s 623us/step - loss: 0.2191 - acc: 0.9384\n",
      "30000/30000 [==============================] - 11s 355us/step\n",
      "30000/30000 [==============================] - 8s 265us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=10, num_neurons=1024, optimizer_algo=sgd, total= 3.4min\n",
      "[CV] activation=relu, dropout=0.5, epochs=10, num_neurons=1024, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 36s 1ms/step - loss: 0.5387 - acc: 0.8511: 0s - loss: 0.5414 - acc:\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 29s 980us/step - loss: 0.4377 - acc: 0.8885\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 29s 962us/step - loss: 0.4181 - acc: 0.8985\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 29s 966us/step - loss: 0.4077 - acc: 0.9040\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 29s 974us/step - loss: 0.4032 - acc: 0.9078\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 29s 969us/step - loss: 0.4067 - acc: 0.91011s\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 29s 958us/step - loss: 0.3848 - acc: 0.9138 ETA: 1s - lo\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 0.3678 - acc: 0.917 - 29s 961us/step - loss: 0.3678 - acc: 0.9173\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 29s 957us/step - loss: 0.3779 - acc: 0.9205\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 29s 970us/step - loss: 0.3709 - acc: 0.9215\n",
      "30000/30000 [==============================] - 11s 368us/step\n",
      "30000/30000 [==============================] - 8s 265us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=10, num_neurons=1024, optimizer_algo=adam, total= 5.1min\n",
      "[CV] activation=relu, dropout=0.5, epochs=10, num_neurons=1024, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 36s 1ms/step - loss: 0.5471 - acc: 0.8528\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 0.4567 - acc: 0.8850\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 29s 977us/step - loss: 0.4254 - acc: 0.8985\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 29s 968us/step - loss: 0.4095 - acc: 0.90523s - loss: 0.\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 30s 984us/step - loss: 0.3901 - acc: 0.9121\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 30s 984us/step - loss: 0.3988 - acc: 0.9108\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 30s 991us/step - loss: 0.3916 - acc: 0.9154\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 30s 988us/step - loss: 0.3863 - acc: 0.91720s - loss: 0.3865 - acc\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 30s 990us/step - loss: 0.3838 - acc: 0.92142s - loss: 0.3810 - acc: 0. - \n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 30s 996us/step - loss: 0.3893 - acc: 0.9247\n",
      "30000/30000 [==============================] - 11s 366us/step\n",
      "30000/30000 [==============================] - 8s 275us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=10, num_neurons=1024, optimizer_algo=adam, total= 5.2min\n",
      "[CV] activation=relu, dropout=0.5, epochs=20, num_neurons=256, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 16s 546us/step - loss: 1.0024 - acc: 0.7094\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 10s 347us/step - loss: 0.5329 - acc: 0.8463\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 10s 339us/step - loss: 0.4395 - acc: 0.8743\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 10s 343us/step - loss: 0.3921 - acc: 0.8893\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 11s 357us/step - loss: 0.3615 - acc: 0.8967\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 10s 348us/step - loss: 0.3320 - acc: 0.9059\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 10s 340us/step - loss: 0.3095 - acc: 0.9142\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 10s 340us/step - loss: 0.2979 - acc: 0.9156\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 10s 339us/step - loss: 0.2805 - acc: 0.9205\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 10s 347us/step - loss: 0.2692 - acc: 0.9247\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 10s 340us/step - loss: 0.2593 - acc: 0.9273\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 10s 341us/step - loss: 0.2478 - acc: 0.9299\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 10s 339us/step - loss: 0.2397 - acc: 0.9326\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 10s 345us/step - loss: 0.2338 - acc: 0.9348\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 10s 340us/step - loss: 0.2252 - acc: 0.9369\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 10s 340us/step - loss: 0.2185 - acc: 0.9391\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 10s 346us/step - loss: 0.2091 - acc: 0.9410\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 10s 349us/step - loss: 0.2064 - acc: 0.9430\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 10s 346us/step - loss: 0.1977 - acc: 0.9447\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 10s 342us/step - loss: 0.1953 - acc: 0.9444\n",
      "30000/30000 [==============================] - 9s 307us/step\n",
      "30000/30000 [==============================] - 7s 219us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=20, num_neurons=256, optimizer_algo=sgd, total= 3.7min\n",
      "[CV] activation=relu, dropout=0.5, epochs=20, num_neurons=256, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 16s 544us/step - loss: 0.9950 - acc: 0.7111\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 10s 339us/step - loss: 0.5254 - acc: 0.8473\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 10s 348us/step - loss: 0.4352 - acc: 0.8746\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 10s 339us/step - loss: 0.3851 - acc: 0.8896\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 10s 348us/step - loss: 0.3539 - acc: 0.8991\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 10s 340us/step - loss: 0.3293 - acc: 0.9045\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 11s 365us/step - loss: 0.3098 - acc: 0.9113\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 10s 336us/step - loss: 0.2893 - acc: 0.9176\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 10s 341us/step - loss: 0.2744 - acc: 0.9220\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 10s 339us/step - loss: 0.2635 - acc: 0.9248\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 10s 343us/step - loss: 0.2522 - acc: 0.9279\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 10s 338us/step - loss: 0.2441 - acc: 0.9292\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 10s 338us/step - loss: 0.2343 - acc: 0.9324\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 10s 338us/step - loss: 0.2259 - acc: 0.9343\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 10s 346us/step - loss: 0.2192 - acc: 0.9366\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 10s 341us/step - loss: 0.2131 - acc: 0.9384\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 10s 327us/step - loss: 0.2032 - acc: 0.9410\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 10s 327us/step - loss: 0.1992 - acc: 0.9428\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 10s 336us/step - loss: 0.1943 - acc: 0.9445\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 10s 327us/step - loss: 0.1899 - acc: 0.9461\n",
      "30000/30000 [==============================] - 10s 329us/step\n",
      "30000/30000 [==============================] - 7s 230us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=20, num_neurons=256, optimizer_algo=sgd, total= 3.7min\n",
      "[CV] activation=relu, dropout=0.5, epochs=20, num_neurons=256, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 19s 634us/step - loss: 0.5051 - acc: 0.8479\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 13s 437us/step - loss: 0.4248 - acc: 0.8821\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 13s 448us/step - loss: 0.4108 - acc: 0.8909\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 13s 442us/step - loss: 0.3964 - acc: 0.8954\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 13s 441us/step - loss: 0.3726 - acc: 0.9045\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 13s 448us/step - loss: 0.3805 - acc: 0.9072\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 13s 442us/step - loss: 0.3804 - acc: 0.9083\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 13s 441us/step - loss: 0.3655 - acc: 0.9124\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 13s 446us/step - loss: 0.3615 - acc: 0.9127\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 13s 441us/step - loss: 0.3536 - acc: 0.9148\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 13s 447us/step - loss: 0.3501 - acc: 0.9183\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 13s 450us/step - loss: 0.3637 - acc: 0.9139\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 13s 443us/step - loss: 0.3546 - acc: 0.9171\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 13s 441us/step - loss: 0.3650 - acc: 0.9183\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 14s 463us/step - loss: 0.3618 - acc: 0.9197\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 13s 442us/step - loss: 0.3555 - acc: 0.9210\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 13s 444us/step - loss: 0.3400 - acc: 0.9265\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 13s 450us/step - loss: 0.3425 - acc: 0.9251\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 13s 442us/step - loss: 0.3513 - acc: 0.9246\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 13s 442us/step - loss: 0.3452 - acc: 0.9247\n",
      "30000/30000 [==============================] - 9s 313us/step\n",
      "30000/30000 [==============================] - 7s 233us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=20, num_neurons=256, optimizer_algo=adam, total= 4.7min\n",
      "[CV] activation=relu, dropout=0.5, epochs=20, num_neurons=256, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 22s 741us/step - loss: 0.5184 - acc: 0.8458\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 13s 426us/step - loss: 0.4316 - acc: 0.8790\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 13s 418us/step - loss: 0.4044 - acc: 0.8907\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 13s 418us/step - loss: 0.4013 - acc: 0.8926\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 12s 411us/step - loss: 0.3843 - acc: 0.8998\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 12s 412us/step - loss: 0.3755 - acc: 0.9043\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 13s 417us/step - loss: 0.3637 - acc: 0.9090\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 12s 410us/step - loss: 0.3725 - acc: 0.9094\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 12s 409us/step - loss: 0.3666 - acc: 0.9124\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 13s 424us/step - loss: 0.3552 - acc: 0.9151\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 12s 412us/step - loss: 0.3613 - acc: 0.9158\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 12s 411us/step - loss: 0.3512 - acc: 0.9176\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 13s 419us/step - loss: 0.3510 - acc: 0.9190\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 12s 410us/step - loss: 0.3470 - acc: 0.9214\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 12s 413us/step - loss: 0.3450 - acc: 0.9198\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 13s 419us/step - loss: 0.3438 - acc: 0.9212\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 12s 413us/step - loss: 0.3487 - acc: 0.9227\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 12s 413us/step - loss: 0.3443 - acc: 0.9241\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 12s 413us/step - loss: 0.3424 - acc: 0.9219\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 13s 420us/step - loss: 0.3290 - acc: 0.9269\n",
      "30000/30000 [==============================] - 9s 314us/step\n",
      "30000/30000 [==============================] - 7s 220us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=20, num_neurons=256, optimizer_algo=adam, total= 4.9min\n",
      "[CV] activation=relu, dropout=0.5, epochs=20, num_neurons=512, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 19s 633us/step - loss: 0.9158 - acc: 0.7471\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 12s 404us/step - loss: 0.4748 - acc: 0.8632\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 12s 403us/step - loss: 0.3959 - acc: 0.8891\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 12s 414us/step - loss: 0.3530 - acc: 0.8998\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 12s 407us/step - loss: 0.3220 - acc: 0.9104\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 12s 411us/step - loss: 0.2994 - acc: 0.9155\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 13s 419us/step - loss: 0.2818 - acc: 0.9206\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 12s 404us/step - loss: 0.2667 - acc: 0.9257\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 12s 409us/step - loss: 0.2517 - acc: 0.9299\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 12s 408us/step - loss: 0.2399 - acc: 0.9337\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 12s 413us/step - loss: 0.2292 - acc: 0.9363\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 12s 415us/step - loss: 0.2207 - acc: 0.9386\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 12s 413us/step - loss: 0.2088 - acc: 0.9408\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 12s 416us/step - loss: 0.2030 - acc: 0.9441\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 12s 406us/step - loss: 0.1945 - acc: 0.9466\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 12s 403us/step - loss: 0.1888 - acc: 0.9471\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 12s 413us/step - loss: 0.1827 - acc: 0.9480\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 12s 407us/step - loss: 0.1764 - acc: 0.9514\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 12s 403us/step - loss: 0.1692 - acc: 0.9534\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 12s 411us/step - loss: 0.1665 - acc: 0.9532\n",
      "30000/30000 [==============================] - 10s 330us/step\n",
      "30000/30000 [==============================] - 7s 237us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=20, num_neurons=512, optimizer_algo=sgd, total= 4.4min\n",
      "[CV] activation=relu, dropout=0.5, epochs=20, num_neurons=512, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 19s 635us/step - loss: 0.9203 - acc: 0.7431\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 13s 418us/step - loss: 0.4812 - acc: 0.8606\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 12s 415us/step - loss: 0.3967 - acc: 0.8868\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 12s 416us/step - loss: 0.3529 - acc: 0.8979\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 12s 410us/step - loss: 0.3243 - acc: 0.9055\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 12s 400us/step - loss: 0.3002 - acc: 0.9134\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 12s 398us/step - loss: 0.2803 - acc: 0.9188\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 13s 423us/step - loss: 0.2652 - acc: 0.9242\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 12s 416us/step - loss: 0.2506 - acc: 0.9274\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 12s 417us/step - loss: 0.2368 - acc: 0.9334\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 13s 422us/step - loss: 0.2273 - acc: 0.9339\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 13s 417us/step - loss: 0.2172 - acc: 0.9381\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 12s 411us/step - loss: 0.2073 - acc: 0.9402\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 13s 429us/step - loss: 0.2016 - acc: 0.9407\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 12s 398us/step - loss: 0.1928 - acc: 0.9442\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 12s 402us/step - loss: 0.1887 - acc: 0.9466\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 12s 400us/step - loss: 0.1819 - acc: 0.9473\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 12s 407us/step - loss: 0.1743 - acc: 0.9498\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 12s 404us/step - loss: 0.1720 - acc: 0.9514\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 12s 401us/step - loss: 0.1678 - acc: 0.9521\n",
      "30000/30000 [==============================] - 10s 333us/step\n",
      "30000/30000 [==============================] - 7s 233us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=20, num_neurons=512, optimizer_algo=sgd, total= 4.4min\n",
      "[CV] activation=relu, dropout=0.5, epochs=20, num_neurons=512, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 22s 746us/step - loss: 0.5109 - acc: 0.8519\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 16s 529us/step - loss: 0.4397 - acc: 0.8859\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 16s 548us/step - loss: 0.4113 - acc: 0.8944 - ETA: 3s - loss: 0.4035 - a - ETA: 2s - lo - ETA: 1s - los\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 16s 540us/step - loss: 0.4143 - acc: 0.89851s - loss:\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 16s 527us/step - loss: 0.4070 - acc: 0.9029\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 16s 522us/step - loss: 0.3724 - acc: 0.9113\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 16s 535us/step - loss: 0.3872 - acc: 0.9121\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 16s 522us/step - loss: 0.3795 - acc: 0.9162\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 16s 533us/step - loss: 0.3713 - acc: 0.9188\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 16s 525us/step - loss: 0.3704 - acc: 0.91900s - loss: 0.3702 - acc: 0\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 16s 527us/step - loss: 0.3784 - acc: 0.9215\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 16s 538us/step - loss: 0.3474 - acc: 0.9259\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 16s 537us/step - loss: 0.3550 - acc: 0.92641s - loss: 0.3536 -  - ETA: 0s - loss: 0.3561 -\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 16s 536us/step - loss: 0.3437 - acc: 0.9292\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 16s 523us/step - loss: 0.3605 - acc: 0.92698s - - ETA: 2s - loss: 0.3631 - acc: 0. - E\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 16s 520us/step - loss: 0.3699 - acc: 0.93061s - \n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 16s 533us/step - loss: 0.3630 - acc: 0.9292: 0s - loss: 0.3617 - acc: \n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 16s 523us/step - loss: 0.3408 - acc: 0.9311\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 16s 531us/step - loss: 0.3344 - acc: 0.9324\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 16s 524us/step - loss: 0.3585 - acc: 0.93081s\n",
      "30000/30000 [==============================] - 10s 344us/step\n",
      "30000/30000 [==============================] - 7s 230us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=20, num_neurons=512, optimizer_algo=adam, total= 5.6min\n",
      "[CV] activation=relu, dropout=0.5, epochs=20, num_neurons=512, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 24s 788us/step - loss: 0.5155 - acc: 0.8512\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 16s 542us/step - loss: 0.4303 - acc: 0.88401s - los\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 16s 544us/step - loss: 0.4084 - acc: 0.8948\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 16s 541us/step - loss: 0.3794 - acc: 0.9041\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 16s 542us/step - loss: 0.3911 - acc: 0.9044\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 16s 536us/step - loss: 0.3731 - acc: 0.9103\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 16s 535us/step - loss: 0.3991 - acc: 0.9104\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 16s 543us/step - loss: 0.3638 - acc: 0.91696s - loss: 0.3628  - ETA: 2s - loss: 0.3605 \n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 16s 545us/step - loss: 0.3657 - acc: 0.9176\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 17s 551us/step - loss: 0.3736 - acc: 0.91741s - \n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 16s 537us/step - loss: 0.3699 - acc: 0.91918s - loss: 0.3703 - acc: 0.920 - ETA\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 16s 539us/step - loss: 0.3543 - acc: 0.92041s -\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 16s 529us/step - loss: 0.3440 - acc: 0.9274\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 16s 529us/step - loss: 0.3689 - acc: 0.9249\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 16s 540us/step - loss: 0.3509 - acc: 0.9254\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 16s 531us/step - loss: 0.3469 - acc: 0.9287\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 16s 542us/step - loss: 0.3491 - acc: 0.9295\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 16s 535us/step - loss: 0.3483 - acc: 0.9280ETA: 1s - loss:\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 16s 532us/step - loss: 0.3618 - acc: 0.9262\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 16s 537us/step - loss: 0.3492 - acc: 0.9312\n",
      "30000/30000 [==============================] - 10s 338us/step\n",
      "30000/30000 [==============================] - 7s 234us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=20, num_neurons=512, optimizer_algo=adam, total= 5.8min\n",
      "[CV] activation=relu, dropout=0.5, epochs=20, num_neurons=784, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 24s 792us/step - loss: 0.8703 - acc: 0.7688\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 16s 548us/step - loss: 0.4482 - acc: 0.8755\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 17s 559us/step - loss: 0.3774 - acc: 0.8943\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 16s 549us/step - loss: 0.3357 - acc: 0.9050\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 16s 548us/step - loss: 0.3069 - acc: 0.9148\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 17s 552us/step - loss: 0.2824 - acc: 0.9213\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 17s 556us/step - loss: 0.2661 - acc: 0.92410s - loss: 0.2665 \n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 17s 556us/step - loss: 0.2498 - acc: 0.9310\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 16s 545us/step - loss: 0.2391 - acc: 0.9331\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 17s 557us/step - loss: 0.2266 - acc: 0.9376\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 16s 545us/step - loss: 0.2168 - acc: 0.9394\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 16s 531us/step - loss: 0.2071 - acc: 0.9418\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 16s 535us/step - loss: 0.1983 - acc: 0.9456\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 16s 537us/step - loss: 0.1904 - acc: 0.9462\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 16s 544us/step - loss: 0.1850 - acc: 0.9480\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 16s 533us/step - loss: 0.1776 - acc: 0.9506\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 16s 538us/step - loss: 0.1727 - acc: 0.9523\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 16s 543us/step - loss: 0.1676 - acc: 0.9532\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 16s 550us/step - loss: 0.1610 - acc: 0.9547\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 16s 549us/step - loss: 0.1557 - acc: 0.9567\n",
      "30000/30000 [==============================] - 11s 359us/step\n",
      "30000/30000 [==============================] - 8s 260us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=20, num_neurons=784, optimizer_algo=sgd, total= 5.8min\n",
      "[CV] activation=relu, dropout=0.5, epochs=20, num_neurons=784, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 25s 843us/step - loss: 0.8684 - acc: 0.7668\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 19s 618us/step - loss: 0.4487 - acc: 0.8726\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 18s 592us/step - loss: 0.3771 - acc: 0.8912\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 17s 567us/step - loss: 0.3379 - acc: 0.9026\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 17s 572us/step - loss: 0.3116 - acc: 0.9109\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 17s 568us/step - loss: 0.2892 - acc: 0.9159\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 17s 563us/step - loss: 0.2688 - acc: 0.9225\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 17s 570us/step - loss: 0.2509 - acc: 0.9282\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 17s 566us/step - loss: 0.2392 - acc: 0.9316\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 17s 571us/step - loss: 0.2276 - acc: 0.9347\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 17s 562us/step - loss: 0.2145 - acc: 0.9393\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 17s 576us/step - loss: 0.2042 - acc: 0.9417\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 17s 567us/step - loss: 0.1966 - acc: 0.9447\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 17s 566us/step - loss: 0.1902 - acc: 0.94620s - loss: 0.1905 \n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 17s 575us/step - loss: 0.1817 - acc: 0.9492\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 17s 569us/step - loss: 0.1762 - acc: 0.9500\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 17s 578us/step - loss: 0.1697 - acc: 0.9520\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 17s 570us/step - loss: 0.1626 - acc: 0.9535\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 17s 579us/step - loss: 0.1583 - acc: 0.9545\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 17s 581us/step - loss: 0.1537 - acc: 0.9571\n",
      "30000/30000 [==============================] - 11s 364us/step\n",
      "30000/30000 [==============================] - 8s 264us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=20, num_neurons=784, optimizer_algo=sgd, total= 6.1min\n",
      "[CV] activation=relu, dropout=0.5, epochs=20, num_neurons=784, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 30s 999us/step - loss: 0.5379 - acc: 0.85275s - loss:\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 23s 766us/step - loss: 0.4375 - acc: 0.88630s - loss: 0.4375 - acc: 0.88\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 23s 768us/step - loss: 0.4165 - acc: 0.8958\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 23s 779us/step - loss: 0.4081 - acc: 0.9054\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 23s 773us/step - loss: 0.3968 - acc: 0.9088\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 23s 757us/step - loss: 0.3921 - acc: 0.91032s - loss: 0.3990 - - ETA: 1s -\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 23s 767us/step - loss: 0.3692 - acc: 0.9188\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 23s 763us/step - loss: 0.3814 - acc: 0.9185\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 23s 774us/step - loss: 0.3937 - acc: 0.9215\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 23s 758us/step - loss: 0.3894 - acc: 0.9208\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 23s 768us/step - loss: 0.3799 - acc: 0.9224\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 24s 788us/step - loss: 0.3618 - acc: 0.9246\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 24s 785us/step - loss: 0.3702 - acc: 0.92733s - lo\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 23s 782us/step - loss: 0.3608 - acc: 0.9286\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 0.3686 - acc: 0.9289- ETA: 6s - loss: 0.3545 - acc: 0.9 - - ETA: - ETA - 23s 764us/step - loss: 0.3684 - acc: 0.9289\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 24s 791us/step - loss: 0.3762 - acc: 0.9292\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 23s 768us/step - loss: 0.3820 - acc: 0.93181s - loss - ETA: 0s - loss: 0.37\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 23s 775us/step - loss: 0.3756 - acc: 0.9298\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 23s 778us/step - loss: 0.3576 - acc: 0.9324\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 23s 768us/step - loss: 0.3381 - acc: 0.9366\n",
      "30000/30000 [==============================] - 11s 376us/step\n",
      "30000/30000 [==============================] - 8s 268us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=20, num_neurons=784, optimizer_algo=adam, total= 8.1min\n",
      "[CV] activation=relu, dropout=0.5, epochs=20, num_neurons=784, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 0.5324 - acc: 0.8525\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 24s 789us/step - loss: 0.4358 - acc: 0.8862\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 24s 797us/step - loss: 0.3989 - acc: 0.8970\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 24s 805us/step - loss: 0.4049 - acc: 0.8998\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 24s 800us/step - loss: 0.3884 - acc: 0.9078\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 24s 797us/step - loss: 0.3841 - acc: 0.9105\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 24s 792us/step - loss: 0.3948 - acc: 0.91125s - loss: 0.3913 - acc:\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 24s 807us/step - loss: 0.3559 - acc: 0.9177\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 24s 790us/step - loss: 0.3473 - acc: 0.9224\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 24s 803us/step - loss: 0.3758 - acc: 0.9195\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 24s 803us/step - loss: 0.3653 - acc: 0.9183\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 24s 788us/step - loss: 0.3755 - acc: 0.91974s - loss: 0.3 - ETA - ETA: 1s - loss: 0.3797 - acc: 0 - ETA: 0s - loss: 0.3800\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 24s 797us/step - loss: 0.3748 - acc: 0.92103s -  - ETA: 1s - \n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 24s 788us/step - loss: 0.3718 - acc: 0.92421s\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 24s 795us/step - loss: 0.3568 - acc: 0.9255 0s - loss: 0.3566 - acc: 0.\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 24s 805us/step - loss: 0.3714 - acc: 0.9269\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 24s 789us/step - loss: 0.3510 - acc: 0.92962s - lo - ETA: 1s - los\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 24s 808us/step - loss: 0.3544 - acc: 0.9289\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 24s 789us/step - loss: 0.3400 - acc: 0.9299\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 28s 933us/step - loss: 0.3729 - acc: 0.93151\n",
      "30000/30000 [==============================] - 13s 443us/step\n",
      "30000/30000 [==============================] - 9s 308us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=20, num_neurons=784, optimizer_algo=adam, total= 8.5min\n",
      "[CV] activation=relu, dropout=0.5, epochs=20, num_neurons=1024, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 30s 991us/step - loss: 0.8378 - acc: 0.7797 - ETA:\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 21s 713us/step - loss: 0.4369 - acc: 0.8801\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 22s 717us/step - loss: 0.3641 - acc: 0.89753s - loss: 0.3682 - acc - ETA: 3s - loss: 0.3676 - \n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 22s 724us/step - loss: 0.3257 - acc: 0.9078\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 21s 716us/step - loss: 0.3025 - acc: 0.91487s - los - ETA: 1s - loss: \n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 22s 718us/step - loss: 0.2792 - acc: 0.9236\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 22s 718us/step - loss: 0.2608 - acc: 0.92740s - loss: 0.2603 -\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 22s 734us/step - loss: 0.2461 - acc: 0.9321: 0s - loss: 0.2461 - acc: 0.\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 22s 723us/step - loss: 0.2346 - acc: 0.93492s - loss: 0. - ETA: 0s - loss: 0.23\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 21s 715us/step - loss: 0.2204 - acc: 0.94010s - loss: 0.2\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 22s 718us/step - loss: 0.2097 - acc: 0.94219s - loss: 0.21  - ETA: 1s - loss: \n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 22s 726us/step - loss: 0.2002 - acc: 0.94550s - loss: 0.2002 - acc\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 22s 722us/step - loss: 0.1934 - acc: 0.94570s - loss: 0.1934 \n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 22s 725us/step - loss: 0.1856 - acc: 0.94871s - loss: 0.\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 21s 714us/step - loss: 0.1798 - acc: 0.9498\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 22s 719us/step - loss: 0.1734 - acc: 0.9532\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 22s 724us/step - loss: 0.1670 - acc: 0.95360s - loss: 0.1669 - acc\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 22s 735us/step - loss: 0.1598 - acc: 0.9548\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 22s 726us/step - loss: 0.1551 - acc: 0.9565\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 23s 752us/step - loss: 0.1505 - acc: 0.9580\n",
      "30000/30000 [==============================] - 13s 446us/step\n",
      "30000/30000 [==============================] - 10s 339us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=20, num_neurons=1024, optimizer_algo=sgd, total= 7.7min\n",
      "[CV] activation=relu, dropout=0.5, epochs=20, num_neurons=1024, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 30s 985us/step - loss: 0.8461 - acc: 0.7779\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 23s 757us/step - loss: 0.4390 - acc: 0.8775\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 22s 739us/step - loss: 0.3717 - acc: 0.8928\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 22s 749us/step - loss: 0.3290 - acc: 0.9069\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 22s 739us/step - loss: 0.3036 - acc: 0.9130\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 23s 751us/step - loss: 0.2810 - acc: 0.9189\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 21s 693us/step - loss: 0.2639 - acc: 0.9237\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 20s 657us/step - loss: 0.2442 - acc: 0.9294\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 20s 661us/step - loss: 0.2327 - acc: 0.9333\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 20s 656us/step - loss: 0.2198 - acc: 0.9372\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 20s 665us/step - loss: 0.2074 - acc: 0.9426\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 20s 654us/step - loss: 0.1993 - acc: 0.9431\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 20s 669us/step - loss: 0.1913 - acc: 0.9448\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 20s 668us/step - loss: 0.1830 - acc: 0.94931s - loss: 0\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 20s 664us/step - loss: 0.1746 - acc: 0.9503\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 20s 660us/step - loss: 0.1695 - acc: 0.9517\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 20s 667us/step - loss: 0.1628 - acc: 0.95401s - l\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 20s 659us/step - loss: 0.1576 - acc: 0.95510s - loss: 0.1566\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 20s 672us/step - loss: 0.1517 - acc: 0.9575 - ETA: 1\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 20s 658us/step - loss: 0.1476 - acc: 0.9584\n",
      "30000/30000 [==============================] - 11s 379us/step\n",
      "30000/30000 [==============================] - 9s 297us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=20, num_neurons=1024, optimizer_algo=sgd, total= 7.3min\n",
      "[CV] activation=relu, dropout=0.5, epochs=20, num_neurons=1024, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 37s 1ms/step - loss: 0.5493 - acc: 0.8524: \n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 29s 954us/step - loss: 0.4453 - acc: 0.8869\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 0.4186 - acc: 0.8985: 3s - loss: 0.408\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.4178 - acc: 0.9017\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.3926 - acc: 0.9091\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.3877 - acc: 0.9120\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.3866 - acc: 0.9165\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.3724 - acc: 0.9197\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.3896 - acc: 0.9170\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.3827 - acc: 0.9212\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.3645 - acc: 0.9244\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.3618 - acc: 0.9258\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.3677 - acc: 0.9278\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.3560 - acc: 0.9269\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.3762 - acc: 0.9289\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 0.3609 - acc: 0.9321\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.3599 - acc: 0.9313\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.3586 - acc: 0.9339\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.3464 - acc: 0.9334\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 32s 1ms/step - loss: 0.3529 - acc: 0.9357\n",
      "30000/30000 [==============================] - 13s 419us/step\n",
      "30000/30000 [==============================] - 10s 326us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=20, num_neurons=1024, optimizer_algo=adam, total=10.9min\n",
      "[CV] activation=relu, dropout=0.5, epochs=20, num_neurons=1024, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 40s 1ms/step - loss: 0.5408 - acc: 0.8486\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 30s 998us/step - loss: 0.4389 - acc: 0.8830\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 0.4270 - acc: 0.8950: 4s - lo\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 30s 998us/step - loss: 0.4093 - acc: 0.9007\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 30s 998us/step - loss: 0.3854 - acc: 0.90810s - loss: 0.3847 \n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 30s 995us/step - loss: 0.3787 - acc: 0.9128\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 30s 991us/step - loss: 0.3873 - acc: 0.9139\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 30s 992us/step - loss: 0.3516 - acc: 0.92021s - loss: 0.3510 - acc: - ETA: 0s - loss: 0.3539 - \n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 30s 995us/step - loss: 0.3735 - acc: 0.9197\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 30s 991us/step - loss: 0.3611 - acc: 0.9206\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 30s 984us/step - loss: 0.3585 - acc: 0.9228\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 30s 984us/step - loss: 0.3634 - acc: 0.9248\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 30s 998us/step - loss: 0.3499 - acc: 0.9272\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 30s 998us/step - loss: 0.3615 - acc: 0.9260\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 30s 990us/step - loss: 0.3698 - acc: 0.9286\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 29s 979us/step - loss: 0.3474 - acc: 0.93173s - lo - ETA: 1s - los - ETA: 0s - loss: 0.3482 - acc:\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 30s 991us/step - loss: 0.3511 - acc: 0.9314\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 0.3664 - acc: 0.9317\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 30s 995us/step - loss: 0.3493 - acc: 0.9325\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 30s 990us/step - loss: 0.3326 - acc: 0.9339\n",
      "30000/30000 [==============================] - 12s 401us/step\n",
      "30000/30000 [==============================] - 9s 287us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=20, num_neurons=1024, optimizer_algo=adam, total=10.3min\n",
      "[CV] activation=relu, dropout=0.5, epochs=30, num_neurons=256, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 17s 582us/step - loss: 1.0167 - acc: 0.7026\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 11s 358us/step - loss: 0.5276 - acc: 0.8492\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 11s 353us/step - loss: 0.4344 - acc: 0.8738\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 11s 359us/step - loss: 0.3856 - acc: 0.8886\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 11s 355us/step - loss: 0.3524 - acc: 0.8988\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 11s 369us/step - loss: 0.3287 - acc: 0.9059\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 11s 357us/step - loss: 0.3069 - acc: 0.9134\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 11s 353us/step - loss: 0.2941 - acc: 0.9172\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 11s 355us/step - loss: 0.2803 - acc: 0.9218\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 11s 361us/step - loss: 0.2655 - acc: 0.9263\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 11s 353us/step - loss: 0.2565 - acc: 0.9277\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 11s 354us/step - loss: 0.2455 - acc: 0.9321\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 11s 362us/step - loss: 0.2382 - acc: 0.9329\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 12s 393us/step - loss: 0.2291 - acc: 0.9345\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 13s 420us/step - loss: 0.2203 - acc: 0.9378\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 12s 408us/step - loss: 0.2138 - acc: 0.9393\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 12s 413us/step - loss: 0.2076 - acc: 0.9404\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 12s 403us/step - loss: 0.2032 - acc: 0.9426\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 12s 401us/step - loss: 0.1959 - acc: 0.9444\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 12s 409us/step - loss: 0.1962 - acc: 0.9426\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 12s 400us/step - loss: 0.1894 - acc: 0.9464\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 12s 398us/step - loss: 0.1848 - acc: 0.9467\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 13s 432us/step - loss: 0.1792 - acc: 0.95002s - loss: 0.1774 - acc: 0.\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 12s 410us/step - loss: 0.1747 - acc: 0.9505\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 12s 401us/step - loss: 0.1742 - acc: 0.9501\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 12s 401us/step - loss: 0.1714 - acc: 0.9504\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 12s 407us/step - loss: 0.1661 - acc: 0.9526\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 12s 405us/step - loss: 0.1629 - acc: 0.9527\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 12s 399us/step - loss: 0.1589 - acc: 0.9541\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 12s 408us/step - loss: 0.1559 - acc: 0.9553\n",
      "30000/30000 [==============================] - 12s 397us/step\n",
      "30000/30000 [==============================] - 9s 285us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=30, num_neurons=256, optimizer_algo=sgd, total= 6.1min\n",
      "[CV] activation=relu, dropout=0.5, epochs=30, num_neurons=256, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 19s 646us/step - loss: 0.9993 - acc: 0.7122\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 12s 402us/step - loss: 0.5179 - acc: 0.8519\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 12s 402us/step - loss: 0.4284 - acc: 0.8765\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 12s 412us/step - loss: 0.3907 - acc: 0.8858\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 12s 401us/step - loss: 0.3502 - acc: 0.8972\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 12s 403us/step - loss: 0.3297 - acc: 0.9054\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 13s 422us/step - loss: 0.3091 - acc: 0.9105\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 12s 404us/step - loss: 0.2887 - acc: 0.9168\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 12s 402us/step - loss: 0.2775 - acc: 0.9201\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 12s 402us/step - loss: 0.2612 - acc: 0.9257\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 12s 415us/step - loss: 0.2529 - acc: 0.9260\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 12s 406us/step - loss: 0.2418 - acc: 0.9308\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 12s 402us/step - loss: 0.2327 - acc: 0.9322\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 12s 410us/step - loss: 0.2250 - acc: 0.9345\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 12s 401us/step - loss: 0.2178 - acc: 0.9360\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 12s 399us/step - loss: 0.2123 - acc: 0.9401\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 12s 410us/step - loss: 0.2051 - acc: 0.9413\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 12s 401us/step - loss: 0.1985 - acc: 0.9432\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 12s 399us/step - loss: 0.1939 - acc: 0.9448\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 12s 409us/step - loss: 0.1865 - acc: 0.9467\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 12s 406us/step - loss: 0.1839 - acc: 0.9469\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 12s 397us/step - loss: 0.1765 - acc: 0.9496\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 12s 398us/step - loss: 0.1744 - acc: 0.9501\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 12s 415us/step - loss: 0.1723 - acc: 0.9502\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 12s 411us/step - loss: 0.1676 - acc: 0.9511\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 12s 399us/step - loss: 0.1645 - acc: 0.9523\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 12s 414us/step - loss: 0.1609 - acc: 0.9541\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 12s 409us/step - loss: 0.1574 - acc: 0.9549\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 12s 391us/step - loss: 0.1551 - acc: 0.9551\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 12s 398us/step - loss: 0.1518 - acc: 0.9566\n",
      "30000/30000 [==============================] - 11s 379us/step\n",
      "30000/30000 [==============================] - 8s 281us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=30, num_neurons=256, optimizer_algo=sgd, total= 6.4min\n",
      "[CV] activation=relu, dropout=0.5, epochs=30, num_neurons=256, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 21s 712us/step - loss: 0.5188 - acc: 0.8463\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 14s 466us/step - loss: 0.4282 - acc: 0.8826\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 15s 506us/step - loss: 0.3917 - acc: 0.8973\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 15s 489us/step - loss: 0.3914 - acc: 0.9003\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 14s 481us/step - loss: 0.3805 - acc: 0.9051\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 14s 478us/step - loss: 0.3783 - acc: 0.9086\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 15s 490us/step - loss: 0.3738 - acc: 0.9077\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 14s 482us/step - loss: 0.3628 - acc: 0.9133\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 15s 484us/step - loss: 0.3600 - acc: 0.9133\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 14s 482us/step - loss: 0.3618 - acc: 0.9167\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 15s 509us/step - loss: 0.3488 - acc: 0.9196\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 15s 493us/step - loss: 0.3451 - acc: 0.9196\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 15s 488us/step - loss: 0.3517 - acc: 0.9217\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 14s 478us/step - loss: 0.3456 - acc: 0.9217\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 15s 484us/step - loss: 0.3616 - acc: 0.9204\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 14s 477us/step - loss: 0.3501 - acc: 0.9250\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 14s 475us/step - loss: 0.3394 - acc: 0.9267\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 15s 485us/step - loss: 0.3383 - acc: 0.9255\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 14s 476us/step - loss: 0.3366 - acc: 0.92600s - loss: 0.3370 - acc\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 14s 481us/step - loss: 0.3314 - acc: 0.9262\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 14s 462us/step - loss: 0.3484 - acc: 0.9272\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 14s 452us/step - loss: 0.3215 - acc: 0.9304\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 14s 458us/step - loss: 0.3351 - acc: 0.9260\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 13s 447us/step - loss: 0.3479 - acc: 0.9258\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 13s 447us/step - loss: 0.3329 - acc: 0.9329\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 14s 456us/step - loss: 0.3443 - acc: 0.9290\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 13s 448us/step - loss: 0.3216 - acc: 0.9308\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 13s 449us/step - loss: 0.3379 - acc: 0.9297\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 14s 455us/step - loss: 0.3235 - acc: 0.9352\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 13s 449us/step - loss: 0.3474 - acc: 0.9309\n",
      "30000/30000 [==============================] - 11s 353us/step\n",
      "30000/30000 [==============================] - 7s 247us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=30, num_neurons=256, optimizer_algo=adam, total= 7.4min\n",
      "[CV] activation=relu, dropout=0.5, epochs=30, num_neurons=256, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 21s 694us/step - loss: 0.5179 - acc: 0.8426\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 16s 518us/step - loss: 0.4258 - acc: 0.8794\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 16s 521us/step - loss: 0.3943 - acc: 0.8919\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 15s 501us/step - loss: 0.3966 - acc: 0.8972\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 14s 477us/step - loss: 0.3963 - acc: 0.8986\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 15s 512us/step - loss: 0.3742 - acc: 0.9040\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 16s 518us/step - loss: 0.3717 - acc: 0.9088\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 15s 493us/step - loss: 0.3693 - acc: 0.9098\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 14s 481us/step - loss: 0.3560 - acc: 0.9126\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 15s 486us/step - loss: 0.3618 - acc: 0.91270s - loss: 0.35\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 15s 489us/step - loss: 0.3621 - acc: 0.9154\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 15s 487us/step - loss: 0.3585 - acc: 0.9178\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 14s 482us/step - loss: 0.3545 - acc: 0.91720s - loss: 0.3552 - a\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 15s 496us/step - loss: 0.3582 - acc: 0.9183\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 15s 486us/step - loss: 0.3627 - acc: 0.9170\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 15s 492us/step - loss: 0.3399 - acc: 0.9226\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 15s 491us/step - loss: 0.3455 - acc: 0.91994s\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 15s 486us/step - loss: 0.3329 - acc: 0.9239\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 15s 493us/step - loss: 0.3439 - acc: 0.9241\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 14s 482us/step - loss: 0.3436 - acc: 0.92083s  - ETA:\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 15s 485us/step - loss: 0.3350 - acc: 0.9249\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 15s 497us/step - loss: 0.3477 - acc: 0.9236\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 15s 496us/step - loss: 0.3322 - acc: 0.9252\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 15s 491us/step - loss: 0.3422 - acc: 0.9265\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 15s 496us/step - loss: 0.3346 - acc: 0.9278\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 15s 487us/step - loss: 0.3474 - acc: 0.9256\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 16s 517us/step - loss: 0.3280 - acc: 0.9285\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 15s 485us/step - loss: 0.3285 - acc: 0.9302\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 15s 487us/step - loss: 0.3239 - acc: 0.9291\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 15s 497us/step - loss: 0.3241 - acc: 0.92950s - loss: 0.3257 - \n",
      "30000/30000 [==============================] - 12s 396us/step\n",
      "30000/30000 [==============================] - 8s 280us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=30, num_neurons=256, optimizer_algo=adam, total= 7.7min\n",
      "[CV] activation=relu, dropout=0.5, epochs=30, num_neurons=512, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 22s 748us/step - loss: 0.9223 - acc: 0.7429\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 15s 492us/step - loss: 0.4728 - acc: 0.8671\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 14s 465us/step - loss: 0.3947 - acc: 0.8892\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 14s 461us/step - loss: 0.3530 - acc: 0.8998\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 14s 462us/step - loss: 0.3207 - acc: 0.9099\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 14s 467us/step - loss: 0.2954 - acc: 0.9171\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 14s 463us/step - loss: 0.2761 - acc: 0.92220s - loss: 0.276\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 14s 478us/step - loss: 0.2609 - acc: 0.9267\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 15s 507us/step - loss: 0.2498 - acc: 0.9295\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 14s 483us/step - loss: 0.2362 - acc: 0.9358\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 13s 437us/step - loss: 0.2293 - acc: 0.9360\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 14s 454us/step - loss: 0.2173 - acc: 0.9408\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 12s 416us/step - loss: 0.2084 - acc: 0.9424\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 12s 414us/step - loss: 0.2004 - acc: 0.9447\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 13s 430us/step - loss: 0.1931 - acc: 0.9459\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 13s 425us/step - loss: 0.1889 - acc: 0.9476\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 13s 434us/step - loss: 0.1796 - acc: 0.9493\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 14s 453us/step - loss: 0.1789 - acc: 0.9496\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 13s 422us/step - loss: 0.1722 - acc: 0.9520\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 13s 428us/step - loss: 0.1650 - acc: 0.9536\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 13s 419us/step - loss: 0.1608 - acc: 0.9550\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 12s 409us/step - loss: 0.1561 - acc: 0.9568\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 12s 410us/step - loss: 0.1518 - acc: 0.9579\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 12s 408us/step - loss: 0.1489 - acc: 0.9568\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 13s 420us/step - loss: 0.1438 - acc: 0.9595\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 12s 410us/step - loss: 0.1421 - acc: 0.9604\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 12s 408us/step - loss: 0.1392 - acc: 0.9601\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 12s 415us/step - loss: 0.1337 - acc: 0.9615\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 12s 413us/step - loss: 0.1339 - acc: 0.9619\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 12s 412us/step - loss: 0.1306 - acc: 0.9636\n",
      "30000/30000 [==============================] - 11s 358us/step\n",
      "30000/30000 [==============================] - 7s 243us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=30, num_neurons=512, optimizer_algo=sgd, total= 6.9min\n",
      "[CV] activation=relu, dropout=0.5, epochs=30, num_neurons=512, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 20s 665us/step - loss: 0.9068 - acc: 0.7475\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 13s 435us/step - loss: 0.4716 - acc: 0.8638\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 13s 433us/step - loss: 0.3961 - acc: 0.8858\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 15s 495us/step - loss: 0.3497 - acc: 0.8985\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 18s 604us/step - loss: 0.3177 - acc: 0.90961s - l\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 15s 509us/step - loss: 0.2986 - acc: 0.9141\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 15s 512us/step - loss: 0.2765 - acc: 0.9204\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 15s 491us/step - loss: 0.2643 - acc: 0.9243\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 14s 473us/step - loss: 0.2480 - acc: 0.9290\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 14s 465us/step - loss: 0.2360 - acc: 0.9327\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 15s 493us/step - loss: 0.2258 - acc: 0.93600s - loss: 0.22\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 15s 515us/step - loss: 0.2157 - acc: 0.93893s - loss: \n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 14s 482us/step - loss: 0.2057 - acc: 0.9412\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 13s 431us/step - loss: 0.2001 - acc: 0.9423\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 13s 426us/step - loss: 0.1911 - acc: 0.9458\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 14s 466us/step - loss: 0.1855 - acc: 0.9465\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 17s 557us/step - loss: 0.1771 - acc: 0.9500\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 15s 484us/step - loss: 0.1713 - acc: 0.9520\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 14s 466us/step - loss: 0.1669 - acc: 0.9523\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 14s 455us/step - loss: 0.1648 - acc: 0.9514\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 13s 445us/step - loss: 0.1573 - acc: 0.9552\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 13s 443us/step - loss: 0.1528 - acc: 0.9570\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 15s 496us/step - loss: 0.1491 - acc: 0.9575\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 17s 558us/step - loss: 0.1464 - acc: 0.95796s - loss: 0.1483  - ET\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 15s 493us/step - loss: 0.1426 - acc: 0.9601\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 14s 482us/step - loss: 0.1390 - acc: 0.95990s - loss: 0.1383 - acc: 0. - ETA: 0s - loss: 0.1379 - a\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 14s 477us/step - loss: 0.1345 - acc: 0.9626\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 16s 540us/step - loss: 0.1345 - acc: 0.9610\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 17s 564us/step - loss: 0.1296 - acc: 0.9618\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 13s 445us/step - loss: 0.1270 - acc: 0.9640\n",
      "30000/30000 [==============================] - 13s 420us/step\n",
      "30000/30000 [==============================] - 8s 273us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=30, num_neurons=512, optimizer_algo=sgd, total= 7.6min\n",
      "[CV] activation=relu, dropout=0.5, epochs=30, num_neurons=512, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 28s 942us/step - loss: 0.5323 - acc: 0.8515\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 19s 622us/step - loss: 0.4211 - acc: 0.88781s - loss: - ETA: 0s - loss: 0.4240 - \n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 20s 676us/step - loss: 0.4089 - acc: 0.89603s - loss: 0.41 - ETA: 2s - loss: 0.4124 - - ETA: 1s - loss: 0.4118 - ETA: 0s - loss: 0.4117 \n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 21s 700us/step - loss: 0.4029 - acc: 0.9035\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 22s 719us/step - loss: 0.3844 - acc: 0.90917s - los - ETA: 1\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 19s 628us/step - loss: 0.3957 - acc: 0.9124\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 22s 732us/step - loss: 0.3783 - acc: 0.91550s - loss: 0.3775 - acc: 0.915\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 20s 678us/step - loss: 0.3826 - acc: 0.91820s - loss: 0.3810 - a\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 20s 659us/step - loss: 0.3686 - acc: 0.9208\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 22s 746us/step - loss: 0.3671 - acc: 0.92196s - loss: 0.3543 - acc: 0.9 - ETA: \n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 18s 601us/step - loss: 0.3762 - acc: 0.9217\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 18s 599us/step - loss: 0.3636 - acc: 0.9260\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 20s 681us/step - loss: 0.3527 - acc: 0.92640s - loss: 0.3500 - ac\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 19s 646us/step - loss: 0.3644 - acc: 0.9265\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 18s 604us/step - loss: 0.3563 - acc: 0.9280\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 21s 696us/step - loss: 0.3760 - acc: 0.92740s - loss: 0.3758 - acc: 0.927\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 21s 685us/step - loss: 0.3636 - acc: 0.9317\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 21s 710us/step - loss: 0.3632 - acc: 0.9320\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 18s 612us/step - loss: 0.3538 - acc: 0.9332\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 18s 608us/step - loss: 0.3681 - acc: 0.9320\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 18s 585us/step - loss: 0.3588 - acc: 0.9320\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 17s 563us/step - loss: 0.3519 - acc: 0.93401s - \n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 21s 712us/step - loss: 0.3565 - acc: 0.9333\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 21s 708us/step - loss: 0.3427 - acc: 0.9329A: 5s - loss: 0.3481 - ac - ETA: 4s - ETA: 3s - loss: 0.3439 - acc: 0.9 - ETA: 3s - - ETA: 1s - loss: 0.3443 - a - ETA: 0s - loss: 0.3433 - acc: 0.9 - ETA: 0s - loss: 0.3430\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 21s 716us/step - loss: 0.3478 - acc: 0.9319\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 20s 668us/step - loss: 0.3752 - acc: 0.93430s - loss: 0.3775 - acc:\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 19s 646us/step - loss: 0.3728 - acc: 0.9372\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 22s 719us/step - loss: 0.3735 - acc: 0.93750s - loss: 0.3722 - acc: \n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 20s 659us/step - loss: 0.3649 - acc: 0.94018s - loss: 0.3430 - acc: 0.94 - ETA: 8s - l - ETA: 7s - loss: 0.3442 - - ETA: 6s - loss: 0.3470 - acc: 0.942 - ETA: 6s - loss: 0.3470 - a - ETA: 6s - loss: 0.3450  - ETA: 5s - loss\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 23s 765us/step - loss: 0.3476 - acc: 0.93798s - lo - ETA: 7s - - ETA: 6s - loss: 0.35 - ETA: 5s - loss: 0.3550 - - ETA: 4s - loss: 0.3549 - acc: 0. - ET\n",
      "30000/30000 [==============================] - 14s 451us/step\n",
      "30000/30000 [==============================] - 9s 296us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=30, num_neurons=512, optimizer_algo=adam, total=10.4min\n",
      "[CV] activation=relu, dropout=0.5, epochs=30, num_neurons=512, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 27s 906us/step - loss: 0.5191 - acc: 0.8501\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 17s 579us/step - loss: 0.4238 - acc: 0.8853\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 21s 688us/step - loss: 0.4199 - acc: 0.89356s - loss: 0.4138 - acc: 0.893 - ETA: 6s - loss: 0.4151 - acc: 0.8 - ETA: 6s - los - ETA: 0s - loss: 0.4174 - a\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 19s 624us/step - loss: 0.4027 - acc: 0.9011\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 21s 693us/step - loss: 0.3914 - acc: 0.9076\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 21s 705us/step - loss: 0.3783 - acc: 0.91271s - loss: 0.38\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 18s 610us/step - loss: 0.3859 - acc: 0.91374s - loss\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 18s 600us/step - loss: 0.3796 - acc: 0.91961s - loss - ETA: 0s - loss: 0.3794 - acc:\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 19s 623us/step - loss: 0.3794 - acc: 0.9165\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 17s 551us/step - loss: 0.3710 - acc: 0.9200\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 21s 712us/step - loss: 0.3493 - acc: 0.9242ETA: 2s - loss: 0.3496 - - ETA: 1s - ETA: 0s - loss: 0.3505 - acc: - ETA: 0s - loss: 0.3494 - acc: 0.924\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 20s 663us/step - loss: 0.3549 - acc: 0.9248\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 17s 578us/step - loss: 0.3450 - acc: 0.9254\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 21s 686us/step - loss: 0.3479 - acc: 0.92501s - lo\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 19s 621us/step - loss: 0.3574 - acc: 0.9281\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 17s 566us/step - loss: 0.3381 - acc: 0.9319\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 20s 653us/step - loss: 0.3258 - acc: 0.9337\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 22s 750us/step - loss: 0.3401 - acc: 0.9331\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 21s 700us/step - loss: 0.3478 - acc: 0.93411s - los\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 21s 690us/step - loss: 0.3461 - acc: 0.9326\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 19s 648us/step - loss: 0.3175 - acc: 0.93780s - loss: 0.3158 - acc: 0.9\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 20s 672us/step - loss: 0.3362 - acc: 0.9352\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 20s 663us/step - loss: 0.3308 - acc: 0.9371\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 19s 638us/step - loss: 0.3369 - acc: 0.93591s - loss:\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 17s 579us/step - loss: 0.3441 - acc: 0.9371\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 17s 577us/step - loss: 0.3392 - acc: 0.93740s - loss: 0.3394 - \n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 21s 705us/step - loss: 0.3409 - acc: 0.93615s - - ETA:  - ETA: 2s - loss: 0.3379 - acc - ETA: 0s - loss: 0.3395 - acc: \n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 21s 690us/step - loss: 0.3480 - acc: 0.9360\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 18s 607us/step - loss: 0.3432 - acc: 0.9392\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 18s 609us/step - loss: 0.3521 - acc: 0.9371\n",
      "30000/30000 [==============================] - 13s 445us/step\n",
      "30000/30000 [==============================] - 11s 352us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=30, num_neurons=512, optimizer_algo=adam, total=10.0min\n",
      "[CV] activation=relu, dropout=0.5, epochs=30, num_neurons=784, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 29s 974us/step - loss: 0.8805 - acc: 0.7624\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 21s 707us/step - loss: 0.4489 - acc: 0.8721\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 21s 706us/step - loss: 0.3770 - acc: 0.89357s - loss: 0.3906 - \n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 20s 677us/step - loss: 0.3376 - acc: 0.9053\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 19s 634us/step - loss: 0.3100 - acc: 0.9135\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 17s 571us/step - loss: 0.2878 - acc: 0.9206\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 21s 694us/step - loss: 0.2691 - acc: 0.9255\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 20s 673us/step - loss: 0.2518 - acc: 0.92950s - loss: 0.2518 - acc: \n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 20s 667us/step - loss: 0.2376 - acc: 0.93392s - loss: 0.2404 - acc - ETA: 2s - loss: 0.2403 - acc - ETA\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 20s 659us/step - loss: 0.2280 - acc: 0.9359\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 19s 649us/step - loss: 0.2160 - acc: 0.9397\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 20s 653us/step - loss: 0.2083 - acc: 0.9427\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 21s 700us/step - loss: 0.1994 - acc: 0.94523s - loss: 0.1990 - acc: 0.945 - ETA: 3s - loss: 0.1991 - acc: 0.9 - ETA: 3s - loss: 0.1996 - ac - ETA: 2s - loss: 0.1993 - \n",
      "Epoch 14/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 22s 725us/step - loss: 0.1886 - acc: 0.9493\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 20s 654us/step - loss: 0.1844 - acc: 0.9485\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 19s 638us/step - loss: 0.1771 - acc: 0.9505\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 19s 640us/step - loss: 0.1707 - acc: 0.95280s - loss: 0.1717 -\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 20s 650us/step - loss: 0.1663 - acc: 0.9526\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 17s 579us/step - loss: 0.1597 - acc: 0.9561\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 18s 597us/step - loss: 0.1546 - acc: 0.9568\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 18s 615us/step - loss: 0.1512 - acc: 0.95682s - loss: 0.1539 - acc: 0. \n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 18s 614us/step - loss: 0.1451 - acc: 0.95930s - loss: 0.14\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 18s 590us/step - loss: 0.1421 - acc: 0.9604\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 18s 614us/step - loss: 0.1391 - acc: 0.96200s - loss: 0.1392\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 18s 608us/step - loss: 0.1342 - acc: 0.9639\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 18s 606us/step - loss: 0.1305 - acc: 0.96442s - loss: 0.1272 - ac - ETA: 2s - loss: 0.1269 -  - ETA: 2s - loss - ETA: 0s - loss: 0.1301 - acc: 0.9 - ETA: 0s - loss: 0.1301 - a\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 23s 752us/step - loss: 0.1262 - acc: 0.9637\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 18s 585us/step - loss: 0.1243 - acc: 0.9658\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 18s 604us/step - loss: 0.1216 - acc: 0.96540s - loss: 0.1216 - acc: 0.9\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 18s 607us/step - loss: 0.1178 - acc: 0.9675- ETA:\n",
      "30000/30000 [==============================] - 13s 436us/step\n",
      "30000/30000 [==============================] - 9s 289us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=30, num_neurons=784, optimizer_algo=sgd, total=10.1min\n",
      "[CV] activation=relu, dropout=0.5, epochs=30, num_neurons=784, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 28s 930us/step - loss: 0.8815 - acc: 0.76221s - loss: 0.9021 - acc: 0.7 - ETA: 1s - loss: \n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 20s 652us/step - loss: 0.4539 - acc: 0.8704\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 19s 619us/step - loss: 0.3844 - acc: 0.88852s - loss: 0.3860 - ac - ETA: 1s - \n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 18s 589us/step - loss: 0.3400 - acc: 0.9029\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 21s 688us/step - loss: 0.3106 - acc: 0.9109\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 21s 696us/step - loss: 0.2875 - acc: 0.9181 - ETA: 2s - loss: 0.289 - ETA: 1s - loss: 0.2892 - acc: 0. - ETA: 1s -\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 0.2681 - acc: 0.923 - 19s 623us/step - loss: 0.2681 - acc: 0.9231\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 19s 618us/step - loss: 0.2519 - acc: 0.9275\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 21s 690us/step - loss: 0.2408 - acc: 0.93000s - loss: 0\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 18s 593us/step - loss: 0.2263 - acc: 0.93401s - loss: 0.2265  - ETA: 0s - loss: 0.2254 -\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 19s 632us/step - loss: 0.2144 - acc: 0.9388\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 18s 614us/step - loss: 0.2059 - acc: 0.9415\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 18s 611us/step - loss: 0.1964 - acc: 0.94280s - loss: 0.1971 - acc: 0.\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 19s 647us/step - loss: 0.1902 - acc: 0.94554s \n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 18s 612us/step - loss: 0.1823 - acc: 0.94840s - loss: 0.1824 - acc: 0.948\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 0.1778 - acc: 0.948 - 21s 687us/step - loss: 0.1779 - acc: 0.9486\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 20s 672us/step - loss: 0.1672 - acc: 0.95230s - loss: 0.1672 - acc: 0.9 - ETA: 0s - loss: 0.1674 - acc:\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 18s 607us/step - loss: 0.1643 - acc: 0.9528\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 19s 640us/step - loss: 0.1593 - acc: 0.9545\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 19s 638us/step - loss: 0.1539 - acc: 0.95621s - loss: 0.1540 - acc: - ETA: 1s - loss: 0.1538 - acc: 0.956 - ETA: 1s - l\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 20s 658us/step - loss: 0.1471 - acc: 0.9590\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 20s 667us/step - loss: 0.1448 - acc: 0.9600\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 19s 644us/step - loss: 0.1410 - acc: 0.9601\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 18s 617us/step - loss: 0.1366 - acc: 0.9609\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 18s 607us/step - loss: 0.1338 - acc: 0.9608\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 18s 605us/step - loss: 0.1297 - acc: 0.9628\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 18s 616us/step - loss: 0.1275 - acc: 0.9642\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 18s 604us/step - loss: 0.1245 - acc: 0.96460s - loss: 0.1242 - acc - ETA: 0s - loss: 0.1247 - acc: 0.96 - ETA: 0s - loss: 0.1247 - acc: 0. - ETA: 0s - loss: 0.1245 - acc: 0.9\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 19s 650us/step - loss: 0.1204 - acc: 0.9666\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 18s 613us/step - loss: 0.1183 - acc: 0.9659\n",
      "30000/30000 [==============================] - 14s 482us/step\n",
      "30000/30000 [==============================] - 10s 343us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=30, num_neurons=784, optimizer_algo=sgd, total= 9.9min\n",
      "[CV] activation=relu, dropout=0.5, epochs=30, num_neurons=784, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 41s 1ms/step - loss: 0.5273 - acc: 0.8556\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 25s 838us/step - loss: 0.4382 - acc: 0.8865\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 26s 856us/step - loss: 0.4079 - acc: 0.9002\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 26s 862us/step - loss: 0.4025 - acc: 0.9060\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 25s 825us/step - loss: 0.4054 - acc: 0.90720s - loss: 0.4084 -\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 25s 818us/step - loss: 0.4041 - acc: 0.9112\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 24s 809us/step - loss: 0.3753 - acc: 0.91630s - loss: 0\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 25s 823us/step - loss: 0.3778 - acc: 0.9190\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 24s 816us/step - loss: 0.3761 - acc: 0.9186\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 25s 830us/step - loss: 0.3609 - acc: 0.92386s \n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 25s 827us/step - loss: 0.3887 - acc: 0.9240\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 25s 822us/step - loss: 0.3601 - acc: 0.9290\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 25s 841us/step - loss: 0.3597 - acc: 0.9294\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 25s 831us/step - loss: 0.3520 - acc: 0.9292\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 27s 905us/step - loss: 0.3435 - acc: 0.9312\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 28s 929us/step - loss: 0.3595 - acc: 0.9312\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 26s 865us/step - loss: 0.3532 - acc: 0.9318\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 26s 852us/step - loss: 0.3521 - acc: 0.9344\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 26s 874us/step - loss: 0.3683 - acc: 0.9322\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 26s 866us/step - loss: 0.3405 - acc: 0.9339\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 25s 847us/step - loss: 0.3325 - acc: 0.9364\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 26s 853us/step - loss: 0.3347 - acc: 0.9362\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 26s 852us/step - loss: 0.3624 - acc: 0.9363\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 26s 855us/step - loss: 0.3524 - acc: 0.9371\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 26s 862us/step - loss: 0.3315 - acc: 0.9397\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 25s 849us/step - loss: 0.3298 - acc: 0.93933s \n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 26s 854us/step - loss: 0.3421 - acc: 0.9420\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 26s 851us/step - loss: 0.3471 - acc: 0.94030s - loss: 0.3473 - ac\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 25s 837us/step - loss: 0.3471 - acc: 0.9431\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 0.3581 - acc: 0.943 - 25s 836us/step - loss: 0.3577 - acc: 0.9430\n",
      "30000/30000 [==============================] - 13s 423us/step\n",
      "30000/30000 [==============================] - 9s 305us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=30, num_neurons=784, optimizer_algo=adam, total=13.4min\n",
      "[CV] activation=relu, dropout=0.5, epochs=30, num_neurons=784, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 39s 1ms/step - loss: 0.5200 - acc: 0.8533: 1s - loss: 0.5238\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 25s 820us/step - loss: 0.4460 - acc: 0.8863\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 25s 830us/step - loss: 0.4102 - acc: 0.8996\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 25s 826us/step - loss: 0.4100 - acc: 0.9021\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 25s 834us/step - loss: 0.3885 - acc: 0.9088\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 25s 831us/step - loss: 0.3958 - acc: 0.9106\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 26s 852us/step - loss: 0.3661 - acc: 0.9169\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 26s 858us/step - loss: 0.3844 - acc: 0.91632s - loss: 0.3837 -  - ETA: 1s \n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 25s 843us/step - loss: 0.3763 - acc: 0.9188\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 25s 833us/step - loss: 0.3500 - acc: 0.9233\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 25s 840us/step - loss: 0.3801 - acc: 0.9237\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 26s 859us/step - loss: 0.3618 - acc: 0.92851s - loss: 0.3 - ETA: 0s - loss: 0.3577\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 25s 832us/step - loss: 0.3776 - acc: 0.9249\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 25s 842us/step - loss: 0.3609 - acc: 0.9284\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 25s 834us/step - loss: 0.3836 - acc: 0.92880s - loss: 0.3829 - acc\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 25s 844us/step - loss: 0.3569 - acc: 0.92887s - loss: 0.3426 - acc: 0 - ETA: 0s - loss: 0.358\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 25s 841us/step - loss: 0.3600 - acc: 0.92982s - loss: 0.3615 \n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 25s 823us/step - loss: 0.3512 - acc: 0.93260s - loss: 0.3516 - acc: 0.932\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 26s 858us/step - loss: 0.3458 - acc: 0.9325\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 25s 840us/step - loss: 0.3558 - acc: 0.9342\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 25s 847us/step - loss: 0.3569 - acc: 0.9320\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 25s 838us/step - loss: 0.3356 - acc: 0.9363\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 26s 850us/step - loss: 0.3628 - acc: 0.9346\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 27s 911us/step - loss: 0.3585 - acc: 0.9337\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 25s 846us/step - loss: 0.3375 - acc: 0.9360\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 25s 818us/step - loss: 0.3607 - acc: 0.9348\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 26s 852us/step - loss: 0.3603 - acc: 0.9367\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 25s 846us/step - loss: 0.3475 - acc: 0.9394\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 27s 902us/step - loss: 0.3483 - acc: 0.9375\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 31s 1ms/step - loss: 0.3600 - acc: 0.9376\n",
      "30000/30000 [==============================] - 15s 512us/step\n",
      "30000/30000 [==============================] - 11s 359us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=30, num_neurons=784, optimizer_algo=adam, total=13.4min\n",
      "[CV] activation=relu, dropout=0.5, epochs=30, num_neurons=1024, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 35s 1ms/step - loss: 0.8408 - acc: 0.7797\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 25s 848us/step - loss: 0.4375 - acc: 0.8784TA: 10s \n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 26s 882us/step - loss: 0.3678 - acc: 0.89924s - loss: 0.3719 - ETA: 1s - loss: 0.3690 - a - ETA: 1s - loss: 0\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 26s 852us/step - loss: 0.3315 - acc: 0.90830s - loss: 0.3326 - acc - ETA: 0s - loss: 0.3318 - acc: \n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 25s 845us/step - loss: 0.3042 - acc: 0.9141\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 26s 853us/step - loss: 0.2827 - acc: 0.9210\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 26s 854us/step - loss: 0.2636 - acc: 0.92674s - loss: 0.2 - ETA: 3s - loss: 0.\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 25s 845us/step - loss: 0.2465 - acc: 0.9324\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 26s 852us/step - loss: 0.2356 - acc: 0.9352\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 27s 892us/step - loss: 0.2227 - acc: 0.9394\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 26s 856us/step - loss: 0.2108 - acc: 0.9425\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 25s 821us/step - loss: 0.2028 - acc: 0.9432\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 24s 796us/step - loss: 0.1931 - acc: 0.9477\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 24s 810us/step - loss: 0.1857 - acc: 0.9500\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 22s 746us/step - loss: 0.1801 - acc: 0.9494\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 27s 893us/step - loss: 0.1722 - acc: 0.9525\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 27s 907us/step - loss: 0.1682 - acc: 0.9542\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 0.1596 - acc: 0.9569: 3s - loss: 0\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 22s 728us/step - loss: 0.1571 - acc: 0.95730s - loss: 0.1571 - acc\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 0.1509 - acc: 0.958 - 25s 820us/step - loss: 0.1509 - acc: 0.9583\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 23s 766us/step - loss: 0.1458 - acc: 0.9591\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 28s 923us/step - loss: 0.1431 - acc: 0.96030s - loss: 0.1425 \n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 28s 941us/step - loss: 0.1392 - acc: 0.9621\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 24s 799us/step - loss: 0.1339 - acc: 0.9637\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 25s 839us/step - loss: 0.1293 - acc: 0.9640\n",
      "Epoch 26/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 24s 813us/step - loss: 0.1275 - acc: 0.96450s - loss: 0.1273 - acc: 0\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 26s 851us/step - loss: 0.1234 - acc: 0.9654\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 26s 853us/step - loss: 0.1192 - acc: 0.9682\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 30s 1ms/step - loss: 0.1188 - acc: 0.9656: 7s  - ET - ETA: 5s - loss - ETA: 4s - l - \n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 25s 849us/step - loss: 0.1153 - acc: 0.9683\n",
      "30000/30000 [==============================] - 15s 512us/step\n",
      "30000/30000 [==============================] - 11s 370us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=30, num_neurons=1024, optimizer_algo=sgd, total=13.3min\n",
      "[CV] activation=relu, dropout=0.5, epochs=30, num_neurons=1024, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 36s 1ms/step - loss: 0.8651 - acc: 0.7716\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 24s 785us/step - loss: 0.4416 - acc: 0.8756\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 24s 789us/step - loss: 0.3665 - acc: 0.89560s - loss: 0.3672 - acc:\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 24s 801us/step - loss: 0.3289 - acc: 0.9064\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 23s 781us/step - loss: 0.3008 - acc: 0.9139\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 24s 801us/step - loss: 0.2828 - acc: 0.9193: 0s - loss: 0.2834 \n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 25s 832us/step - loss: 0.2607 - acc: 0.9254\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 29s 957us/step - loss: 0.2437 - acc: 0.9289\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 28s 923us/step - loss: 0.2311 - acc: 0.93381s - loss: 0.\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 26s 875us/step - loss: 0.2175 - acc: 0.93938s - loss: 0. - ETA: 6s -\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 26s 861us/step - loss: 0.2071 - acc: 0.9412\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 24s 786us/step - loss: 0.1987 - acc: 0.9441\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 27s 910us/step - loss: 0.1901 - acc: 0.94600s - loss: 0.1895 - acc:  - ETA: 0s - loss: 0.1898 - acc:\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 26s 883us/step - loss: 0.1816 - acc: 0.94861s - loss: 0.1\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 22s 738us/step - loss: 0.1746 - acc: 0.9508\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 24s 790us/step - loss: 0.1656 - acc: 0.9524\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 24s 796us/step - loss: 0.1617 - acc: 0.9538\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 24s 787us/step - loss: 0.1551 - acc: 0.9554\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 25s 817us/step - loss: 0.1504 - acc: 0.9569\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 22s 722us/step - loss: 0.1473 - acc: 0.9575\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 23s 767us/step - loss: 0.1420 - acc: 0.95973s - loss: 0.1428 - acc: 0.9 - ETA: 0s - loss: 0\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 23s 773us/step - loss: 0.1374 - acc: 0.95989\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 24s 806us/step - loss: 0.1329 - acc: 0.9632\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 23s 765us/step - loss: 0.1295 - acc: 0.9640\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 23s 774us/step - loss: 0.1268 - acc: 0.9645\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 23s 757us/step - loss: 0.1235 - acc: 0.9656\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 27s 914us/step - loss: 0.1199 - acc: 0.9661\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.1158 - acc: 0.9665: 1s - loss: 0.1166 - acc:  - ETA: 0s - loss: 0.1163 - acc\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 29s 951us/step - loss: 0.1125 - acc: 0.9692\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 25s 840us/step - loss: 0.1102 - acc: 0.96921s - loss\n",
      "30000/30000 [==============================] - 25s 820us/step\n",
      "30000/30000 [==============================] - 13s 431us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=30, num_neurons=1024, optimizer_algo=sgd, total=13.2min\n",
      "[CV] activation=relu, dropout=0.5, epochs=30, num_neurons=1024, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 57s 2ms/step - loss: 0.5414 - acc: 0.8524\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 36s 1ms/step - loss: 0.4357 - acc: 0.8889\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 37s 1ms/step - loss: 0.4297 - acc: 0.8953\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 36s 1ms/step - loss: 0.4152 - acc: 0.9047\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 0.4009 - acc: 0.9088\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 36s 1ms/step - loss: 0.3958 - acc: 0.9136\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.3984 - acc: 0.9174\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 0.3898 - acc: 0.9179\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.3789 - acc: 0.9220\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.3868 - acc: 0.9219\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.3634 - acc: 0.9249\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.3619 - acc: 0.9263\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.3535 - acc: 0.9294\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.3912 - acc: 0.9267: 2s - loss: 0.3917 - acc: 0.9 - ETA: 2s - loss: 0.3905 - acc: - ETA: 2\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 33s 1ms/step - loss: 0.3718 - acc: 0.9296\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.3693 - acc: 0.9308\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.3570 - acc: 0.9325\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 35s 1ms/step - loss: 0.3616 - acc: 0.9307\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.3535 - acc: 0.9356\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.3507 - acc: 0.9364\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.3671 - acc: 0.9331: 0s - loss: 0.3670\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.3518 - acc: 0.9384\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.3687 - acc: 0.9388\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.3931 - acc: 0.9360\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - ETA: 0s - loss: 0.3506 - acc: 0.939 - 34s 1ms/step - loss: 0.3504 - acc: 0.9396\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.3819 - acc: 0.9383\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.3611 - acc: 0.9412\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.3591 - acc: 0.9389\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.3330 - acc: 0.9419\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.3468 - acc: 0.9417\n",
      "30000/30000 [==============================] - 16s 521us/step\n",
      "30000/30000 [==============================] - 12s 394us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=30, num_neurons=1024, optimizer_algo=adam, total=18.2min\n",
      "[CV] activation=relu, dropout=0.5, epochs=30, num_neurons=1024, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 45s 1ms/step - loss: 0.5409 - acc: 0.8531\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.4396 - acc: 0.8865\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.4045 - acc: 0.8975\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.4088 - acc: 0.9030\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.3994 - acc: 0.9071\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 35s 1ms/step - loss: 0.3919 - acc: 0.9113\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 36s 1ms/step - loss: 0.3852 - acc: 0.9170\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.3738 - acc: 0.9181\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.3851 - acc: 0.9196\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.3717 - acc: 0.9220\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.3815 - acc: 0.9236\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.3656 - acc: 0.9218\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 36s 1ms/step - loss: 0.3566 - acc: 0.9295\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 36s 1ms/step - loss: 0.3607 - acc: 0.9284: 1s - loss: 0.358\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 35s 1ms/step - loss: 0.3497 - acc: 0.9294\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 36s 1ms/step - loss: 0.3639 - acc: 0.9295\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 36s 1ms/step - loss: 0.3543 - acc: 0.9328: 0s - loss: 0.35\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 38s 1ms/step - loss: 0.3993 - acc: 0.9286\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 36s 1ms/step - loss: 0.3772 - acc: 0.9310\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 36s 1ms/step - loss: 0.3552 - acc: 0.9338\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 36s 1ms/step - loss: 0.3401 - acc: 0.9354\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 37s 1ms/step - loss: 0.3690 - acc: 0.9354\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 35s 1ms/step - loss: 0.3296 - acc: 0.9385\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 37s 1ms/step - loss: 0.3374 - acc: 0.9364\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 34s 1ms/step - loss: 0.3601 - acc: 0.9363\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 35s 1ms/step - loss: 0.3554 - acc: 0.9360\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 35s 1ms/step - loss: 0.3658 - acc: 0.9382\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 41s 1ms/step - loss: 0.3432 - acc: 0.9400\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 36s 1ms/step - loss: 0.3459 - acc: 0.9406: 0s - loss: 0.346\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 40s 1ms/step - loss: 0.3558 - acc: 0.9344\n",
      "30000/30000 [==============================] - 16s 524us/step\n",
      "30000/30000 [==============================] - 9s 315us/step\n",
      "[CV]  activation=relu, dropout=0.5, epochs=30, num_neurons=1024, optimizer_algo=adam, total=18.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 288 out of 288 | elapsed: 1476.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.3374 - acc: 0.8997\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 51s 856us/step - loss: 0.2585 - acc: 0.9290\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 51s 843us/step - loss: 0.2434 - acc: 0.9359\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 51s 857us/step - loss: 0.2380 - acc: 0.9405\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 52s 862us/step - loss: 0.2393 - acc: 0.94300s - loss: 0.2384\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 52s 862us/step - loss: 0.2145 - acc: 0.9477\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 52s 866us/step - loss: 0.2137 - acc: 0.9485\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 51s 846us/step - loss: 0.2030 - acc: 0.9517\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 51s 844us/step - loss: 0.1976 - acc: 0.9531\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 51s 856us/step - loss: 0.1985 - acc: 0.9535\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 51s 853us/step - loss: 0.1905 - acc: 0.9566\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 52s 859us/step - loss: 0.1942 - acc: 0.9558\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 51s 844us/step - loss: 0.1891 - acc: 0.9579\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 51s 858us/step - loss: 0.1953 - acc: 0.9580\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 52s 861us/step - loss: 0.1944 - acc: 0.9584\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 51s 848us/step - loss: 0.1793 - acc: 0.9606\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 52s 859us/step - loss: 0.1901 - acc: 0.9601\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 52s 869us/step - loss: 0.1753 - acc: 0.96172s - loss: - ETA: 1s - loss: \n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 51s 849us/step - loss: 0.1706 - acc: 0.9637\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 55s 922us/step - loss: 0.1771 - acc: 0.9626\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 51s 854us/step - loss: 0.1671 - acc: 0.9646\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 50s 842us/step - loss: 0.1814 - acc: 0.9632\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 51s 846us/step - loss: 0.1911 - acc: 0.9636\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 50s 835us/step - loss: 0.1709 - acc: 0.9650\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 50s 839us/step - loss: 0.1645 - acc: 0.9654\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 50s 834us/step - loss: 0.1701 - acc: 0.9673\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 50s 828us/step - loss: 0.1719 - acc: 0.9657\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 50s 833us/step - loss: 0.1706 - acc: 0.96690s - loss: 0.17\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 51s 855us/step - loss: 0.1716 - acc: 0.9676\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 52s 865us/step - loss: 0.1684 - acc: 0.9678\n"
     ]
    }
   ],
   "source": [
    "grid_search_fit = grid_search.fit(x_trainval_nn, y_trainval_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eoKrt9u68vVe",
    "outputId": "5699598e-c893-464a-b37e-9a9b54e644f4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Validation Accuracy Score from CV: 97.24% using {'activation': 'sigmoid', 'dropout': 0.5, 'epochs': 30, 'num_neurons': 784, 'optimizer_algo': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best Validation Accuracy Score from CV: %.2f%% using %s\" % ((100*grid_search_fit.best_score_), grid_search_fit.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([  18.35012329,   38.90721452,   54.45113087,   98.41866636,\n",
      "         75.98988795,  137.59147894,   91.04404223,  176.71902561,\n",
      "         38.84992111,   70.77791727,   88.41152477,  231.98152554,\n",
      "        171.3811605 ,  324.00426853,  192.63055325,  381.47989011,\n",
      "         72.13069952,  119.23986983,  139.11549342,  250.35243809,\n",
      "        202.74002504,  386.00446618,  267.54767787,  508.16244376,\n",
      "         32.59298944,   45.89766955,   55.32063389,   88.90156686,\n",
      "         77.55560124,  131.75551927,   94.90850747,  169.15433502,\n",
      "         70.68764532,  102.38776886,  161.16102338,  229.21274757,\n",
      "        205.19938505,  307.65329862,  236.20360732,  482.31411624,\n",
      "        135.3106432 ,  178.39199567,  189.82958114,  299.96988237,\n",
      "        242.34379482,  470.80326533,  347.85084438,  651.03312516,\n",
      "         44.03293002,   56.4422009 ,   65.93471849,  104.22960114,\n",
      "         89.20106757,  154.92654133,  111.6268419 ,  199.38199925,\n",
      "         94.85861504,  120.73370552,  137.50570023,  216.39463615,\n",
      "        188.12890983,  321.09927952,  231.71035051,  407.84542048,\n",
      "        160.69766188,  195.59250963,  215.61002076,  332.38287556,\n",
      "        296.06064332,  495.45813   ,  365.94899821,  629.50472796,\n",
      "         58.95541883,   69.58710635,   76.60495567,  117.13517725,\n",
      "        102.41410434,  153.95375669,  111.29702878,  191.52585912,\n",
      "        102.8742218 ,  133.96005619,  147.39754331,  210.12942851,\n",
      "        187.05490482,  302.87226188,  225.84163332,  382.45227838,\n",
      "        167.42463827,  220.49856782,  233.98981965,  328.82114697,\n",
      "        306.55791962,  555.06008613,  436.32014906,  671.42685974,\n",
      "         84.12533212,  109.49398637,  108.56035173,  159.14042199,\n",
      "        153.90429246,  204.57298613,  153.99649405,  260.25455606,\n",
      "        166.32180238,  220.88743818,  226.66011071,  305.10696387,\n",
      "        316.7780776 ,  436.50130415,  325.47060692,  501.51410055,\n",
      "        262.42956233,  334.5485605 ,  336.99318612,  450.17433345,\n",
      "        462.45688236,  640.88904834,  513.06951737,  834.06006455,\n",
      "        100.87338901,  128.18781352,  126.65648997,  164.45052791,\n",
      "        167.40269852,  234.98050857,  192.59076917,  300.6138581 ,\n",
      "        211.9029783 ,  280.46890783,  254.07133627,  331.01097894,\n",
      "        346.52621639,  484.38312459,  434.81437743,  623.99430478,\n",
      "        363.75542653,  443.98485124,  425.38365281,  600.22308838,\n",
      "        586.31935513,  790.87418425,  776.80490446, 1083.26714134]), 'std_fit_time': array([4.57514644e-01, 3.64144933e+00, 7.99374104e-01, 3.27946877e+00,\n",
      "       1.77422953e+00, 2.18873584e+00, 4.47245240e-01, 2.61357379e+00,\n",
      "       5.18963492e+00, 1.92364442e+00, 7.71104813e-01, 2.69965013e+01,\n",
      "       3.20160627e+00, 3.70176593e+01, 1.55102577e+01, 1.64736543e+01,\n",
      "       9.03233135e+00, 3.29186821e+00, 2.69517815e+00, 7.40742326e-01,\n",
      "       7.60965586e-01, 7.80561328e-01, 6.20231855e+00, 2.01490414e+00,\n",
      "       1.20988297e+00, 1.41188407e+00, 3.11815739e-01, 5.61137080e-01,\n",
      "       3.42956185e-01, 8.23905587e-01, 4.49069381e-01, 6.33271694e-01,\n",
      "       4.91358161e-01, 5.97695839e+00, 5.76486754e+00, 4.46384215e+00,\n",
      "       1.58821295e+01, 2.28131087e+01, 7.59396577e+00, 5.40626345e+01,\n",
      "       1.22571750e+01, 3.14164305e+00, 1.08756994e+01, 1.61999122e+01,\n",
      "       5.72056770e-02, 7.68571973e+00, 1.08071327e-01, 9.69472599e+00,\n",
      "       1.97515523e+00, 1.32018924e+00, 8.93912196e-01, 1.13460016e+00,\n",
      "       9.78156328e-02, 2.75111437e-01, 2.11660981e-01, 5.34396648e-01,\n",
      "       6.94742799e-01, 3.06548119e-01, 2.39073038e-02, 3.49774241e+00,\n",
      "       7.29770660e-01, 2.16219628e+00, 8.08650255e-01, 1.94113529e+00,\n",
      "       1.16240168e+00, 2.78481495e+00, 9.40607667e-01, 1.59218109e+00,\n",
      "       8.39327455e-01, 4.96538997e-01, 1.36090326e+00, 7.58892667e+00,\n",
      "       1.55708838e+00, 2.63515115e-01, 3.36737633e-01, 7.80200362e-01,\n",
      "       8.73883367e-01, 5.60613310e+00, 5.67927361e-02, 1.29443789e+00,\n",
      "       6.76800251e-01, 1.11273181e+00, 1.73193419e+00, 1.92539632e+00,\n",
      "       1.86337245e+00, 1.00245118e-01, 2.71614313e-01, 3.01044297e+00,\n",
      "       1.36606240e+00, 2.22495914e+00, 1.67666638e+00, 9.76442575e-01,\n",
      "       6.25002027e-01, 9.01076604e+01, 2.21529323e+01, 6.31589758e+00,\n",
      "       2.15955853e+00, 9.93967056e-04, 8.72234464e-01, 1.25504315e+00,\n",
      "       1.63155830e+00, 5.61010838e-01, 1.73076963e+00, 8.63833654e+00,\n",
      "       1.21397781e+00, 3.58040154e+00, 4.36779499e+00, 3.21343970e+00,\n",
      "       2.70863390e+00, 2.45407786e+01, 3.22598803e+00, 1.36539960e+01,\n",
      "       4.36836195e+00, 1.75462127e-01, 2.95593846e+00, 7.69381642e-01,\n",
      "       4.05530918e+00, 1.15919960e+01, 1.51320283e+01, 7.21701813e+00,\n",
      "       1.38285613e+00, 2.00176716e+00, 2.02525055e+00, 9.55648422e-02,\n",
      "       7.85195112e+00, 9.53209400e-02, 1.55379236e+00, 2.78368771e+00,\n",
      "       1.10607541e+00, 6.91018963e+00, 1.12689257e-01, 4.75182796e+00,\n",
      "       9.25000036e+00, 1.04392214e+01, 1.09714459e+01, 1.60552579e+01,\n",
      "       8.89343369e+00, 8.79164469e+00, 1.96664909e+01, 1.07536956e+01,\n",
      "       4.22341263e+00, 2.83312094e+00, 6.43383551e+00, 7.21377182e+00]), 'mean_score_time': array([7.75925398e-01, 8.86630416e-01, 1.62565637e+00, 1.39925969e+00,\n",
      "       2.27292407e+00, 1.88239276e+00, 2.32378125e+00, 2.28282499e+00,\n",
      "       8.88128996e-01, 9.43976402e-01, 1.62375224e+00, 2.07913446e+00,\n",
      "       2.69742107e+00, 2.77840757e+00, 2.88120008e+00, 2.97355199e+00,\n",
      "       1.22223461e+00, 1.31151295e+00, 2.02602386e+00, 2.12681615e+00,\n",
      "       2.62874269e+00, 8.15320706e+00, 3.22388196e+00, 3.87856424e+00,\n",
      "       1.67698836e+00, 1.55313027e+00, 2.12888396e+00, 2.15377307e+00,\n",
      "       2.82749355e+00, 2.81844854e+00, 3.29134035e+00, 3.32274926e+00,\n",
      "       1.79357076e+00, 2.54648507e+00, 2.42153275e+01, 1.90595227e+01,\n",
      "       4.21511630e+01, 3.45539761e+00, 5.30018365e+00, 4.83544064e+00,\n",
      "       2.86128640e+00, 3.15569985e+00, 3.07989192e+00, 3.28985691e+00,\n",
      "       4.06174195e+00, 4.34302640e+00, 4.90824533e+00, 6.12611389e+00,\n",
      "       2.88051856e+00, 2.96003771e+00, 3.73904252e+00, 3.91996539e+00,\n",
      "       4.48834872e+00, 4.67516184e+00, 5.17946541e+00, 5.23716307e+00,\n",
      "       3.52961993e+00, 3.77360451e+00, 4.29475164e+00, 4.28901577e+00,\n",
      "       5.25440264e+00, 5.42683589e+00, 5.58434582e+00, 5.67714155e+00,\n",
      "       4.02548087e+00, 4.14480042e+00, 4.84114122e+00, 4.91130340e+00,\n",
      "       5.69088209e+00, 5.73531711e+00, 6.20232654e+00, 6.44917405e+00,\n",
      "       4.76971209e+00, 4.77179778e+00, 5.32564020e+00, 5.45906472e+00,\n",
      "       6.07739890e+00, 5.81757176e+00, 5.91297865e+00, 6.13799822e+00,\n",
      "       4.46838164e+00, 4.62812531e+00, 5.46308887e+00, 5.52412713e+00,\n",
      "       6.30282235e+00, 6.21927845e+00, 6.59729588e+00, 6.78810537e+00,\n",
      "       5.25817454e+00, 5.56653774e+00, 5.99019909e+00, 5.88562715e+00,\n",
      "       6.70016682e+00, 5.82218218e+03, 8.56852913e+00, 8.06217706e+00,\n",
      "       7.02845120e+00, 7.13531876e+00, 7.30074584e+00, 7.66626883e+00,\n",
      "       8.28772485e+00, 8.02890027e+00, 8.50057805e+00, 9.00364578e+00,\n",
      "       7.60671425e+00, 7.84348786e+00, 8.58191776e+00, 8.09401464e+00,\n",
      "       9.83440614e+00, 9.05256116e+00, 8.96200621e+00, 9.20423663e+00,\n",
      "       7.73001683e+00, 7.95671821e+00, 8.68006051e+00, 8.38421369e+00,\n",
      "       9.13335419e+00, 9.52893615e+00, 1.02209677e+01, 1.00016365e+01,\n",
      "       8.66738236e+00, 8.75721908e+00, 9.32074451e+00, 9.28392863e+00,\n",
      "       1.03773015e+01, 1.01507025e+01, 1.05568895e+01, 1.10181717e+01,\n",
      "       9.55080700e+00, 9.47176278e+00, 9.94314134e+00, 1.02455370e+01,\n",
      "       1.10905672e+01, 1.22988504e+01, 1.23890631e+01, 1.23033940e+01,\n",
      "       1.16497465e+01, 1.12311471e+01, 1.16777771e+01, 1.34508392e+01,\n",
      "       1.37710199e+01, 1.40887299e+01, 2.00271382e+01, 1.57657218e+01]), 'std_score_time': array([1.73534870e-01, 1.79521203e-01, 2.20415831e-01, 6.18346930e-02,\n",
      "       2.11434007e-01, 2.99285650e-02, 8.27729702e-02, 5.37841320e-02,\n",
      "       4.83682156e-02, 1.54597759e-02, 5.27855158e-02, 1.08402729e-01,\n",
      "       3.29750776e-01, 5.21210432e-01, 2.91123390e-01, 9.82370377e-02,\n",
      "       9.47487354e-03, 8.96167755e-03, 1.31088734e-01, 2.04464197e-02,\n",
      "       2.21759081e-01, 5.22004604e+00, 8.72662067e-02, 6.43210769e-01,\n",
      "       7.48989582e-02, 1.49759054e-02, 3.59952450e-03, 7.44748116e-03,\n",
      "       1.15602851e-01, 1.59745216e-02, 5.92517853e-03, 2.65280008e-02,\n",
      "       6.77084923e-03, 7.04294801e-01, 2.10223320e+01, 1.23344628e+01,\n",
      "       6.79959476e+00, 1.59750700e-01, 9.92172122e-01, 1.03959560e-01,\n",
      "       2.57215023e-01, 7.26815462e-02, 1.05375051e-01, 1.17080450e-01,\n",
      "       1.92021728e-01, 2.79778481e-01, 2.76471853e-01, 1.11423707e+00,\n",
      "       2.33701468e-02, 3.39601040e-02, 6.18727207e-02, 1.40986562e-01,\n",
      "       9.28544998e-03, 2.74269581e-02, 2.62411833e-02, 1.41520262e-01,\n",
      "       1.99551582e-02, 1.56107306e-01, 9.77396965e-03, 9.45568085e-03,\n",
      "       1.29514217e-01, 3.48649859e-01, 1.56819820e-02, 7.29882717e-03,\n",
      "       4.40148115e-02, 3.69243622e-02, 1.10146046e-01, 7.14932680e-02,\n",
      "       4.37878370e-02, 5.64218760e-02, 2.14300871e-01, 1.90189242e-01,\n",
      "       1.08111262e-01, 6.49801493e-02, 8.82780552e-02, 2.80249357e-01,\n",
      "       3.85423899e-02, 1.01584196e-02, 2.47197151e-02, 6.11411333e-02,\n",
      "       2.33674049e-03, 2.29076147e-02, 3.38787198e-01, 2.22232223e-01,\n",
      "       3.63304615e-02, 1.77036166e-01, 1.52493715e-02, 1.20705962e-01,\n",
      "       2.87853599e-01, 1.56190753e-01, 3.57658386e-01, 2.06910729e-01,\n",
      "       7.95813799e-02, 5.81379263e+03, 1.57217741e-01, 2.55204439e-02,\n",
      "       9.99121666e-02, 9.65001583e-02, 2.13606715e-01, 1.70307875e-01,\n",
      "       3.43855977e-01, 2.33017206e-02, 2.31082797e-01, 4.60125089e-01,\n",
      "       1.66104078e-01, 2.48607278e-01, 2.92367935e-02, 3.13058853e-01,\n",
      "       3.76690865e-01, 9.00882483e-02, 5.05483150e-03, 4.02485132e-02,\n",
      "       9.50349569e-02, 1.63487196e-01, 2.89255500e-01, 1.85434818e-02,\n",
      "       1.24928951e-01, 2.18787193e-02, 2.46049762e-01, 4.51776981e-02,\n",
      "       7.80020952e-02, 2.26503134e-01, 1.59130096e-01, 1.23595476e-01,\n",
      "       6.46932125e-02, 1.18355751e-01, 9.29303169e-02, 4.08219099e-02,\n",
      "       3.18934917e-01, 5.89789152e-02, 4.45164442e-02, 8.97688866e-02,\n",
      "       9.07484293e-02, 9.97790456e-01, 1.00072265e+00, 2.80326247e-01,\n",
      "       2.80833840e-01, 6.46573782e-01, 9.18489933e-01, 8.54152441e-02,\n",
      "       6.97151899e-01, 1.38800573e+00, 4.66309571e+00, 1.13839388e-01]), 'param_activation': masked_array(data=['sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
      "                   'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
      "                   'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
      "                   'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
      "                   'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
      "                   'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
      "                   'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
      "                   'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
      "                   'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
      "                   'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
      "                   'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
      "                   'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
      "                   'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
      "                   'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',\n",
      "                   'sigmoid', 'sigmoid', 'relu', 'relu', 'relu', 'relu',\n",
      "                   'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
      "                   'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
      "                   'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
      "                   'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
      "                   'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
      "                   'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
      "                   'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
      "                   'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
      "                   'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
      "                   'relu', 'relu', 'relu', 'relu', 'relu'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_dropout': masked_array(data=[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
      "                   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
      "                   0.0, 0.0, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
      "                   0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
      "                   0.3, 0.3, 0.3, 0.3, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
      "                   0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
      "                   0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
      "                   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
      "                   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.3, 0.3,\n",
      "                   0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
      "                   0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.5,\n",
      "                   0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
      "                   0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
      "                   0.5],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_epochs': masked_array(data=[10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20, 20,\n",
      "                   20, 20, 30, 30, 30, 30, 30, 30, 30, 30, 10, 10, 10, 10,\n",
      "                   10, 10, 10, 10, 20, 20, 20, 20, 20, 20, 20, 20, 30, 30,\n",
      "                   30, 30, 30, 30, 30, 30, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   20, 20, 20, 20, 20, 20, 20, 20, 30, 30, 30, 30, 30, 30,\n",
      "                   30, 30, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20,\n",
      "                   20, 20, 20, 20, 30, 30, 30, 30, 30, 30, 30, 30, 10, 10,\n",
      "                   10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "                   30, 30, 30, 30, 30, 30, 30, 30, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 20, 20, 20, 20, 20, 20, 20, 20, 30, 30, 30, 30,\n",
      "                   30, 30, 30, 30],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_num_neurons': masked_array(data=[256, 256, 512, 512, 784, 784, 1024, 1024, 256, 256,\n",
      "                   512, 512, 784, 784, 1024, 1024, 256, 256, 512, 512,\n",
      "                   784, 784, 1024, 1024, 256, 256, 512, 512, 784, 784,\n",
      "                   1024, 1024, 256, 256, 512, 512, 784, 784, 1024, 1024,\n",
      "                   256, 256, 512, 512, 784, 784, 1024, 1024, 256, 256,\n",
      "                   512, 512, 784, 784, 1024, 1024, 256, 256, 512, 512,\n",
      "                   784, 784, 1024, 1024, 256, 256, 512, 512, 784, 784,\n",
      "                   1024, 1024, 256, 256, 512, 512, 784, 784, 1024, 1024,\n",
      "                   256, 256, 512, 512, 784, 784, 1024, 1024, 256, 256,\n",
      "                   512, 512, 784, 784, 1024, 1024, 256, 256, 512, 512,\n",
      "                   784, 784, 1024, 1024, 256, 256, 512, 512, 784, 784,\n",
      "                   1024, 1024, 256, 256, 512, 512, 784, 784, 1024, 1024,\n",
      "                   256, 256, 512, 512, 784, 784, 1024, 1024, 256, 256,\n",
      "                   512, 512, 784, 784, 1024, 1024, 256, 256, 512, 512,\n",
      "                   784, 784, 1024, 1024],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_optimizer_algo': masked_array(data=['sgd', 'adam', 'sgd', 'adam', 'sgd', 'adam', 'sgd',\n",
      "                   'adam', 'sgd', 'adam', 'sgd', 'adam', 'sgd', 'adam',\n",
      "                   'sgd', 'adam', 'sgd', 'adam', 'sgd', 'adam', 'sgd',\n",
      "                   'adam', 'sgd', 'adam', 'sgd', 'adam', 'sgd', 'adam',\n",
      "                   'sgd', 'adam', 'sgd', 'adam', 'sgd', 'adam', 'sgd',\n",
      "                   'adam', 'sgd', 'adam', 'sgd', 'adam', 'sgd', 'adam',\n",
      "                   'sgd', 'adam', 'sgd', 'adam', 'sgd', 'adam', 'sgd',\n",
      "                   'adam', 'sgd', 'adam', 'sgd', 'adam', 'sgd', 'adam',\n",
      "                   'sgd', 'adam', 'sgd', 'adam', 'sgd', 'adam', 'sgd',\n",
      "                   'adam', 'sgd', 'adam', 'sgd', 'adam', 'sgd', 'adam',\n",
      "                   'sgd', 'adam', 'sgd', 'adam', 'sgd', 'adam', 'sgd',\n",
      "                   'adam', 'sgd', 'adam', 'sgd', 'adam', 'sgd', 'adam',\n",
      "                   'sgd', 'adam', 'sgd', 'adam', 'sgd', 'adam', 'sgd',\n",
      "                   'adam', 'sgd', 'adam', 'sgd', 'adam', 'sgd', 'adam',\n",
      "                   'sgd', 'adam', 'sgd', 'adam', 'sgd', 'adam', 'sgd',\n",
      "                   'adam', 'sgd', 'adam', 'sgd', 'adam', 'sgd', 'adam',\n",
      "                   'sgd', 'adam', 'sgd', 'adam', 'sgd', 'adam', 'sgd',\n",
      "                   'adam', 'sgd', 'adam', 'sgd', 'adam', 'sgd', 'adam',\n",
      "                   'sgd', 'adam', 'sgd', 'adam', 'sgd', 'adam', 'sgd',\n",
      "                   'adam', 'sgd', 'adam', 'sgd', 'adam', 'sgd', 'adam',\n",
      "                   'sgd', 'adam', 'sgd', 'adam'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'activation': 'sigmoid', 'dropout': 0.0, 'epochs': 10, 'num_neurons': 256, 'optimizer_algo': 'sgd'}, {'activation': 'sigmoid', 'dropout': 0.0, 'epochs': 10, 'num_neurons': 256, 'optimizer_algo': 'adam'}, {'activation': 'sigmoid', 'dropout': 0.0, 'epochs': 10, 'num_neurons': 512, 'optimizer_algo': 'sgd'}, {'activation': 'sigmoid', 'dropout': 0.0, 'epochs': 10, 'num_neurons': 512, 'optimizer_algo': 'adam'}, {'activation': 'sigmoid', 'dropout': 0.0, 'epochs': 10, 'num_neurons': 784, 'optimizer_algo': 'sgd'}, {'activation': 'sigmoid', 'dropout': 0.0, 'epochs': 10, 'num_neurons': 784, 'optimizer_algo': 'adam'}, {'activation': 'sigmoid', 'dropout': 0.0, 'epochs': 10, 'num_neurons': 1024, 'optimizer_algo': 'sgd'}, {'activation': 'sigmoid', 'dropout': 0.0, 'epochs': 10, 'num_neurons': 1024, 'optimizer_algo': 'adam'}, {'activation': 'sigmoid', 'dropout': 0.0, 'epochs': 20, 'num_neurons': 256, 'optimizer_algo': 'sgd'}, {'activation': 'sigmoid', 'dropout': 0.0, 'epochs': 20, 'num_neurons': 256, 'optimizer_algo': 'adam'}, {'activation': 'sigmoid', 'dropout': 0.0, 'epochs': 20, 'num_neurons': 512, 'optimizer_algo': 'sgd'}, {'activation': 'sigmoid', 'dropout': 0.0, 'epochs': 20, 'num_neurons': 512, 'optimizer_algo': 'adam'}, {'activation': 'sigmoid', 'dropout': 0.0, 'epochs': 20, 'num_neurons': 784, 'optimizer_algo': 'sgd'}, {'activation': 'sigmoid', 'dropout': 0.0, 'epochs': 20, 'num_neurons': 784, 'optimizer_algo': 'adam'}, {'activation': 'sigmoid', 'dropout': 0.0, 'epochs': 20, 'num_neurons': 1024, 'optimizer_algo': 'sgd'}, {'activation': 'sigmoid', 'dropout': 0.0, 'epochs': 20, 'num_neurons': 1024, 'optimizer_algo': 'adam'}, {'activation': 'sigmoid', 'dropout': 0.0, 'epochs': 30, 'num_neurons': 256, 'optimizer_algo': 'sgd'}, {'activation': 'sigmoid', 'dropout': 0.0, 'epochs': 30, 'num_neurons': 256, 'optimizer_algo': 'adam'}, {'activation': 'sigmoid', 'dropout': 0.0, 'epochs': 30, 'num_neurons': 512, 'optimizer_algo': 'sgd'}, {'activation': 'sigmoid', 'dropout': 0.0, 'epochs': 30, 'num_neurons': 512, 'optimizer_algo': 'adam'}, {'activation': 'sigmoid', 'dropout': 0.0, 'epochs': 30, 'num_neurons': 784, 'optimizer_algo': 'sgd'}, {'activation': 'sigmoid', 'dropout': 0.0, 'epochs': 30, 'num_neurons': 784, 'optimizer_algo': 'adam'}, {'activation': 'sigmoid', 'dropout': 0.0, 'epochs': 30, 'num_neurons': 1024, 'optimizer_algo': 'sgd'}, {'activation': 'sigmoid', 'dropout': 0.0, 'epochs': 30, 'num_neurons': 1024, 'optimizer_algo': 'adam'}, {'activation': 'sigmoid', 'dropout': 0.3, 'epochs': 10, 'num_neurons': 256, 'optimizer_algo': 'sgd'}, {'activation': 'sigmoid', 'dropout': 0.3, 'epochs': 10, 'num_neurons': 256, 'optimizer_algo': 'adam'}, {'activation': 'sigmoid', 'dropout': 0.3, 'epochs': 10, 'num_neurons': 512, 'optimizer_algo': 'sgd'}, {'activation': 'sigmoid', 'dropout': 0.3, 'epochs': 10, 'num_neurons': 512, 'optimizer_algo': 'adam'}, {'activation': 'sigmoid', 'dropout': 0.3, 'epochs': 10, 'num_neurons': 784, 'optimizer_algo': 'sgd'}, {'activation': 'sigmoid', 'dropout': 0.3, 'epochs': 10, 'num_neurons': 784, 'optimizer_algo': 'adam'}, {'activation': 'sigmoid', 'dropout': 0.3, 'epochs': 10, 'num_neurons': 1024, 'optimizer_algo': 'sgd'}, {'activation': 'sigmoid', 'dropout': 0.3, 'epochs': 10, 'num_neurons': 1024, 'optimizer_algo': 'adam'}, {'activation': 'sigmoid', 'dropout': 0.3, 'epochs': 20, 'num_neurons': 256, 'optimizer_algo': 'sgd'}, {'activation': 'sigmoid', 'dropout': 0.3, 'epochs': 20, 'num_neurons': 256, 'optimizer_algo': 'adam'}, {'activation': 'sigmoid', 'dropout': 0.3, 'epochs': 20, 'num_neurons': 512, 'optimizer_algo': 'sgd'}, {'activation': 'sigmoid', 'dropout': 0.3, 'epochs': 20, 'num_neurons': 512, 'optimizer_algo': 'adam'}, {'activation': 'sigmoid', 'dropout': 0.3, 'epochs': 20, 'num_neurons': 784, 'optimizer_algo': 'sgd'}, {'activation': 'sigmoid', 'dropout': 0.3, 'epochs': 20, 'num_neurons': 784, 'optimizer_algo': 'adam'}, {'activation': 'sigmoid', 'dropout': 0.3, 'epochs': 20, 'num_neurons': 1024, 'optimizer_algo': 'sgd'}, {'activation': 'sigmoid', 'dropout': 0.3, 'epochs': 20, 'num_neurons': 1024, 'optimizer_algo': 'adam'}, {'activation': 'sigmoid', 'dropout': 0.3, 'epochs': 30, 'num_neurons': 256, 'optimizer_algo': 'sgd'}, {'activation': 'sigmoid', 'dropout': 0.3, 'epochs': 30, 'num_neurons': 256, 'optimizer_algo': 'adam'}, {'activation': 'sigmoid', 'dropout': 0.3, 'epochs': 30, 'num_neurons': 512, 'optimizer_algo': 'sgd'}, {'activation': 'sigmoid', 'dropout': 0.3, 'epochs': 30, 'num_neurons': 512, 'optimizer_algo': 'adam'}, {'activation': 'sigmoid', 'dropout': 0.3, 'epochs': 30, 'num_neurons': 784, 'optimizer_algo': 'sgd'}, {'activation': 'sigmoid', 'dropout': 0.3, 'epochs': 30, 'num_neurons': 784, 'optimizer_algo': 'adam'}, {'activation': 'sigmoid', 'dropout': 0.3, 'epochs': 30, 'num_neurons': 1024, 'optimizer_algo': 'sgd'}, {'activation': 'sigmoid', 'dropout': 0.3, 'epochs': 30, 'num_neurons': 1024, 'optimizer_algo': 'adam'}, {'activation': 'sigmoid', 'dropout': 0.5, 'epochs': 10, 'num_neurons': 256, 'optimizer_algo': 'sgd'}, {'activation': 'sigmoid', 'dropout': 0.5, 'epochs': 10, 'num_neurons': 256, 'optimizer_algo': 'adam'}, {'activation': 'sigmoid', 'dropout': 0.5, 'epochs': 10, 'num_neurons': 512, 'optimizer_algo': 'sgd'}, {'activation': 'sigmoid', 'dropout': 0.5, 'epochs': 10, 'num_neurons': 512, 'optimizer_algo': 'adam'}, {'activation': 'sigmoid', 'dropout': 0.5, 'epochs': 10, 'num_neurons': 784, 'optimizer_algo': 'sgd'}, {'activation': 'sigmoid', 'dropout': 0.5, 'epochs': 10, 'num_neurons': 784, 'optimizer_algo': 'adam'}, {'activation': 'sigmoid', 'dropout': 0.5, 'epochs': 10, 'num_neurons': 1024, 'optimizer_algo': 'sgd'}, {'activation': 'sigmoid', 'dropout': 0.5, 'epochs': 10, 'num_neurons': 1024, 'optimizer_algo': 'adam'}, {'activation': 'sigmoid', 'dropout': 0.5, 'epochs': 20, 'num_neurons': 256, 'optimizer_algo': 'sgd'}, {'activation': 'sigmoid', 'dropout': 0.5, 'epochs': 20, 'num_neurons': 256, 'optimizer_algo': 'adam'}, {'activation': 'sigmoid', 'dropout': 0.5, 'epochs': 20, 'num_neurons': 512, 'optimizer_algo': 'sgd'}, {'activation': 'sigmoid', 'dropout': 0.5, 'epochs': 20, 'num_neurons': 512, 'optimizer_algo': 'adam'}, {'activation': 'sigmoid', 'dropout': 0.5, 'epochs': 20, 'num_neurons': 784, 'optimizer_algo': 'sgd'}, {'activation': 'sigmoid', 'dropout': 0.5, 'epochs': 20, 'num_neurons': 784, 'optimizer_algo': 'adam'}, {'activation': 'sigmoid', 'dropout': 0.5, 'epochs': 20, 'num_neurons': 1024, 'optimizer_algo': 'sgd'}, {'activation': 'sigmoid', 'dropout': 0.5, 'epochs': 20, 'num_neurons': 1024, 'optimizer_algo': 'adam'}, {'activation': 'sigmoid', 'dropout': 0.5, 'epochs': 30, 'num_neurons': 256, 'optimizer_algo': 'sgd'}, {'activation': 'sigmoid', 'dropout': 0.5, 'epochs': 30, 'num_neurons': 256, 'optimizer_algo': 'adam'}, {'activation': 'sigmoid', 'dropout': 0.5, 'epochs': 30, 'num_neurons': 512, 'optimizer_algo': 'sgd'}, {'activation': 'sigmoid', 'dropout': 0.5, 'epochs': 30, 'num_neurons': 512, 'optimizer_algo': 'adam'}, {'activation': 'sigmoid', 'dropout': 0.5, 'epochs': 30, 'num_neurons': 784, 'optimizer_algo': 'sgd'}, {'activation': 'sigmoid', 'dropout': 0.5, 'epochs': 30, 'num_neurons': 784, 'optimizer_algo': 'adam'}, {'activation': 'sigmoid', 'dropout': 0.5, 'epochs': 30, 'num_neurons': 1024, 'optimizer_algo': 'sgd'}, {'activation': 'sigmoid', 'dropout': 0.5, 'epochs': 30, 'num_neurons': 1024, 'optimizer_algo': 'adam'}, {'activation': 'relu', 'dropout': 0.0, 'epochs': 10, 'num_neurons': 256, 'optimizer_algo': 'sgd'}, {'activation': 'relu', 'dropout': 0.0, 'epochs': 10, 'num_neurons': 256, 'optimizer_algo': 'adam'}, {'activation': 'relu', 'dropout': 0.0, 'epochs': 10, 'num_neurons': 512, 'optimizer_algo': 'sgd'}, {'activation': 'relu', 'dropout': 0.0, 'epochs': 10, 'num_neurons': 512, 'optimizer_algo': 'adam'}, {'activation': 'relu', 'dropout': 0.0, 'epochs': 10, 'num_neurons': 784, 'optimizer_algo': 'sgd'}, {'activation': 'relu', 'dropout': 0.0, 'epochs': 10, 'num_neurons': 784, 'optimizer_algo': 'adam'}, {'activation': 'relu', 'dropout': 0.0, 'epochs': 10, 'num_neurons': 1024, 'optimizer_algo': 'sgd'}, {'activation': 'relu', 'dropout': 0.0, 'epochs': 10, 'num_neurons': 1024, 'optimizer_algo': 'adam'}, {'activation': 'relu', 'dropout': 0.0, 'epochs': 20, 'num_neurons': 256, 'optimizer_algo': 'sgd'}, {'activation': 'relu', 'dropout': 0.0, 'epochs': 20, 'num_neurons': 256, 'optimizer_algo': 'adam'}, {'activation': 'relu', 'dropout': 0.0, 'epochs': 20, 'num_neurons': 512, 'optimizer_algo': 'sgd'}, {'activation': 'relu', 'dropout': 0.0, 'epochs': 20, 'num_neurons': 512, 'optimizer_algo': 'adam'}, {'activation': 'relu', 'dropout': 0.0, 'epochs': 20, 'num_neurons': 784, 'optimizer_algo': 'sgd'}, {'activation': 'relu', 'dropout': 0.0, 'epochs': 20, 'num_neurons': 784, 'optimizer_algo': 'adam'}, {'activation': 'relu', 'dropout': 0.0, 'epochs': 20, 'num_neurons': 1024, 'optimizer_algo': 'sgd'}, {'activation': 'relu', 'dropout': 0.0, 'epochs': 20, 'num_neurons': 1024, 'optimizer_algo': 'adam'}, {'activation': 'relu', 'dropout': 0.0, 'epochs': 30, 'num_neurons': 256, 'optimizer_algo': 'sgd'}, {'activation': 'relu', 'dropout': 0.0, 'epochs': 30, 'num_neurons': 256, 'optimizer_algo': 'adam'}, {'activation': 'relu', 'dropout': 0.0, 'epochs': 30, 'num_neurons': 512, 'optimizer_algo': 'sgd'}, {'activation': 'relu', 'dropout': 0.0, 'epochs': 30, 'num_neurons': 512, 'optimizer_algo': 'adam'}, {'activation': 'relu', 'dropout': 0.0, 'epochs': 30, 'num_neurons': 784, 'optimizer_algo': 'sgd'}, {'activation': 'relu', 'dropout': 0.0, 'epochs': 30, 'num_neurons': 784, 'optimizer_algo': 'adam'}, {'activation': 'relu', 'dropout': 0.0, 'epochs': 30, 'num_neurons': 1024, 'optimizer_algo': 'sgd'}, {'activation': 'relu', 'dropout': 0.0, 'epochs': 30, 'num_neurons': 1024, 'optimizer_algo': 'adam'}, {'activation': 'relu', 'dropout': 0.3, 'epochs': 10, 'num_neurons': 256, 'optimizer_algo': 'sgd'}, {'activation': 'relu', 'dropout': 0.3, 'epochs': 10, 'num_neurons': 256, 'optimizer_algo': 'adam'}, {'activation': 'relu', 'dropout': 0.3, 'epochs': 10, 'num_neurons': 512, 'optimizer_algo': 'sgd'}, {'activation': 'relu', 'dropout': 0.3, 'epochs': 10, 'num_neurons': 512, 'optimizer_algo': 'adam'}, {'activation': 'relu', 'dropout': 0.3, 'epochs': 10, 'num_neurons': 784, 'optimizer_algo': 'sgd'}, {'activation': 'relu', 'dropout': 0.3, 'epochs': 10, 'num_neurons': 784, 'optimizer_algo': 'adam'}, {'activation': 'relu', 'dropout': 0.3, 'epochs': 10, 'num_neurons': 1024, 'optimizer_algo': 'sgd'}, {'activation': 'relu', 'dropout': 0.3, 'epochs': 10, 'num_neurons': 1024, 'optimizer_algo': 'adam'}, {'activation': 'relu', 'dropout': 0.3, 'epochs': 20, 'num_neurons': 256, 'optimizer_algo': 'sgd'}, {'activation': 'relu', 'dropout': 0.3, 'epochs': 20, 'num_neurons': 256, 'optimizer_algo': 'adam'}, {'activation': 'relu', 'dropout': 0.3, 'epochs': 20, 'num_neurons': 512, 'optimizer_algo': 'sgd'}, {'activation': 'relu', 'dropout': 0.3, 'epochs': 20, 'num_neurons': 512, 'optimizer_algo': 'adam'}, {'activation': 'relu', 'dropout': 0.3, 'epochs': 20, 'num_neurons': 784, 'optimizer_algo': 'sgd'}, {'activation': 'relu', 'dropout': 0.3, 'epochs': 20, 'num_neurons': 784, 'optimizer_algo': 'adam'}, {'activation': 'relu', 'dropout': 0.3, 'epochs': 20, 'num_neurons': 1024, 'optimizer_algo': 'sgd'}, {'activation': 'relu', 'dropout': 0.3, 'epochs': 20, 'num_neurons': 1024, 'optimizer_algo': 'adam'}, {'activation': 'relu', 'dropout': 0.3, 'epochs': 30, 'num_neurons': 256, 'optimizer_algo': 'sgd'}, {'activation': 'relu', 'dropout': 0.3, 'epochs': 30, 'num_neurons': 256, 'optimizer_algo': 'adam'}, {'activation': 'relu', 'dropout': 0.3, 'epochs': 30, 'num_neurons': 512, 'optimizer_algo': 'sgd'}, {'activation': 'relu', 'dropout': 0.3, 'epochs': 30, 'num_neurons': 512, 'optimizer_algo': 'adam'}, {'activation': 'relu', 'dropout': 0.3, 'epochs': 30, 'num_neurons': 784, 'optimizer_algo': 'sgd'}, {'activation': 'relu', 'dropout': 0.3, 'epochs': 30, 'num_neurons': 784, 'optimizer_algo': 'adam'}, {'activation': 'relu', 'dropout': 0.3, 'epochs': 30, 'num_neurons': 1024, 'optimizer_algo': 'sgd'}, {'activation': 'relu', 'dropout': 0.3, 'epochs': 30, 'num_neurons': 1024, 'optimizer_algo': 'adam'}, {'activation': 'relu', 'dropout': 0.5, 'epochs': 10, 'num_neurons': 256, 'optimizer_algo': 'sgd'}, {'activation': 'relu', 'dropout': 0.5, 'epochs': 10, 'num_neurons': 256, 'optimizer_algo': 'adam'}, {'activation': 'relu', 'dropout': 0.5, 'epochs': 10, 'num_neurons': 512, 'optimizer_algo': 'sgd'}, {'activation': 'relu', 'dropout': 0.5, 'epochs': 10, 'num_neurons': 512, 'optimizer_algo': 'adam'}, {'activation': 'relu', 'dropout': 0.5, 'epochs': 10, 'num_neurons': 784, 'optimizer_algo': 'sgd'}, {'activation': 'relu', 'dropout': 0.5, 'epochs': 10, 'num_neurons': 784, 'optimizer_algo': 'adam'}, {'activation': 'relu', 'dropout': 0.5, 'epochs': 10, 'num_neurons': 1024, 'optimizer_algo': 'sgd'}, {'activation': 'relu', 'dropout': 0.5, 'epochs': 10, 'num_neurons': 1024, 'optimizer_algo': 'adam'}, {'activation': 'relu', 'dropout': 0.5, 'epochs': 20, 'num_neurons': 256, 'optimizer_algo': 'sgd'}, {'activation': 'relu', 'dropout': 0.5, 'epochs': 20, 'num_neurons': 256, 'optimizer_algo': 'adam'}, {'activation': 'relu', 'dropout': 0.5, 'epochs': 20, 'num_neurons': 512, 'optimizer_algo': 'sgd'}, {'activation': 'relu', 'dropout': 0.5, 'epochs': 20, 'num_neurons': 512, 'optimizer_algo': 'adam'}, {'activation': 'relu', 'dropout': 0.5, 'epochs': 20, 'num_neurons': 784, 'optimizer_algo': 'sgd'}, {'activation': 'relu', 'dropout': 0.5, 'epochs': 20, 'num_neurons': 784, 'optimizer_algo': 'adam'}, {'activation': 'relu', 'dropout': 0.5, 'epochs': 20, 'num_neurons': 1024, 'optimizer_algo': 'sgd'}, {'activation': 'relu', 'dropout': 0.5, 'epochs': 20, 'num_neurons': 1024, 'optimizer_algo': 'adam'}, {'activation': 'relu', 'dropout': 0.5, 'epochs': 30, 'num_neurons': 256, 'optimizer_algo': 'sgd'}, {'activation': 'relu', 'dropout': 0.5, 'epochs': 30, 'num_neurons': 256, 'optimizer_algo': 'adam'}, {'activation': 'relu', 'dropout': 0.5, 'epochs': 30, 'num_neurons': 512, 'optimizer_algo': 'sgd'}, {'activation': 'relu', 'dropout': 0.5, 'epochs': 30, 'num_neurons': 512, 'optimizer_algo': 'adam'}, {'activation': 'relu', 'dropout': 0.5, 'epochs': 30, 'num_neurons': 784, 'optimizer_algo': 'sgd'}, {'activation': 'relu', 'dropout': 0.5, 'epochs': 30, 'num_neurons': 784, 'optimizer_algo': 'adam'}, {'activation': 'relu', 'dropout': 0.5, 'epochs': 30, 'num_neurons': 1024, 'optimizer_algo': 'sgd'}, {'activation': 'relu', 'dropout': 0.5, 'epochs': 30, 'num_neurons': 1024, 'optimizer_algo': 'adam'}], 'split0_test_score': array([0.89223333, 0.9592    , 0.8918    , 0.9637    , 0.8924    ,\n",
      "       0.9543    , 0.89126667, 0.9637    , 0.90593333, 0.96333333,\n",
      "       0.90363333, 0.96376667, 0.9035    , 0.9575    , 0.9017    ,\n",
      "       0.9649    , 0.9109    , 0.9653    , 0.91      , 0.96513333,\n",
      "       0.90773333, 0.96713333, 0.9093    , 0.9608    , 0.8888    ,\n",
      "       0.96726667, 0.89023333, 0.9654    , 0.89066667, 0.96353333,\n",
      "       0.88803333, 0.9642    , 0.90253333, 0.97046667, 0.9019    ,\n",
      "       0.96776667, 0.89956667, 0.96916667, 0.90143333, 0.96926667,\n",
      "       0.9091    , 0.9718    , 0.90593333, 0.9728    , 0.9064    ,\n",
      "       0.96843333, 0.9058    , 0.97123333, 0.88483333, 0.9634    ,\n",
      "       0.88696667, 0.96866667, 0.8868    , 0.96616667, 0.8879    ,\n",
      "       0.96373333, 0.89773333, 0.96903333, 0.8971    , 0.9712    ,\n",
      "       0.89793333, 0.9702    , 0.89696667, 0.9706    , 0.9076    ,\n",
      "       0.9706    , 0.9057    , 0.974     , 0.90253333, 0.97173333,\n",
      "       0.903     , 0.97176667, 0.9338    , 0.9609    , 0.93546667,\n",
      "       0.956     , 0.93573333, 0.96016667, 0.9382    , 0.96156667,\n",
      "       0.9489    , 0.9563    , 0.9506    , 0.96083333, 0.952     ,\n",
      "       0.9657    , 0.95306667, 0.9637    , 0.95806667, 0.9662    ,\n",
      "       0.9606    , 0.9644    , 0.96043333, 0.96573333, 0.961     ,\n",
      "       0.96206667, 0.93833333, 0.95703333, 0.94023333, 0.95586667,\n",
      "       0.93883333, 0.95096667, 0.9386    , 0.95803333, 0.95233333,\n",
      "       0.96056667, 0.954     , 0.95853333, 0.95546667, 0.96146667,\n",
      "       0.95546667, 0.95966667, 0.95913333, 0.9568    , 0.9621    ,\n",
      "       0.9617    , 0.96196667, 0.9628    , 0.96206667, 0.96236667,\n",
      "       0.93646667, 0.9507    , 0.93916667, 0.95253333, 0.94      ,\n",
      "       0.9499    , 0.93953333, 0.94606667, 0.951     , 0.952     ,\n",
      "       0.955     , 0.9506    , 0.95426667, 0.95623333, 0.95546667,\n",
      "       0.9535    , 0.95783333, 0.9525    , 0.96176667, 0.958     ,\n",
      "       0.96233333, 0.95753333, 0.96283333, 0.9581    ]), 'split1_test_score': array([0.89506667, 0.96126667, 0.89603333, 0.96296667, 0.89596667,\n",
      "       0.9583    , 0.8951    , 0.96186667, 0.90833333, 0.9611    ,\n",
      "       0.90716667, 0.9627    , 0.9074    , 0.96223333, 0.90746667,\n",
      "       0.96113333, 0.91453333, 0.96583333, 0.91293333, 0.95966667,\n",
      "       0.90896667, 0.96976667, 0.91243333, 0.96286667, 0.89113333,\n",
      "       0.9698    , 0.89296667, 0.96553333, 0.89093333, 0.96946667,\n",
      "       0.8933    , 0.96296667, 0.90376667, 0.96673333, 0.9034    ,\n",
      "       0.97133333, 0.90366667, 0.96996667, 0.90213333, 0.96833333,\n",
      "       0.9114    , 0.9688    , 0.9108    , 0.97116667, 0.90926667,\n",
      "       0.96983333, 0.90786667, 0.96736667, 0.887     , 0.96686667,\n",
      "       0.88486667, 0.96756667, 0.88593333, 0.96626667, 0.8845    ,\n",
      "       0.96846667, 0.90023333, 0.96723333, 0.90006667, 0.96763333,\n",
      "       0.89906667, 0.97076667, 0.90016667, 0.9689    , 0.90843333,\n",
      "       0.96986667, 0.9079    , 0.968     , 0.9057    , 0.973     ,\n",
      "       0.90706667, 0.96966667, 0.9375    , 0.95266667, 0.93826667,\n",
      "       0.95336667, 0.94063333, 0.9552    , 0.9408    , 0.96163333,\n",
      "       0.95043333, 0.95906667, 0.95283333, 0.96346667, 0.95453333,\n",
      "       0.96316667, 0.95493333, 0.96346667, 0.95883333, 0.9606    ,\n",
      "       0.95946667, 0.9637    , 0.9616    , 0.96313333, 0.9614    ,\n",
      "       0.96613333, 0.94036667, 0.95893333, 0.9398    , 0.95616667,\n",
      "       0.94256667, 0.95706667, 0.94186667, 0.9573    , 0.95306667,\n",
      "       0.95886667, 0.9566    , 0.96083333, 0.95633333, 0.96033333,\n",
      "       0.95656667, 0.95826667, 0.96013333, 0.96186667, 0.9622    ,\n",
      "       0.9607    , 0.96233333, 0.96066667, 0.96313333, 0.9631    ,\n",
      "       0.9392    , 0.9539    , 0.9417    , 0.95073333, 0.94253333,\n",
      "       0.9508    , 0.94293333, 0.95556667, 0.9538    , 0.9531    ,\n",
      "       0.955     , 0.9558    , 0.95646667, 0.9546    , 0.9561    ,\n",
      "       0.9561    , 0.96016667, 0.95606667, 0.9622    , 0.9569    ,\n",
      "       0.96263333, 0.95196667, 0.9634    , 0.9498    ]), 'mean_test_score': array([0.89365   , 0.96023333, 0.89391667, 0.96333333, 0.89418333,\n",
      "       0.9563    , 0.89318333, 0.96278333, 0.90713333, 0.96221667,\n",
      "       0.9054    , 0.96323333, 0.90545   , 0.95986667, 0.90458333,\n",
      "       0.96301667, 0.91271667, 0.96556667, 0.91146667, 0.9624    ,\n",
      "       0.90835   , 0.96845   , 0.91086667, 0.96183333, 0.88996667,\n",
      "       0.96853333, 0.8916    , 0.96546667, 0.8908    , 0.9665    ,\n",
      "       0.89066667, 0.96358333, 0.90315   , 0.9686    , 0.90265   ,\n",
      "       0.96955   , 0.90161667, 0.96956667, 0.90178333, 0.9688    ,\n",
      "       0.91025   , 0.9703    , 0.90836667, 0.97198333, 0.90783333,\n",
      "       0.96913333, 0.90683333, 0.9693    , 0.88591667, 0.96513333,\n",
      "       0.88591667, 0.96811667, 0.88636667, 0.96621667, 0.8862    ,\n",
      "       0.9661    , 0.89898333, 0.96813333, 0.89858333, 0.96941667,\n",
      "       0.8985    , 0.97048333, 0.89856667, 0.96975   , 0.90801667,\n",
      "       0.97023333, 0.9068    , 0.971     , 0.90411667, 0.97236667,\n",
      "       0.90503333, 0.97071667, 0.93565   , 0.95678333, 0.93686667,\n",
      "       0.95468333, 0.93818333, 0.95768333, 0.9395    , 0.9616    ,\n",
      "       0.94966667, 0.95768333, 0.95171667, 0.96215   , 0.95326667,\n",
      "       0.96443333, 0.954     , 0.96358333, 0.95845   , 0.9634    ,\n",
      "       0.96003333, 0.96405   , 0.96101667, 0.96443333, 0.9612    ,\n",
      "       0.9641    , 0.93935   , 0.95798333, 0.94001667, 0.95601667,\n",
      "       0.9407    , 0.95401667, 0.94023333, 0.95766667, 0.9527    ,\n",
      "       0.95971667, 0.9553    , 0.95968333, 0.9559    , 0.9609    ,\n",
      "       0.95601667, 0.95896667, 0.95963333, 0.95933333, 0.96215   ,\n",
      "       0.9612    , 0.96215   , 0.96173333, 0.9626    , 0.96273333,\n",
      "       0.93783333, 0.9523    , 0.94043333, 0.95163333, 0.94126667,\n",
      "       0.95035   , 0.94123333, 0.95081667, 0.9524    , 0.95255   ,\n",
      "       0.955     , 0.9532    , 0.95536667, 0.95541667, 0.95578333,\n",
      "       0.9548    , 0.959     , 0.95428333, 0.96198333, 0.95745   ,\n",
      "       0.96248333, 0.95475   , 0.96311667, 0.95395   ]), 'std_test_score': array([1.41666667e-03, 1.03333333e-03, 2.11666667e-03, 3.66666667e-04,\n",
      "       1.78333333e-03, 2.00000000e-03, 1.91666667e-03, 9.16666667e-04,\n",
      "       1.20000000e-03, 1.11666667e-03, 1.76666667e-03, 5.33333333e-04,\n",
      "       1.95000000e-03, 2.36666667e-03, 2.88333333e-03, 1.88333333e-03,\n",
      "       1.81666667e-03, 2.66666667e-04, 1.46666667e-03, 2.73333333e-03,\n",
      "       6.16666667e-04, 1.31666667e-03, 1.56666667e-03, 1.03333333e-03,\n",
      "       1.16666667e-03, 1.26666667e-03, 1.36666667e-03, 6.66666667e-05,\n",
      "       1.33333333e-04, 2.96666667e-03, 2.63333333e-03, 6.16666667e-04,\n",
      "       6.16666667e-04, 1.86666667e-03, 7.50000000e-04, 1.78333333e-03,\n",
      "       2.05000000e-03, 4.00000000e-04, 3.50000000e-04, 4.66666667e-04,\n",
      "       1.15000000e-03, 1.50000000e-03, 2.43333333e-03, 8.16666667e-04,\n",
      "       1.43333333e-03, 7.00000000e-04, 1.03333333e-03, 1.93333333e-03,\n",
      "       1.08333333e-03, 1.73333333e-03, 1.05000000e-03, 5.50000000e-04,\n",
      "       4.33333333e-04, 5.00000000e-05, 1.70000000e-03, 2.36666667e-03,\n",
      "       1.25000000e-03, 9.00000000e-04, 1.48333333e-03, 1.78333333e-03,\n",
      "       5.66666667e-04, 2.83333333e-04, 1.60000000e-03, 8.50000000e-04,\n",
      "       4.16666667e-04, 3.66666667e-04, 1.10000000e-03, 3.00000000e-03,\n",
      "       1.58333333e-03, 6.33333333e-04, 2.03333333e-03, 1.05000000e-03,\n",
      "       1.85000000e-03, 4.11666667e-03, 1.40000000e-03, 1.31666667e-03,\n",
      "       2.45000000e-03, 2.48333333e-03, 1.30000000e-03, 3.33333333e-05,\n",
      "       7.66666667e-04, 1.38333333e-03, 1.11666667e-03, 1.31666667e-03,\n",
      "       1.26666667e-03, 1.26666667e-03, 9.33333333e-04, 1.16666667e-04,\n",
      "       3.83333333e-04, 2.80000000e-03, 5.66666667e-04, 3.50000000e-04,\n",
      "       5.83333333e-04, 1.30000000e-03, 2.00000000e-04, 2.03333333e-03,\n",
      "       1.01666667e-03, 9.50000000e-04, 2.16666667e-04, 1.50000000e-04,\n",
      "       1.86666667e-03, 3.05000000e-03, 1.63333333e-03, 3.66666667e-04,\n",
      "       3.66666667e-04, 8.50000000e-04, 1.30000000e-03, 1.15000000e-03,\n",
      "       4.33333333e-04, 5.66666667e-04, 5.50000000e-04, 7.00000000e-04,\n",
      "       5.00000000e-04, 2.53333333e-03, 5.00000000e-05, 5.00000000e-04,\n",
      "       1.83333333e-04, 1.06666667e-03, 5.33333333e-04, 3.66666667e-04,\n",
      "       1.36666667e-03, 1.60000000e-03, 1.26666667e-03, 9.00000000e-04,\n",
      "       1.26666667e-03, 4.50000000e-04, 1.70000000e-03, 4.75000000e-03,\n",
      "       1.40000000e-03, 5.50000000e-04, 0.00000000e+00, 2.60000000e-03,\n",
      "       1.10000000e-03, 8.16666667e-04, 3.16666667e-04, 1.30000000e-03,\n",
      "       1.16666667e-03, 1.78333333e-03, 2.16666667e-04, 5.50000000e-04,\n",
      "       1.50000000e-04, 2.78333333e-03, 2.83333333e-04, 4.15000000e-03]), 'rank_test_score': array([135,  54, 134,  33, 133,  70, 136,  37, 117,  42, 121,  34, 120,\n",
      "        56, 123,  36, 109,  23, 110,  41, 114,  17, 111,  47, 140,  16,\n",
      "       137,  24, 138,  20, 139,  30, 125,  15, 126,  10, 128,   9, 127,\n",
      "        14, 112,   6, 113,   2, 116,  13, 118,  12, 143,  25, 143,  19,\n",
      "       141,  21, 142,  22, 129,  18, 130,  11, 132,   5, 131,   8, 115,\n",
      "         7, 119,   3, 124,   1, 122,   4, 108,  69, 107,  81, 105,  65,\n",
      "       103,  49,  96,  65,  92,  43,  86,  26,  84,  30,  63,  32,  55,\n",
      "        29,  52,  26,  50,  28, 104,  64, 102,  71,  99,  83, 101,  67,\n",
      "        88,  57,  77,  58,  73,  53,  71,  62,  59,  60,  43,  50,  43,\n",
      "        48,  39,  38, 106,  91, 100,  93,  97,  95,  98,  94,  90,  89,\n",
      "        78,  87,  76,  75,  74,  79,  61,  82,  46,  68,  40,  80,  35,\n",
      "        85]), 'split0_train_score': array([0.8975    , 0.9823    , 0.8966    , 0.98253333, 0.89796667,\n",
      "       0.9737    , 0.89673333, 0.98383333, 0.91253333, 0.98643333,\n",
      "       0.91063333, 0.98523333, 0.91113333, 0.98166667, 0.91143333,\n",
      "       0.98696667, 0.9206    , 0.99403333, 0.91806667, 0.99093333,\n",
      "       0.9175    , 0.99163333, 0.91743333, 0.98293333, 0.89306667,\n",
      "       0.98396667, 0.8953    , 0.98196667, 0.89483333, 0.98053333,\n",
      "       0.8916    , 0.97956667, 0.90836667, 0.99073333, 0.90793333,\n",
      "       0.98683333, 0.90593333, 0.98776667, 0.90746667, 0.98473333,\n",
      "       0.91603333, 0.99233333, 0.91316667, 0.99386667, 0.9144    ,\n",
      "       0.9893    , 0.91366667, 0.98983333, 0.88736667, 0.97856667,\n",
      "       0.88993333, 0.98116667, 0.88926667, 0.97946667, 0.89076667,\n",
      "       0.97536667, 0.9024    , 0.98743333, 0.9023    , 0.98636667,\n",
      "       0.9031    , 0.98616667, 0.90196667, 0.986     , 0.91366667,\n",
      "       0.98826667, 0.91126667, 0.9904    , 0.9093    , 0.98976667,\n",
      "       0.9097    , 0.98603333, 0.9448    , 0.98526667, 0.94556667,\n",
      "       0.9798    , 0.94593333, 0.98423333, 0.94873333, 0.98566667,\n",
      "       0.96223333, 0.98253333, 0.96353333, 0.98613333, 0.96576667,\n",
      "       0.99      , 0.96606667, 0.9887    , 0.97323333, 0.9935    ,\n",
      "       0.97486667, 0.9915    , 0.97563333, 0.9914    , 0.9778    ,\n",
      "       0.98853333, 0.94783333, 0.97373333, 0.94876667, 0.9746    ,\n",
      "       0.94916667, 0.9692    , 0.94853333, 0.97573333, 0.963     ,\n",
      "       0.9816    , 0.96473333, 0.98      , 0.96656667, 0.98196667,\n",
      "       0.9673    , 0.9812    , 0.97166667, 0.98043333, 0.9752    ,\n",
      "       0.98406667, 0.97653333, 0.98503333, 0.97696667, 0.98286667,\n",
      "       0.94543333, 0.9651    , 0.94753333, 0.9652    , 0.9496    ,\n",
      "       0.96463333, 0.9493    , 0.96006667, 0.9602    , 0.9701    ,\n",
      "       0.96513333, 0.96796667, 0.9655    , 0.971     , 0.96653333,\n",
      "       0.96876667, 0.97036667, 0.9715    , 0.97443333, 0.97556667,\n",
      "       0.97543333, 0.97526667, 0.97646667, 0.97446667]), 'split1_train_score': array([0.89516667, 0.98536667, 0.89633333, 0.98433333, 0.89663333,\n",
      "       0.9785    , 0.89523333, 0.98006667, 0.90886667, 0.98736667,\n",
      "       0.90736667, 0.98573333, 0.9088    , 0.9841    , 0.90853333,\n",
      "       0.98326667, 0.91643333, 0.99366667, 0.91506667, 0.9828    ,\n",
      "       0.9115    , 0.9917    , 0.91356667, 0.98586667, 0.8906    ,\n",
      "       0.98786667, 0.89243333, 0.9836    , 0.8905    , 0.98593333,\n",
      "       0.89336667, 0.98063333, 0.9045    , 0.9887    , 0.90273333,\n",
      "       0.9909    , 0.90436667, 0.99013333, 0.90323333, 0.98653333,\n",
      "       0.91353333, 0.99143333, 0.91196667, 0.9914    , 0.91036667,\n",
      "       0.99096667, 0.90926667, 0.98823333, 0.88706667, 0.9829    ,\n",
      "       0.88636667, 0.9823    , 0.8864    , 0.98066667, 0.88533333,\n",
      "       0.98183333, 0.90186667, 0.98443333, 0.90103333, 0.98536667,\n",
      "       0.90103333, 0.98853333, 0.89993333, 0.98476667, 0.91063333,\n",
      "       0.99013333, 0.90883333, 0.9873    , 0.90793333, 0.99073333,\n",
      "       0.9079    , 0.98666667, 0.9413    , 0.97613333, 0.9446    ,\n",
      "       0.9769    , 0.94673333, 0.9799    , 0.9478    , 0.9868    ,\n",
      "       0.9624    , 0.98533333, 0.9649    , 0.98943333, 0.96506667,\n",
      "       0.98963333, 0.9669    , 0.98866667, 0.97296667, 0.98506667,\n",
      "       0.97433333, 0.99023333, 0.97666667, 0.98833333, 0.9766    ,\n",
      "       0.99173333, 0.94473333, 0.97563333, 0.94513333, 0.97303333,\n",
      "       0.94763333, 0.97446667, 0.9481    , 0.97543333, 0.9627    ,\n",
      "       0.9816    , 0.96556667, 0.98056667, 0.9671    , 0.98056667,\n",
      "       0.96703333, 0.9811    , 0.97293333, 0.98573333, 0.975     ,\n",
      "       0.98286667, 0.97663333, 0.9831    , 0.97713333, 0.98443333,\n",
      "       0.9434    , 0.9671    , 0.94603333, 0.96376667, 0.9477    ,\n",
      "       0.96506667, 0.94823333, 0.96806667, 0.96076667, 0.96916667,\n",
      "       0.9645    , 0.9718    , 0.96583333, 0.96933333, 0.96713333,\n",
      "       0.9718    , 0.97023333, 0.97393333, 0.97443333, 0.9757    ,\n",
      "       0.97556667, 0.96906667, 0.97716667, 0.96893333]), 'mean_train_score': array([0.89633333, 0.98383333, 0.89646667, 0.98343333, 0.8973    ,\n",
      "       0.9761    , 0.89598333, 0.98195   , 0.9107    , 0.9869    ,\n",
      "       0.909     , 0.98548333, 0.90996667, 0.98288333, 0.90998333,\n",
      "       0.98511667, 0.91851667, 0.99385   , 0.91656667, 0.98686667,\n",
      "       0.9145    , 0.99166667, 0.9155    , 0.9844    , 0.89183333,\n",
      "       0.98591667, 0.89386667, 0.98278333, 0.89266667, 0.98323333,\n",
      "       0.89248333, 0.9801    , 0.90643333, 0.98971667, 0.90533333,\n",
      "       0.98886667, 0.90515   , 0.98895   , 0.90535   , 0.98563333,\n",
      "       0.91478333, 0.99188333, 0.91256667, 0.99263333, 0.91238333,\n",
      "       0.99013333, 0.91146667, 0.98903333, 0.88721667, 0.98073333,\n",
      "       0.88815   , 0.98173333, 0.88783333, 0.98006667, 0.88805   ,\n",
      "       0.9786    , 0.90213333, 0.98593333, 0.90166667, 0.98586667,\n",
      "       0.90206667, 0.98735   , 0.90095   , 0.98538333, 0.91215   ,\n",
      "       0.9892    , 0.91005   , 0.98885   , 0.90861667, 0.99025   ,\n",
      "       0.9088    , 0.98635   , 0.94305   , 0.9807    , 0.94508333,\n",
      "       0.97835   , 0.94633333, 0.98206667, 0.94826667, 0.98623333,\n",
      "       0.96231667, 0.98393333, 0.96421667, 0.98778333, 0.96541667,\n",
      "       0.98981667, 0.96648333, 0.98868333, 0.9731    , 0.98928333,\n",
      "       0.9746    , 0.99086667, 0.97615   , 0.98986667, 0.9772    ,\n",
      "       0.99013333, 0.94628333, 0.97468333, 0.94695   , 0.97381667,\n",
      "       0.9484    , 0.97183333, 0.94831667, 0.97558333, 0.96285   ,\n",
      "       0.9816    , 0.96515   , 0.98028333, 0.96683333, 0.98126667,\n",
      "       0.96716667, 0.98115   , 0.9723    , 0.98308333, 0.9751    ,\n",
      "       0.98346667, 0.97658333, 0.98406667, 0.97705   , 0.98365   ,\n",
      "       0.94441667, 0.9661    , 0.94678333, 0.96448333, 0.94865   ,\n",
      "       0.96485   , 0.94876667, 0.96406667, 0.96048333, 0.96963333,\n",
      "       0.96481667, 0.96988333, 0.96566667, 0.97016667, 0.96683333,\n",
      "       0.97028333, 0.9703    , 0.97271667, 0.97443333, 0.97563333,\n",
      "       0.9755    , 0.97216667, 0.97681667, 0.9717    ]), 'std_train_score': array([1.16666667e-03, 1.53333333e-03, 1.33333333e-04, 9.00000000e-04,\n",
      "       6.66666667e-04, 2.40000000e-03, 7.50000000e-04, 1.88333333e-03,\n",
      "       1.83333333e-03, 4.66666667e-04, 1.63333333e-03, 2.50000000e-04,\n",
      "       1.16666667e-03, 1.21666667e-03, 1.45000000e-03, 1.85000000e-03,\n",
      "       2.08333333e-03, 1.83333333e-04, 1.50000000e-03, 4.06666667e-03,\n",
      "       3.00000000e-03, 3.33333333e-05, 1.93333333e-03, 1.46666667e-03,\n",
      "       1.23333333e-03, 1.95000000e-03, 1.43333333e-03, 8.16666667e-04,\n",
      "       2.16666667e-03, 2.70000000e-03, 8.83333333e-04, 5.33333333e-04,\n",
      "       1.93333333e-03, 1.01666667e-03, 2.60000000e-03, 2.03333333e-03,\n",
      "       7.83333333e-04, 1.18333333e-03, 2.11666667e-03, 9.00000000e-04,\n",
      "       1.25000000e-03, 4.50000000e-04, 6.00000000e-04, 1.23333333e-03,\n",
      "       2.01666667e-03, 8.33333333e-04, 2.20000000e-03, 8.00000000e-04,\n",
      "       1.50000000e-04, 2.16666667e-03, 1.78333333e-03, 5.66666667e-04,\n",
      "       1.43333333e-03, 6.00000000e-04, 2.71666667e-03, 3.23333333e-03,\n",
      "       2.66666667e-04, 1.50000000e-03, 6.33333333e-04, 5.00000000e-04,\n",
      "       1.03333333e-03, 1.18333333e-03, 1.01666667e-03, 6.16666667e-04,\n",
      "       1.51666667e-03, 9.33333333e-04, 1.21666667e-03, 1.55000000e-03,\n",
      "       6.83333333e-04, 4.83333333e-04, 9.00000000e-04, 3.16666667e-04,\n",
      "       1.75000000e-03, 4.56666667e-03, 4.83333333e-04, 1.45000000e-03,\n",
      "       4.00000000e-04, 2.16666667e-03, 4.66666667e-04, 5.66666667e-04,\n",
      "       8.33333333e-05, 1.40000000e-03, 6.83333333e-04, 1.65000000e-03,\n",
      "       3.50000000e-04, 1.83333333e-04, 4.16666667e-04, 1.66666667e-05,\n",
      "       1.33333333e-04, 4.21666667e-03, 2.66666667e-04, 6.33333333e-04,\n",
      "       5.16666667e-04, 1.53333333e-03, 6.00000000e-04, 1.60000000e-03,\n",
      "       1.55000000e-03, 9.50000000e-04, 1.81666667e-03, 7.83333333e-04,\n",
      "       7.66666667e-04, 2.63333333e-03, 2.16666667e-04, 1.50000000e-04,\n",
      "       1.50000000e-04, 0.00000000e+00, 4.16666667e-04, 2.83333333e-04,\n",
      "       2.66666667e-04, 7.00000000e-04, 1.33333333e-04, 5.00000000e-05,\n",
      "       6.33333333e-04, 2.65000000e-03, 1.00000000e-04, 6.00000000e-04,\n",
      "       5.00000000e-05, 9.66666667e-04, 8.33333333e-05, 7.83333333e-04,\n",
      "       1.01666667e-03, 1.00000000e-03, 7.50000000e-04, 7.16666667e-04,\n",
      "       9.50000000e-04, 2.16666667e-04, 5.33333333e-04, 4.00000000e-03,\n",
      "       2.83333333e-04, 4.66666667e-04, 3.16666667e-04, 1.91666667e-03,\n",
      "       1.66666667e-04, 8.33333333e-04, 3.00000000e-04, 1.51666667e-03,\n",
      "       6.66666667e-05, 1.21666667e-03, 0.00000000e+00, 6.66666667e-05,\n",
      "       6.66666667e-05, 3.10000000e-03, 3.50000000e-04, 2.76666667e-03])}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search_fit.cv_results_)\n",
    "sys.setrecursionlimit(300000)\n",
    "with open('mlp_grid_search_cv_results.pickle', 'wb') as handle:\n",
    "    pickle.dump(grid_search_fit.cv_results_, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fewqrpx28vVi"
   },
   "source": [
    "#### We fit model with best CV parameters on (train+val) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P9xtRQO18vVi",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# build the model\n",
    "#model = create_mlp_model(activation=\"relu\",dropout=0.5,num_neurons=784,optimizer_algo=\"adam\")\n",
    "model = create_mlp_model(activation=grid_search_fit.best_params_['activation'], \\\n",
    "                         dropout=grid_search_fit.best_params_['dropout'], \\\n",
    "                         num_neurons=grid_search_fit.best_params_['num_neurons'], \\\n",
    "                         optimizer_algo=grid_search_fit.best_params_['optimizer_algo'])\n",
    "# Fit the model\n",
    "\n",
    "# This is the final fit on entire data, so that we can get the test accuracy.\n",
    "fit_model_final = model.fit(x_trainval_nn, y_trainval_nn, validation_data=(x_test_nn, y_test_nn), epochs=grid_search_fit.best_params_['epochs'], batch_size=200, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QaJv_d_Dp7OM"
   },
   "source": [
    "### 2.2.4: Evaluation\n",
    "\n",
    "Evaluate your model.\n",
    "\n",
    "When possible, you should have:\n",
    "  * Loss curves: Plot epoch (# passes over training data) and loss\n",
    "  * Accuracy curves: Plot epoch and accuracy over val/test set\n",
    "  * Final numbers: Report final accuracy numbers for your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_varying_num_neurons_sgd = []\n",
    "idx_varying_num_neurons_adam = []\n",
    "for i in range(len(grid_search_fit.cv_results_['params'])):\n",
    "    param = grid_search_fit.cv_results_['params'][i]\n",
    "    if param['activation'] == grid_search_fit.best_params_['activation']\\\n",
    "     and param['dropout'] == grid_search_fit.best_params_['dropout']\\\n",
    "     and param['epochs'] == grid_search_fit.best_params_['epochs']:\n",
    "        if param['optimizer_algo'] == 'sgd':\n",
    "            idx_varying_num_neurons_sgd.append(i)\n",
    "        elif param['optimizer_algo'] == 'adam':\n",
    "            idx_varying_num_neurons_adam.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm8AAAHwCAYAAADw7oiDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzs3Xd4FNXCBvB3dje9E1JA4SIEwRaKCCmA9BYSELhUQaqiIhpABQHBUASkqKCAQIg06VKkxcAFDEQ0dPSjKhJKCgmQENJ2d74/xu2bbBISkoH39zx5sjuzO3vm7GTz7jlnzgiiKIogIiIiIllQVHQBiIiIiKj4GN6IiIiIZIThjYiIiEhGGN6IiIiIZIThjYiIiEhGGN6IiIiIZIThjaiSGThwIL777juL5dHR0Xj77beLfO748eOxYsUKAEC3bt2QmZlp8ZgVK1Zg/PjxNssxadIknDt3DgAwceJEHD16tDjFL5atW7eiR48eiIiIQFhYGCZOnIisrKwy235FS0lJQd++fSu6GET0mGJ4I6pk+vfvjy1btlgs37hxIwYMGFDs7Wzfvh3u7u6lLsfRo0ehmwZyxowZCAkJKfW2jJ05cwbffPMNoqOjsWPHDuzYsQNKpRJTp04tk+1XBn5+fli/fn1FF4OIHlOqii4AEZlq3749Zs6cicTERDRp0gQA8Ntvv0EURYSGhkKr1WLmzJk4ffo0srOzIYoipk+fjpdfftlkO/Xq1UNCQgLc3Nwwffp0HD16FN7e3vD29oabmxsA4NSpU/jiiy+Qn5+PtLQ0hISEYObMmViwYAFSU1Mxbtw4zJkzB3PnzsWAAQPQqVMnxMXFYdGiRdBqtXBxccGECRMQGBiIhQsX4saNG0hLS8ONGzfg5+eHL774Ar6+viblSktLgyiKyM3NBQAolUq8//77uHTpEgBArVbjiy++wMGDB6FUKtGoUSNMmTIFgiBg1qxZSEhIgFKpRGBgICZMmABXV1e0adMGgYGBuHDhAsaMGYPAwEBERUXh1q1bKCgoQFhYGEaOHGlSjr///ht9+/bFL7/8Ant7e2g0GrRq1QoxMTHIysqyWi/Xr1/HgAEDUKdOHdy4cQPdu3fH5cuXMW/ePABAYmIipk+fjkWLFiE8PBwnT54ssl7OnDmDqVOnoqCgADVr1sTNmzcxfvx4NGvWzKSsbdq0wWuvvYaEhATcunUL3bp1wwcffIBjx45h2rRp+OmnnwDA5P7ChQtx7do1pKSkIC0tDS+88AKaNWuGbdu24fr16/jwww/RtWvXIo/Fwl4XAA4cOIDFixejoKAAjo6O+Pjjj9GoUSMsXLgQd+7cwaeffgoAJvcHDhwIDw8P/PXXX+jXrx/at2+PqVOn4saNGxBFEd27d8fw4cNx/fp1DB48GK+++ipOnz6NzMxMfPjhh2jfvj2uXLmCiRMnIj8/H6IoolevXiX6UkP0OGB4I6pkVCoVevfujc2bN+vD24YNG9C/f38IgoBTp04hNTUVGzZsgEKhwHfffYdly5ZZhDeddevW4erVq9i1axfUajVef/11fXhbtWoVRo8ejWbNmiE7Oxtt27bFuXPnEBkZiZ07d2Lu3Ll46aWX9Nu6cuUKpkyZgvXr16NGjRpISEjAO++8g7179wKQwsu2bdvg6uqKkSNHYv369Rg9erRJeVq2bIndu3ejTZs2qFevHho1aoSWLVvi1Vdf1Zf3jz/+wPbt22Fvb48xY8Zg9+7duHbtGlJTU7F9+3YolUpMnDgRc+bMQVRUFACgbt26+PLLLwEAgwYNwuDBg9GmTRvk5eVhxIgRqFmzJrp06aIvxzPPPIO6deviwIED6NSpE+Lj4/H000+jTp06GDNmjNV68fT0RHJyMubNm4cmTZogPT0dHTp0wN27d+Hp6YmNGzda7S61Vi/vvPMO3nvvPURFReHVV1/Fr7/+isGDBxd6XDx48ADr1q1DSkoK2rdvj549exZ5HAHA8ePHsX37dtjZ2aFly5aoWrUq1q5di7i4OHzxxRc2w1thr6vRaLBgwQKsWrUKXl5euHTpEoYMGYLY2Fib23N3d8fu3bsBAK+//jratm2LIUOGICsrCwMGDEC1atXQoEEDJCUloXnz5pg8eTL27duHmTNnon379lixYgXatGmDN998E2lpaZg5cyb69esHhYIdSfTkYHgjqoR69+6NsLAw3L9/H2q1GvHx8fpuxUaNGsHDwwPr169HUlISjh07BhcXl0K3lZCQgK5du8Le3h729vYIDw/HhQsXAACzZs3C4cOHsWTJEvz111/Iy8vDgwcPCt3Wr7/+iqCgINSoUQMAEBwcjCpVqujHxjVt2hSurq4AgOeffx737t2z2IadnR3mzZuHjz76CMeOHcPvv/+Ojz/+GMHBwfjyyy9x9OhRdOvWDY6OjgCgD2S9evVCZGQk7OzsAEhjA9999139dnVB98GDB/j9999x7949fPXVV/pl58+fNwlvum3++OOP6NSpE7Zu3YrevXsXWS+enp5QqVRo2LAhAMDb2xutWrXC9u3b0b17d8THx2PKlCm4c+eOyetYq5eLFy8CgD60BgUFoW7duoXWfdu2bQFIXbLe3t5W69ZcSEiIPqj7+vqiRYsWAICaNWvi7t27Np9f2OuePn0aqampJmFTEARcu3bN5vaM36cTJ04gOjoaAODm5oYePXrg8OHDaNCgAezs7PR18/zzz+vL2759e3z88cc4c+YMgoODMWnSJAY3euIwvBFVQn5+fggJCcHu3bvx4MEDdOzYUf9P+ODBg5gxYwaGDBmCtm3bonbt2tixY0ext61UKvW3X3/9ddSrVw8tWrRA586dcfr0aRR1uWOtVgtBEEyWiaIItVoNAPrABUj/zK1ta/PmzfDy8kLbtm0RERGBiIgIvP3222jTpg0yMjKgUpl+LN2+fRtardbitbVaLQoKCvT3nZ2d9ctFUcT69evh5OQEAMjIyICDg4NFWTp37oxZs2bhypUr+P333zFr1iyb9WJvb29SxgEDBmDq1KlQqVTo0KEDXFxcLMKbtXpRKpUW9WP83pgzLr9uG+Z1bFwfurIaM6/b4rD2ulqtVh+2dW7dugVfX1/ExcUVWSbz98mYVqvVH0t2dnb6UGb8vrdu3Rr79u3D0aNHkZCQgG+++QZbt26Fv79/ifeNSK74dYWokhowYAB27tyJbdu2mYzpOXLkCFq3bo3+/fvjxRdfRFxcHDQaTaHbadGiBbZt24a8vDzk5eXpu6wyMzNx9uxZjBs3Dh06dEBycjKuXbsGrVYLQAoSun+kOsHBwYiPj0dSUhIA6MdCNWjQoNj7pVAoMHfuXCQnJ+uXXbp0CdWrV4eHhweCg4Px008/IT8/H1qtFlOnTsWuXbvQokUL/PDDDygoKIBWq8XatWsRGhpqsX1XV1c0bNgQK1eu1O9nv379sH//fovHOjg4ICwsDOPHj0eHDh3g5ORks17MNW7cGAqFAitWrCjRGaZ16tSBvb09Dh8+DEA6kePixYsW4bgoVapUwc2bN5Geng5RFLFr165iP/dhBAcH48iRI7hy5QoA4NChQ4iIiEBubi68vLzwxx9/QBRF3L9/H//73/+sbsPV1RUNGjTA2rVrAQBZWVnYtm2bzRNjxo4di927dyMsLAxTpkyBq6trsVr8iB4nbHkjqqSaNWuG6dOnw8PDA/Xq1dMv79u3L8aOHYvw8HCo1WqEhoYiNja20HDRt29fXLt2DV27doWnpyf+85//AJDGHr355pt47bXX4OzsDD8/PzRu3Bj//PMPgoOD0b59e3z44YcmZ4EGBARgypQpGDVqFDQaDRwdHbFkyRJ9q2Bx9OjRAzk5ORgxYgTy8/MhCAJq1aqFFStWQKlUom/fvrhx4wZ69OgBURTRtGlTDBw4EGq1GrNnz0b37t2hVqsRGBiIyZMnW32NuXPnYtq0aQgPD0d+fj66du2KiIgIq4/973//izVr1uj3s6h60XUXW9un3bt3o379+sWuB5VKhYULF2LKlCmYP38+atWqhapVq5q00tkSEBCAvn37omfPnvDx8UGrVq1w9uzZYj+/tAICAhAVFYUxY8ZAFEWoVCosXrwYLi4uiIiIwC+//IIOHTrAz88PTZs2LbQ1d+7cuYiKisLWrVuRn5+P8PBw9OjRAzdu3Cj0td955x1MnDgRGzZsgFKpRLt27fDKK6+U164SVUqCWFQfCRERFUmtVmPUqFGIiIiwGFNny+zZszFs2DBUrVpVfzZnXFzcQ03xQkSPP7a8ERGV0uXLl9GvXz+0a9cOnTp1KvHzn3rqKQwePBgqlUo/5cujDG47duzQT+psLjw8HMOHD39kZSGi4mPLGxEREZGM8IQFIiIiIhlheCMiIiKSEYY3IiIiIhl5LE9YuHMnG1rt4zeUz9vbFenp9yu6GBWO9SBhPUhYDxLWg4T1IGE9SCp7PSgUAry8Cr9CTmEey/Cm1YqPZXgD8NjuV0mxHiSsBwnrQcJ6kLAeJKwHyeNYD+w2JSIiIpIRhjciIiIiGWF4IyIiIpIRhjciIiIiGWF4IyIiIpIRhjciIiIiGWF4IyIiIpIRhjciIiIiGWF4IyIiIpIRhjciIiIiGWF4IyIiIpIRhjciIiIiGWF4IyIiIpIRhjciIiIiGWF4IyIiIpIRhjciIiIiGWF4IyIiIpIRVUUXgIhKT6MBCgqkn/x8AWo18OABkJ0t3VcoAIVChEIBKJWAQgGoVNDf1/0IgvSjUOh+i0a3pdeStmX+OMNziYjo0WB4I6qkigpmubkCHByAtDQlRBEQBBGiKEAQAKVShJ2dFMpEERBF4d/fgFYrbVurNV0HQP8bMIQxQQDEf1dIvwSrQU0X5HRhUKEQ9WFRqRQhCFJoNCyzFSBFqwHRWng0LjcR0ZOA4Y2oAmi1QH5+4cHswQNpWWHBTKUCXF0BrdY4uZQmxZT0OdYfby0YarVSAM3PF6yERhgFSsFiW5YBsfAA6eEB3Lun1LcM6sKjSgV9aLTW+mgeII0DokIhWoREgK2PRFQ5MLwRlTHjYCb9CKUIZlLLlYFlaDJdX7Gk8ku3S16uhwuQXl6ASiWaBENdWNRo8G9dl7710fg1S9v6qFJJz7fW+mjcjW2t9dE4HJqHRvNwSURPBoY3ohIobjCTlD6YUcmVPsCUb+ujWl1466NhWdGtj1LIN6yzFiA9PYHMTKVF66PxfbY+Ej0eGN6I/lVYMHvwAMjJYTCjolVk6yMghTddyDMOhmq1dDzban3UanVjHE33ydpr6o59c7ZaH3V1ZK31UXe7qNZH3W3zH4ZGetIwvNETobjB7GG7MokqysN1n1au1kddgBQEID5eifXr7ZCeLsDbW0SfPvlo0UJr8rqGACiialUgK0sBlUrUh0Ldb93fsnHronFoNB03yWBIlRfDG8kegxlR5VDWrY/79yuxbJk98vKkBHX7toDlyx3g5paHtm01+scZB0VRlD4P8vIE/TLdj/n4RvOuaSlICmbLDQHQzk7897aoD4y6M7tVKkMwNO6mLuxH101NVBoMb1Sp6YKZ9M1dCmb37gE3bkihjMGMSH4KCoDcXGmcaG6uFLRyc6UvW9J9ad2KFYbgppOXJ2DxYntUrZoHFxfAxUWEi4sIZ2cpSDk6Ak5Ohb1ycf72TR9jHABFUSq7cTA0rDftejbvcpaWme6LcTBUKsV/WwdFk9ZCXSi0szNvHbTsUjZuMaTHG8MbVRhrwUxqLUORwczbG8jOFqBUMpgRlQeNxjRcGUKW5TLLx5gvN31MXh6g0Txck9O9ewqMG2eZ0BwcRLi6As7OTnB2FvXhzvi2Lujpbru4wGS9g4N5i5xhnF7RSh8MjafWUasFs1BoOqWOcZey9Nt6i6GnJ5CVpdS3FOpCoO5EFt2XW+OgaGgZFE1aB81bDBkOKx7DG5ULa8FMCmVFBzPjCWYLC2ZeXhWyS0SVhlarC1KGYHTjBpCaqrASnix/mz/XsEy6X1BQsnClUIhwdAQcHc1/Ax4e4r/3pWUODuK/rWOGxzo4mD5H95jRox2RlmaZFLy8tJgwIQ8PHgjIzhaQnS19oXvwAFCr7ZGRoUV2tvRZk56u0K/PybG9X0pl0eHOWvgzv+3kVLyAY9zNbJutcGi63tNTWmYcAnNzpRBordUQsN5iaFRak+0bJtg2BEPdbfMWQ+MQaKvFkOMMi4fhjUrMVjDLyRH+PbtNCma6P/riBDOix4Fu3FVJWqjy8gzdhoU/xvDbOuv9hYKgC0iWAatqVfHfAGW63HDfWigzfYyuS6+sDRuWjwULHEz218FBxFtv5aNRI63V53h52ePOnTyr6zQaqWVfF/jMw59pEDTcTk0VTB5rPrWLNVLgKywIGrcKFr7ezq509QaUdTC0fIwu/Gk00u+8PMOYQt0y43GG1loMDcutjzOUWgdNxxmatxjqpsMxbjE0/snNlf4WjU9MeRwwvJGJsghmLi4MZlS5iaJ0jFtrfTIOULZaqAoPZtI/rZJwcDBvgRL1LVd+fqKVAGXaalW1qiPU6hyrIcveXp7/tNq21UCjyUNMjD1u3xZQtaqIwYPz0bq1xvaTrZC+OEpfHiUl/2wSRemYMA53ula/wsJfdraAzEwBt24ZQmPhAdzA3r444c+49c+wXjdFjKNj+bz3upbF8uhONj8BpTjjDAvbpqcncPeuoZDm4wx1J6IYT1mjC4i6+z4+le9/GMPbE4TBjOSksHFX5i1SggDcuWNnI2RZbqc4rSfG7Oysd/O5uoqoWtV68DL+XdR6B4eHH0fk5QXcuWO9Naqy0l0BQxc0DGPhDJ8/ISFatG2bA5VKRH6+gPx8AXfvGp81Kv77z1vQh/KsLMtr55bVGZ6CIJ0Q4eQkwttbV9aSKyiAPvCZBz3jbmDzZXfuGHcD2/qS4AKFwnbQszU20Nn50V7RpSyDoZeX9D9M/wyzACgde4WPMxRF4NVXNVBVsrRUyYpDpaXVGl/EnMHsSbZ/vxLR0fZISxPg4yNi6NB8k2kVyoq1cVelaaEqrDuxZOOu7Iscd+XpaRh3ZStk6cKU+bLKdDkyOdD9YzSEM0E/pkr3W6WSAoSHhxQQnJ1F2NmJsLeXWj8sWwxFq9s33Bbg5QXcuiUiL086vnTXDzb+DAQsQ580/kq0CHvl1d1mZyddl9fDQ0RpP2u1WtNuYONWQFF0RFpavtUWwdu3BfzzjyEUFucEEienok78KN6JIfb2pdrNMlXS7uT09MrZZM3wJgO6YJaVBWRkWAaz3FwB+fnWg5mu6ZfB7Mmwf7/SZIxQaqqA+fMdcO9ePl5+WVOMkFW8ICb9YyzZh5ogmLdCWY67KqqlSvcc84Hu/v7OyM3NfqjxQVQyuhYu4x+NRvg3mIkQBOm2+bgvKZCJ+mD2MIFYoZC2YRoIRPj4mLa06JbraDSGFj/DbwEajRT28vN1P9Ln6oMHhtAnBT9RP+WHLgjqpvl4FKHPvA50Ycl8P6WW2AKb29CNzzQdB2itO9h0+f37AlJSDM/JzbW9o3Z2xWvxK+okESenRzMEwPhLcPXqIiZNykPPnmrbT3xEGN4qmK0WM+Ng5uVl6Ls3DmbOziLc3Iy3ymD2qBia3aUftVowui29nw+zTrdt4/UFBYYzdXNyHE3WpacLFt2B+fkCFi92KNb+FDZoXddyVfiZgtYGuksftLrHlNe4K3d36Z8wlR2NBibHn+GYMnw5dHSUPnucnKR/sg4OIuztpc8lXctZZaQLVuahz5LpMuMuXuOWPt1ZnNLEwNLfZ36+NHZSdzk98y/Wtlr6HmUrryBILc0ODiKqVLHc7+JSq2ER9GwFwQcPBNy8qYBxN7GtsaIKhaGV1vb0LyL8/ABRVFisL6qOzb8E37ghYMwYRwC5lSbAMbyVo6KCWU6O1IyvC2YKhag/aAsLZuZ9908C43CkCzUPHkghRRdkCgs8upCjW5afL1gNQ5bPLX6Qetj5qqyxs5NaJqQfw5xMprcBZ2fAzU2ESiV1M6lUIvbtK+xPWsTEiXmFhqyyGndFlZ/535RaLeg/g7RawaQ7081N+qfo5CSatJiV19mllZkuVDmYfA8qOvTpzry01tKnVltv6Sss9BmframbbsPamL6KolJJX6Tc3UvfDSx9IbU+3s/auEDdGcAZGQKSkgxjBy2HXFiehe3oaNriZxzuDh1SWfQs5OQImDHDgeFNrrZsUWHGDAfcuCE1pY4bl4fOndUPHcwkjz6Y6c7k0X2jNA04psGlqHXmYam462yFJbW6sP8QzqXeZ1040p1lpAtD0vtiuO/qKpo8xnideZAyXWeYFFMXqnTb19033DZsy96+ZN0sXl4uFlMinDypRGqq5QZ8fUW0asXmqcedcXem7ouGYdZ/qbtPoZDCmKuroYVC6n40hDOG+LKhC8IqVelCn7WWPl33rmFMn6APf7oWaN1xcO+eYTyfrTF9lYHU1S4dk5LS/U+UuoF1k7k749atHCtzAlqeGHL7ttQKmJNjfbs3blSebyzlGt527tyJxYsXQ61W44033sCAAQNM1h86dAhz584FADz77LOIioqCi4sLevToAc2/R2Fubi6SkpJw+PBhVK1atTyLa9OWLSqMGeOon+jxxg0BH3/siCtX8tG8ucZqMDN8mIr64JKbW3ioMe6CM79vZwdkZtqZrNOdOaprDTIOWcUJUoWHo9LThRFr4cg4OEmDk40fLxoFGtP7xuHI09MBeXm5VrdrHqTM1z3u1xMcOtT6vFhDh+ZXYKmorJieAGDanalWA5mZgr5FwcvLcMUA42BW2c6aI0vGoc+U7dCna+Hz8gKSkzX6wGfc0if9FlBQoDthQfd8y5M4imrpqyyhz5xuLKSXl/R3UK1ayc7CHjDAyeqX4Keeqjw9X4IoiuVSmpSUFPTr1w9bt26Fvb09+vbti/nz5yMgIAAAkJmZiY4dO2L16tUICAjAsmXLkJKSgkmTJpls56OPPkLt2rUxcuTIYr92evp9aLVlv1uNG7vg+nXLo1WpFFGtmmg1SJV0pvLi0LXcWGsBMg1O1luZSr7OsvvOeB4c3TgX3bLyDkdSi1N2+b6IDBRWD4/qbNPK4nE5HoxbWoy7M42vQGJvL33pkcaa4d853KS/x6eecsPdu1mP9ZeT4vDxcUNaWlZFF6PClaQeDJfmMu7mNW0gMHTxStO1SHMZSs8v7Mxd89Y93e1HeYyW5vPBfMwbILVWz59f9mPeFAoB3t6uJX5euX0HO3r0KIKCguApXaMDHTt2xN69ezFq1CgAwNWrV1G9enV9mGvdujWGDx9uEt4SEhJw/vx5fP755+VVzBIprMlUowECArSFdqUZB5yShiPjdb6+LsjKyq6033aocmjbVoO2bQtp96cKYT48wXTaDKk7U6mUgpm7u6E707jV2FZ3plwn4qWKp2tFMz3JpLAGEMvpWozH9ela+qSJdXXjvXVTABmGEwFFT9diraXvUR3f0pfdvCfzbNPU1FT4+Pjo7/v6+uLMmTP6+7Vq1UJycjLOnz+P+vXrY8+ePbh9+7bJNr7++mtERkZCWcJRmKVJscVRsybwzz+Wy/39Bcyd+2j6Iry9XR7J61R2Xl6sB4D1oFPR9WA63AH/XijcQBAANzf8G8qkWf51Z+DqTgAoi+5MHx832w96ArAeJJW1HkzDnultXSuf7se41a+wfkLdNVKNr5KgC3/STA0l/3zo1Uv6SUsD2rUToFJZv/RcRSm3xKHVavVz4QCGb5c67u7umD17NiZPngytVovevXvDzij2X7p0CXfu3EHr1q1L/Nrl1W06frzpmDdAalHr1SsPly+bflpbu8baw36DeFy6hx4W60HCepCUdz0U5yoADg6GSUzd3U27M3XjzKz9zevONCwL7C6UsB4kcqwHw5hx6+stu3YNJ+UYh72cHEE/rs/FxRl37z6wOl0LUPgcfbo2o3v3BKSlld8VFipdt6m/vz8SExP199PS0uDr66u/r9Fo4O/vj02bNgEAzpw5gxo1aujXx8XFoUuXLuVVvFKRmkxzTc42/eijPISHq/UHk0Yj6KcIMTQXG8bB5eWZz/Jtff4f8zED0hli0vYq09lBRHJWFlcBsLPj3yPRo2B9DryiT+Lw8QFu3dJYHdNnPDGzLuyZT9eiUomVcjhCuYW3kJAQLFy4EBkZGXByckJsbCymTZumXy8IAoYOHYpNmzbB19cXMTExJmHt1KlTeOONN8qreKXWs6faRr+37XECgGGAqOWPoL+t+1auO0NUEHRnCBmfHSRt23jcAGA5dsC8BfBRjh8gqgiV4SoARFTxHma6Fq22cn4GlFt48/PzQ2RkJAYNGoSCggL06tULgYGBGDFiBEaPHo2XXnoJUVFRGD58OPLz8xEcHIxhw4bpn5+UlAQ/P7/yKl6Fsz5AFCgq/Pn4AGlpUmoznvxRd4AZX+ZFdxF64xZAXfAz/lYhbcsQ/nTbNj9F3Dz4VebTxOnJoBsUnZUF3LnzeF0FgIgqlq7VvbIqt6lCKlJ5jXmraGU9hsG81c84AFpeHcIwGaRu3jjTI8ey6xewnBTSPAiWBsd6SR7neijsKgA6xt2ZTz/tgtzc+3ByMrSYWb+o+eNNjmOcygPrQcJ6kFT2eqh0Y96o8iv8Gnql6/o13Bf0YwsMwc8wgbAuBBpfj1IUpRY+UTT9J208OaQu9Omey65febJ1FQBAmjajuFcBkFqkH78va0REhWF4o1Iredev6TprXb/mY/+Mw59uAmSNRrqUie7i7LptCYI0jkkUiz7xg12/5auoqwAA0jgzqTtTy6sAEBGVAj8iqcIUfgkYoLhj/6x1/RqHP/OuX91Zv7m5gsl8XMYnfgiCoSUIsDzxw/z2k6QkVwFwd5dOAnB05EXNiYjKEsMbydrDdv0aXwDaWvgzP+vX0PVruEasYVumJ37olMecf+XhUVwFgIiIHh7DGz3RSnYBaMt1omh6XUDzrl/zs36Nr337MHP+KRSGmfyLG5ZMTwAwTDare02pO1OaNsPJSQpmxt2ZZXUVACIiejj8KCZ6CNJ0KtKPvb352pKf+GEaAC1b/0zDH5CZKRQ655/utcy7Mz09rXdnFnYVACIiqlwY3ogqWGnm/AOgH/ufJhUtAAAgAElEQVRX2Jx/omi4AgCvAkBE9PhgeCOSuaJP/CAioscNv4sTERERyQjDGxEREZGMMLwRERERyQjDGxEREZGMMLwRERERyQjDGxEREZGMMLwRERERyQjDGxEREZGMMLwRERERyQjDGxEREZGMMLwRERERyQjDGxEREZGMMLwRERERyQjDGxEREZGMMLwRERERyQjDGxEREZGMMLwRERERyQjDGxEREZGMMLwRERERyQjDGxEREZGMMLwRERERyQjDGxEREZGMMLwRERERyQjDGxEREZGMMLwRERERyQjDGxEREZGMMLwRERERyQjDGxEREZGMMLwRERERyQjDGxEREZGMMLwRERERyQjDGxEREZGMMLwRERERyQjDGxEREZGMMLwRERERyQjDGxEREZGMMLwRERERyQjDGxEREZGMlGt427lzJ7p06YIOHTpg7dq1FusPHTqE8PBwhIeHY+zYscjOzgYA3L9/H2PHjkX37t3RvXt3/PHHH+VZTCIiIiLZKLfwlpKSggULFmDdunXYtm0bNmzYgMuXL+vXZ2ZmYvz48ViwYAF27tyJ+vXrY8GCBQCAzz//HNWqVcO2bdswZswYTJ06tbyKSURERCQr5Rbejh49iqCgIHh6esLZ2RkdO3bE3r179euvXr2K6tWrIyAgAADQunVrxMXFQRRFxMbG4s033wQAtGzZEjNnziyvYhIRERHJSrmFt9TUVPj4+Ojv+/r6IiUlRX+/Vq1aSE5Oxvnz5wEAe/bswe3bt5Geng57e3usW7cOffr0waBBg6DRaMqrmERERESyoiqvDWu1WgiCoL8viqLJfXd3d8yePRuTJ0+GVqtF7969YWdnB41Gg9u3b8PNzQ0bNmzAkSNH8O6772L//v3Ffm1vb9cy3ZfKxMfHraKLUCmwHiSsBwnrQcJ6kLAeJKwHyeNYD+UW3vz9/ZGYmKi/n5aWBl9fX/19jUYDf39/bNq0CQBw5swZ1KhRA15eXlCpVOjatSsAIDQ0FA8ePEB6ejq8vb2L9drp6feh1YpluDeVg4+PG9LSsiq6GBWO9SBhPUhYDxLWg4T1IGE9SCp7PSgUQqkanMqt2zQkJAQJCQnIyMhATk4OYmNj0bJlS/16QRAwdOhQpKSkQBRFxMTEoEuXLrC3t0dISAh27doFADh16hScnJzg5eVVXkUlIiIiko1ya3nz8/NDZGQkBg0ahIKCAvTq1QuBgYEYMWIERo8ejZdeeglRUVEYPnw48vPzERwcjGHDhgEAZsyYgU8//RTr1q2DSqXCggULoFBwSjoiIiIiQRTFx65/kd2mjzfWg4T1IGE9SFgPEtaDhPUgqez1UOm6TYmIiIio7DG8EREREckIwxsRERGRjDC8EREREckIwxsRERGRjDC8EREREckIwxsRERGRjDC8EREREckIwxsRERGRjDC8EREREckIwxsRERGRjDC8EREREckIwxsRERGRjDC8EREREckIwxsRERGRjDC8EREREckIwxsRERGRjDC8EREREckIwxsRERGRjDC8EREREckIwxsRERGRjDC8EREREckIwxsRERGRjDC8EREREckIwxsRERGRjDC8EREREckIwxsRERGRjDC8EREREckIwxsRERGRjDC8EREREckIwxsRERGRjDC8EREREckIwxsRERGRjDC8EREREckIwxsRERGRjDC8EREREckIwxsRERGRjDC8EREREckIwxsRERGRjDC8EREREckIwxsRERGRjDC8EREREckIwxsRERGRjDC8EREREckIwxsRERGRjDC8EREREckIwxsRERGRjJRreNu5cye6dOmCDh06YO3atRbrDx06hPDwcISHh2Ps2LHIzs4GAPz2229o1qwZunXrhm7dumHChAnlWUwiIiIi2VCV14ZTUlKwYMECbN26Ffb29ujbty+aNWuGgIAAAEBmZibGjx+P1atXIyAgAMuWLcOCBQswadIknDt3DkOHDsVbb71VXsUjIiIikqVya3k7evQogoKC4OnpCWdnZ3Ts2BF79+7Vr7969SqqV6+uD3OtW7dGXFwcAODs2bOIj49HeHg4Ro4ciVu3bpVXMYmIiIhkpdxa3lJTU+Hj46O/7+vrizNnzujv16pVC8nJyTh//jzq16+PPXv24Pbt2wAANzc3dO7cGR06dMAPP/yAyMhIrF+/vtiv7e3tWnY7Usn4+LhVdBEqBdaDhPUgYT1IWA8S1oOE9SB5HOuh3MKbVquFIAj6+6Iomtx3d3fH7NmzMXnyZGi1WvTu3Rt2dnYAgKioKP3j+vXrh3nz5iErKwtubsV7A9LT70OrFctoTyoPHx83pKVlVXQxKhzrQcJ6kLAeJKwHCetBwnqQVPZ6UCiEUjU4lVu3qb+/P9LS0vT309LS4Ovrq7+v0Wjg7++PTZs2YcuWLXjuuedQo0YNaLVaLF68GBqNxmR7SqWyvIpKREREJBvlFt5CQkKQkJCAjIwM5OTkIDY2Fi1bttSvFwQBQ4cORUpKCkRRRExMDLp06QKFQoGff/4Z+/btAwBs27YNDRo0gLOzc3kVlYiIiEg2yi28+fn5ITIyEoMGDUL37t3RtWtXBAYGYsSIETh79iwUCgWioqIwfPhwdOrUCe7u7hg2bBgAYPbs2Vi1ahXCwsKwZcsWTJ8+vbyKSURERCQrgiiKj93gMI55e7yxHiSsBwnrQcJ6kLAeJKwHSWWvh0o35o2IiIiIyh7DGxEREZGMMLwRERERyQjDGxEREZGMMLwRERERyQjDGxEREZGMMLwRERERyQjDGxEREZGMMLwRERERyQjDGxEREZGMMLwRERERyQjDGxEREZGMMLwRERERyQjDGxEREZGMMLwRERERyQjDGxEREZGMMLwRERERyQjDGxEREZGMMLwRERERyQjDGxEREZGMMLwRERERyQjDGxEREZGMMLwRERERyQjDGxEREZGMMLwRERERyQjDGxEREZGMMLwRERERyQjDGxEREZGMMLwRERERyQjDGxEREZGMMLwRERERyQjDGxEREZGMMLwRERERyQjDGxEREZGMMLwRERERyYjN8Hbnzp1HUQ4iIiIiKgab4S0sLAxjx45FYmLioygPERERERXBZng7cOAAQkJCMGfOHISHh2Pt2rW4f//+oygbEREREZmxGd4cHR3Rs2dPbNy4EZMmTUJ0dDRatGiBzz77jF2qRERERI9YsU5YOHz4MN577z1ERkaiXbt2WL9+PapVq4Z33nmnvMtHREREREZUth7QunVreHp6on///vjiiy/g6OgIAKhXrx42bNhQ7gUkIiIiIgOb4W3evHmoV68eXFxckJ+fj/T0dHh7ewMA9u/fX+4FJCIiIiIDm+EtOTkZ48ePR2xsLG7cuIF+/fph5syZaNOmzaMoHxGRBY1GjTt30qBW5yM1VQGtVlvRRapwrAcJ60HCepBUpnpQqezh5eUDpdJm9LK9LVsPWLJkCVatWgUAeOaZZ/Djjz/inXfeYXgjogpz504aHB2d4eLiDzs7JdTqyvHhXJFUKgXrAawHHdaDpLLUgyiKyM7OxJ07aahatdpDb8/mCQtarRb+/v76+9WqVas0KZaInkxqdT5cXNwhCEJFF4WIyCZBEODi4g61Or9MtmczvFWpUgXr16+HWq2GRqPB5s2bUbVq1TJ5cSKi0mJwIyI5KcvPLJvhLSoqChs3bkRgYCACAwOxceNGTJkypVgb37lzJ7p06YIOHTpg7dq1FusPHTqE8PBwhIeHY+zYscjOzjZZn5ycjKZNm+L69evF3B0iIiKix5vN8FarVi1s3boVCQkJOHbsGDZu3IiaNWva3HBKSgoWLFiAdevWYdu2bdiwYQMuX76sX5+ZmYnx48djwYIF2LlzJ+rXr48FCxbo12u1WkycOBEFBQWl3DUiIgOHLRtRpfELqOrngSqNX4DDlo1ltu3s7PuYN282Bg7sjcGD++O9997ChQvny2z7hbl+PQmdOrVGXl6eyfI9e37CJ598WOjzbt26iV69wgEAy5cvQXz8IYvHrFixFCtWLC3y9VesWIrTp08CAGbNmobz5/8s6S7QYyw+/hCWL19S5GN27PgRP/+8F0Dhx2JpbNq0/qG3Zfx3smHDWhw58ktZFK1M2AxvGRkZiImJwZo1axATE4Ovv/4aY8eOtbnho0ePIigoCJ6ennB2dkbHjh2xd+9e/fqrV6+ievXqCAgIACDNJxcXF6dfv3z5coSEhMDLy6s0+0VEpOewZSPcxrwH5fUkCKII5fUkuI15r0wCnFarxbhx78Pd3R0rV65DTMw6DBkyAuPGjca9e3fLoPSFe/rpGqhTJwAJCfEmy/fu3YWuXbsVaxvDh49E8+avlur1T548Do1GAwAYP34y6td/vlTbocdT8+avYvjwkUU+5uzZ0/pGmoc5Fo1lZKQjPv5wmWxLp0eP3vj++xXIzy+bMWsPy+bZph988AEcHR1x+fJlhISE4OjRo3j55Zdtbjg1NRU+Pj76+76+vjhz5oz+fq1atZCcnIzz58+jfv362LNnD27fvg0AOHfuHH799VcsX77canerLd7eriV+jlz4+LhVdBEqBdaD5Emth9RUBVQq6bun/fp1cF27qsjHqxJ/h2DWOiXk5MDtg3fhtCam0OflDxiE/L79i9z277//jtTUFLz11ttQKKQyNW3aFJMnT4UgAKdPn8A333wFjUaDOnUC8NFHEzBz5nRcvnwRgiBgwIBB6NKlKy5duohZs6ZDo9HA3t4BkyZNRfXq1TB9+mf4668rAIAePf6L7t17mLx+eHgE4uL2oV279lCpFEhNTUFS0jWEhoZCFLWYM+dz/PXXZWRkZCAgoC6iomZCqZTKqVIpEBU1BY0bv4yuXSOwZs332LZtKzw9PeHm5o7nn38BKpUCmzatx549u5GbmwOVyg7Tps3EH3+cw4UL/4c5c6Zj1qx5mDdvDoYPfwsvv9wEMTErsHfvbiiVSjRtGoRRo95HSkoKxo8fi9q16+DixQuoUqUKZsyYAw8PD/2+qNUFVvf31q2bmD59Ku7cuQNHR0dMmDAZdes+i59+2o5169ZAEATUq/ccxo37GCqVM7p2bYf69Z9HevptrFy5GuvWrUFc3M/QajVo1iwYo0a9bzL+6ObNm4WWLSioMX799QQA4KefduDEieP49NPP0L17GDp06ITffvsVSqUSQ4eOwLp1q5GUlITRoyPRrl2HQo+ZZcuWIC0tDUlJ15CcfAsREd0xZMhwaDQaLFz4JU6cOA6tVoOwsHD06/c6jh9PxPLlS7F48TIA0L9njRs3QWTkKHh4eMLBwQFfffUNFiyYi8TE3yAIAjp1CsOgQYNx/Hgivv8+Go6Ojrh69W/UqROAqKiZyM/Pw+TJnyA9XfrfO2zYW2jZ0hB4Ll26iKlTJ2HtWulLzi+/HMKOHdvw+edfWD2uMjIyTMrTsWNnfX3t3/8z1q1bjby8PBQUFGDixCnIzc3FkSOHceJEInx9fRAbu09/LFp7b52dnREW1gGtW7fFmTOnoFQqMWPGbFSv/pRJ/W7bthlt27bT/z1MmTIROTk5UCgUGDPmQ7z4YiCOH0/E/PlzoFQq8eKLgfj777+wePEyXLhwHjNmRAEA6tatq/87Uakc0LBhIxw4sK/YX4ysUSgUZfK5bTO83bx5E3FxcZg6dSr69u2L9957r1iXxdJqtSZ/HKIomtx3d3fH7NmzMXnyZGi1WvTu3Rt2dnbIycnBZ599hq+++kr/QVhS6en3odWKpXpuZebj44a0tKyKLkaFYz1InuR60Gq1+tP/7QGItv7czYKb8fKinqvRaG1OM/B//3ceAQF1odXC5Ez8pk1D9Nu4du0fbN78E1xdXfHtt1/B3d0dq1ZtwN27dzFixBuoXbsuNm5chz59XkebNu2wZ89POHPmNFJSUnDv3j1ER6/F7dtpWLx4Ibp27W7y+q++2g6LFn2F+/ez4Ojogl27dqFjxy4QRQGnTp2EUqnCkiUrodVqMXr0SMTH/4J69Z4DAKjVWoiiCK1WxLlz57Bz53ZER6+FIAgYOXII6td/HvfuZeLgwYNYuHAJHBwcsXz5EmzcuB6RkR9hx45tGDr0TdSqVQeiKEKj0eKXX37B4cOHsHz5aqhUKkya9BE2b96EkJDmuHTpIsaPn4xnn62PiRM/xJ49u9CrV1/9vpw8ecrq/s6Z8zlatmyDnj17IyEhHtHRyzF48HCsXLkC330XAw8PT8ybNxvLli3F++9H4u7du+jffxAaN26CX389ij///BPLln0PQRAwbdqn2L1bqiPj97mosumOAa1WhCiK+vuenlWwfPlqzJz5Gb7/fiW+/noJzp49ja+/nodWrdoVesxotSIuXbqIb79djvv3s9C7d3d07/5f7N+/D6IoIjp6DfLz8zFmzCg8++xz0Gi0Jq+re880Gi3++ecqNm3agWrVqmPz5k1ITk5GTMwPEEU13n57BGrVqg1HR0ecPXsaa9duRtWqPnjrrcE4cuQIsrIy4edXDXPmfIlLly4gNnYvQkJa6Mv5zDMBAARcvHgRtWsHIDZ2H9q374xTp04VelwZl2f37p0QRRH5+Wps3boZs2d/CU9PT/z003bExERjzpwFCA1tiUaNXkaTJkHYt28vtFoRFy5ctPrevvvu+0hPv43GjV/BBx98iIULF2DDhvV4771Ik/o9fPgQpkyZDrVaix07tiE4uDn69x+EX389ihMnTiIgoD4++2wy5sz5EgEBdfHll3P19fvZZ5Px3nuReOWVIMTELAeQqK/3wMCG2LVrJzp1Ci/yM6EoWq3W5HNboRBK1eBkM7zpziytVasWLl68iIiICKjVapsb9vf3R2Jiov5+WloafH199fc1Gg38/f2xadMmAMCZM2dQo0YNJCYmIj09HW+//TYAqQXvzTffxKJFi1C7du2S7R0RPfby+/bHA6MAYE2Vxi9AeT3JYrn26Rq4t233Q72+QiHA3t6hyMfUqPEfuLpKH9DHjydi/PjJAABPT0+0aNESJ08eR3BwKObPn4Njx44iNLQlQkNb4P79LFy79g/GjBmFoKBQvPvu+xbbdnJyQkhICxw8eACdOoUjNnY3Zs6cCwBo2LAx3N09sGXLRly7dhXXrychJyfHahlPnDiOoKBQODs7AwBat24HjUYDFxdXTJ06HXFxsUhKuoZjx46ibt16he7r8eO/o127jvpLKYaFRWDPnl0ICWkOL68qePbZ+gCA2rUDkJmZafLc2rXrWN3fU6dOYOrUGQCA4ODmCA5uji1bNiA0tAU8PDwBABERr+Hzzz/Tb+uFF14EACQm/oY//zyHYcMGAgDy8nLh5+cPc7bKZk1QkBTQ/fz8UbWqD1QqFfz9qyEry/aXqsaNm8DOzg5eXlXg7u6O7Oz7SEz8DZcuXcTx49L/zpycB7hy5TJq1Xqm0O14eVVBtWrVAQAnTvyOLl26QqlUQqWyQ/v2nXH8+G8IDW2JZ56pA19fPwDAf/7zDLKyMvHii4FYuvQb3L6diuDg5hg8eJjF9jt27Iy4uFi88cbTOHXqBMaPnwwHB4dCjyvj8ugoFArMnPkFjhz5Bdeu/YOTJ48X2Thz6tTxIt/bZs2CAUjHi27MpbHr16/p88YrrzTD+PHjcPHiBYSENEfPnr1x5cpleHp6ISBAalkLC4vAV1/Nxd27d3H79m288koQAKBz56746aft+u36+VXD9evXCi33o2Szacvb2xvLly/Hiy++iC1btuDAgQPIzc21ueGQkBAkJCQgIyMDOTk5iI2NRcuWLfXrBUHA0KFDkZKSAlEUERMTgy5duqBFixY4cOAAtm/fju3bt8PX1xffffcdgxsRlVr2xCkQnZxMlolOTsieWLwz54tSv/7zuHjxPESzJrylS7/BiRPSP2EHB0O4E0XTljxRlK4Y0bp1O0RHr8Fzz72AjRvXYe7cz+Hh4YnVqzeiZ88+uHbtHwwd+rrVYBAW1g379u3FhQvn4eHhiRo1pJPK4uMPISpqMhwdHdGlSwQaNGhkUU4dqWfEsE6pVAIAUlKS8dZbQ3D/fhaCgkLQuXN4odsoav8AwN7e3myd6XYK21/jGelFUcTff/9lpXdF1I+/AwAHByk8arUa9O7dDzEx0njE7777HoMGDbUod1Fl0902b7iws7PT39bVV3EZv54gCPqWy3feGa0v69KlMQgLi7CYYsK4HMbHVlF1Yu31atSoiXXrNqN9+844ffokRox4w2Ie1w4dOuPgwf04ciQeTZsGwcHBocjjyrg8Og8ePMCIEW/g5s0baNCgEXr16lPkMWT7vXUw2Q9zgqCASiUdMw0aNMSaNRvRrFkw9u+PxccfR0KhUFgcp9LzTN938yshKJXKUvcIlrViTRVib2+PJk2a4MUXX8TXX3+NcePG2dywn58fIiMjMWjQIHTv3h1du3ZFYGAgRowYgbNnz0KhUCAqKgrDhw9Hp06d4O7ujmHDLFM/EdHDyuvZG1nzF0LzdA2IggDN0zWQNX8h8nr2fuhtN2jQCF5eVRAd/Z3+H8yxYwnYvXuH1RaTxo1fwa5d0rf5u3fv4pdfDqJRoyb49NMJ+L//+xPdu/fE8OEjceHCecTHH8K0aZ8iJKQ5PvhgHJycnJCammKlDA2RlpaKH3/chLCwCP3yxMTf0KZNO4SFRcDV1RUnT0pjqaxp0uQVHDnyC+7fv4+8vDwcPvw/AMD583/i6adroE+fAXjuuedx+PD/9NtQKlUm/1R1+xcXtw95eblQq9XYvXsHGjduUqy6LGx/GzZshLi42H/36RjmzJmBRo1eRnz8YWRm3gMA7NixDY0aWb5O48avYN++3Xjw4AHUajUmTBiLgweLf11uT09P/P33FYiiiPj4w8V+Xmm8/HIT7NixDWq1Gg8ePMA77wzDH3+chYeHJ27evIG8vDxkZt6z2tqke/6ePbug0WiQm5uD2Ni9VutEZ8uWDVixYinatGmHsWPH486dOxZTdlWt6gNfXz+sWbNS39VckuMKAJKSrkEQBAwaNBSNGzfBoUP/04dEpVJpcQwV970tzFNPPY1bt24BABYu/BL79u1B585dERn5MS5evIBatZ5BVlYWrlyRZsD4+ee9EAQBHh6e8Pf3x9Gj8frlxpKTb+Gpp2oUuxzlyWa36ezZszFnzhwAwIcffogPPyz89HNzujncjC1btkx/u1WrVmjVqlWR2zhw4ECxX4+IqDB5PXuXSVgzJwgCZs2aj4UL52HQoD5QqVTw8PDEF198hSpVvHH16t8mjx8yZDjmzZuNQYP6QKvVYtCgoahXrz4GDhyC2bOnIyZmGVQqO4wbNx7PPlsfBw8ewMCBvWFvb4+OHbugTp0Aq+Xo3DkMq1fH4IMPDJ/R4eGv4bPPJiIubh9UKju89FIgbt68CWvnnNWtWw///W8/DB8+CG5ubvDzky7h88orQfjxx814/fX/QhRFNGzYWH9CQbNmwZg793NMmmTo0goNbYFLly5g2LBB0GjUaNo0CD179kFaWqrNugwKCrW6v5GRH2H27On48cfNcHR0xMcfT8Izz9TGwIFDMGrUm1Cr1ahX7zl8+OEEi202b94Sly9fxJtvDv73hIUQdO7c1WZZdEaOHIWPPopElSreCAxsWK5nEHfv3gvXrydhyJD+0Gg06NIlXB98g4NDMXBgb1SrVh0NGjSy+vxu3XoiKekaBg/uB41Gg/btO+HVV1vrW4DNdeoUhqlTJ2LQoD5QKpV4993RcHOzHEzfsWMXLFu2GA0bNgZQsuMKAAIC6iIg4Fn0798LCoWApk2DcebMKQBAkyZNsXTpt/phBbrHF+e9LUxoaAucOJGIWrWeQe/efTF58ifYvXsnFAoFJk36DHZ2dpg8eRqmT/8UgqBAzZr/0bfmTZ48DZ9//hmWLfsWL7wQaLLdEycS0aJF2Z3B+jAEsai2S0gBbMeOHbKazZwnLDzeWA+SJ7kekpP/gb//fwBUnmsXVjTWg4T1IHmS6yE9/TY+/XQCvvlmmdV60Gq1WLJkIYYMeRNOTk5Yv34N0tLSLE58MFZQUIC33hqCJUuiLbrYS8L4swsoxxMWfH19ERYWhgYNGsDFxUW/fNKkSSV+MSIioifBhg1rsWfPLovlVatWxdy5X1dAiZ4c3t5V0bJlKxw+fBBt2rSxWK9QKODm5oERIwZBpbJDtWrV9CcRFWbTpvUYPHj4QwW3smSz5W3RokVWl48aNapcClQW2PL2eGM9SJ7kemDLmyXWg4T1IGE9SCpbPTyylrfKHNKIiIiInjQ2w5v5CQc6O3fuLPPCEBEREVHRbIa3yZMN/cAFBQXYtWsXatSoHKfKEhERET1pbIa3pk2bmtwPCQlB37599VdAICIiIqJHp8RTBd+5cwepqbbn6yEielJkZ9/HvHmzMXBgbwwe3B/vvfcWLlw4X+6ve/16Ejp1ao08s2u37tnzEz75pPA5OW/duolevaQhMcuXL0F8/CGLx6xYsRQrViwt8vVXrFiqnzB21qxpOH/+z5LuAj3G4uMPYfnyJUU+ZseOH/WT4RZ2LJbGpk3rS7St4hzvxbFhw1ocOfLLQ2/HlhKPebt58yb69OlTbgUiIioPW7aoMGOGA27cEPDUUyImTsxDz562r9Nsi1arxbhx76Nx4yZYuXIdVCoVTpxIxLhxo7FmzUb99RnLw9NP10CdOgFISIhHu3bt9cv37t2FPn0GFGsbw4ePLPXrnzx5HI0aSTOz2ppqgZ48zZu/iubNi57U9uzZ0/pj6GGORWMZGemIjz+Mr776tky2VxI9evTGu++OwCuvNCvXaUVKNOZNEARUqVIFderUKbcCERGVtS1bVBgzxhE5OdJk49evCxgzxhFA7kMHuBMnEpGSkoxhw97SX/ewceMm+OSTT6HVanHiRCIWL/4aGo0WtWvXwbhxEzB79nRcvnwRCoUCffVq1ZsAACAASURBVPu+js6du+Ly5UuYM2cGNBoN7O3t8cknU1CtWnV8/vln+isavPbafxER8ZrJ63fpEo6ff96rD2+pqSlISrqGZs2CoVarMW/eLPz11xVkZGQgICBAf4F3nRkzpqJRo5fRpUs41q1bhR07foSHhyfc3Nzw3HMv/Ft/G7B3727k5ubAzs4OU6fOwB9/nMOFC/+H2bOnY+bMuViwYA6GDn0TjRs3wapV0YiN3QOFQoFXXgnCO++MRmpqCj75ZBxq166DixcvoEoVb0ybNgvu7h76sqjVaqv7m5x8CzNnfoY7dzL+vcLCZAQE1MWuXTuwfv0aCIKAevWeQ2TkR3B3d0XXru1Qr97zSE+/jeXLV+GHH9bgf//7GRqNFs2aBeHtt0ebTDx/69bNQsvWvHkTxMdLVyjYvXsnTp48jokTp6JXr3C0a9cRv/9+DEqlEoMHD8f69Wtw/XoS3n33A7Rt2x6FWbFiKW7fTkNS0jWkpCSja9dueOONYdBoNPj2269w8uRxaDRadOnSFX36DMCJE4mIjv4OixZ9Z/KeNWr0MsaOfQ8eHp5wcHDA/PmL8PXX85CY+DsUCgEdOnTG668PxokTiVi9eiUcHR1x9erfqFMnAFOmzEB+fh6mTp2I9PR0AMDQoSNMwtbly5cQFTUJq1ZtAADExx/GTz9tw/Tpc6weVxkZGSbl6dChs76+DhyIw/r1a5CXl4eCgnxMmPApcnNzER9/GMeP/w5v76qIi9unPxatvbfOzs7o1q0jWrVqizNnTkGpVCEq6nNUr/6USf1u3boJrVu30R9Ts2fPtCirg4NjiY73mjVrFes9t7OzQ2BgQ/z8816TS9WVNZvdpjVr1sTu3bvRtGlTeHt7Y968ebh9+3a5FYiIqCTWr1ehe3enIn8++MAQ3HRycgR88IFjkc/bsMHm91tcvHgBdes+a3HB6uDg5vDyqgJAurbj118vwaRJnyE6eik8PDywevVGfPXVEkRHL8Ply5ewceM69O37OlasWI2IiNfwxx9ncfbsaWRmZmLlynX44ouvrF7Tsk2b9jh9+iTu35fm/Nu3bw86duwCpVKJc+fOQKWyw9KlK7Fhw4/IyspCQsIRq/tx/vyf2LVrB6Kj1+LLL7/VX84qO/s+Dh8+hEWLlmL16o0ICWmBLVs2onPnrqhX7zl8/PEkk0t2JSQcQXz8YSxfvhrR0Wtx40YStm3bAkAKA336DMDq1Rvh6uqK2Ng9JmUobH/nzZuFV19tg9WrN2Lo0Dfx/fcrcOXKZaxaFY1Fi77DqlUb4OjohJUrpcsv3r17FwMGDEJMzDokJv6GCxf+D8uWrcLKlWuRlpZm8brFKZs1Vap4Y8WK1ahV6xmsWROD+fMXYfLkKKxZs9Lmcy9fvoQFC77Bd9/FYM2a75GVlYWdO38EAERHr8WyZd/jl18OFXodU51r1/7Bp59Ow5dffott27YgJSUF33//A6KjV+HQoQP663SeO3cGkZEfYe3azUhJScaxYwk4fPgg/P2rIzp6DSZMmIzTp0+ZbDsgoC4EQYG//pKuAbp/fyw6dOhS5HFlXB4drVaL7du3YM6cL/H99z+gf/9BWL06Bq+80gzNm7fE8OEj0axZsP7xRb236enpePnlpli5ch0aNGiELVs2WtRJfPxhNGggXcrr7NnTVsta0uO9JO95w4aNyv06uDY/mcaPH6+fofipp55C06ZNMWHCBJNrlBIRVWZmQ8JsLi8JhUKAvb1DkY+pUeM/+ms3Hj+eqO9i9PT0RIsWLXHy5HEEB4di/vw5OHbsKEJDWyI0tAXu38/CtWv/YMyYUQgKCsW7775vsW0nJyeEhLTAwYMH0KlTOGJjd2PmzLkAgIYNG8Pd3QNbtmzEtWtXcf16EnJycqyW8cSJ4wgKCoWzszMAoHXrdtBoNHBxccXUqdMRFxeLpKRrOHbsKOrWrVfovh4//jvatesIR0dHAEBYWAT27NmFkBApzD77bH0AQO3aAcjMzDR5bu3adazu76lTJ/QthsHBzREc3BxbtmxAaGgLfbd0RMRr+PxzwzVWX3jhRQDSRdT//PMchg0bCADIy8uFn5+/Rbltlc2aoKAQAICfnz+qVvWBSqWCv381ZGXZnjy7ceMmsLOzg5dXFbi7uyM7+z4SE3/DpUsXcfz4/7d35+FRVQcbwN97ZyaTfQESgkCLLRb6qSyKShBCsZqQhAgqIFah7FXrR0VsCRUXqLaCtGmp1qqfiCjIUgUEAREtIBBa0Fq0ggUVZU0CZM/s93x/3Jk7dzaSQIbkJu/veWByl7lz5mSWN+ece67a0mez1ePLL4+gR4/LIx4nLa0DunS5DADw8cf7kJ8/AiaTCWazBbfckoePPvonbrwxG5df/n1kZHQGAHz3u5ejpqYaV13VBy+88BzOnClDVtZgTJw4JeT4ubl52LZtK37602745JOPUVT0KKxWa8TXlb48PrIs47e/fQa7d3+Ib7/9Bv/610chf+zoffLJR+f93fqC3ve+9/2w4fb48W+RkZEBQL3IfUJCckhZL/T13pjfeefOXXD8+LcRn19zaDC8VVRUYMKECQAAq9WKiRMnYt26dVEtFBFRY40b58bo0c7z7nPNNQk4fjz0+szdugmsWxc+zDRW797/g7Vr/wYhREBX3AsvPIfrrrsBALSLXgOAEIGzvQsBeDxuDBt2M666qg927/4Qq1evQEnJLsyePRevvbYa+/b9AyUluzF58j147bXVIRcPLygYiaVLX8Lll1+BlJRUdO/+HQC+AeMvYMyYccjPvxWVlZWIdFEdtez+bSaTCR6PB6Wlp/G///sz3HHHWAwcOAgdOnTE4cNfRKyPSM8PQMgYoOCypKSkhn2+JpM54D5Hj34d5io6Ah6PR1uyWtXwqCgejB17F8aNuwcAUFNTA5PJFFLu85XN97t1uwO72C0Wi/ZzuGOej/7xJEmCEAIej4L775+BoUPVBpPKykrExcXh888/C7ivvhz619b56iTc43Xv/h2sWPE37N1bgt27d2Llytfx+utrAoJVTk4eZsy4Fz17/gDXXz8QVqv1vK8rfXl86uvrMW3aT5GTk4e+ffvj+9/vGbbFrDHPQ/8YvucRTJJkmM3qa2bnzh148cXnQ8p6oa/3xvzOTSbTecNpc2jw6OqTKdWWz5w5E/HNT0TUGj3yiANxcYGfW3Fx6kkLF6tv3/5IS+uAJUte1L5g/vGPEmza9HbYFpNrrrkO77yzHoD65fzhh9vRv/8APPbYHBw8+DlGjboDU6feiy++OIRdu3bgN795DIMGDcaDDz6MuLg4lJWVhhyzb99+KC8vw9q1awLG2ezf/0/cdNPNKCi4FYmJifjXvz6ConhC7g8AAwZch927P0RtbS0cDgd27vw7ALU7tVu37rjzzrvxwx/+D3bu/Lt2DJPJHPCl6nt+27a9C4fDDrfbjU2b3sY11wxoVF1Ger79+vXHtm1bvc/pH1i48Cn0738tdu3aierqKgDA22+vQ//+oY9zzTXX4d13N6G+vh5utxtz5szC9u3vN6o8gNo6+vXXX0IIEfWusGuvHYC3314Ht9uN+vp63H//FPznP58iJSUVJ0+egMPhQHV1VcSu1GuvHYDNm9+Bx+OB3W7D1q1bwtaJz5tvrsLLL7+Am266GbNmFaGiogJ1dXUB+3TqlI6MjM54/fVXkJubD6BprytAHTYgSRImTJiMa64ZgB07/g5FUUO+LzTpNfZ3G0nXrt1w6tQpAMC+ff8IW9YLeb031unTp9C1a3Tnw22w5W3ixIkYNWoUhgwZAkmSsGfPHvzqV7+KaqGIiJqTelKCPSpnm0qShKef/gP+/OffY8KEO2E2m5GSkopnnvkTOnToiKNHvw7Yf9Kkqfj97xdgwoQ7oSgKJkyYjF69emP8+ElYsOBJLF36EsxmCx5+uAg/+EFvbN/+AcaPH4uYmBjk5uYHjC/Ty8srwGuvLcWDD/qnCCksvA3z5j2CbdvehdlswdVX98HJkydx7bWh97/iil4YM+YuTJ06AUlJSejcuQsA4LrrBmLt2r/hnnvGQAiBfv2u0U4ouOGGLCxa9DvMnevv0rrxxiE4fPgLTJkyAR6PG9dfPxB33HGnNqbofAYOvDHs850581dYsOBJrF37N+8JC3Nx+eXfw/jxk/DAA9PhdrvRq9cP8ctfzgk55uDB2Thy5L+YPn0iFMWDG24YhLy8EQ2Wxefeex/Ar341Ex06dESfPv1QVVXZ6Ps21ahRo3H8+DFMmvQTeDwe5OcXasE3K+tGjB8/Fl26XIa+ffuHvf/IkXfg2LFvMXHiXfB4PLjlluEYOnQYPv54f9j9hw8vwBNPPIIJE+6EyWTCz38+I6RVFwByc/Px0kvPo18/dRxZU15XgDp2rmfPH+AnPxkNWZZw/fVZOHBAHV83YMD1eOGFv2jDCnz7N+Z3G8mNNw7Bxx/vR48el2PkyNvw2GO/DinriBGjmvx6b6yPP96PIUPOf5btxWrwwvQAcOjQIezduxcmkwkDBw7EFVdcEdVCXSxemL5tYz2o2nM98ML0oVgPKtaDqj3Xw9mzZ/DYY3Pw3HMvXfJ6cLlc+NnPJuGvf10SdqqQS3Zh+tLSUqxcuRJPPPEEvvrqKyxatAjz5s1Denp6kx+MiIioPVi1ajk2b34nZH2nTp2waNHiFihR+9GxYydkZ/8IO3du1064vFTWrFmJiROnRnWON6ARLW8TJ07ETTfdhAkTJsDhcOCNN97A7t27W/XZpmx5a9tYD6r2XA9seQvFelCxHlSsB1Vrq4fmanlr8ISFcGeblpeXN/mBiIiIiOji8WxTIjIkfg4RkZE052dWk842BYCSkhKebUpELcpsjkFdXTUSEpJbuihERA0SQqCurhpmc/OMhWswvI0ePRpXXXWVdrbpd77zHSxbtizkgvVERJdKWlo6KirKUVtbCVmWtTmj2jPWg4r1oGI9qFpTPZjNMUhLa56TPRu+cB+ALl26wOl0Yvny5aivr8f48eOb5cGJiC6EyWRGp07qvEzt+cQNPdaDivWgYj2o2mo9nDe8ffXVV3j11Vfx9ttvo2vXrrDb7fjggw/CTuJHRERERNEX8YSF6dOn45577oHFYsGyZcuwceNGJCQkMLgRERERtaCI4e3zzz/HlVdeiSuuuALf/a46J4n+ostEREREdOlFDG/bt2/Hbbfdho0bN2Lw4MGYMWMGHI6Lv4gzEREREV24iOHNbDYjPz8fr732Gt566y1kZGTA4XAgJycHb7zxxqUsIxERERF5NThJLwD07NkTc+fOxc6dOzFlyhSsXr062uUiIiIiojAaFd584uLicOedd2Lt2rXRKg8RERERnUeTwhsRERERtSyGNyIiIiIDYXgjIiIiMhCGNyIiIiIDYXgjIiIiMhCGNyIiIiIDYXgjIiIiMhCGNyIiIiIDYXgjIiIiMhCGNyIiIiIDYXgjIiIiMhCGNyIiIiIDYXgjIiIiMhCGNyIiIiIDYXgjIiIiMhCGNyIiIiIDiWp427BhA/Lz85GTk4Ply5eHbN+xYwcKCwtRWFiIWbNmoa6uDgBw5MgRjBs3DrfeeivGjx+PEydORLOYRERERIYRtfBWWlqK4uJirFixAuvWrcOqVatw5MgRbXt1dTWKiopQXFyMDRs2oHfv3iguLgYAzJs3D/fffz/efvtt5Ofn4w9/+EO0iklERERkKFELb3v27MHAgQORmpqK+Ph45ObmYsuWLdr2o0eP4rLLLkPPnj0BAMOGDcO2bdsAAK+88gqys7OhKApOnjyJ5OTkaBWTiIiIyFCiFt7KysqQnp6uLWdkZKC0tFRb7tGjB06fPo1Dhw4BADZv3owzZ84AAMxmM6qrq5GdnY033ngDY8eOjVYxiYiIiAzFHK0DK4oCSZK0ZSFEwHJycjIWLFiARx99FIqiYOzYsbBYLAHbd+3ahZ07d+K+++7D+++/D5PJ1KjH7tgxsfmeSCuTnp7U0kVoFVgPKtaDivWgYj2oWA8q1oOqLdZD1MJbZmYm9u/fry2Xl5cjIyNDW/Z4PMjMzMSaNWsAAAcOHED37t0BAJs2bUJeXh4kSUJ2djbsdjuqqqrQoUOHRj322bO1UBTRjM+mdUhPT0J5eU1LF6PFsR5UrAcV60HFelCxHlSsB1VrrwdZli6owSlq3aaDBg1CSUkJzp07B5vNhq1btyI7O1vbLkkSJk+ejNLSUgghsHTpUuTn5wMAlixZgvfeew8AsHfvXqSlpTU6uBERERG1ZVFreevcuTNmzpyJCRMmwOVyYfTo0ejTpw+mTZuGGTNm4Oqrr8b8+fMxdepUOJ1OZGVlYcqUKQCAp59+Go8++iiee+45JCUlYfHixdEqJhEREZGhSEKINte/yG7Tto31oGI9qFgPKtaDivWgYj2oWns9tLpuUyIiIiJqfgxvRERERAbC8EZERERkIAxvRERERAbC8EZERERkIAxvRERERAbC8EZERERkIAxvRERERAbC8EZERERkIAxvRERERAbC8EZERERkIAxvRERERAbC8EZERERkIAxvRERERAbC8EZERERkIAxvRERERAbC8EZERERkIAxvRERERAbC8EZERERkIAxvRERERAbC8EZERERkIAxvRERERAbC8EZERERkIAxvRERERAbC8EZERERkIAxvRERERAbC8EZERERkIAxvRERERAbC8EZERERkIAxvRERERAbC8EZERERkIAxvRERERAbC8EZERERkIAxvRERERAbC8EZERERkIAxvRERERAbC8EZERERkIAxvRERERAbC8EZERERkIAxvRERERAbC8EZERERkIAxvRERERAbC8EZERERkIAxvRERERAbC8EZERERkIAxvRERERAbC8EZERERkIFENbxs2bEB+fj5ycnKwfPnykO07duxAYWEhCgsLMWvWLNTV1QEAvvzyS9x9990YOXIk7rzzThw8eDCaxSQiIiIyjKiFt9LSUhQXF2PFihVYt24dVq1ahSNHjmjbq6urUVRUhOLiYmzYsAG9e/dGcXExAGDu3LmYNm0a1q9fjwcffBCzZ8+OVjGJiIiIDCVq4W3Pnj0YOHAgUlNTER8fj9zcXGzZskXbfvToUVx22WXo2bMnAGDYsGHYtm0bAGDMmDEYMmQIAKBXr144depUtIpJREREZCjmaB24rKwM6enp2nJGRgYOHDigLffo0QOnT5/GoUOH0Lt3b2zevBlnzpwBANx+++3afosXL8bNN9/cpMfu2DHxIkvfeqWnJ7V0EVoF1oOK9aBiPahYDyrWg4r1oGqL9RC18KYoCiRJ0paFEAHLycnJWLBgAR599FEoioKxY8fCYrEE7L9w4UL8+9//xrJly5r02GfP1kJRxMU/iVYmPT0J5eU1LV2MFsd6ULEeVKwHFetBxXpQsR5Urb0eZFm6oAanqIW3zMxM7N+/X1suLy9HRkaGtuzxeJCZmYk1a9YAAA4cOIDu3bsDANxuN2bPno3S0lIsW7YMSUltLzUTERERXYiojXkbNGgQSkpKcO7cOdhsNmzduhXZ2dnadkmSMHnyZJSWlkIIgaVLlyI/Px8AsGDBAtTW1mLJkiUMbkREREQ6UWt569y5M2bOnIkJEybA5XJh9OjR6NOnD6ZNm4YZM2bg6quvxvz58zF16lQ4nU5kZWVhypQpOHfuHJYvX45u3bphzJgx2vHWr18fraISERERGYYkhGhzg8M45q1tYz2oWA8q1oOK9aBiPahYD6rWXg8XOuaNV1ggIiIiMhCGNyIiIiIDYXgjIiIiMhCGNyIiIiIDYXgjIiIiMhCGNyIiIiIDYXgjIiIiMhCGNyIiIiIDYXgjIiIiMhCGNyIiIiIDYXgjIiIiMhCGNyIiIiIDYXgjIiIiMhCGNyIiIiIDYXgjIiIiMhCGNyIiIiIDYXgjIiIiMhCGNyIiIiIDYXgjIiIiMhCGNyIiIiIDYXgjIiIiMhCGNyIiIiIDYXgjIiIiMhCGNyIiIiIDYXgjIiIiMhCGNyIiIiIDYXgjIiIiMhCGNyIiIiIDYXgjIiIiMhCGNyIiIiIDYXgjIiIiMhCGNyIiIiIDYXgjIiIiMhCGNyIiIiIDYXgjIiIiMhCGNyIiIiIDYXgjIiIiMhCGNyIiIiIDYXgjIiIiMhCGNyIiIiIDYXgjIiIiMhCGNyIiIiIDYXgjIiIiMhCGNyIiIiIDYXgjIiIiMhCGNyIiIiIDiWp427BhA/Lz85GTk4Ply5eHbN+xYwcKCwtRWFiIWbNmoa6uLmD7mjVrUFRUFM0iEhERERlK1MJbaWkpiouLsWLFCqxbtw6rVq3CkSNHtO3V1dUoKipCcXExNmzYgN69e6O4uBgA4HA4sGjRIvz2t7+NVvGIiIiIDClq4W3Pnj0YOHAgUlNTER8fj9zcXGzZskXbfvToUVx22WXo2bMnAGDYsGHYtm0bAGDfvn1QFAW//OUvo1U8IiIiIkMyR+vAZWVlSE9P15YzMjJw4MABbblHjx44ffo0Dh06hN69e2Pz5s04c+YMAGDw4MEYPHgw3nrrrQt67I4dEy+u8K1YenpSSxehVWA9qFgPKtaDivWgYj2oWA+qtlgPUQtviqJAkiRtWQgRsJycnIwFCxbg0UcfhaIoGDt2LCwWS7M89tmztVAU0SzHak3S05NQXl7T0sVocawHFetBxXpQsR5UrAcV60HV2utBlqULanCKWnjLzMzE/v37teXy8nJkZGRoyx6PB5mZmVizZg0A4MCBA+jevXu0ikNERETUJkRtzNugQYNQUlKCc+fOwWazYevWrcjOzta2S5KEyZMno7S0FEIILF26FPn5+dEqDhEREVGbELXw1rlzZ8ycORMTJkzAqFGjMGLECPTp0wfTpk3Dp59+ClmWMX/+fEydOhXDhw9HcnIypkyZEq3iEBEREbUJkhCizQ0O45i3to31oGI9qFgPKtaDivWgYj2oWns9XOiYN15hgYiIiMhAGN6IiIiIDIThrYmsb65Gh2uuRKfOKejQ/39gXf0G4PEAigK0vR5oIiIiamWiNlVIW2R9czWSHvpfSDYbAMB04jiSHpoB06HP4Ro81LuXACQZQpIASQIkGZBlQPYuy95lCeo2bZ0EAXWbCN5H9u5XlQS5wqYeS9atl2UIeOfQ0x7X9y9oXdA+AsH7h98v7HYiIiK65BjemiDhqXlacPORnA7EvboEiI+HsMZCWGMBa4z6c0wMEGuFsFohYmKBmBg1cEEACgDh9rbWCTXzAYAQkCAgCXWdf7sAauNhqqwPXOfbx5enfI1/voAl4N8WTLuP8N8veFvIgf3rheQLpUEB1RdI9T/rA6ok6QJq8D6y93hBx/HeCkiAUg/pbF1oQPU976B/AQE1wj4RgysREVErw/DWBPKJ4+HX19QgYeHvGnUMYYmBiLUC1lg11MXGqj/HWr3BT12nrdf2sQIdU2F2Q1sWVu9+sd79rLFArBUwXYJfqxD+bmJdAPWv994qitqt7F0nefcJG1C14+I8AVUCUuNhrqjTFUYKDKhacPUFThFwE7JfyAb/cYU+SEphAmpQuITsbXWFFNSKGmZ/SIGtqPqAGjZMInB9jAKpplbbJ2wrqtkMmEwMokREbQjDWxMoXbvBdPxYyHpPp3TU/v5PgMMOye6A5LADDgckuy1o2Q7Jblf38y7r10uVVZC829Rj2SG5XAGP1ZgTioXZHDb8idg4CKs1KOypAVBYdYEyznff2MD9Y+O04Amz+aIDwQWPEExLgDDFXdRjN5ovjEYKqBCAIsIGVEBAFrrgGC6Q+pb1+4TNlL6A6r0VAkiJg7nKFrizQGB49d5HmExqy6/FAhFjVVuFvf+EJUYNeGYTYDJByCZ/6GPwIyJqdRjemqDukccDxrwBgLBaYRv/UyhpaYBs8regmEzN86AeN+BwQnLYkWqVUVV6Tg1+DjvgDYZaIGwoODockKqrQu/vdDa5WMJk8rYYBoW/WGtgcLTqWgZDWhl997f6w2KsLyw2T0C8aBfZfRrVU1jSEiDMdQ3vB/hPqvF4INXVQq72AIrHHzp9oU+S1P0kSSu9MMcAMRYt6GnBz2qFMJm9QU8GzObQ4EdERM2O4a0JHHeMBaCOfZNPHIfSORP1P7sfzmE3Q3Y7Aaf3n8sFyeNR7+RrVdGNQRO+RhRZVr/0ZFkNQ+HCn8kMxJsh4uOBtAQo8anN/8Q8HsDpCBv+AloJ7XZ/y6AvDDp06737y2fP6loZHf77NJGQTd4xg7G61sNYICEeiSZLSGugFhBjw7caal3SuqAJS0zLB8RLwRemLBYATQiVQnhDngI4nZDsdsi+rnAlKPj59vdVpySrrXoWs1r3ZvV3BkuMOi7UZPa39pm8gc8X/GSeCE9EFAnDWxM57hirhTg9JXiF8Halef9Jigdwu9UvQY8HksetBT04nd7w51KXXS5Ibn13qffb0F0PqdIG9ewGKTD8+YKfydT0lj+TCYiLh4iLj15LkaJ4g5w+8DnCtBp619t0P/v2994HHhek6grIjsBAKdntTS6WkGXd+EGrvzVQP/7Q6m8NDBxvqG9lDHN/XwtjzKUNiJb330Pckpcgl5dBSc+AbfI0uH58y4UdTJLUPyB0L6emBz+P+ntS6iB7lKCpdXx/yfhCoPeukgmwqt28sMZAMfu7eWG1elv4vIE0Xgbsdn/4aw9hnIjaNYa3aPENFjerVRz8hRe83KjwlxYPd2kl4PYu61r6ZJdDF/7ckNy6rlABdWC8dl6A99FN/rAnglv9fAPrm4ssA3FxEHFxFx0Q09ISUFMRprtQCG/rkC2gq1gLh3Zb4HKYVkPJ2+oIuwNSVSXkMt34Q98+TZzPT0hS6EkpQV3EYQNiQCthYCAUVivg6AjJ7vEHRFmG5f33kFD8jNbSaSorRULxM6gDLjzAXSgt+Pk/Zhpdc4riP9mlvh4mT41/HPqgcAAAHyNJREFUWfGOE/S9PlPiYKmyaUcXJrNufF8MRIzVH/wsFm8rX4RuXgY/orZPfzKdbziJ0C17xzFLQv0jU+mc2eo+GxjeWqtw4S81CcJl8i/rhA1/vhen262GPS0MKoEtfy4XJKdDPTnC6QRsdm/Ln34QPOBvFtGFP1kGZJO321fWtQa2wBehJHmDkVUrdrMTAnA51SCntfrpxg86HECEE1WCxx/CbodUXQ3ZUa5rifQGTyXkNxqWvhNdWK1qeA0Kl5LDgfjFf4D93DmI1FQoqakQKf5beOurVfG9liL88RMgeOxfwPi+OsjV1WoLoC8Q6k9N1oY1qP8JsyW0m5fj+4haTqSgpf9jzrfO5VJ7uLy3ktsNJFthLq8EXG7A7f0+FN5hTZBChzb5HtM37FcIKJ3Stc+i1qJ1lYaajyT5v1RiYhps+QtL3/LncQeGv6CWP8nphOTyhsGA8CcFTvMB+FtNtGkyTGr3pdbl20LhrzEkCYixqq05yclRDIiukFZDbfygtwUwUVZQX1EdEByta1aGL3Z9PeJf/Ev4h4uNg5KaApGaBiUlFSIlRQ15Kb6QlwaRmqL+nJIKxF2iM30v1EWN7/N+Ibhc6vi+6qroje/zdfNyfB+1FRcatDweSC6X+j3jdkUIWvC/mYOClpAk9Y9WWfKOHfdN2yQDMUnq43qHYEDyTuHUSNLZM81TN82M4Y0i07UoXGz4Cx73p4U/b2uf5HSqgc/lUsOI2wUIxf9g+vDnrodUVa+bH83kn09N6wpupeGvMSRJDdwxMUBSUuS6TkuAI6j72LLj7zCVlYbsqmR0Rs0LL6vT0VRVQq6s8N5WQqqq0n6Wz56B/OURSFWVIdPU+AirVQt2AS15Kan+kJeapgVAxMUZ43eh/4PHK2rj+7Q/671zCXrP5kVMDBRLmPF94Vr7OL6PLkZw0FK8n8sRg5ZHDVZu90UFLU24oKVvcW9i0Ir4Xo2LA+yN68kwEoY3ip7zfBE26ktRUbxhTxf+POrYP09ppdblC6cDktPlb/lz2NWfg8OfJPvnaPNNeCv75jYL6vI16Pgn2+RpAWPeAO90NpOnQSQmQSQmAd26wXOeY6h3EkB9PeSqSkiVleqt7+dK9WffNvM3R9UwGGHKGWGJgUhN0bXkqaHPH/h0t6mpQHyC8eq+ucb32ephqtWN7/MoQXURdGKHbnwfOqdBrnN7WxisHN/XlviCli5sRQxabrcaqM7FQC6rCg1aHgVwu9T7a8f33jYpaHnXXUDQoovH8EatlyyrX0xe2kdJehIUxDZ8f+0LMHjcn7c53xWh5c9mV7vNhILAL8ug7jJf+NOmetGFP18YvMRcP74FdcDFn20qSUBCApSEBOCyro0Le3YbZG/Lnr9Vz3urC4DmE8fU/ey28Icym8O35KWkqt27uvF6IjUNSI1v2nNrbZoyvi+YrtUEtbUwnasJXBfczQtwfF+0XUjQCmnR8v3zRA5avpPQfI8J+K/EIpuAtASYauxhgpYMSPEMWgbH8EZtl+9LMcLYpwa/JPXhL2Dcnzf8+cKeQz3ZQ3J7T/iw2wGny9+FEDb86T5kZRnCd/JH8Hx/F8D141ta5szSuHgocfFAly6Nu4/drrXe+VvyqnStfBWQK6sgnzoFS1UlpPr68McxmZCSkhLYlZuiG8OntfKpY/lEUnLbGWemD1MJCRBNmW/b99pu0vg+dSJnYbaEmbjZ6h/fp79ih34Ov9ZW740JWr51wUHL7Vbf8+cLWpHG/AJBnwGSv+XKF7RMJrWOLzRopSZAiEZO4k2Gw/BGFElzhz9fy59bFwa9J30Ejvnztvwp/vAnJMl/jqTvy8Bjg1TjCAx/vg/9Fmr5a5LYWCixmUDnzMbt73RAqvKGuwp/S168ox6u02XqtsoKyP/9AuaqKsh1tWEPI2QTRHKyP+Tpum8DunB9YTA5uW22NjXH+D6HA5KtPmB8nwDUS8TJkjp0IXj+vuDxfb5u3piYyN28vjP9IgUtRVH/qFIUwF0LubQyNGh5/GchBgYt7/hDresQiBi0JG/renMHLaImYngjipaLDX++uf684/4Cun3dbiA1Fp5TFYDL6Z3o2dvy53B4r/Lh1h1M8rf4mU0QZu/4LCNduD7GCpGeAU96RsDq+LQE1Ieb98/l8oc9XUuefryeVFUJ09dfwVxZAbmmJuzDCklSw54+5Pla+lJDu3RFSkrA2Lc2pxHj+yK+toPG98l1terVaHzhz3d831F0wc+7ERGDFqC+xtMSYKqqP3/QslgAmUGLjKsNf8IQGVwDEz0jPQmKNUVbDDvXn/6KHS63Os7PbgdsNsh2mza/nL+FxDuORhLaGBlhNvmDnpG+7CwWiE6d4OnUqXH7u93qtX+rKv0hr9Ib+qq8Z+VWVsL0zVE1DFZXR5ywWUlK8nbbpui6clP9Ic8X+Hxhzxvw27yg8X1AFOZjTEuAMLG7kC5OwJVqLuuKurlPhL26UktheCNqq7xTjujn+dN/UWphTwhtviUt5Lm9J27YvSHPZgNq69RxfPqxUBDesXpmtTXPF/SM2M1oNkN06AjRoWNoEA7H41EDnK4lTwt5FRVai5/pxHFI//lMDYYRJl9WEhK98+uleU/GSAkar5cKkeYPgPoTeYioeYVcqebEcSQ99L8A0GoCHMMbUXsnSWrLj8Vy/pAHBIU8b9BzeFvyHDY18NXXqF22+hM1fBNoms3+Mxl9Qc+oTCaItDSItLTGhT1FgVRb4w12Vf6pV6qCzso9dRLyoc/VEOjxhD2UiI8PmXoFndNhtSb4p2XRgmArvYoGUUMURRsTrN46gpbDr1Onj/JOIi8LxFXXqVcR0u/j8t46HIHLTiek2loEDySRbDYkPDWP4Y2IDMjbjSvgv8qCL+gFBBhFCe2ydToAmw2SzQbJYQPqbJBcDt2d2sC4vPORZYjkFIjklMaFPSHULxFtfr2KgC5dbWLlsjLIh/8LVFUi3u0OfyjfVTSCAl9AANR177b6q2jQpeM9sUoNOr7g4/AGp9B1Afu6gkJW0LoGA1mE13NjCdkExFoRY/GfGY2YGAirVb3ucWwcRHKKf1J0qxXCEgPrujfDHk8+cfyiytOcGN6IqPnJstraY7WGbc3TNMe4PJMHsDmMOS7vfCQJIikJIikJ6Na9wbn20lLjUXGiTDe/XpVuvJ6vla8KUsU5WL7+Sj1hwxVhYuWAq2joWvL0c+/pTtgwzFU0jMg3rMEbagJbmEJbmrQWJ5NAbFVtg0EJLqd6XWXfOl+4cnhvlYZeeQ0U32IBvNPJCN8wjhirFphEYpJuvX976Dr9beB2ERMDWKwQ1sB9YTIjLS0BVeFOaDoPy55d4a9U07XbRdVFc2J4I6KW0xzj8uJlwH2mfYzLOx9JAhISoSQkAl0beRUNmy1wvJ5+YmXdrfnbb9Xtdnv4Q4W7ikbw1TN0YVAkJDY67AUMHL/QSacvlhC6bjZdYAoOOvpWKYcztIvO6VDXu4JamhyOkHUBgSzCiTEN8bWfiobCT0oqFG+LVEALla81KiZGC2D6lquAdbqWK23ZYjHk+yzslWri4lD3yOMtWKpADG9E1Pqdb1xeehLcGbppPjgur3EkCYiPhxIfD3S5rOGwB/jDXtCEyr6zcn1Ts5hPHFe32ZpwFY3ga+WmpsL8+X8Qt+wV/8DxslIkFD+D+ppquK8fGNKqJDmdgEVCTEVN5JYmp67LL6j1KXQ8lDdcRWihbCwhSaHBRr9staotrA2ErICWprDb/C1aqRlpqKh3AZYYtoo2UciValrh2aaSEBcY6Vuxs2droSht7mkhPT0J5eXh56JqT1gPKtaD6oLrIdK4PLtdHZdntwF2h7pOm3NM8k/c6g13/qDXsheKT0tLQEUTu4eizuHQJk/Wt+Sp6wKnYZErKyHVR6/8wmQ6f9ecRdfy5Ftv8bc8BaxroJUqoFXKam2RMZut8vXQAi62HqSzZ+DKHhYwvU1zkmUJHTsmNvl+bfRPSiKiBjT3uLyamrY5X97FsFohMjLgychoeF9AbfmqrtLOvE2c83DIWX+AWrX1v/p12Jan5E4pqLJ7glqjLG23BZXaJb6aiYjOh/PlXToxMRCd0uHplA4AUDI6hx84ntEZzltywx8jLQEKW5yojWN4IyJqDpwvr9mFHThutcI2eVoLloqo5bXNdzwRUWt2MfPluZz++fLsNqDero7Lc9dDqqxv1ePymipk4HhLnW1K1MowvBERtVZNGZeXGgvXyXNtblye68e3MKwRBWF4IyIyOt+4vIQEjssjag5C+FuwWyGGNyKi9qIp4/I8ntBxeQGXOLOrIc/t0h3lPJc4i9JUC3QJ+IKMENCmzdGv963zhZ2Qdep6SQSt0/YPWqc/vu5vB/UgvmEBEgJORdYPF9DfwWODFHwCi28MaUg7tu7BJBlCkiASk1rlUAO+m4iIKJTJBJhMEIjVVoVth2jMuDybPfx8eZKkPo5RxuXpW2OCA4oWHILXhQYUKTig6ENLwHF06/SBI+AXERRifNz1kKrtoWUAAoNOwH3DBxohyeomWQYkWb2/LKm3kqSulyUAsvdndR8hSdr+QlsPdZ0s+++rP37AegkCusfxlV3yPuew6yX//QAgIxmuM7WB28PsH7K+lWN4IyKiC3ep5svz/RzcGuP7ovW1xrjrIVXZgtbDfwdJUg8R3CWm7x4O3OBfJ8lqKJD9oQSy5B8f6AsfMgDJpAsiEgSCQ4wu+GgBSFYfTw63HoFBJiBwIHR9pyS4z9Y2EIAaud7IEhKAeqXh/QyG4Y2IiKLvYufL83hCW2N8x9W3xqQnw32mJmIQiRyAGrHeSFKSIJyt46QTan4Mb0RE1Ho0MC6vQR2SIDyWKBSMqPVgLCciIiIyEIY3IiIiIgNheCMiIiIyEIY3IiIiIgNheCMiIiIyEIY3IiIiIgNheCMiIiIyEIY3IiIiIgOJanjbsGED8vPzkZOTg+XLl4ds37FjBwoLC1FYWIhZs2ahrk69eGx1dTWmT5+OvLw83H333SgvL49mMYmIiIgMI2rhrbS0FMXFxVixYgXWrVuHVatW4ciRI9r26upqFBUVobi4GBs2bEDv3r1RXFwMAPjjH/+IAQMGYPPmzRgzZgyeeuqpaBWTiIiIyFCiFt727NmDgQMHIjU1FfHx8cjNzcWWLVu07UePHsVll12Gnj17AgCGDRuGbdu2AQC2b9+OwsJCAMCIESOwc+dOuFyuaBWViIiIyDCiFt7KysqQnp6uLWdkZKC0tFRb7tGjB06fPo1Dhw4BADZv3owzZ86E3NdsNiMxMRHnzp2LVlGJiIiIDCNqF6ZXFAWSJGnLQoiA5eTkZCxYsACPPvooFEXB2LFjYbGEv5iwEAKy3Pic2bFj4oUXvJVLT09q6SK0CqwHFetBxXpQsR5UrAcV60HVFushauEtMzMT+/fv15bLy8uRkZGhLXs8HmRmZmLNmjUAgAMHDqB79+4A1Fa6M2fOIDMzE263G3V1dUhNTW30Y589WwtFEc30TFqP9PQklJfXtHQxWhzrQcV6ULEeVKwHFetBxXpQtfZ6kGXpghqcotZtOmjQIJSUlODcuXOw2WzYunUrsrOzte2SJGHy5MkoLS2FEAJLly5Ffn4+AGDo0KFYt24dAGDTpk0YMGBAxFY5IiIiovYkauGtc+fOmDlzJiZMmIBRo0ZhxIgR6NOnD6ZNm4ZPP/0Usixj/vz5mDp1KoYPH47k5GRMmTIFAPCLX/wCn3zyCQoKCrBixQo89thj0SomERERkaFIQog2179YUVHXJrtNO3ZMxNmztS1djBbHelCxHlSsBxXrQcV6ULEeVK29HmRZQlpaQpPv1ybDGxEREVFbxctjERERERkIwxsRERGRgTC8ERERERkIwxsRERGRgTC8ERERERkIwxsRERGRgTC8ERERERkIwxsRERGRgTC8ERERERkIwxsRERGRgTC8tSJ/+tOfkJ+fj4KCArzyyisAgD179qCwsBA5OTkoLi7W9j148CBuv/125Obm4pFHHoHb7W6pYkfNggULUFRUBCDy8z158iTuvvtuDB8+HPfddx/q6upassjNavz48SgoKMDIkSMxcuRI/Pvf/8aGDRuQn5+PnJwcLF++XNs30uukLfjggw9w++23Iy8vD08++SSA9ve+WLNmjfY6GDlyJK699lrMnz+/3dUDAKxfvx4FBQUoKCjAggULALTPz4cXX3wRubm5KCwsxPPPPw+gfdVDbW0tRowYgePHjwNo+meC4etEUKvwj3/8Q4wbN064XC5hs9nEsGHDxMGDB8XQoUPFt99+K1wul5g8ebLYvn27EEKIgoIC8a9//UsIIcScOXPE8uXLW7L4zW7Pnj3ihhtuELNnzxZCRH6+06dPFxs3bhRCCPHss8+KhQsXtkyBm5miKGLw4MHC5XJp606fPi2GDRsmKioqRF1dnSgsLBSHDx8WNpst4uvE6L799lsxePBgcerUKeF0OsVdd90ltm/f3m7fF0II8d///lfccsst4uTJk+2uHurr68V1110nzp49K1wulxg9erTYvXt3u/t82L17txgxYoSoqakRbrdb/OxnPxPvvvtuu6mHTz75RIwYMUJceeWV4tixY+f9DGyrdcKWt1bi+uuvx7Jly2A2m3H27Fl4PB5UV1fju9/9Lrp37w6z2YzCwkJs2bIFJ06cgN1uR79+/QAAt99+O7Zs2dLCz6D5VFZWori4GPfeey8ARHy+LpcL+/btQ25ubsD6tuCrr74CAEyePBm33norXn/9dezZswcDBw5Eamoq4uPjkZubiy1btuDAgQNhXydtwXvvvYf8/HxkZmbCYrGguLgYcXFx7fJ94fPEE09g5syZOHbsWLurB4/HA0VRYLPZ4Ha74Xa7YTab293nw+eff47BgwcjMTERJpMJQ4YMwWuvvdZu6mH16tV4/PHHkZGRAQARPwPb8ncHw1srYrFYsHjxYhQUFCArKwtlZWVIT0/XtmdkZKC0tDRkfXp6OkpLS1uiyFHx2GOPYebMmUhOTgaAiM+3oqICiYmJMJvNAevbgurqamRlZeG5557D0qVLsXLlSpw8ebJRrwff+rbgm2++gcfjwb333ouRI0dixYoV7fZ9AahdQ3a7HXl5ee2yHhITE/GLX/wCeXl5GDp0KLp27QqLxdLuPh+uvPJK7Nq1C5WVlXA4HPjggw9gNpvbTT089dRTGDBggLbc1PdCW6gThrdWZsaMGSgpKcGpU6dw9OhRSJKkbRNCQJIkKIoSdn1bsGbNGnTp0gVZWVnaukjPN9zzbiv10L9/fyxcuBBJSUno0KEDRo8ejcWLF7e714PH40FJSQl++9vfYtWqVThw4ACOHTvW7urBZ+XKlZg0aRKAyO+LtlwPhw4dwptvvom///3v+PDDDyHLMnbv3t3uPh+ysrJw++23Y/z48Zg6dSquvfZauN3udlcPPk19L7SFOjG3dAFI9eWXX8LpdOKHP/wh4uLikJOTgy1btsBkMmn7lJeXIyMjA5mZmSgvL9fWnzlzRms+NrpNmzahvLwcI0eORFVVFerr6yFJUtjn26FDB9TU1MDj8cBkMmn10xbs378fLpdLC7FCCHTt2jWgHiK9HtpSPXTq1AlZWVno0KEDAODmm29ul+8LAHA6ndi3bx+efvppAIj4e2/L9bBr1y5kZWWhY8eOANTurpdffrndfT7U1tYiJydHC/L/93//h27dumH//v3aPu2hHnya+l5oC3XClrdW4vjx45g7dy6cTiecTifef/99jBs3Dl9//bXWdbRx40ZkZ2eja9eusFqt+OijjwCoZ19lZ2e38DNoHq+88go2btyI9evXY8aMGbjpppvwu9/9LuzztVgsGDBgADZt2gQAWLduXZuph5qaGixcuBAOhwO1tbVYu3YtnnnmGZSUlODcuXOw2WzYunUrsrOz0bdv37Cvk7Zg2LBh2LVrF6qrq+HxePDhhx9i+PDh7e59AQBffPEFevTogfj4eACI+Htvy/XQu3dv7NmzB/X19RBC4IMPPsD111/f7j4fjh8/jvvvvx9utxs1NTX429/+htGjR7e7evBp6nuhTdTJJT5Bgs5j8eLFIi8vT4wYMUIsXrxYCKGedVlYWChycnLEU089JRRFEUIIcfDgQXHHHXeI3Nxc8dBDDwmHw9GSRY+KN998UzvbNNLzPX78uLjnnntEXl6emDx5sqisrGzJIjer4uJiMXz4cJGTkyOWLl0qhBDi7bffFgUFBSInJ0e8+OKL2r6RXidtwZo1a7TnPG/ePOHxeNrl++Kdd94RDz74YMC69lgPL7zwgsjNzRUjRowQc+bMEXa7vV1+Pjz77LMiLy9P5OTkiBUrVggh2t/n5LBhw8SxY8eEEE1/Lxi9TiQhhGjpAElEREREjcNuUyIiIiIDYXgjIiIiMhCGNyIiIiIDYXgjIiIiMhCGNyIiIiIDYXgjoqg4fvw4evXqhTVr1gSsf/nll1FUVNRsj3PTTTfh008/bbbjnU9tbS3GjRuHgoICbN26NWBbUVERhg8fjvr6+oD1/fv3x/Hjxy9J+YiofWB4I6KokWUZCxYswFdffdXSRWkWBw8exNmzZ/HOO+8gJycnZPuJEyfw1FNPtUDJiKg94eWxiChqYmNjMWnSJDz88MNYuXIlYmJiArYXFRXhiiuuwJQpU0KWb7rpJowYMQJ79+5FVVUVpk6dio8//hj/+c9/YDab8fzzz6Nz584AgBUrVuDQoUNwOp2YNGkSRo8eDQD44IMP8Pzzz8PlciE2NhazZ89G//798ec//xmffPIJysrK0KtXLyxatCigXNu2bcOzzz4LRVGQkJCAOXPmIDExEb/+9a9RWlqKkSNHYtWqVYiNjQ2434QJE7B+/Xq8++67yM3NDamPjz/+GIsWLYLNZoMsy3jggQcwbNgwvPXWW3j33XfxwgsvAEDAclFRESorK3Hs2DH86Ec/wr333ot58+bh0KFDkCQJQ4YMwUMPPQSz2Yyrr74a06dPx+7du1FWVoapU6fiJz/5CcrLyzF79mxUVFQAAIYOHYoHH3ywGX7DRNQSGN6IKKruu+8+lJSUoLi4GLNnz27SfR0OB1avXo1NmzZh1qxZWLt2LXr37o2f//znWLt2Le69914AgNVqxdq1a1FaWorbbrsNffv2hcViQXFxMZYtW4a0tDQcPnwYkyZN0ro7T5w4gY0bN8JsDvwY/PLLL/H4449j5cqV6N69O0pKSnD//fdjy5YtePLJJ/Gb3/wG69evD1veDh064Omnn8asWbPQp08fdOnSRdtWVVWFOXPm4OWXX0a3bt1QWlqKsWPHolevXg3Wg91uxzvvvAMAmD17NlJTU7Fhwwa4XC7cd999WLJkCaZPnw6n04m0tDSsXLkSn332Ge666y7ccccdWL16Nbp164YlS5agvr4ejzzyCGpqapCUlNSk3wcRtQ4Mb0QUVbIs45lnnsGoUaMwePDgJt3X1zXZvXt3dOrUCb179wYAfOc730FVVZW237hx4wAAnTt3xo033oiSkhKYTCaUlZVh4sSJ2n6SJOHbb78FAPTr1y8kuAHA3r17MXDgQHTv3h0AkJWVhQ4dOuCzzz6DJEkNlnnw4MG47bbb8Mtf/hLLli3T1n/yyScoLy/Hz3/+84DyfPHFFw0e89prr9V+3rlzJ9544w1IkoSYmBiMGzcOr776KqZPnw4A+PGPfwwAuPLKK+F0OlFfX48hQ4Zg+vTpOHXqFAYNGoRZs2YxuBEZGMMbEUVdly5dMG/ePMyePRujRo3S1kuSBP0V+lwuV8D99N2sFosl4vFl2T98V1EUmM1meDweZGVl4Y9//KO27dSpU8jIyMB7772nXeA9mKIoISFNCAG3233eMug99NBDuPPOO/HXv/5VW+fxePD9738/4ASO0tJSdOjQARs3bjxvPejLGlw+RVHgdru1ZavVCgDaPkII9OnTB++//z5KSkqwd+9ejBkzBi+99BKuuuqqRj0fImpdeMICEV0Sw4cPR3Z2Nl599VVtXVpaGj777DMAapD55z//eUHHXrt2LQDg5MmTKCkpQVZWFrKysrB79258+eWXAIAdO3bg1ltvhd1uP++xsrKysGvXLhw7dgwAUFJSglOnTqFv376NLk9MTAx+//vfY8mSJdrj9evXD9988w327dsHQD35ITc3Vwtwhw8fhsPhgMvlwrvvvhvx2IMHD8brr78OIQScTidWr16NQYMGnbc8ixYtwl/+8hfcfPPNeOSRR9CzZ08cPny40c+HiFoXtrwR0SUzd+5cfPTRR9ry+PHj8fDDDyM3NxfdunXDwIEDL+i4DocDt912G1wuF+bOnYvLL78cADB//nw89NBDEEJoJzkkJCSc91g9e/bE448/jgceeAAejwexsbH461//2uRuxu9973uYPXs25s6dC0AdD7d48WIsXLgQDocDQggsXLgQ3bp1Q2ZmJq677jrk5eUhPT0dN9xwQ8Tu1Llz5+LJJ59EYWEhXC4XhgwZoo39i+SnP/0pioqKMGLECMTExKBXr14oKCho0vMhotZDEvq2eiIiIiJq1dhtSkRERGQgDG9EREREBsLwRkRERGQgDG9EREREBsLwRkRERGQgDG9EREREBsLwRkRERGQg/w84ZINDcjjTpQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_scores_mean_sgd = grid_search_fit.cv_results_['mean_test_score'][idx_varying_num_neurons_sgd]\n",
    "test_scores_std_sgd = grid_search_fit.cv_results_['std_test_score'][idx_varying_num_neurons_sgd]\n",
    "\n",
    "test_scores_mean_adam = grid_search_fit.cv_results_['mean_test_score'][idx_varying_num_neurons_adam]\n",
    "test_scores_std_adam = grid_search_fit.cv_results_['std_test_score'][idx_varying_num_neurons_adam]\n",
    "\n",
    "plt.title('Validation Score varying num_neurons')\n",
    "plt.xlabel('Number of Neurons')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.plot(num_neurons, test_scores_mean_sgd,'o-', label=\"Cross Validation score num_neurons variation (sgd)\",\n",
    "         color='red')\n",
    "plt.fill_between(num_neurons, test_scores_mean_sgd - test_scores_std_sgd,\n",
    "             test_scores_mean_sgd + test_scores_std_sgd, alpha=0.2,\n",
    "             color='red')\n",
    "\n",
    "plt.plot(num_neurons, test_scores_mean_adam,'o-', label=\"Cross Validation score num_neurons variation (adam)\",\n",
    "         color='blue')\n",
    "plt.fill_between(num_neurons, test_scores_mean_adam - test_scores_std_adam,\n",
    "             test_scores_mean_adam + test_scores_std_adam, alpha=0.2,\n",
    "             color='blue')\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3HuI9sUn8vVo"
   },
   "source": [
    "#### Use the model fitted on (train+val) with best CV parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vi7S1CKt8vVp"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test_nn)\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TKzWayhw8vVt"
   },
   "source": [
    "#### Now use the val history to plot loss and accuracy curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cbfqj8Ah8vVt",
    "outputId": "5f99c730-6fea-40a8-bdfa-1b4c408ee2af"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_context(\"notebook\")\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "plt.plot(range(1,epochs[-1]+1),fit_model_final.history['loss'],label='Training Loss',linewidth=2.0)\n",
    "plt.plot(range(1,epochs[-1]+1),fit_model_final.history['val_loss'],label='Validation Loss',linewidth=2.0)\n",
    "plt.xticks(range(1,epochs[-1]+1,2));\n",
    "plt.legend(loc='best')\n",
    "plt.title('Loss vs Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Q-lDVba8vVw",
    "outputId": "8cb464cc-fed3-4035-89cc-079f91fe0ab6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_context(\"notebook\")\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "plt.plot(range(1,epochs[-1]+1),fit_model_final.history['acc'],label='Training Accuracy',linewidth=2.0)\n",
    "plt.plot(range(1,epochs[-1]+1),fit_model_final.history['val_acc'],label='Validation Accuracy',linewidth=2.0)\n",
    "plt.xticks(range(1,epochs[-1]+1,2));\n",
    "plt.legend(loc='best')\n",
    "plt.title('Accuracy vs Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mr3ZOrMI8vV4"
   },
   "source": [
    "#### Show prediction report on test data. Training on (train+val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ID7Ptp8U8vV5",
    "outputId": "1d49e993-ffc7-4ba7-b8ad-480af692b347"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 98.21%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       986\n",
      "           1       0.99      0.99      0.99      1125\n",
      "           2       0.98      0.98      0.98       999\n",
      "           3       0.98      0.97      0.98      1020\n",
      "           4       0.98      0.99      0.98       975\n",
      "           5       0.97      0.99      0.98       902\n",
      "           6       0.99      0.99      0.99       982\n",
      "           7       0.98      0.98      0.98      1042\n",
      "           8       0.98      0.97      0.98       975\n",
      "           9       0.98      0.96      0.97       994\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     10000\n",
      "   macro avg       0.98      0.98      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n",
      "Confidence Matrix:\n",
      " [[ 983    1    0    0    0    0    1    0    1    0]\n",
      " [   0 1117    3    1    1    0    0    2    1    0]\n",
      " [   2    0  981    5    3    0    0    2    5    1]\n",
      " [   1    1    5  986    0   15    0    6    5    1]\n",
      " [   0    0    1    0  962    0    1    0    0   11]\n",
      " [   2    0    1    2    1  890    2    0    2    2]\n",
      " [   2    1    0    0    1    3  972    0    3    0]\n",
      " [   2    3    4    0    4    0    0 1023    1    5]\n",
      " [   4    5    1    5    0    5    3    2  948    2]\n",
      " [   2    4    0    3   11    4    0    8    3  959]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_classification_results(y_test, y_pred,\"Heatmap of Predictions of 2-Layer MLP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DEQrdyLHsUIu"
   },
   "source": [
    "### 2.2.5: Summary\n",
    "\n",
    "Summarize your findings:\n",
    " * Which hyper-parameters were important and how did they influence your results?\n",
    " > *The hyperparameters for MLP classifier that were important were the paramaters number of epochs, number of neurons, optimizer algorithm, non-linear activation, and dropout rate.*\n",
    " * What were other design choices you faced?\n",
    " > *The other choice was the number of layers, which we decided to keep at 1. Also, we left the learning rate to be the default rate of SGD(0.01) and Adam optimizers (0.001) in Keras. As these values gave good enough results, we decided not to change them.*\n",
    " * Any other interesting insights...\n",
    " > *We actually saw that having Adam optimizer drastically improved the performance of the network. At the same time, dropout rate with number of neurons equalling the input dimension of 784 actually gave the best performance.*<br>\n",
    " > *We also see that validation loss is actually increasing very slightly towards the end of the 30 epochs, whereas the validation accuracy is also fluctuating, but seems to have a slight positive trend. This could mean that if we applied a learning rate decay after some epochs, it might have helped in reaching a better local minima.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1jEdTUtn-uqf"
   },
   "source": [
    "# 2.3: Model [M3]: *ConvNet*\n",
    "\n",
    "####  Short description : *We use a ConvNet to perform the multiclass classification task. We use maxpool and dropout, and a fully connected layer.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lVyT9Oddp3GB"
   },
   "source": [
    "### 2.3.1: Hyper-parameters\n",
    "\n",
    "Define hyper-parameters for your method here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WFBHlavAO-rk"
   },
   "outputs": [],
   "source": [
    "# Define the parameter space\n",
    "epoch = np.arange(10,40,10)\n",
    "batch_size = [200] #[150, 200, 250]\n",
    "activation =  [\"sigmoid\",\"relu\"]\n",
    "optimizer_algo = [\"sgd\",\"adam\"]\n",
    "## learning_rate\n",
    "# learning_rate =  [0.001] #[0.001, 0.01]\n",
    "dropout_rate = [0.3, 0.4, 0.5]\n",
    "filter_size =  [(3,3), (5, 5)]\n",
    "no_filters = [32] # [16, 32, 48]\n",
    "\n",
    "\n",
    "param_space = {\"epochs\":epochs,\\\n",
    "               \"batch_size\": batch_size,\\\n",
    "               \"activation\": activation,\\\n",
    "               \"optimizer_algo\": optimizer_algo,\\\n",
    "               \"dropout\": dropout_rate,\\\n",
    "               \"filter_size\": filter_size,\\\n",
    "               \"no_filters\": no_filters \n",
    "              }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pkuCgPatp59X"
   },
   "source": [
    "### 2.2.2: Model\n",
    "\n",
    "Define your model here (all hyper-parameters in 2.1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iQtM3uC3sBQm"
   },
   "outputs": [],
   "source": [
    "def CNN_model(no_filters = 32, filter_size=(5,5), activation = 'relu', optimizer_algo = 'adam', dropout=0.0):\n",
    "  # create model\n",
    "    model = Sequential()\n",
    "    # Convolution layer\n",
    "    model.add(Conv2D(filters=no_filters, kernel_size=filter_size, input_shape=(1, 28, 28), activation= activation))\n",
    "    # Pooling layer\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Drop out \n",
    "    model.add(Dropout(dropout))\n",
    "    # Flattening into a single vector\n",
    "    model.add(Flatten())\n",
    "    # Fully connected layer\n",
    "    model.add(Dense(128, activation=activation))\n",
    "    # output layer\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    # Compile model|\n",
    "    if(optimizer_algo == 'adam'):\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    elif(optimizer_algo == 'sgd'):\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CbK4naklsPFI"
   },
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=CNN_model)\n",
    "grid_search_result = sklearn.model_selection.GridSearchCV(estimator=model, param_grid=param_space, verbose=2, cv=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SxE6d6OXp6sU"
   },
   "source": [
    "### 2.3.3: Fit Model\n",
    "\n",
    "Define optimization procedure and fit your model to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107520
    },
    "colab_type": "code",
    "id": "EgJYzpewsfxa",
    "outputId": "242de250-32d3-4bfa-bbdc-d71fb9d72d1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 72 candidates, totalling 144 fits\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.3, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 2.3172 - acc: 0.1038\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 2s 58us/step - loss: 2.3049 - acc: 0.1109\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 2s 58us/step - loss: 2.3000 - acc: 0.1170\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 2s 57us/step - loss: 2.2922 - acc: 0.1289\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 2s 58us/step - loss: 2.2867 - acc: 0.1383\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 2s 56us/step - loss: 2.2776 - acc: 0.1510\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 2s 58us/step - loss: 2.2677 - acc: 0.1717\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 2s 57us/step - loss: 2.2567 - acc: 0.1865\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 2s 55us/step - loss: 2.2379 - acc: 0.2192\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 2.2140 - acc: 0.2556\n",
      "30000/30000 [==============================] - 1s 32us/step\n",
      "30000/30000 [==============================] - 1s 23us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.3, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd, total=  19.5s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.3, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   20.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 2.3142 - acc: 0.1068\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 2s 57us/step - loss: 2.3076 - acc: 0.1105\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 2s 57us/step - loss: 2.3057 - acc: 0.1111\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 2s 56us/step - loss: 2.3004 - acc: 0.1185\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 2s 56us/step - loss: 2.2964 - acc: 0.1254\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 2s 57us/step - loss: 2.2905 - acc: 0.1311\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 2s 55us/step - loss: 2.2856 - acc: 0.1406\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 2s 56us/step - loss: 2.2761 - acc: 0.1557\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 2s 54us/step - loss: 2.2659 - acc: 0.1709\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 2s 57us/step - loss: 2.2528 - acc: 0.1915\n",
      "30000/30000 [==============================] - 1s 32us/step\n",
      "30000/30000 [==============================] - 1s 22us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.3, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd, total=  19.1s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.3, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 3s 94us/step - loss: 2.2959 - acc: 0.1579\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 1.5583 - acc: 0.6691\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.7885 - acc: 0.8366\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 0.5327 - acc: 0.8756\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 0.4332 - acc: 0.8899\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 0.3747 - acc: 0.9001\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 0.3404 - acc: 0.9066\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 0.3154 - acc: 0.9108\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 0.2949 - acc: 0.9156\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 0.2795 - acc: 0.9194\n",
      "30000/30000 [==============================] - 1s 32us/step\n",
      "30000/30000 [==============================] - 1s 21us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.3, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=adam, total=  20.8s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.3, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 3s 89us/step - loss: 2.3061 - acc: 0.1212\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 1.6349 - acc: 0.5752\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 0.7183 - acc: 0.8423\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 0.4657 - acc: 0.8810\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 0.3885 - acc: 0.8953\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 0.3411 - acc: 0.9045\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 0.3180 - acc: 0.9084\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 0.2972 - acc: 0.9141\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 0.2755 - acc: 0.9190\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.2628 - acc: 0.9232\n",
      "30000/30000 [==============================] - 1s 34us/step\n",
      "30000/30000 [==============================] - 1s 22us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.3, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=adam, total=  20.7s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.3, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 2.3137 - acc: 0.1047\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 2.3040 - acc: 0.1128\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 2.2998 - acc: 0.1180\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 2.2952 - acc: 0.1243\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 2s 58us/step - loss: 2.2870 - acc: 0.1384\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 2.2756 - acc: 0.1549\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 2.2619 - acc: 0.1769\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 2.2419 - acc: 0.2124\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 2.2112 - acc: 0.2615\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 2s 58us/step - loss: 2.1690 - acc: 0.3270\n",
      "30000/30000 [==============================] - 1s 37us/step\n",
      "30000/30000 [==============================] - 1s 24us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.3, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd, total=  20.2s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.3, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 3s 93us/step - loss: 2.3104 - acc: 0.1051\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 2s 57us/step - loss: 2.3028 - acc: 0.1161\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 2s 57us/step - loss: 2.2972 - acc: 0.1230\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 2s 56us/step - loss: 2.2890 - acc: 0.1359\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 2s 58us/step - loss: 2.2810 - acc: 0.1475\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 2.2682 - acc: 0.1696\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 2.2497 - acc: 0.1974\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 2s 58us/step - loss: 2.2251 - acc: 0.2393\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 2.1889 - acc: 0.2890\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 2.1408 - acc: 0.3476\n",
      "30000/30000 [==============================] - 1s 44us/step\n",
      "30000/30000 [==============================] - 1s 25us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.3, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd, total=  20.4s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.3, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 3s 109us/step - loss: 2.1689 - acc: 0.2680\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.9257 - acc: 0.8163\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.4783 - acc: 0.8867\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.3539 - acc: 0.9098\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.2896 - acc: 0.9227\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.2466 - acc: 0.9335\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.2178 - acc: 0.9394\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.1920 - acc: 0.9475\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.1751 - acc: 0.9509\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.1543 - acc: 0.9570\n",
      "30000/30000 [==============================] - 1s 37us/step\n",
      "30000/30000 [==============================] - 1s 23us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.3, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=adam, total=  22.9s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.3, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 3s 112us/step - loss: 2.1873 - acc: 0.2675\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 1.1623 - acc: 0.7808\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.6299 - acc: 0.8710\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.4544 - acc: 0.8919\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.3622 - acc: 0.9086\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.3096 - acc: 0.9187\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.2662 - acc: 0.9293\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.2311 - acc: 0.9382\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.2105 - acc: 0.9437\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.1874 - acc: 0.9480\n",
      "30000/30000 [==============================] - 1s 42us/step\n",
      "30000/30000 [==============================] - 1s 25us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.3, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=adam, total=  23.3s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.3, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 3s 103us/step - loss: 2.3141 - acc: 0.1052\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 2.3045 - acc: 0.1106\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 2.3007 - acc: 0.1156\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 2.2955 - acc: 0.1251\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 2.2898 - acc: 0.1317\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 2.2819 - acc: 0.1475\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 2.2700 - acc: 0.1614\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 2.2565 - acc: 0.1863\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 2.2385 - acc: 0.2178\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 2.2120 - acc: 0.2594\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 2.1798 - acc: 0.3030\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 2.1332 - acc: 0.3583\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 2s 57us/step - loss: 2.0733 - acc: 0.4147\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 2s 57us/step - loss: 1.9990 - acc: 0.4723\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 2s 57us/step - loss: 1.9081 - acc: 0.5194\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 2s 57us/step - loss: 1.7983 - acc: 0.5705\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 2s 58us/step - loss: 1.6798 - acc: 0.6122\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 2s 57us/step - loss: 1.5565 - acc: 0.6502\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 2s 57us/step - loss: 1.4326 - acc: 0.6804\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 2s 58us/step - loss: 1.3174 - acc: 0.7048\n",
      "30000/30000 [==============================] - 1s 39us/step\n",
      "30000/30000 [==============================] - 1s 24us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.3, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd, total=  38.8s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.3, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 3s 96us/step - loss: 2.3103 - acc: 0.1093\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 2s 57us/step - loss: 2.3019 - acc: 0.1171\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 2s 56us/step - loss: 2.2957 - acc: 0.1252\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 2.2877 - acc: 0.1367\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 2.2789 - acc: 0.1458\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 2.2655 - acc: 0.1691\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 2.2485 - acc: 0.1990\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 2.2259 - acc: 0.2350\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 2.1927 - acc: 0.2802\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 2.1508 - acc: 0.3373\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 2.0960 - acc: 0.3904\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 2.0228 - acc: 0.4558\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 1.9327 - acc: 0.5085\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 1.8254 - acc: 0.5663\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 1.7091 - acc: 0.6078\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 1.5819 - acc: 0.6469\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 1.4598 - acc: 0.6746\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 1.3408 - acc: 0.6991\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 1.2336 - acc: 0.7218\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 1.1374 - acc: 0.7382\n",
      "30000/30000 [==============================] - 1s 48us/step\n",
      "30000/30000 [==============================] - 1s 28us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.3, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd, total=  41.3s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.3, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 2.3427 - acc: 0.1106\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 2.0568 - acc: 0.3928\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 1.3181 - acc: 0.7644\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.8796 - acc: 0.8406\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.6519 - acc: 0.8659\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.5335 - acc: 0.8760\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.4648 - acc: 0.8858\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.4175 - acc: 0.8935\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.3860 - acc: 0.8991\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.3628 - acc: 0.9029\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.3389 - acc: 0.9057\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.3180 - acc: 0.9120\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.3057 - acc: 0.9143\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.2963 - acc: 0.9163\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.2861 - acc: 0.9192\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.2755 - acc: 0.9216\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.2619 - acc: 0.9229\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.2568 - acc: 0.9253\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.2499 - acc: 0.9267\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.2432 - acc: 0.9287\n",
      "30000/30000 [==============================] - 1s 41us/step\n",
      "30000/30000 [==============================] - 1s 24us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.3, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=adam, total=  47.6s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.3, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 3s 107us/step - loss: 2.3183 - acc: 0.1517\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 1.8565 - acc: 0.5389\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 1.0925 - acc: 0.7834\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 0.6565 - acc: 0.8591\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 0.4931 - acc: 0.8809\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 0.4181 - acc: 0.8939\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 0.3760 - acc: 0.9007\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 0.3451 - acc: 0.9075\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.3219 - acc: 0.9110\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.3050 - acc: 0.9137\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 0.2886 - acc: 0.9207\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.2688 - acc: 0.9260\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.2638 - acc: 0.9240\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 0.2528 - acc: 0.9270\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 0.2426 - acc: 0.9318\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 0.2330 - acc: 0.9339\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.2297 - acc: 0.9336\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 0.2195 - acc: 0.9371\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 0.2122 - acc: 0.9388\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 0.2050 - acc: 0.9404\n",
      "30000/30000 [==============================] - 1s 39us/step\n",
      "30000/30000 [==============================] - 1s 23us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.3, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=adam, total=  40.2s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.3, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 3s 99us/step - loss: 2.3125 - acc: 0.1070\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 2.3028 - acc: 0.1122\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 2.2975 - acc: 0.1191\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 2.2909 - acc: 0.1301\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 2.2798 - acc: 0.1500\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 2.2670 - acc: 0.1700\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 2.2499 - acc: 0.1984\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 2.2269 - acc: 0.2342\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 2.1934 - acc: 0.2887\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 2.1505 - acc: 0.3409\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 2.0941 - acc: 0.4034\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 2.0168 - acc: 0.4761\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 1.9247 - acc: 0.5261\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 1.8155 - acc: 0.5703\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 1.6914 - acc: 0.6119\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 1.5638 - acc: 0.6478\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 1.4377 - acc: 0.6765\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 1.3178 - acc: 0.7032\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 1.2140 - acc: 0.7229\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 1.1179 - acc: 0.7407\n",
      "30000/30000 [==============================] - 2s 50us/step\n",
      "30000/30000 [==============================] - 1s 28us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.3, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd, total=  41.7s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.3, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 4s 118us/step - loss: 2.3130 - acc: 0.1070\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 2.3050 - acc: 0.1117\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 2.3001 - acc: 0.1197\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 2.2942 - acc: 0.1269\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 2.2883 - acc: 0.1356\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 2.2776 - acc: 0.1500\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 2.2644 - acc: 0.1713\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 2.2445 - acc: 0.2038\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 2.2181 - acc: 0.2455\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 2.1777 - acc: 0.3043\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 2.1242 - acc: 0.3607\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 2.0516 - acc: 0.4264\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 1.9578 - acc: 0.4885\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 1.8451 - acc: 0.5485\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 1.7167 - acc: 0.5966\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 1.5816 - acc: 0.6379\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 1.4521 - acc: 0.6682\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 1.3298 - acc: 0.6972\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 1.2171 - acc: 0.7242\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 1.1253 - acc: 0.7387\n",
      "30000/30000 [==============================] - 1s 49us/step\n",
      "30000/30000 [==============================] - 1s 28us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.3, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd, total=  42.4s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.3, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 2.1382 - acc: 0.3023\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.9317 - acc: 0.8119\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.4574 - acc: 0.8899\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.3383 - acc: 0.9094\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.2761 - acc: 0.9243\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 0.2323 - acc: 0.9357\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.2024 - acc: 0.9434\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.1815 - acc: 0.9480\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.1609 - acc: 0.9537\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.1445 - acc: 0.9578\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 0.1330 - acc: 0.9621\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 0.1218 - acc: 0.9661\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.1130 - acc: 0.9677\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.1034 - acc: 0.9708\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 0.0977 - acc: 0.9722\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.0956 - acc: 0.9717\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.0861 - acc: 0.9758\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.0836 - acc: 0.9765\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.0784 - acc: 0.9775\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.0772 - acc: 0.9772\n",
      "30000/30000 [==============================] - 2s 52us/step\n",
      "30000/30000 [==============================] - 1s 28us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.3, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=adam, total=  42.8s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.3, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 4s 130us/step - loss: 2.1998 - acc: 0.2283\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.9513 - acc: 0.8021\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.4812 - acc: 0.8842\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.3627 - acc: 0.9053\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.3059 - acc: 0.9152\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.2618 - acc: 0.9279\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.2326 - acc: 0.9346\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.2106 - acc: 0.9413\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.1883 - acc: 0.9471\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.1720 - acc: 0.9507\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.1589 - acc: 0.9548\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.1418 - acc: 0.9597\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.1338 - acc: 0.9622\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.1223 - acc: 0.9653\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.1126 - acc: 0.9686\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.1055 - acc: 0.9704\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.0983 - acc: 0.9716\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.0900 - acc: 0.9746\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.0857 - acc: 0.9752\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.0812 - acc: 0.9773\n",
      "30000/30000 [==============================] - 2s 52us/step\n",
      "30000/30000 [==============================] - 1s 28us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.3, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=adam, total=  46.3s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.3, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 4s 125us/step - loss: 2.3079 - acc: 0.1131\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 2.3007 - acc: 0.1148\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 2.2965 - acc: 0.1220\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 2.2917 - acc: 0.1322\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 2.2815 - acc: 0.1478\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 2.2717 - acc: 0.1639\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 2.2577 - acc: 0.1826\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 2.2377 - acc: 0.2170\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 2.2122 - acc: 0.2577\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 2.1773 - acc: 0.3079\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 2.1311 - acc: 0.3644\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 2.0696 - acc: 0.4215\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 1.9920 - acc: 0.4795\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 1.8963 - acc: 0.5318\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 2s 58us/step - loss: 1.7898 - acc: 0.5787\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 2s 58us/step - loss: 1.6689 - acc: 0.6220\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 2s 58us/step - loss: 1.5479 - acc: 0.6570\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 2s 58us/step - loss: 1.4247 - acc: 0.6854\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 2s 58us/step - loss: 1.3089 - acc: 0.7106\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 2s 58us/step - loss: 1.2071 - acc: 0.7296\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 2s 58us/step - loss: 1.1176 - acc: 0.7439\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 1.0353 - acc: 0.7614\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 0.9681 - acc: 0.7705\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 2s 58us/step - loss: 0.9077 - acc: 0.7842\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 0.8587 - acc: 0.7913\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 0.8146 - acc: 0.7977\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 2s 58us/step - loss: 0.7769 - acc: 0.8046\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 2s 58us/step - loss: 0.7432 - acc: 0.8136\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 0.7148 - acc: 0.8183\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.6905 - acc: 0.8213\n",
      "30000/30000 [==============================] - 2s 56us/step\n",
      "30000/30000 [==============================] - 1s 31us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.3, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd, total= 1.0min\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.3, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 4s 130us/step - loss: 2.3125 - acc: 0.1068\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 2.3058 - acc: 0.1092\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 2.3001 - acc: 0.1195\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 2.2975 - acc: 0.1221\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 2.2919 - acc: 0.1297\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 2.2840 - acc: 0.1410\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 2.2767 - acc: 0.1555\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 2.2653 - acc: 0.1699\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 2.2485 - acc: 0.1992\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 2.2308 - acc: 0.2254\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 2.2015 - acc: 0.2680\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 2.1669 - acc: 0.3138\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 2.1178 - acc: 0.3771\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 2.0542 - acc: 0.4350\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 1.9785 - acc: 0.4844\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 1.8786 - acc: 0.5401\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 1.7667 - acc: 0.5835\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 1.6463 - acc: 0.6219\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 1.5239 - acc: 0.6557\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 1.4021 - acc: 0.6844\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 1.2882 - acc: 0.7100\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 1.1881 - acc: 0.7258\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 1.1013 - acc: 0.7471\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 1.0257 - acc: 0.7601\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.9591 - acc: 0.7716\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.9016 - acc: 0.7815\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.8534 - acc: 0.7910\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.8110 - acc: 0.7992\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.7725 - acc: 0.8051\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.7408 - acc: 0.8112\n",
      "30000/30000 [==============================] - 2s 56us/step\n",
      "30000/30000 [==============================] - 1s 29us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.3, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd, total= 1.1min\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.3, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 2.3121 - acc: 0.1342\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 1.7185 - acc: 0.6166\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.9209 - acc: 0.8314\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.6046 - acc: 0.8719\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.4743 - acc: 0.8851\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.4075 - acc: 0.8933\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.3665 - acc: 0.9007\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 0.3435 - acc: 0.9045\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 0.3164 - acc: 0.9102\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 0.3032 - acc: 0.9122\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.2854 - acc: 0.9176\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.2733 - acc: 0.9213\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.2614 - acc: 0.9232\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.2498 - acc: 0.9283\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 0.2429 - acc: 0.9291\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 0.2350 - acc: 0.9306\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.2262 - acc: 0.9334\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 0.2153 - acc: 0.9357\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 0.2103 - acc: 0.9367\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.2067 - acc: 0.9381\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.1986 - acc: 0.9394\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.1909 - acc: 0.9432\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.1873 - acc: 0.9442\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.1842 - acc: 0.9431\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.1750 - acc: 0.9467\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.1714 - acc: 0.9491\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.1653 - acc: 0.9502\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.1641 - acc: 0.9512\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.1566 - acc: 0.9541\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.1529 - acc: 0.9544\n",
      "30000/30000 [==============================] - 2s 54us/step\n",
      "30000/30000 [==============================] - 1s 30us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.3, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=adam, total= 1.1min\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.3, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 4s 148us/step - loss: 2.3084 - acc: 0.1385\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 1.7396 - acc: 0.5637\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.9599 - acc: 0.8045\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.6362 - acc: 0.8633\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.4931 - acc: 0.8801\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.4199 - acc: 0.8929\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.3760 - acc: 0.9016\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.3482 - acc: 0.9044\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.3235 - acc: 0.9114\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.3125 - acc: 0.9122\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.2911 - acc: 0.9180\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.2774 - acc: 0.9217\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.2680 - acc: 0.9222\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.2576 - acc: 0.9279\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.2425 - acc: 0.9301\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.2349 - acc: 0.9320\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.2281 - acc: 0.9337\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.2214 - acc: 0.9350\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.2158 - acc: 0.9373\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.2078 - acc: 0.9396\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.2011 - acc: 0.9405\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.1941 - acc: 0.9425\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.1880 - acc: 0.9447\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.1877 - acc: 0.9436\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.1783 - acc: 0.9478\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.1764 - acc: 0.9499\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.1723 - acc: 0.9488\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.1664 - acc: 0.9507\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.1610 - acc: 0.9526\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.1560 - acc: 0.9544\n",
      "30000/30000 [==============================] - 1s 48us/step\n",
      "30000/30000 [==============================] - 1s 25us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.3, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=adam, total= 1.2min\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.3, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 3s 116us/step - loss: 2.3175 - acc: 0.1030\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 2s 56us/step - loss: 2.3063 - acc: 0.1105\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 2s 56us/step - loss: 2.3010 - acc: 0.1154\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 2s 56us/step - loss: 2.2945 - acc: 0.1255\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 2s 56us/step - loss: 2.2862 - acc: 0.1380\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 2s 57us/step - loss: 2.2770 - acc: 0.1511\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 2s 56us/step - loss: 2.2623 - acc: 0.1761\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 2s 55us/step - loss: 2.2415 - acc: 0.2125\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 2s 57us/step - loss: 2.2107 - acc: 0.2587\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 2.1698 - acc: 0.3188\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 2.1107 - acc: 0.3909\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 2.0316 - acc: 0.4602\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 1.9325 - acc: 0.5223\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 1.8157 - acc: 0.5721\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 1.6804 - acc: 0.6183\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 1.5445 - acc: 0.6544\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 1.4130 - acc: 0.6855\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 1.2914 - acc: 0.7118\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 1.1841 - acc: 0.7295\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 1.0886 - acc: 0.7499\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 1.0119 - acc: 0.7594\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.9427 - acc: 0.7744\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.8850 - acc: 0.7850\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.8347 - acc: 0.7936\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.7903 - acc: 0.8010\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.7527 - acc: 0.8095\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.7245 - acc: 0.8128\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.6952 - acc: 0.8182\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.6702 - acc: 0.8254\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.6464 - acc: 0.8301\n",
      "30000/30000 [==============================] - 2s 59us/step\n",
      "30000/30000 [==============================] - 1s 30us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.3, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd, total= 1.0min\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.3, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 4s 148us/step - loss: 2.3137 - acc: 0.1069\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 2.3014 - acc: 0.1205\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 2.2969 - acc: 0.1240\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 2.2909 - acc: 0.1351\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 2.2806 - acc: 0.1489\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 2.2670 - acc: 0.1686\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 2.2504 - acc: 0.1988\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 2.2218 - acc: 0.2418\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 2.1836 - acc: 0.2919\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 2.1327 - acc: 0.3543\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 2.0607 - acc: 0.4235\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 1.9683 - acc: 0.4900\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 1.8563 - acc: 0.5515\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 1.7309 - acc: 0.5963\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 1.5972 - acc: 0.6435\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 1.4655 - acc: 0.6805\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 1.3431 - acc: 0.7039\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 1.2328 - acc: 0.7253\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 1.1352 - acc: 0.7434\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 2s 57us/step - loss: 1.0496 - acc: 0.7587\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 2s 56us/step - loss: 0.9763 - acc: 0.7714\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 2s 56us/step - loss: 0.9147 - acc: 0.7835\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 2s 56us/step - loss: 0.8629 - acc: 0.7899\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 2s 55us/step - loss: 0.8167 - acc: 0.7992\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 2s 57us/step - loss: 0.7775 - acc: 0.8042\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 2s 57us/step - loss: 0.7424 - acc: 0.8108\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 2s 58us/step - loss: 0.7150 - acc: 0.8157\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 2s 56us/step - loss: 0.6882 - acc: 0.8212\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 2s 56us/step - loss: 0.6631 - acc: 0.8248\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 2s 55us/step - loss: 0.6424 - acc: 0.8290\n",
      "30000/30000 [==============================] - 1s 48us/step\n",
      "30000/30000 [==============================] - 1s 24us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.3, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd, total=  59.0s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.3, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 4s 125us/step - loss: 1.9736 - acc: 0.3818\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.7966 - acc: 0.8273\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.4770 - acc: 0.8804\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.3721 - acc: 0.8989\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.3145 - acc: 0.9131\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.2749 - acc: 0.9235\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.2438 - acc: 0.9314\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.2149 - acc: 0.9388\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.1960 - acc: 0.9433\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.1805 - acc: 0.9474\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.1609 - acc: 0.9547\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.1482 - acc: 0.9572\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.1371 - acc: 0.9602\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.1286 - acc: 0.9632\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.1158 - acc: 0.9663\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.1088 - acc: 0.9683\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.1028 - acc: 0.9706\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.0969 - acc: 0.9712\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.0930 - acc: 0.9736\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.0853 - acc: 0.9756\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.0833 - acc: 0.9752\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.0777 - acc: 0.9775\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.0720 - acc: 0.9795\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.0699 - acc: 0.9790\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.0718 - acc: 0.9784\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.0656 - acc: 0.9804\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.0628 - acc: 0.9811\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.0589 - acc: 0.9824\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.0586 - acc: 0.9828\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.0524 - acc: 0.9847\n",
      "30000/30000 [==============================] - 2s 62us/step\n",
      "30000/30000 [==============================] - 1s 30us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.3, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=adam, total= 1.2min\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.3, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 5s 153us/step - loss: 2.2025 - acc: 0.2381\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 1.0036 - acc: 0.7991\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.5107 - acc: 0.8768\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.3831 - acc: 0.8968\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.3217 - acc: 0.9113\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.2820 - acc: 0.9211\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.2480 - acc: 0.9295\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.2227 - acc: 0.9362\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 0.1982 - acc: 0.9429\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.1754 - acc: 0.9505\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.1588 - acc: 0.9545\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 0.1460 - acc: 0.9582\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.1320 - acc: 0.9625\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 0.1227 - acc: 0.9657\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 0.1091 - acc: 0.9697\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.1038 - acc: 0.9699\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 0.0949 - acc: 0.9740\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 0.0887 - acc: 0.9747\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.0843 - acc: 0.9766\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 0.0781 - acc: 0.9771\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.0734 - acc: 0.9790\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.0705 - acc: 0.9801\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.0656 - acc: 0.9819\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.0635 - acc: 0.9817\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.0596 - acc: 0.9826\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.0575 - acc: 0.9830\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.0525 - acc: 0.9849\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.0533 - acc: 0.9849\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.0499 - acc: 0.9854\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.0458 - acc: 0.9869\n",
      "30000/30000 [==============================] - 2s 62us/step\n",
      "30000/30000 [==============================] - 1s 30us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.3, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=adam, total= 1.1min\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.4, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 5s 155us/step - loss: 2.3195 - acc: 0.1031\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 2.3080 - acc: 0.1117\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 2.3019 - acc: 0.1159\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 2.2944 - acc: 0.1271\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 2.2890 - acc: 0.1310\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 2.2786 - acc: 0.1445\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 2.2662 - acc: 0.1629\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 2.2493 - acc: 0.1867\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 2.2267 - acc: 0.2152\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 2.1987 - acc: 0.2533\n",
      "30000/30000 [==============================] - 2s 65us/step\n",
      "30000/30000 [==============================] - 1s 32us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.4, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd, total=  26.6s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.4, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 5s 154us/step - loss: 2.3166 - acc: 0.1062\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 2.3092 - acc: 0.1091\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 2.3066 - acc: 0.1135\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 2.3022 - acc: 0.1148\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 2.2994 - acc: 0.1218\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 2.2965 - acc: 0.1210\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 2.2886 - acc: 0.1318\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 2.2845 - acc: 0.1378\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 2.2779 - acc: 0.1466\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 2.2680 - acc: 0.1651\n",
      "30000/30000 [==============================] - 2s 64us/step\n",
      "30000/30000 [==============================] - 1s 30us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.4, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd, total=  25.8s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.4, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 5s 156us/step - loss: 2.2947 - acc: 0.1430\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 1.6409 - acc: 0.6259\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.7854 - acc: 0.8340\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.5347 - acc: 0.8703\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.4431 - acc: 0.8831\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.3941 - acc: 0.8916\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.3594 - acc: 0.8990\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.3406 - acc: 0.9018\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.3178 - acc: 0.9080\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.2978 - acc: 0.9134\n",
      "30000/30000 [==============================] - 2s 57us/step\n",
      "30000/30000 [==============================] - 1s 26us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.4, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=adam, total=  25.7s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.4, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 4s 144us/step - loss: 2.2471 - acc: 0.2013\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 1.2435 - acc: 0.7204\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.6401 - acc: 0.8479\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.4801 - acc: 0.8733\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.4063 - acc: 0.8875\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.3690 - acc: 0.8949\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.3413 - acc: 0.9021\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.3161 - acc: 0.9074\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.2952 - acc: 0.9136\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.2820 - acc: 0.9183\n",
      "30000/30000 [==============================] - 2s 65us/step\n",
      "30000/30000 [==============================] - 1s 32us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.4, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=adam, total=  27.0s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.4, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 5s 152us/step - loss: 2.3139 - acc: 0.1053\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 2.3060 - acc: 0.1130\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 2.2997 - acc: 0.1205\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 2.2927 - acc: 0.1295\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 2.2848 - acc: 0.1347\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 2.2727 - acc: 0.1566\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 2.2580 - acc: 0.1749\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 2.2355 - acc: 0.2052\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 2.2076 - acc: 0.2471\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 2.1659 - acc: 0.2919\n",
      "30000/30000 [==============================] - 2s 67us/step\n",
      "30000/30000 [==============================] - 1s 30us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.4, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd, total=  25.2s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.4, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 5s 158us/step - loss: 2.3192 - acc: 0.1075\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 2.3070 - acc: 0.1097\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 2.3016 - acc: 0.1198\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 2.2949 - acc: 0.1239\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 2.2874 - acc: 0.1367\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 2.2781 - acc: 0.1492\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 2.2645 - acc: 0.1682\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 2.2478 - acc: 0.1926\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 2.2217 - acc: 0.2338\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 2.1859 - acc: 0.2800\n",
      "30000/30000 [==============================] - 2s 67us/step\n",
      "30000/30000 [==============================] - 1s 29us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.4, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd, total=  25.4s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.4, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 5s 163us/step - loss: 2.1216 - acc: 0.3025\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.8744 - acc: 0.8044\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.4911 - acc: 0.8747\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.3861 - acc: 0.8935\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.3321 - acc: 0.9052\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.2978 - acc: 0.9138\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.2671 - acc: 0.9222\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.2400 - acc: 0.9313\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.2172 - acc: 0.9374\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.2008 - acc: 0.9413\n",
      "30000/30000 [==============================] - 2s 60us/step\n",
      "30000/30000 [==============================] - 1s 26us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.4, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=adam, total=  25.6s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.4, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 4s 150us/step - loss: 2.1902 - acc: 0.2497\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 1.0171 - acc: 0.7720\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 0.5090 - acc: 0.8748\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 0.3906 - acc: 0.8956\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.3325 - acc: 0.9069\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.2882 - acc: 0.9191\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.2521 - acc: 0.9288\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.2248 - acc: 0.9357\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.2025 - acc: 0.9421\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.1828 - acc: 0.9472\n",
      "30000/30000 [==============================] - 2s 73us/step\n",
      "30000/30000 [==============================] - 1s 30us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.4, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=adam, total=  26.3s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.4, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 5s 169us/step - loss: 2.3206 - acc: 0.1010\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 2.3101 - acc: 0.1076\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 2.3044 - acc: 0.1105\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 2.2986 - acc: 0.1185\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 2.2954 - acc: 0.1214\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 2.2883 - acc: 0.1336\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 2.2805 - acc: 0.1438\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 2.2722 - acc: 0.1546\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 2.2577 - acc: 0.1755\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 2.2434 - acc: 0.1947\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 2.2182 - acc: 0.2320\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 2.1883 - acc: 0.2706\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 2.1471 - acc: 0.3220\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 2.0975 - acc: 0.3721\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 2.0318 - acc: 0.4263\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 1.9525 - acc: 0.4849\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 1.8524 - acc: 0.5429\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 1.7476 - acc: 0.5787\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 1.6323 - acc: 0.6187\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 1.5178 - acc: 0.6478\n",
      "30000/30000 [==============================] - 2s 75us/step\n",
      "30000/30000 [==============================] - 1s 33us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.4, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd, total=  48.4s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.4, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 5s 175us/step - loss: 2.3201 - acc: 0.1066\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 2.3062 - acc: 0.1159\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 2.3022 - acc: 0.1149\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 2.2960 - acc: 0.1238\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 2.2895 - acc: 0.1312\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 2.2829 - acc: 0.1436\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 2.2730 - acc: 0.1565\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 2.2595 - acc: 0.1737\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 2.2410 - acc: 0.1975\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 2.2172 - acc: 0.2349\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 2.1868 - acc: 0.2709\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 2.1446 - acc: 0.3179\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 2.0928 - acc: 0.3676\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 2.0284 - acc: 0.4174\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 1.9508 - acc: 0.4699\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 1.8576 - acc: 0.5194\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 1.7541 - acc: 0.5613\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 1.6440 - acc: 0.5984\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 1.5308 - acc: 0.6349\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 1.4197 - acc: 0.6638\n",
      "30000/30000 [==============================] - 2s 63us/step\n",
      "30000/30000 [==============================] - 1s 27us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.4, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd, total=  44.0s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.4, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 5s 167us/step - loss: 2.3440 - acc: 0.1061\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 2.2207 - acc: 0.2493\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 1.6796 - acc: 0.6580\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 1.0505 - acc: 0.8008\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 2s 83us/step - loss: 0.7118 - acc: 0.8590\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.5603 - acc: 0.8749\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.4861 - acc: 0.8823\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.4328 - acc: 0.8897\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.3939 - acc: 0.8967\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.3718 - acc: 0.8992\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.3494 - acc: 0.9049\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.3282 - acc: 0.9090\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.3119 - acc: 0.9120\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.3009 - acc: 0.9158\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.2890 - acc: 0.9171\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.2776 - acc: 0.9215\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.2671 - acc: 0.9218\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.2557 - acc: 0.9257\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.2528 - acc: 0.9261\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.2484 - acc: 0.9277\n",
      "30000/30000 [==============================] - 2s 74us/step\n",
      "30000/30000 [==============================] - 1s 32us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.4, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=adam, total=  52.6s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.4, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 5s 183us/step - loss: 2.2520 - acc: 0.1889\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 1.2784 - acc: 0.7008\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.6617 - acc: 0.8441\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.4815 - acc: 0.8750\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.4085 - acc: 0.8863\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.3675 - acc: 0.8959\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.3406 - acc: 0.9020\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.3168 - acc: 0.9083\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.3048 - acc: 0.9134\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.2880 - acc: 0.9155\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.2761 - acc: 0.9187\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.2652 - acc: 0.9218\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.2530 - acc: 0.9239\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.2416 - acc: 0.9281\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.2356 - acc: 0.9302\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.2305 - acc: 0.9322\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.2229 - acc: 0.9325\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.2125 - acc: 0.9367\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.2111 - acc: 0.9374\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.2023 - acc: 0.9399\n",
      "30000/30000 [==============================] - 2s 66us/step\n",
      "30000/30000 [==============================] - 1s 27us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.4, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=adam, total=  49.9s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.4, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 2.3147 - acc: 0.1065\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 2s 57us/step - loss: 2.3065 - acc: 0.1118\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 2s 58us/step - loss: 2.3009 - acc: 0.1189\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 2.2956 - acc: 0.1277\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 2.2862 - acc: 0.1372\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 2.2750 - acc: 0.1510\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 2.2600 - acc: 0.1749\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 2.2389 - acc: 0.2043\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 2.2084 - acc: 0.2421\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 2.1687 - acc: 0.2956\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 2.1154 - acc: 0.3515\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 2.0434 - acc: 0.4064\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 1.9578 - acc: 0.4629\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 1.8549 - acc: 0.5175\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 1.7393 - acc: 0.5624\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 1.6183 - acc: 0.6075\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 1.4962 - acc: 0.6391\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 1.3801 - acc: 0.6679\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 1.2772 - acc: 0.6906\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 1.1833 - acc: 0.7121\n",
      "30000/30000 [==============================] - 2s 79us/step\n",
      "30000/30000 [==============================] - 1s 30us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.4, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd, total=  45.6s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.4, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 5s 179us/step - loss: 2.3207 - acc: 0.1045\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 2.3066 - acc: 0.1146\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 2.2994 - acc: 0.1198\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 2.2923 - acc: 0.1330\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 2.2847 - acc: 0.1416\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 2.2733 - acc: 0.1575\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 2.2566 - acc: 0.1822\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 2.2343 - acc: 0.2091\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 2.1989 - acc: 0.2590\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 2.1542 - acc: 0.3097\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 2.0915 - acc: 0.3709\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 2.0087 - acc: 0.4341\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 1.9096 - acc: 0.4952\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 1.7889 - acc: 0.5522\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 1.6640 - acc: 0.5973\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 1.5347 - acc: 0.6378\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 1.4091 - acc: 0.6727\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 1.2964 - acc: 0.6985\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 1.1929 - acc: 0.7175\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 1.1061 - acc: 0.7351\n",
      "30000/30000 [==============================] - 2s 67us/step\n",
      "30000/30000 [==============================] - 1s 25us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.4, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd, total=  45.6s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.4, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 5s 158us/step - loss: 2.1225 - acc: 0.2965\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.8840 - acc: 0.8001\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 0.4777 - acc: 0.8788\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.3738 - acc: 0.8973\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.3126 - acc: 0.9130\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.2732 - acc: 0.9214\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.2432 - acc: 0.9296\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 0.2165 - acc: 0.9389\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 0.1959 - acc: 0.9436\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.1777 - acc: 0.9487\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.1643 - acc: 0.9525\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.1491 - acc: 0.9569\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.1338 - acc: 0.9605\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.1267 - acc: 0.9635\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.1150 - acc: 0.9664\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.1082 - acc: 0.9683\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.1010 - acc: 0.9708\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.0929 - acc: 0.9730\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.0903 - acc: 0.9732\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.0843 - acc: 0.9760\n",
      "30000/30000 [==============================] - 2s 81us/step\n",
      "30000/30000 [==============================] - 1s 32us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.4, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=adam, total=  47.3s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.4, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 6s 198us/step - loss: 2.1332 - acc: 0.2766\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.9641 - acc: 0.7799\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.5142 - acc: 0.8747\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.3725 - acc: 0.9030\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.3037 - acc: 0.9162\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.2585 - acc: 0.9288\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.2295 - acc: 0.9344\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.2040 - acc: 0.9417\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.1859 - acc: 0.9470\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.1663 - acc: 0.9527\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.1524 - acc: 0.9567\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.1395 - acc: 0.9597\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.1337 - acc: 0.9609\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.1218 - acc: 0.9653\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.1158 - acc: 0.9659\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.1123 - acc: 0.9676\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.1029 - acc: 0.9691\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.0946 - acc: 0.9722\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.0916 - acc: 0.9736\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.0882 - acc: 0.9750\n",
      "30000/30000 [==============================] - 2s 81us/step\n",
      "30000/30000 [==============================] - 1s 30us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.4, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=adam, total=  52.1s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.4, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 5s 174us/step - loss: 2.3150 - acc: 0.1057\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 2.3089 - acc: 0.1082\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 2.3039 - acc: 0.1151\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 2.2974 - acc: 0.1204\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 2.2913 - acc: 0.1308\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 2.2833 - acc: 0.1422\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 2.2742 - acc: 0.1522\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 2.2616 - acc: 0.1713\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 2.2437 - acc: 0.1957\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 2.2215 - acc: 0.2268\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 2.1911 - acc: 0.2719\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 2.1506 - acc: 0.3198\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 2.0988 - acc: 0.3720\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 2.0308 - acc: 0.4338\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 1.9452 - acc: 0.4956\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 1.8444 - acc: 0.5425\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 1.7342 - acc: 0.5874\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 1.6090 - acc: 0.6277\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 1.4873 - acc: 0.6590\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 1.3700 - acc: 0.6877\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 1.2629 - acc: 0.7095\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 1.1665 - acc: 0.7245\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 1.0818 - acc: 0.7436\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 1.0109 - acc: 0.7578\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.9496 - acc: 0.7687\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.8999 - acc: 0.7766\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.8508 - acc: 0.7857\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.8095 - acc: 0.7917\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.7780 - acc: 0.7974\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.7480 - acc: 0.8032\n",
      "30000/30000 [==============================] - 3s 86us/step\n",
      "30000/30000 [==============================] - 1s 33us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.4, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd, total= 1.1min\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.4, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 6s 192us/step - loss: 2.3207 - acc: 0.1039\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 2.3081 - acc: 0.1087\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 2.3010 - acc: 0.1158\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 2.2942 - acc: 0.1273\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 2.2871 - acc: 0.1384\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 2.2791 - acc: 0.1470\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 2.2673 - acc: 0.1623\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 2.2525 - acc: 0.1844\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 2.2346 - acc: 0.2090\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 2.2056 - acc: 0.2505\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 2.1724 - acc: 0.2915\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 2.1263 - acc: 0.3426\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 2.0681 - acc: 0.3870\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 1.9935 - acc: 0.4407\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 1.9093 - acc: 0.4894\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 1.8080 - acc: 0.5367\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 1.7003 - acc: 0.5773\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 1.5861 - acc: 0.6125\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 1.4719 - acc: 0.6424\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 1.3633 - acc: 0.6736\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 1.2659 - acc: 0.6924\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 1.1792 - acc: 0.7090\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 1.0997 - acc: 0.7281\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 1.0323 - acc: 0.7434\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.9714 - acc: 0.7558\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.9198 - acc: 0.7658\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.8727 - acc: 0.7752\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 0.8326 - acc: 0.7833\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 0.8010 - acc: 0.7897\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.7685 - acc: 0.7966\n",
      "30000/30000 [==============================] - 2s 78us/step\n",
      "30000/30000 [==============================] - 1s 28us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.4, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd, total= 1.1min\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.4, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 6s 186us/step - loss: 2.2888 - acc: 0.1553\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 1.6374 - acc: 0.6117\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.8377 - acc: 0.8189\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.5507 - acc: 0.8656\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.4412 - acc: 0.8830\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.3933 - acc: 0.8916\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.3616 - acc: 0.8966\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.3338 - acc: 0.9041\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.3186 - acc: 0.9071\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.3005 - acc: 0.9110\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.2860 - acc: 0.9167\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.2753 - acc: 0.9195\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.2646 - acc: 0.9221\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.2552 - acc: 0.9250\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.2427 - acc: 0.9283\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.2356 - acc: 0.9313\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.2249 - acc: 0.9326\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.2232 - acc: 0.9340\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.2155 - acc: 0.9350\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.2087 - acc: 0.9373\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.2008 - acc: 0.9400\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.1934 - acc: 0.9426\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.1901 - acc: 0.9431\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.1862 - acc: 0.9441\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.1817 - acc: 0.9457\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.1763 - acc: 0.9476\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.1718 - acc: 0.9488\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.1670 - acc: 0.9508\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.1623 - acc: 0.9516\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.1598 - acc: 0.9532\n",
      "30000/30000 [==============================] - 2s 73us/step\n",
      "30000/30000 [==============================] - 1s 28us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.4, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=adam, total= 1.2min\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.4, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 6s 193us/step - loss: 2.2789 - acc: 0.1618\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 1.3935 - acc: 0.6693\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.7058 - acc: 0.8441\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.5056 - acc: 0.8715\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.4237 - acc: 0.8870\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.3845 - acc: 0.8934\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.3466 - acc: 0.9029\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.3228 - acc: 0.9070\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.3057 - acc: 0.9124\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.2939 - acc: 0.9160\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.2784 - acc: 0.9193\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.2718 - acc: 0.9201\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.2592 - acc: 0.9255\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.2492 - acc: 0.9266\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.2387 - acc: 0.9298\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.2310 - acc: 0.9317\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.2257 - acc: 0.9329\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.2162 - acc: 0.9357\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.2107 - acc: 0.9368\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.2088 - acc: 0.9378\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.1997 - acc: 0.9416\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.1939 - acc: 0.9414\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.1938 - acc: 0.9424\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.1906 - acc: 0.9436\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.1814 - acc: 0.9443\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.1794 - acc: 0.9466\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.1766 - acc: 0.9475\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.1702 - acc: 0.9506\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.1629 - acc: 0.9517\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.1587 - acc: 0.9525\n",
      "30000/30000 [==============================] - 2s 78us/step\n",
      "30000/30000 [==============================] - 1s 28us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.4, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=adam, total= 1.2min\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.4, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 5s 171us/step - loss: 2.3197 - acc: 0.1005\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 2.3098 - acc: 0.1058\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 2.3052 - acc: 0.1092\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 2.2994 - acc: 0.1188\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 2.2935 - acc: 0.1300\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 2.2852 - acc: 0.1374\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 2s 58us/step - loss: 2.2754 - acc: 0.1515\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 2.2605 - acc: 0.1748\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 2.2414 - acc: 0.2014\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 2.2128 - acc: 0.2429\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 2.1739 - acc: 0.2941\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 2.1210 - acc: 0.3509\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 2.0526 - acc: 0.4126\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 2s 57us/step - loss: 1.9619 - acc: 0.4710\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 1.8524 - acc: 0.5366\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 1.7365 - acc: 0.5788\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 1.6051 - acc: 0.6232\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 1.4756 - acc: 0.6620\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 1.3558 - acc: 0.6901\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 1.2484 - acc: 0.7110\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 1.1495 - acc: 0.7340\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 1.0679 - acc: 0.7462\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 0.9961 - acc: 0.7582\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.9324 - acc: 0.7719\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.8802 - acc: 0.7831\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.8350 - acc: 0.7887\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.7956 - acc: 0.7989\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 0.7605 - acc: 0.8018\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 0.7308 - acc: 0.8082\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 2s 57us/step - loss: 0.7038 - acc: 0.8145\n",
      "30000/30000 [==============================] - 2s 75us/step\n",
      "30000/30000 [==============================] - 1s 27us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.4, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd, total= 1.0min\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.4, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 5s 171us/step - loss: 2.3181 - acc: 0.1031\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 2.3054 - acc: 0.1130\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 2.2998 - acc: 0.1184\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 2.2898 - acc: 0.1316\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 2.2802 - acc: 0.1457\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 2.2659 - acc: 0.1671\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 2.2464 - acc: 0.1940\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 2.2175 - acc: 0.2341\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 2s 57us/step - loss: 2.1766 - acc: 0.2844\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 2s 58us/step - loss: 2.1157 - acc: 0.3482\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 2s 58us/step - loss: 2.0409 - acc: 0.4122\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 2s 58us/step - loss: 1.9457 - acc: 0.4719\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 1.8343 - acc: 0.5276\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 1.7093 - acc: 0.5770\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 1.5845 - acc: 0.6192\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 2s 58us/step - loss: 1.4568 - acc: 0.6504\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 1.3428 - acc: 0.6794\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 1.2347 - acc: 0.7027\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 2s 58us/step - loss: 1.1446 - acc: 0.7198\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 2s 58us/step - loss: 1.0664 - acc: 0.7374\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 0.9976 - acc: 0.7493\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 0.9379 - acc: 0.7635\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 0.8887 - acc: 0.7738\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.8453 - acc: 0.7797\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.8088 - acc: 0.7866\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.7702 - acc: 0.7973\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.7425 - acc: 0.8010\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.7144 - acc: 0.8065\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 0.6921 - acc: 0.8123\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 0.6671 - acc: 0.8173\n",
      "30000/30000 [==============================] - 2s 76us/step\n",
      "30000/30000 [==============================] - 1s 27us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.4, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd, total= 1.0min\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.4, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 6s 187us/step - loss: 2.2021 - acc: 0.2575\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 1.0917 - acc: 0.7867\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.5703 - acc: 0.8655\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.4296 - acc: 0.8876\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.3588 - acc: 0.9023\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.3131 - acc: 0.9135\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.2760 - acc: 0.9219\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.2450 - acc: 0.9302\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.2206 - acc: 0.9372\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.1977 - acc: 0.9431\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.1821 - acc: 0.9465\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.1638 - acc: 0.9526\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.1486 - acc: 0.9581\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.1398 - acc: 0.9605\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.1290 - acc: 0.9627\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.1208 - acc: 0.9655\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.1139 - acc: 0.9676\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.1046 - acc: 0.9699\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.1019 - acc: 0.9704\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.0948 - acc: 0.9724\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.0924 - acc: 0.9725\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.0831 - acc: 0.9763\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.0793 - acc: 0.9762\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.0777 - acc: 0.9780\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.0756 - acc: 0.9783\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.0720 - acc: 0.9788\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.0688 - acc: 0.9800\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.0675 - acc: 0.9803\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.0618 - acc: 0.9808\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.0618 - acc: 0.9823\n",
      "30000/30000 [==============================] - 2s 81us/step\n",
      "30000/30000 [==============================] - 1s 27us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.4, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=adam, total= 1.2min\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.4, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 6s 201us/step - loss: 2.1301 - acc: 0.3067\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.9704 - acc: 0.7910\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.5346 - acc: 0.8712\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.4008 - acc: 0.8943\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.3317 - acc: 0.9089\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.2857 - acc: 0.9204\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.2542 - acc: 0.9285\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.2228 - acc: 0.9382\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.2013 - acc: 0.9423\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.1819 - acc: 0.9487\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.1655 - acc: 0.9522\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.1558 - acc: 0.9556\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.1400 - acc: 0.9595\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.1319 - acc: 0.9615\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.1244 - acc: 0.9643\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.1148 - acc: 0.9679\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.1086 - acc: 0.9682\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.1005 - acc: 0.9716\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.0959 - acc: 0.9719\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.0926 - acc: 0.9735\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.0865 - acc: 0.9747\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.0828 - acc: 0.9763\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.0768 - acc: 0.9779\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.0764 - acc: 0.9777\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.0719 - acc: 0.9795\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.0685 - acc: 0.9801\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.0651 - acc: 0.9810\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.0659 - acc: 0.9801\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.0616 - acc: 0.9813\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.0584 - acc: 0.9840\n",
      "30000/30000 [==============================] - 3s 86us/step\n",
      "30000/30000 [==============================] - 1s 32us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.4, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=adam, total= 1.2min\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.5, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 6s 201us/step - loss: 2.3243 - acc: 0.1035\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 2.3125 - acc: 0.1063\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 2.3111 - acc: 0.1070\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 2.3051 - acc: 0.1181\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 2.3009 - acc: 0.1182\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 2.2971 - acc: 0.1241\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 2.2928 - acc: 0.1294\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 2.2869 - acc: 0.1365\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 2.2792 - acc: 0.1463\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 2.2720 - acc: 0.1553\n",
      "30000/30000 [==============================] - 3s 94us/step\n",
      "30000/30000 [==============================] - 1s 34us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.5, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd, total=  28.4s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.5, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 6s 212us/step - loss: 2.3213 - acc: 0.1053\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 2.3109 - acc: 0.1100\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 2.3061 - acc: 0.1156\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 2.3002 - acc: 0.1246\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 2.2943 - acc: 0.1287\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 2.2848 - acc: 0.1362\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 2.2763 - acc: 0.1482\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 2.2646 - acc: 0.1644\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 2.2451 - acc: 0.1840\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 2.2243 - acc: 0.2125\n",
      "30000/30000 [==============================] - 3s 89us/step\n",
      "30000/30000 [==============================] - 1s 30us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.5, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd, total=  28.5s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.5, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 6s 205us/step - loss: 2.2439 - acc: 0.2013\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 1.3722 - acc: 0.6885\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.7201 - acc: 0.8297\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.5083 - acc: 0.8680\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.4327 - acc: 0.8805\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.3856 - acc: 0.8886\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.3594 - acc: 0.8954\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.3360 - acc: 0.9014\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.3141 - acc: 0.9077\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.3022 - acc: 0.9097\n",
      "30000/30000 [==============================] - 2s 82us/step\n",
      "30000/30000 [==============================] - 1s 28us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.5, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=adam, total=  28.0s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.5, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 6s 204us/step - loss: 2.2499 - acc: 0.1844\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 1.3458 - acc: 0.6819\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.7229 - acc: 0.8288\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 3s 86us/step - loss: 0.5323 - acc: 0.8631\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 3s 86us/step - loss: 0.4519 - acc: 0.8759\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.4054 - acc: 0.8869\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.3697 - acc: 0.8936\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.3477 - acc: 0.8983\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.3301 - acc: 0.9042\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.3111 - acc: 0.9084\n",
      "30000/30000 [==============================] - 3s 93us/step\n",
      "30000/30000 [==============================] - 1s 34us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.5, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=adam, total=  31.3s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.5, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 6s 204us/step - loss: 2.3248 - acc: 0.1031\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 2.3104 - acc: 0.1097\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 2.3044 - acc: 0.1141\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 2.2965 - acc: 0.1241\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 2.2902 - acc: 0.1324\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 2.2789 - acc: 0.1442\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 2.2641 - acc: 0.1630\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 2.2450 - acc: 0.1898\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 2.2155 - acc: 0.2207\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 2.1779 - acc: 0.2648\n",
      "30000/30000 [==============================] - 3s 92us/step\n",
      "30000/30000 [==============================] - 1s 31us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.5, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd, total=  27.7s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.5, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 6s 213us/step - loss: 2.3203 - acc: 0.1024\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 2.3124 - acc: 0.1082\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 2.3065 - acc: 0.1135\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 2.3014 - acc: 0.1214\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 2.2949 - acc: 0.1300\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 2.2874 - acc: 0.1349\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 2.2762 - acc: 0.1474\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 2.2644 - acc: 0.1644\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 2.2444 - acc: 0.1908\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 2.2222 - acc: 0.2180\n",
      "30000/30000 [==============================] - 3s 85us/step\n",
      "30000/30000 [==============================] - 1s 27us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.5, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd, total=  27.3s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.5, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 6s 196us/step - loss: 2.1677 - acc: 0.2566\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.9974 - acc: 0.7826\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.5477 - acc: 0.8670\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.4193 - acc: 0.8863\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.3563 - acc: 0.9012\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.3119 - acc: 0.9113\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.2791 - acc: 0.9194\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.2494 - acc: 0.9282\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.2250 - acc: 0.9356\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.2038 - acc: 0.9414\n",
      "30000/30000 [==============================] - 3s 83us/step\n",
      "30000/30000 [==============================] - 1s 26us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.5, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=adam, total=  26.5s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.5, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 7s 222us/step - loss: 2.0263 - acc: 0.3445\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.8427 - acc: 0.8001\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.5109 - acc: 0.8618\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.4085 - acc: 0.8845\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.3570 - acc: 0.8973\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.3138 - acc: 0.9086\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.2874 - acc: 0.9152\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.2576 - acc: 0.9244\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.2372 - acc: 0.9310\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.2183 - acc: 0.9375\n",
      "30000/30000 [==============================] - 3s 102us/step\n",
      "30000/30000 [==============================] - 1s 36us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.5, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=adam, total=  30.6s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.5, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 7s 224us/step - loss: 2.3255 - acc: 0.1034\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 2.3129 - acc: 0.1086\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 2.3068 - acc: 0.1137\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 2.3053 - acc: 0.1162\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 2.3003 - acc: 0.1227\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 2.2959 - acc: 0.1253\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 2.2905 - acc: 0.1311\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 2.2822 - acc: 0.1425\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 2.2709 - acc: 0.1573\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 2.2605 - acc: 0.1710\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 2.2429 - acc: 0.1907\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 2.2202 - acc: 0.2193\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 2.1901 - acc: 0.2512\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 2.1524 - acc: 0.2915\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 2.0991 - acc: 0.3409\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 2.0345 - acc: 0.3867\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 1.9551 - acc: 0.4394\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 1.8630 - acc: 0.4872\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 1.7599 - acc: 0.5334\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 1.6505 - acc: 0.5743\n",
      "30000/30000 [==============================] - 3s 94us/step\n",
      "30000/30000 [==============================] - 1s 28us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.5, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd, total=  49.9s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.5, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 6s 198us/step - loss: 2.3192 - acc: 0.1071\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 2.3138 - acc: 0.1082\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 2.3087 - acc: 0.1125\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 2.3043 - acc: 0.1165\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 2.2979 - acc: 0.1239\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 2.2932 - acc: 0.1314\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 2.2851 - acc: 0.1382\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 2.2756 - acc: 0.1505\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 2.2631 - acc: 0.1619\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 2.2490 - acc: 0.1839\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 2.2272 - acc: 0.2110\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 2.1970 - acc: 0.2470\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 2.1612 - acc: 0.2850\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 2.1123 - acc: 0.3322\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 2.0517 - acc: 0.3820\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 1.9776 - acc: 0.4335\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 1.8865 - acc: 0.4830\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 1.7856 - acc: 0.5254\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 1.6790 - acc: 0.5684\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 1.5703 - acc: 0.6011\n",
      "30000/30000 [==============================] - 3s 104us/step\n",
      "30000/30000 [==============================] - 1s 36us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.5, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd, total=  47.5s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.5, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 7s 247us/step - loss: 2.3118 - acc: 0.1330\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 1.6860 - acc: 0.5877\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.8729 - acc: 0.8034\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.5785 - acc: 0.8592\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.4730 - acc: 0.8770\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.4182 - acc: 0.8844\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.3818 - acc: 0.8912\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.3565 - acc: 0.8982\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.3369 - acc: 0.9017\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.3195 - acc: 0.9056\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.3049 - acc: 0.9102\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.2961 - acc: 0.9128\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.2832 - acc: 0.9157\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.2713 - acc: 0.9193\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.2651 - acc: 0.9207\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.2568 - acc: 0.9231\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.2493 - acc: 0.9255\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.2410 - acc: 0.9280\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.2330 - acc: 0.9307\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.2252 - acc: 0.9321\n",
      "30000/30000 [==============================] - 3s 92us/step\n",
      "30000/30000 [==============================] - 1s 29us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.5, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=adam, total=  55.9s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.5, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 6s 212us/step - loss: 2.3149 - acc: 0.1218\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 1.7108 - acc: 0.5471\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.8315 - acc: 0.8167\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.5706 - acc: 0.8575\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.4693 - acc: 0.8745\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.4183 - acc: 0.8838\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.3745 - acc: 0.8952\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.3523 - acc: 0.8993\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.3303 - acc: 0.9040\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.3143 - acc: 0.9092\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.2992 - acc: 0.9123\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.2874 - acc: 0.9169\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.2759 - acc: 0.9188\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.2648 - acc: 0.9218\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.2565 - acc: 0.9246\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.2455 - acc: 0.9282\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.2400 - acc: 0.9278\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.2337 - acc: 0.9314\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.2248 - acc: 0.9336\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.2178 - acc: 0.9356\n",
      "30000/30000 [==============================] - 3s 104us/step\n",
      "30000/30000 [==============================] - 1s 34us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.5, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=adam, total=  51.8s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.5, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 7s 226us/step - loss: 2.3221 - acc: 0.1017\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 2.3098 - acc: 0.1119\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 2.3040 - acc: 0.1147\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 2.2986 - acc: 0.1215\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 2.2902 - acc: 0.1341\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 2.2780 - acc: 0.1458\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 2.2651 - acc: 0.1615\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 2.2480 - acc: 0.1832\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 2.2215 - acc: 0.2149\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 2.1835 - acc: 0.2602\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 2.1315 - acc: 0.3139\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 2.0670 - acc: 0.3685\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 1.9855 - acc: 0.4248\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 1.8884 - acc: 0.4859\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 1.7758 - acc: 0.5367\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 1.6593 - acc: 0.5829\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 1.5417 - acc: 0.6173\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 1.4254 - acc: 0.6505\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 1.3179 - acc: 0.6775\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 1.2207 - acc: 0.6986\n",
      "30000/30000 [==============================] - 3s 97us/step\n",
      "30000/30000 [==============================] - 1s 29us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.5, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd, total=  48.8s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.5, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 6s 209us/step - loss: 2.3248 - acc: 0.1036\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 2.3143 - acc: 0.1077\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 2.3058 - acc: 0.1129\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 2.3027 - acc: 0.1200\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 2.2952 - acc: 0.1269\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 2.2861 - acc: 0.1357\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 2.2767 - acc: 0.1452\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 2s 58us/step - loss: 2.2617 - acc: 0.1661\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 2.2428 - acc: 0.1904\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 2.2165 - acc: 0.2241\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 2.1769 - acc: 0.2741\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 2.1270 - acc: 0.3243\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 2.0608 - acc: 0.3799\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 1.9781 - acc: 0.4366\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 2s 58us/step - loss: 1.8713 - acc: 0.5015\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 1.7599 - acc: 0.5464\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 1.6369 - acc: 0.5889\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 1.5176 - acc: 0.6249\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 2s 58us/step - loss: 1.3980 - acc: 0.6548\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 1.2937 - acc: 0.6799\n",
      "30000/30000 [==============================] - 3s 103us/step\n",
      "30000/30000 [==============================] - 1s 33us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.5, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd, total=  43.7s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.5, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 7s 240us/step - loss: 2.0385 - acc: 0.3260\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.8021 - acc: 0.8119\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.4653 - acc: 0.8745\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.3672 - acc: 0.8971\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.3194 - acc: 0.9065\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.2818 - acc: 0.9177\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.2504 - acc: 0.9271\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.2224 - acc: 0.9357\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.2024 - acc: 0.9408\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.1839 - acc: 0.9463\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.1711 - acc: 0.9500\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.1529 - acc: 0.9554\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.1422 - acc: 0.9575\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.1334 - acc: 0.9613\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.1258 - acc: 0.9625\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.1172 - acc: 0.9651\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.1087 - acc: 0.9682\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.1039 - acc: 0.9688\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.0971 - acc: 0.9718\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.0939 - acc: 0.9728\n",
      "30000/30000 [==============================] - 3s 105us/step\n",
      "30000/30000 [==============================] - 1s 32us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.5, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=adam, total=  53.8s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.5, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 7s 238us/step - loss: 2.1942 - acc: 0.2381\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.9923 - acc: 0.7822\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.5360 - acc: 0.8656\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.4149 - acc: 0.8864\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.3556 - acc: 0.9004\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.3133 - acc: 0.9111\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.2801 - acc: 0.9197\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.2527 - acc: 0.9268\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.2325 - acc: 0.9319\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.2127 - acc: 0.9386\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.1920 - acc: 0.9445\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.1769 - acc: 0.9487\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.1659 - acc: 0.9519\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.1504 - acc: 0.9554\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.1402 - acc: 0.9590\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.1279 - acc: 0.9633\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.1211 - acc: 0.9647\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.1129 - acc: 0.9673\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.1076 - acc: 0.9688\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.1004 - acc: 0.9711\n",
      "30000/30000 [==============================] - 3s 100us/step\n",
      "30000/30000 [==============================] - 1s 33us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.5, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=adam, total=  49.2s\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.5, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 7s 242us/step - loss: 2.3220 - acc: 0.1032\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 2.3112 - acc: 0.1080\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 2.3061 - acc: 0.1133\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 2.3004 - acc: 0.1201\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 2.2952 - acc: 0.1233\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 2.2887 - acc: 0.1319\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 2.2811 - acc: 0.1453\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 2.2680 - acc: 0.1569\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 2.2549 - acc: 0.1734\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 2.2368 - acc: 0.1990\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 2.2165 - acc: 0.2243\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 2.1823 - acc: 0.2622\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 2.1407 - acc: 0.3063\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 2.0913 - acc: 0.3541\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 2.0322 - acc: 0.3932\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 1.9619 - acc: 0.4411\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 1.8758 - acc: 0.4860\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 1.7816 - acc: 0.5286\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 1.6837 - acc: 0.5660\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 1.5771 - acc: 0.6025\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 1.4774 - acc: 0.6300\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 1.3763 - acc: 0.6579\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 1.2841 - acc: 0.6795\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 1.2038 - acc: 0.6970\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 1.1236 - acc: 0.7141\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 1.0585 - acc: 0.7287\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.9982 - acc: 0.7411\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.9500 - acc: 0.7512\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.9031 - acc: 0.7598\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.8666 - acc: 0.7644\n",
      "30000/30000 [==============================] - 3s 103us/step\n",
      "30000/30000 [==============================] - 1s 30us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.5, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd, total= 1.2min\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.5, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 7s 224us/step - loss: 2.3215 - acc: 0.1051\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 2.3120 - acc: 0.1108\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 2.3065 - acc: 0.1117\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 2.2999 - acc: 0.1225\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 2.2933 - acc: 0.1293\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 2.2874 - acc: 0.1344\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 2.2759 - acc: 0.1490\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 2.2610 - acc: 0.1661\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 2.2450 - acc: 0.1871\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 2.2205 - acc: 0.2172\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 2.1874 - acc: 0.2528\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 2.1461 - acc: 0.2963\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 2.0904 - acc: 0.3446\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 2.0221 - acc: 0.3964\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 1.9399 - acc: 0.4468\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 1.8436 - acc: 0.4964\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 1.7369 - acc: 0.5460\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 1.6267 - acc: 0.5837\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 1.5164 - acc: 0.6189\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 1.4118 - acc: 0.6472\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 1.3099 - acc: 0.6724\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 1.2191 - acc: 0.6913\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 1.1396 - acc: 0.7107\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 1.0674 - acc: 0.7284\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 1.0079 - acc: 0.7377\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.9546 - acc: 0.7464\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.9067 - acc: 0.7587\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.8665 - acc: 0.7670\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.8319 - acc: 0.7753\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.8017 - acc: 0.7794\n",
      "30000/30000 [==============================] - 3s 111us/step\n",
      "30000/30000 [==============================] - 1s 36us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.5, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd, total= 1.2min\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.5, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 8s 264us/step - loss: 2.3106 - acc: 0.1234\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 1.7023 - acc: 0.5674\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.7668 - acc: 0.8241\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.5165 - acc: 0.8643\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.4325 - acc: 0.8792\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.3859 - acc: 0.8898\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.3539 - acc: 0.8974\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.3320 - acc: 0.9020\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.3112 - acc: 0.9083\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.2961 - acc: 0.9119\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.2857 - acc: 0.9138\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.2712 - acc: 0.9183\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.2612 - acc: 0.9217\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.2510 - acc: 0.9247\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.2422 - acc: 0.9252\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.2297 - acc: 0.9317\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.2250 - acc: 0.9320\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.2171 - acc: 0.9350\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.2165 - acc: 0.9359\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.2011 - acc: 0.9401\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.2013 - acc: 0.9399\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.1952 - acc: 0.9414\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.1879 - acc: 0.9425\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.1821 - acc: 0.9441\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.1808 - acc: 0.9448\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.1792 - acc: 0.9455\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.1753 - acc: 0.9473\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.1691 - acc: 0.9499\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.1628 - acc: 0.9505\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.1624 - acc: 0.9508\n",
      "30000/30000 [==============================] - 3s 112us/step\n",
      "30000/30000 [==============================] - 1s 34us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.5, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=adam, total= 1.3min\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.5, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 8s 257us/step - loss: 2.2082 - acc: 0.2274\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 1.1178 - acc: 0.7390\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.5979 - acc: 0.8459\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.4707 - acc: 0.8690\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.4075 - acc: 0.8842\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.3711 - acc: 0.8921\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.3451 - acc: 0.8988\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.3223 - acc: 0.9042\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.3080 - acc: 0.9087\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 2s 83us/step - loss: 0.2923 - acc: 0.9127\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.2765 - acc: 0.9172\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.2620 - acc: 0.9231\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.2531 - acc: 0.9249\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.2444 - acc: 0.9262\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 2s 83us/step - loss: 0.2386 - acc: 0.9289\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.2275 - acc: 0.9314\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.2199 - acc: 0.9344\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.2129 - acc: 0.9358\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.2076 - acc: 0.9382\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.2015 - acc: 0.9410\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.1936 - acc: 0.9413\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.1891 - acc: 0.9422\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.1844 - acc: 0.9435\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.1796 - acc: 0.9459\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.1759 - acc: 0.9479\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.1709 - acc: 0.9502\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.1693 - acc: 0.9498\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.1664 - acc: 0.9499\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.1588 - acc: 0.9512\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.1523 - acc: 0.9537\n",
      "30000/30000 [==============================] - 3s 100us/step\n",
      "30000/30000 [==============================] - 1s 29us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.5, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=adam, total= 1.3min\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.5, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 7s 223us/step - loss: 2.3197 - acc: 0.1102\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 2.3116 - acc: 0.1107\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 2.3050 - acc: 0.1154\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 2.2982 - acc: 0.1251\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 2.2919 - acc: 0.1297\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 2.2825 - acc: 0.1401\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 2.2708 - acc: 0.1539\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 2.2531 - acc: 0.1793\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 2.2296 - acc: 0.2050\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 2.2003 - acc: 0.2430\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 2.1576 - acc: 0.2894\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 2.1014 - acc: 0.3396\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 2.0295 - acc: 0.3933\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 1.9433 - acc: 0.4444\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 1.8429 - acc: 0.4920\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 1.7305 - acc: 0.5407\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 1.6152 - acc: 0.5798\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 1.5006 - acc: 0.6182\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 1.3891 - acc: 0.6476\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 1.2851 - acc: 0.6723\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 1.1943 - acc: 0.6951\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 1.1145 - acc: 0.7137\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 1.0415 - acc: 0.7310\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.9825 - acc: 0.7418\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.9323 - acc: 0.7527\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.8824 - acc: 0.7655\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.8399 - acc: 0.7763\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.8066 - acc: 0.7804\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.7745 - acc: 0.7888\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.7461 - acc: 0.7944\n",
      "30000/30000 [==============================] - 3s 112us/step\n",
      "30000/30000 [==============================] - 1s 34us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.5, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd, total= 1.2min\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.5, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 8s 253us/step - loss: 2.3274 - acc: 0.1042\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 2.3118 - acc: 0.1096\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 2.3075 - acc: 0.1144\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 2.2990 - acc: 0.1262\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 2.2923 - acc: 0.1332\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 2.2821 - acc: 0.1441\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 2.2707 - acc: 0.1551\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 2.2519 - acc: 0.1839\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 2.2268 - acc: 0.2128\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 2.1912 - acc: 0.2495\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 2.1457 - acc: 0.2963\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 2.0813 - acc: 0.3509\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 2.0038 - acc: 0.4052\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 1.9086 - acc: 0.4549\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 1.8007 - acc: 0.5064\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 1.6849 - acc: 0.5518\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 1.5645 - acc: 0.5975\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 1.4514 - acc: 0.6297\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 1.3488 - acc: 0.6608\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 1.2515 - acc: 0.6834\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 1.1656 - acc: 0.7041\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 1.0922 - acc: 0.7175\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 1.0294 - acc: 0.7329\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 0.9725 - acc: 0.7423\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 0.9191 - acc: 0.7558\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 0.8811 - acc: 0.7640\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 0.8382 - acc: 0.7741\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 0.8086 - acc: 0.7797\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.7754 - acc: 0.7870\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.7474 - acc: 0.7930\n",
      "30000/30000 [==============================] - 4s 117us/step\n",
      "30000/30000 [==============================] - 1s 34us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.5, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd, total= 1.1min\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.5, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 8s 272us/step - loss: 2.2011 - acc: 0.2404\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 1.0642 - acc: 0.7702\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.5122 - acc: 0.8734\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.3784 - acc: 0.8972\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.3159 - acc: 0.9130\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.2696 - acc: 0.9236\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.2386 - acc: 0.9332\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.2151 - acc: 0.9377\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.1931 - acc: 0.9454\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.1757 - acc: 0.9482\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.1667 - acc: 0.9515\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.1531 - acc: 0.9553\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.1442 - acc: 0.9580\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.1343 - acc: 0.9607\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.1283 - acc: 0.9623\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.1168 - acc: 0.9659\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.1119 - acc: 0.9674\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.1062 - acc: 0.9682\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.1048 - acc: 0.9680\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.0943 - acc: 0.9728\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.0927 - acc: 0.9731\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.0890 - acc: 0.9737\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.0857 - acc: 0.9744\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.0830 - acc: 0.9751\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.0798 - acc: 0.9757\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.0745 - acc: 0.9776\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.0729 - acc: 0.9777\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.0700 - acc: 0.9785\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.0658 - acc: 0.9803\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.0653 - acc: 0.9792\n",
      "30000/30000 [==============================] - 3s 102us/step\n",
      "30000/30000 [==============================] - 1s 28us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.5, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=adam, total= 1.3min\n",
      "[CV] activation=sigmoid, batch_size=200, dropout=0.5, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 7s 235us/step - loss: 1.9847 - acc: 0.3528\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.8139 - acc: 0.8052\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.5063 - acc: 0.8671\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.4073 - acc: 0.8858\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.3510 - acc: 0.8987\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.3053 - acc: 0.9114\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.2779 - acc: 0.9190\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.2535 - acc: 0.9257\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.2293 - acc: 0.9323\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.2120 - acc: 0.9382\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.1972 - acc: 0.9413\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.1789 - acc: 0.9482\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.1705 - acc: 0.9506\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.1574 - acc: 0.9542\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.1478 - acc: 0.9576\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.1390 - acc: 0.9596\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.1312 - acc: 0.9618\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.1229 - acc: 0.9633\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.1145 - acc: 0.9664\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.1088 - acc: 0.9687\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.1024 - acc: 0.9705\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.0978 - acc: 0.9712\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.0938 - acc: 0.9717\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.0910 - acc: 0.9731\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.0835 - acc: 0.9753\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.0800 - acc: 0.9767\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.0774 - acc: 0.9775\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.0760 - acc: 0.9773\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.0720 - acc: 0.9789\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.0679 - acc: 0.9802\n",
      "30000/30000 [==============================] - 4s 126us/step\n",
      "30000/30000 [==============================] - 1s 36us/step\n",
      "[CV]  activation=sigmoid, batch_size=200, dropout=0.5, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=adam, total= 1.3min\n",
      "[CV] activation=relu, batch_size=200, dropout=0.3, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 8s 268us/step - loss: 1.8130 - acc: 0.5223\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.6916 - acc: 0.8278\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.4752 - acc: 0.8645\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.4143 - acc: 0.8770\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.3853 - acc: 0.8853\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.3608 - acc: 0.8914\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.3495 - acc: 0.8943\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 0.3321 - acc: 0.9008\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.3177 - acc: 0.9046\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.3070 - acc: 0.9092\n",
      "30000/30000 [==============================] - 3s 106us/step\n",
      "30000/30000 [==============================] - 1s 29us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.3, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd, total=  30.2s\n",
      "[CV] activation=relu, batch_size=200, dropout=0.3, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 7s 238us/step - loss: 1.8388 - acc: 0.4964\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.7455 - acc: 0.8103\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.5000 - acc: 0.8575\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.4315 - acc: 0.8744\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.3975 - acc: 0.8826\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.3736 - acc: 0.8899\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.3564 - acc: 0.8937\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.3390 - acc: 0.8995\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.3258 - acc: 0.9033\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.3149 - acc: 0.9070\n",
      "30000/30000 [==============================] - 4s 126us/step\n",
      "30000/30000 [==============================] - 1s 36us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.3, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd, total=  29.6s\n",
      "[CV] activation=relu, batch_size=200, dropout=0.3, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 9s 293us/step - loss: 0.3983 - acc: 0.8858\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.1443 - acc: 0.9575\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 2s 83us/step - loss: 0.0979 - acc: 0.9708\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.0759 - acc: 0.9773\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.0638 - acc: 0.9801\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.0547 - acc: 0.9827\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.0471 - acc: 0.9853\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.0396 - acc: 0.9878\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.0378 - acc: 0.9875\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 3s 85us/step - loss: 0.0309 - acc: 0.9901\n",
      "30000/30000 [==============================] - 4s 127us/step\n",
      "30000/30000 [==============================] - 1s 41us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.3, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=adam, total=  35.5s\n",
      "[CV] activation=relu, batch_size=200, dropout=0.3, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 9s 285us/step - loss: 0.4072 - acc: 0.8826\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.1388 - acc: 0.9589\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.0922 - acc: 0.9733\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.0697 - acc: 0.9801\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.0580 - acc: 0.9827\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.0492 - acc: 0.9856\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.0400 - acc: 0.9877\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.0335 - acc: 0.9899\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.0299 - acc: 0.9910\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.0256 - acc: 0.9920\n",
      "30000/30000 [==============================] - 3s 115us/step\n",
      "30000/30000 [==============================] - 1s 29us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.3, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=adam, total=  33.5s\n",
      "[CV] activation=relu, batch_size=200, dropout=0.3, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 7s 243us/step - loss: 1.8180 - acc: 0.5079\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 0.6858 - acc: 0.8206\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 0.4823 - acc: 0.8590\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 0.4247 - acc: 0.8745\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 0.3910 - acc: 0.8841\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 0.3678 - acc: 0.8877\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 0.3508 - acc: 0.8951\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 0.3343 - acc: 0.8987\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 0.3237 - acc: 0.9015\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 2s 60us/step - loss: 0.3059 - acc: 0.9089\n",
      "30000/30000 [==============================] - 4s 128us/step\n",
      "30000/30000 [==============================] - 1s 37us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.3, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd, total=  28.6s\n",
      "[CV] activation=relu, batch_size=200, dropout=0.3, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 9s 286us/step - loss: 1.7738 - acc: 0.5231\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.6762 - acc: 0.8203\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.4679 - acc: 0.8671\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.4109 - acc: 0.8810\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.3741 - acc: 0.8903\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.3551 - acc: 0.8955\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.3376 - acc: 0.9011\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.3171 - acc: 0.9064\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.3028 - acc: 0.9112\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.2901 - acc: 0.9143\n",
      "30000/30000 [==============================] - 4s 131us/step\n",
      "30000/30000 [==============================] - 1s 35us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.3, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd, total=  32.6s\n",
      "[CV] activation=relu, batch_size=200, dropout=0.3, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 9s 301us/step - loss: 0.4002 - acc: 0.8852\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.1303 - acc: 0.9614\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.0890 - acc: 0.9731\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.0703 - acc: 0.9787\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.0566 - acc: 0.9825\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.0482 - acc: 0.9850\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.0418 - acc: 0.9872\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.0351 - acc: 0.9891\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.0306 - acc: 0.9904\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.0282 - acc: 0.9906\n",
      "30000/30000 [==============================] - 4s 118us/step\n",
      "30000/30000 [==============================] - 1s 32us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.3, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=adam, total=  34.4s\n",
      "[CV] activation=relu, batch_size=200, dropout=0.3, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 8s 268us/step - loss: 0.3635 - acc: 0.8971\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.1079 - acc: 0.9678\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.0753 - acc: 0.9777\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.0591 - acc: 0.9821\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.0478 - acc: 0.9855\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.0375 - acc: 0.9890\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.0338 - acc: 0.9891\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.0303 - acc: 0.9904\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.0241 - acc: 0.9926\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.0222 - acc: 0.9932\n",
      "30000/30000 [==============================] - 3s 114us/step\n",
      "30000/30000 [==============================] - 1s 31us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.3, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=adam, total=  31.8s\n",
      "[CV] activation=relu, batch_size=200, dropout=0.3, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 8s 263us/step - loss: 1.7680 - acc: 0.5484\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.6871 - acc: 0.8241\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.4809 - acc: 0.8628\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.4193 - acc: 0.8757\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.3882 - acc: 0.8840\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.3631 - acc: 0.8899\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.3470 - acc: 0.8962\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.3317 - acc: 0.9004\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.3186 - acc: 0.9045\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.3081 - acc: 0.9081\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.2943 - acc: 0.9114\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.2837 - acc: 0.9173\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.2777 - acc: 0.9179\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.2669 - acc: 0.9211\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.2593 - acc: 0.9222\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.2538 - acc: 0.9247\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.2462 - acc: 0.9257\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.2388 - acc: 0.9291\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.2328 - acc: 0.9304\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.2260 - acc: 0.9316\n",
      "30000/30000 [==============================] - 4s 126us/step\n",
      "30000/30000 [==============================] - 1s 32us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.3, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd, total=  52.3s\n",
      "[CV] activation=relu, batch_size=200, dropout=0.3, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 8s 270us/step - loss: 1.8468 - acc: 0.5002\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.7296 - acc: 0.8132\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.4917 - acc: 0.8606\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.4280 - acc: 0.8756\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.3921 - acc: 0.8854\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.3670 - acc: 0.8910\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.3483 - acc: 0.8963\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.3296 - acc: 0.9036\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.3162 - acc: 0.9055\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.3065 - acc: 0.9082\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.2937 - acc: 0.9137\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.2838 - acc: 0.9166\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.2742 - acc: 0.9198\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.2650 - acc: 0.9212\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.2578 - acc: 0.9235\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.2473 - acc: 0.9265\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.2394 - acc: 0.9286\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.2332 - acc: 0.9302\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.2261 - acc: 0.9327\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.2218 - acc: 0.9348\n",
      "30000/30000 [==============================] - 4s 125us/step\n",
      "30000/30000 [==============================] - 1s 33us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.3, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd, total=  52.1s\n",
      "[CV] activation=relu, batch_size=200, dropout=0.3, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 8s 281us/step - loss: 0.4049 - acc: 0.8807\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.1523 - acc: 0.9554\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.1030 - acc: 0.9699\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.0795 - acc: 0.9763\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.0628 - acc: 0.9815\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.0570 - acc: 0.9823\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.0445 - acc: 0.9856\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.0398 - acc: 0.9871\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.0342 - acc: 0.9885\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.0309 - acc: 0.9902\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.0268 - acc: 0.9915\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.0251 - acc: 0.9923\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.0227 - acc: 0.9928\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.0195 - acc: 0.9937\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.0149 - acc: 0.9957\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.0147 - acc: 0.9954\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.0126 - acc: 0.9960\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.0116 - acc: 0.9963\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.0114 - acc: 0.9963\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.0111 - acc: 0.9963\n",
      "30000/30000 [==============================] - 4s 120us/step\n",
      "30000/30000 [==============================] - 1s 31us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.3, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=adam, total=  56.8s\n",
      "[CV] activation=relu, batch_size=200, dropout=0.3, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 8s 277us/step - loss: 0.4152 - acc: 0.8824\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 2s 83us/step - loss: 0.1356 - acc: 0.9603\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.0902 - acc: 0.9736\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.0700 - acc: 0.9789\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.0547 - acc: 0.9838\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.0488 - acc: 0.9849\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.0397 - acc: 0.9884\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.0350 - acc: 0.9903\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.0307 - acc: 0.9903\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.0252 - acc: 0.9923\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.0242 - acc: 0.9930\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.0199 - acc: 0.9935\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.0180 - acc: 0.9941\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.0170 - acc: 0.9948\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.0149 - acc: 0.9955\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.0147 - acc: 0.9954\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.0105 - acc: 0.9968\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.0105 - acc: 0.9968\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.0115 - acc: 0.9964\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.0082 - acc: 0.9977\n",
      "30000/30000 [==============================] - 4s 121us/step\n",
      "30000/30000 [==============================] - 1s 30us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.3, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=adam, total=  54.8s\n",
      "[CV] activation=relu, batch_size=200, dropout=0.3, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 8s 267us/step - loss: 1.8608 - acc: 0.5044\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 0.7053 - acc: 0.8131\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.4780 - acc: 0.8609\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 0.4198 - acc: 0.8751\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.3848 - acc: 0.8842\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.3601 - acc: 0.8919\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.3435 - acc: 0.8982\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.3281 - acc: 0.9012\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.3114 - acc: 0.9086\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 0.2997 - acc: 0.9102\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.2889 - acc: 0.9134\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.2774 - acc: 0.9181\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.2667 - acc: 0.9208\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.2552 - acc: 0.9243\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.2457 - acc: 0.9283\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.2390 - acc: 0.9294\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.2283 - acc: 0.9333\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.2206 - acc: 0.9365\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.2155 - acc: 0.9378\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.2067 - acc: 0.9388\n",
      "30000/30000 [==============================] - 4s 122us/step\n",
      "30000/30000 [==============================] - 1s 32us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.3, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd, total=  49.2s\n",
      "[CV] activation=relu, batch_size=200, dropout=0.3, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 9s 293us/step - loss: 1.7544 - acc: 0.5514\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.6486 - acc: 0.8303\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.4606 - acc: 0.8676\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.4082 - acc: 0.8798\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.3736 - acc: 0.8885\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 0.3536 - acc: 0.8944\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.3368 - acc: 0.9010\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 0.3171 - acc: 0.9072\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.3022 - acc: 0.9111\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 0.2907 - acc: 0.9152\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.2768 - acc: 0.9187\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.2628 - acc: 0.9238\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 0.2557 - acc: 0.9249\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.2481 - acc: 0.9267\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 2s 59us/step - loss: 0.2353 - acc: 0.9315\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 0.2261 - acc: 0.9341\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.2206 - acc: 0.9348\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.2099 - acc: 0.9382\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.2056 - acc: 0.9384\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.1976 - acc: 0.9419\n",
      "30000/30000 [==============================] - 4s 119us/step\n",
      "30000/30000 [==============================] - 1s 29us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.3, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd, total=  48.6s\n",
      "[CV] activation=relu, batch_size=200, dropout=0.3, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 9s 292us/step - loss: 0.3765 - acc: 0.8917\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.1291 - acc: 0.9622\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.0872 - acc: 0.9739\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.0658 - acc: 0.9798\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.0536 - acc: 0.9836\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.0458 - acc: 0.9854\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.0394 - acc: 0.9876\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.0330 - acc: 0.9897\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.0291 - acc: 0.9908\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.0237 - acc: 0.9923\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.0231 - acc: 0.9928\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.0189 - acc: 0.9940\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.0173 - acc: 0.9945\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.0163 - acc: 0.9947\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.0139 - acc: 0.9955\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.0108 - acc: 0.9972\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.0121 - acc: 0.9964\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.0092 - acc: 0.9973\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.0109 - acc: 0.9964\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.0129 - acc: 0.9960\n",
      "30000/30000 [==============================] - 4s 130us/step\n",
      "30000/30000 [==============================] - 1s 33us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.3, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=adam, total=  55.9s\n",
      "[CV] activation=relu, batch_size=200, dropout=0.3, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 9s 298us/step - loss: 0.3789 - acc: 0.8880\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.1223 - acc: 0.9640\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.0827 - acc: 0.9753\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.0633 - acc: 0.9808\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.0514 - acc: 0.9848\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.0418 - acc: 0.9872\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.0350 - acc: 0.9897\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.0316 - acc: 0.9897\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.0257 - acc: 0.9925\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.0219 - acc: 0.9932\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.0178 - acc: 0.9940\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.0174 - acc: 0.9944\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.0170 - acc: 0.9946\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.0132 - acc: 0.9958\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.0127 - acc: 0.9957\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.0127 - acc: 0.9960\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.0109 - acc: 0.9968\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.0094 - acc: 0.9969\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.0074 - acc: 0.9977\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.0071 - acc: 0.9978\n",
      "30000/30000 [==============================] - 4s 124us/step\n",
      "30000/30000 [==============================] - 1s 29us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.3, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=adam, total=  53.6s\n",
      "[CV] activation=relu, batch_size=200, dropout=0.3, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 9s 306us/step - loss: 1.7846 - acc: 0.5698\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.6829 - acc: 0.8217\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.4823 - acc: 0.8602\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.4212 - acc: 0.8748\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.3888 - acc: 0.8845\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.3664 - acc: 0.8903\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.3453 - acc: 0.8967\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.3324 - acc: 0.9012\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.3173 - acc: 0.9047\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.3041 - acc: 0.9106\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.2924 - acc: 0.9125\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.2812 - acc: 0.9156\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.2716 - acc: 0.9191\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.2629 - acc: 0.9221\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.2539 - acc: 0.9250\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.2481 - acc: 0.9260\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.2395 - acc: 0.9296\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.2313 - acc: 0.9318\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.2234 - acc: 0.9334\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.2184 - acc: 0.9361\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.2138 - acc: 0.9370\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.2097 - acc: 0.9371\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.2032 - acc: 0.9404\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.1988 - acc: 0.9408\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.1942 - acc: 0.9429\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.1886 - acc: 0.9443\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.1857 - acc: 0.9453\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.1792 - acc: 0.9466\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.1755 - acc: 0.9476\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.1739 - acc: 0.9488\n",
      "30000/30000 [==============================] - 4s 145us/step\n",
      "30000/30000 [==============================] - 1s 41us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.3, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd, total= 1.4min\n",
      "[CV] activation=relu, batch_size=200, dropout=0.3, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 10s 320us/step - loss: 1.8624 - acc: 0.4954\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.7469 - acc: 0.8154\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.4965 - acc: 0.8585\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.4307 - acc: 0.8742\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.3982 - acc: 0.8819\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.3768 - acc: 0.8896\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.3558 - acc: 0.8945\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.3393 - acc: 0.9009\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.3261 - acc: 0.9024\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.3131 - acc: 0.9072\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.3026 - acc: 0.9098\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.2920 - acc: 0.9137\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.2837 - acc: 0.9179\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.2741 - acc: 0.9196\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.2641 - acc: 0.9217\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.2565 - acc: 0.9245\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.2513 - acc: 0.9265\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.2413 - acc: 0.9289\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.2373 - acc: 0.9289\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.2295 - acc: 0.9304\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.2247 - acc: 0.9326\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.2182 - acc: 0.9355\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.2111 - acc: 0.9386\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.2092 - acc: 0.9394\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.2011 - acc: 0.9410\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.1996 - acc: 0.9409\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.1913 - acc: 0.9431\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.1900 - acc: 0.9441\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.1855 - acc: 0.9452\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.1767 - acc: 0.9471\n",
      "30000/30000 [==============================] - 4s 149us/step\n",
      "30000/30000 [==============================] - 1s 40us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.3, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd, total= 1.3min\n",
      "[CV] activation=relu, batch_size=200, dropout=0.3, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 10s 327us/step - loss: 0.3935 - acc: 0.8929\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 3s 85us/step - loss: 0.1356 - acc: 0.9602\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 3s 85us/step - loss: 0.0931 - acc: 0.9711\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.0734 - acc: 0.9785\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.0611 - acc: 0.9816\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.0504 - acc: 0.9846\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.0449 - acc: 0.9857\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 2s 83us/step - loss: 0.0381 - acc: 0.9882\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 2s 83us/step - loss: 0.0331 - acc: 0.9901\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.0277 - acc: 0.9914\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 2s 83us/step - loss: 0.0249 - acc: 0.9926\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.0243 - acc: 0.9924\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.0206 - acc: 0.9936\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.0190 - acc: 0.9937\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.0145 - acc: 0.9957\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.0133 - acc: 0.9959\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 3s 88us/step - loss: 0.0152 - acc: 0.9950\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 3s 86us/step - loss: 0.0120 - acc: 0.9962\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 3s 86us/step - loss: 0.0096 - acc: 0.9971\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 3s 85us/step - loss: 0.0096 - acc: 0.9969\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 3s 85us/step - loss: 0.0099 - acc: 0.9971\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 3s 89us/step - loss: 0.0093 - acc: 0.9970\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 3s 86us/step - loss: 0.0074 - acc: 0.9973\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 3s 85us/step - loss: 0.0084 - acc: 0.9972\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.0085 - acc: 0.9971\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.0078 - acc: 0.9974\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.0060 - acc: 0.9980\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.0055 - acc: 0.9984\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.0056 - acc: 0.9984\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.0048 - acc: 0.9986\n",
      "30000/30000 [==============================] - 4s 130us/step\n",
      "30000/30000 [==============================] - 1s 31us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.3, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=adam, total= 1.4min\n",
      "[CV] activation=relu, batch_size=200, dropout=0.3, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 9s 303us/step - loss: 0.4277 - acc: 0.8793\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.1440 - acc: 0.9576\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.0952 - acc: 0.9730\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.0722 - acc: 0.9787\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.0604 - acc: 0.9821\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.0512 - acc: 0.9840\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.0447 - acc: 0.9859\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.0381 - acc: 0.9887\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.0354 - acc: 0.9888\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 3s 86us/step - loss: 0.0299 - acc: 0.9903\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 3s 88us/step - loss: 0.0267 - acc: 0.9915\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.0224 - acc: 0.9930\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 3s 88us/step - loss: 0.0211 - acc: 0.9933\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.0194 - acc: 0.9938\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 3s 88us/step - loss: 0.0170 - acc: 0.9945\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 3s 88us/step - loss: 0.0148 - acc: 0.9952\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.0137 - acc: 0.9959\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.0141 - acc: 0.9953\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 3s 86us/step - loss: 0.0126 - acc: 0.9961\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 3s 88us/step - loss: 0.0130 - acc: 0.9953\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 3s 86us/step - loss: 0.0106 - acc: 0.9969\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 3s 86us/step - loss: 0.0097 - acc: 0.9970\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.0100 - acc: 0.9966\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 3s 85us/step - loss: 0.0086 - acc: 0.9972\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 3s 85us/step - loss: 0.0065 - acc: 0.9977\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.0077 - acc: 0.9977\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.0076 - acc: 0.9975\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.0074 - acc: 0.9974\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 3s 85us/step - loss: 0.0070 - acc: 0.9977\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 3s 88us/step - loss: 0.0063 - acc: 0.9978\n",
      "30000/30000 [==============================] - 5s 152us/step\n",
      "30000/30000 [==============================] - 1s 40us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.3, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=adam, total= 1.4min\n",
      "[CV] activation=relu, batch_size=200, dropout=0.3, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 10s 318us/step - loss: 1.7666 - acc: 0.5264\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.6548 - acc: 0.8229\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.4740 - acc: 0.8609\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.4168 - acc: 0.8748\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.3875 - acc: 0.8836\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.3634 - acc: 0.8920\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.3436 - acc: 0.8965\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.3273 - acc: 0.9025\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.3152 - acc: 0.9056\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.3047 - acc: 0.9094\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.2894 - acc: 0.9131\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.2806 - acc: 0.9170\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.2677 - acc: 0.9209\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.2621 - acc: 0.9221\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 0.2497 - acc: 0.9262\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 0.2424 - acc: 0.9286\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.2332 - acc: 0.9317\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.2239 - acc: 0.9338\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 0.2160 - acc: 0.9371\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.2080 - acc: 0.9379\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.2019 - acc: 0.9414\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 0.1961 - acc: 0.9421\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.1916 - acc: 0.9435\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.1837 - acc: 0.9471\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.1787 - acc: 0.9482\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.1750 - acc: 0.9491\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 2s 63us/step - loss: 0.1701 - acc: 0.9502\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.1642 - acc: 0.9524\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 2s 61us/step - loss: 0.1615 - acc: 0.9537\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 2s 62us/step - loss: 0.1545 - acc: 0.9557\n",
      "30000/30000 [==============================] - 4s 130us/step\n",
      "30000/30000 [==============================] - 1s 30us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.3, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd, total= 1.2min\n",
      "[CV] activation=relu, batch_size=200, dropout=0.3, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 10s 338us/step - loss: 1.6365 - acc: 0.5531\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.6151 - acc: 0.8358\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.4569 - acc: 0.8666\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.4040 - acc: 0.8796\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.3750 - acc: 0.8886\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.3518 - acc: 0.8966\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.3313 - acc: 0.9014\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.3170 - acc: 0.9056\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.3031 - acc: 0.9112\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.2889 - acc: 0.9149\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.2784 - acc: 0.9176\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.2673 - acc: 0.9211\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.2547 - acc: 0.9229\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.2473 - acc: 0.9275\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.2359 - acc: 0.9307\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.2273 - acc: 0.9334\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.2211 - acc: 0.9340\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.2139 - acc: 0.9354\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.2063 - acc: 0.9386\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.1987 - acc: 0.9414\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.1949 - acc: 0.9421\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.1893 - acc: 0.9438\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.1819 - acc: 0.9461\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.1771 - acc: 0.9483\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.1735 - acc: 0.9480\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.1662 - acc: 0.9514\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.1613 - acc: 0.9526\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.1580 - acc: 0.9539\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.1572 - acc: 0.9528\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.1502 - acc: 0.9554\n",
      "30000/30000 [==============================] - 4s 149us/step\n",
      "30000/30000 [==============================] - 1s 36us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.3, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd, total= 1.3min\n",
      "[CV] activation=relu, batch_size=200, dropout=0.3, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 10s 323us/step - loss: 0.3784 - acc: 0.8919\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.1109 - acc: 0.9685\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.0777 - acc: 0.9759\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.0590 - acc: 0.9815\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.0490 - acc: 0.9848\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.0439 - acc: 0.9860\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.0368 - acc: 0.9883\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.0306 - acc: 0.9903\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.0276 - acc: 0.9910\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.0228 - acc: 0.9931\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.0195 - acc: 0.9934\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.0178 - acc: 0.9950\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.0165 - acc: 0.9945\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.0143 - acc: 0.9953\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.0131 - acc: 0.9959\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.0121 - acc: 0.9961\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.0106 - acc: 0.9963\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.0108 - acc: 0.9970\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.0116 - acc: 0.9962\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.0088 - acc: 0.9973\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.0084 - acc: 0.9976\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.0078 - acc: 0.9976\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.0081 - acc: 0.9974\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 2s 83us/step - loss: 0.0061 - acc: 0.9981\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.0055 - acc: 0.9985\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.0064 - acc: 0.9982\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 2s 83us/step - loss: 0.0061 - acc: 0.9982\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.0052 - acc: 0.9985\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.0056 - acc: 0.9981\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.0061 - acc: 0.9980\n",
      "30000/30000 [==============================] - 5s 154us/step\n",
      "30000/30000 [==============================] - 1s 38us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.3, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=adam, total= 1.3min\n",
      "[CV] activation=relu, batch_size=200, dropout=0.3, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 10s 340us/step - loss: 0.3692 - acc: 0.8979\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.1087 - acc: 0.9685\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.0742 - acc: 0.9781\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.0574 - acc: 0.9827\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.0470 - acc: 0.9852\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.0385 - acc: 0.9886\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 3s 88us/step - loss: 0.0309 - acc: 0.9907\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 3s 83us/step - loss: 0.0280 - acc: 0.9909\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 2s 83us/step - loss: 0.0226 - acc: 0.9927\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 2s 83us/step - loss: 0.0208 - acc: 0.9935\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 3s 83us/step - loss: 0.0185 - acc: 0.9941\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 3s 85us/step - loss: 0.0157 - acc: 0.9952\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.0132 - acc: 0.9960\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 3s 83us/step - loss: 0.0125 - acc: 0.9961\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.0121 - acc: 0.9960\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 2s 83us/step - loss: 0.0088 - acc: 0.9972\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.0092 - acc: 0.9969\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 2s 83us/step - loss: 0.0086 - acc: 0.9971\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.0077 - acc: 0.9973\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.0072 - acc: 0.9977\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.0070 - acc: 0.9980\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.0067 - acc: 0.9978\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.0073 - acc: 0.9976\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.0054 - acc: 0.9982\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.0058 - acc: 0.9980\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.0050 - acc: 0.9985\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.0049 - acc: 0.9981\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.0074 - acc: 0.9977\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.0058 - acc: 0.9982\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.0039 - acc: 0.9988\n",
      "30000/30000 [==============================] - 4s 131us/step\n",
      "30000/30000 [==============================] - 1s 29us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.3, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=adam, total= 1.4min\n",
      "[CV] activation=relu, batch_size=200, dropout=0.4, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 9s 287us/step - loss: 1.7134 - acc: 0.5337\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.6815 - acc: 0.8150\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.4870 - acc: 0.8560\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.4308 - acc: 0.8726\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.3994 - acc: 0.8792\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.3797 - acc: 0.8850\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.3621 - acc: 0.8901\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.3460 - acc: 0.8955\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.3333 - acc: 0.8995\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.3219 - acc: 0.9031\n",
      "30000/30000 [==============================] - 5s 157us/step\n",
      "30000/30000 [==============================] - 1s 40us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.4, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd, total=  32.2s\n",
      "[CV] activation=relu, batch_size=200, dropout=0.4, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 10s 345us/step - loss: 1.9517 - acc: 0.4258\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.8162 - acc: 0.7905\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.5276 - acc: 0.8477\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.4499 - acc: 0.8655\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.4119 - acc: 0.8771\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.3863 - acc: 0.8848\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.3695 - acc: 0.8889\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.3548 - acc: 0.8918\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.3385 - acc: 0.8996\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.3285 - acc: 0.9035\n",
      "30000/30000 [==============================] - 5s 162us/step\n",
      "30000/30000 [==============================] - 1s 40us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.4, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd, total=  37.3s\n",
      "[CV] activation=relu, batch_size=200, dropout=0.4, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 11s 362us/step - loss: 0.4370 - acc: 0.8762\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.1514 - acc: 0.9555\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.1048 - acc: 0.9692\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 3s 83us/step - loss: 0.0839 - acc: 0.9744\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.0721 - acc: 0.9777\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 3s 89us/step - loss: 0.0616 - acc: 0.9808\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 3s 86us/step - loss: 0.0547 - acc: 0.9823\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 3s 88us/step - loss: 0.0488 - acc: 0.9838\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 3s 88us/step - loss: 0.0430 - acc: 0.9863\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 3s 86us/step - loss: 0.0385 - acc: 0.9877\n",
      "30000/30000 [==============================] - 5s 160us/step\n",
      "30000/30000 [==============================] - 1s 40us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.4, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=adam, total=  39.7s\n",
      "[CV] activation=relu, batch_size=200, dropout=0.4, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 10s 340us/step - loss: 0.4101 - acc: 0.8846\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.1495 - acc: 0.9572\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.1078 - acc: 0.9672\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.0828 - acc: 0.9746\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.0706 - acc: 0.9786\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.0604 - acc: 0.9811\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.0555 - acc: 0.9830\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.0471 - acc: 0.9852\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.0438 - acc: 0.9856\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.0377 - acc: 0.9882\n",
      "30000/30000 [==============================] - 4s 137us/step\n",
      "30000/30000 [==============================] - 1s 31us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.4, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=adam, total=  35.6s\n",
      "[CV] activation=relu, batch_size=200, dropout=0.4, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 9s 299us/step - loss: 1.9301 - acc: 0.4290\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.7619 - acc: 0.8000\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.5006 - acc: 0.8527\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.4360 - acc: 0.8670\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.4002 - acc: 0.8792\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.3772 - acc: 0.8882\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.3582 - acc: 0.8933\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.3387 - acc: 0.8996\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.3263 - acc: 0.9006\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.3115 - acc: 0.9068\n",
      "30000/30000 [==============================] - 5s 166us/step\n",
      "30000/30000 [==============================] - 1s 41us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.4, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd, total=  34.0s\n",
      "[CV] activation=relu, batch_size=200, dropout=0.4, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 11s 367us/step - loss: 1.9404 - acc: 0.4245\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.7567 - acc: 0.7950\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.5089 - acc: 0.8475\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.4416 - acc: 0.8676\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.4081 - acc: 0.8764\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.3844 - acc: 0.8837\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.3646 - acc: 0.8911\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.3456 - acc: 0.8986\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.3265 - acc: 0.9015\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.3088 - acc: 0.9087\n",
      "30000/30000 [==============================] - 5s 167us/step\n",
      "30000/30000 [==============================] - 1s 40us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.4, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd, total=  37.5s\n",
      "[CV] activation=relu, batch_size=200, dropout=0.4, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 11s 376us/step - loss: 0.3733 - acc: 0.8926\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.1231 - acc: 0.9637\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.0877 - acc: 0.9732\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.0685 - acc: 0.9786\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.0588 - acc: 0.9818\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.0501 - acc: 0.9838\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.0440 - acc: 0.9859\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.0358 - acc: 0.9893\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.0334 - acc: 0.9892\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.0282 - acc: 0.9911\n",
      "30000/30000 [==============================] - 4s 143us/step\n",
      "30000/30000 [==============================] - 1s 30us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.4, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=adam, total=  37.8s\n",
      "[CV] activation=relu, batch_size=200, dropout=0.4, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 10s 328us/step - loss: 0.3863 - acc: 0.8831\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.1261 - acc: 0.9627\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.0894 - acc: 0.9737\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.0674 - acc: 0.9796\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.0541 - acc: 0.9836\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.0483 - acc: 0.9849\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.0408 - acc: 0.9871\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.0338 - acc: 0.9895\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.0305 - acc: 0.9899\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.0272 - acc: 0.9909\n",
      "30000/30000 [==============================] - 5s 166us/step\n",
      "30000/30000 [==============================] - 1s 42us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.4, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=adam, total=  34.4s\n",
      "[CV] activation=relu, batch_size=200, dropout=0.4, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 11s 369us/step - loss: 1.7933 - acc: 0.5330\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.6960 - acc: 0.8165\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.4868 - acc: 0.8575\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.4269 - acc: 0.8724\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.3970 - acc: 0.8800\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.3770 - acc: 0.8863\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.3605 - acc: 0.8911\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.3476 - acc: 0.8939\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.3366 - acc: 0.8972\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.3213 - acc: 0.9033\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.3148 - acc: 0.9039\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.3074 - acc: 0.9076\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.2977 - acc: 0.9092\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 2s 83us/step - loss: 0.2868 - acc: 0.9125\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.2791 - acc: 0.9169\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.2734 - acc: 0.9181\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.2645 - acc: 0.9213\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.2592 - acc: 0.9224\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.2530 - acc: 0.9244\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.2436 - acc: 0.9276\n",
      "30000/30000 [==============================] - 5s 177us/step\n",
      "30000/30000 [==============================] - 1s 43us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.4, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd, total= 1.0min\n",
      "[CV] activation=relu, batch_size=200, dropout=0.4, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 11s 377us/step - loss: 1.9197 - acc: 0.4784\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.7831 - acc: 0.8008\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.5122 - acc: 0.8515\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.4436 - acc: 0.8680\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.4080 - acc: 0.8795\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.3915 - acc: 0.8836\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.3730 - acc: 0.8906\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.3594 - acc: 0.8920\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.3483 - acc: 0.8976\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.3347 - acc: 0.9002\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.3249 - acc: 0.9033\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.3150 - acc: 0.9060\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.3060 - acc: 0.9079\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.2960 - acc: 0.9119\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.2871 - acc: 0.9150\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.2803 - acc: 0.9165\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.2719 - acc: 0.9190\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.2625 - acc: 0.9228\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.2579 - acc: 0.9230\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.2517 - acc: 0.9246\n",
      "30000/30000 [==============================] - 4s 149us/step\n",
      "30000/30000 [==============================] - 1s 32us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.4, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd, total=  56.9s\n",
      "[CV] activation=relu, batch_size=200, dropout=0.4, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 11s 357us/step - loss: 0.3967 - acc: 0.8851\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 3s 89us/step - loss: 0.1376 - acc: 0.9606\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 3s 88us/step - loss: 0.0985 - acc: 0.9705\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 3s 94us/step - loss: 0.0801 - acc: 0.9758\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 3s 88us/step - loss: 0.0674 - acc: 0.9797\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.0563 - acc: 0.9819\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.0495 - acc: 0.9841\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.0421 - acc: 0.9860\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 3s 86us/step - loss: 0.0384 - acc: 0.9878\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.0346 - acc: 0.9890\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.0317 - acc: 0.9900\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.0282 - acc: 0.9905\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.0260 - acc: 0.9918\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 3s 88us/step - loss: 0.0236 - acc: 0.9924\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 3s 90us/step - loss: 0.0196 - acc: 0.9935\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.0184 - acc: 0.9940\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 3s 88us/step - loss: 0.0174 - acc: 0.9942\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 3s 92us/step - loss: 0.0150 - acc: 0.9954\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 3s 91us/step - loss: 0.0164 - acc: 0.9944\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 3s 90us/step - loss: 0.0136 - acc: 0.9953\n",
      "30000/30000 [==============================] - 5s 177us/step\n",
      "30000/30000 [==============================] - 1s 44us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.4, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=adam, total= 1.1min\n",
      "[CV] activation=relu, batch_size=200, dropout=0.4, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 12s 393us/step - loss: 0.4162 - acc: 0.8784\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 3s 91us/step - loss: 0.1416 - acc: 0.9591\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 3s 92us/step - loss: 0.0960 - acc: 0.9708\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 3s 88us/step - loss: 0.0764 - acc: 0.9778\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 3s 89us/step - loss: 0.0640 - acc: 0.9816\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 3s 90us/step - loss: 0.0550 - acc: 0.9835\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.0493 - acc: 0.9851\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 3s 86us/step - loss: 0.0426 - acc: 0.9869\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.0374 - acc: 0.9880\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.0355 - acc: 0.9888\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.0308 - acc: 0.9903\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.0263 - acc: 0.9915\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.0251 - acc: 0.9923\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.0209 - acc: 0.9930\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.0213 - acc: 0.9929\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.0167 - acc: 0.9951\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.0154 - acc: 0.9954\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.0159 - acc: 0.9947\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.0130 - acc: 0.9956\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.0137 - acc: 0.9960\n",
      "30000/30000 [==============================] - 4s 150us/step\n",
      "30000/30000 [==============================] - 1s 33us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.4, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=adam, total= 1.1min\n",
      "[CV] activation=relu, batch_size=200, dropout=0.4, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 11s 359us/step - loss: 1.8589 - acc: 0.4661\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.7253 - acc: 0.8033\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.4973 - acc: 0.8530\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.4331 - acc: 0.8715\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.3986 - acc: 0.8793\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.3712 - acc: 0.8890\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.3484 - acc: 0.8943\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.3317 - acc: 0.9014\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.3174 - acc: 0.9048\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.3024 - acc: 0.9103\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.2890 - acc: 0.9151\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.2805 - acc: 0.9162\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.2675 - acc: 0.9198\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.2596 - acc: 0.9230\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.2537 - acc: 0.9261\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.2424 - acc: 0.9288\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.2331 - acc: 0.9317\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 3s 85us/step - loss: 0.2252 - acc: 0.9335\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 3s 89us/step - loss: 0.2181 - acc: 0.9348\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 3s 83us/step - loss: 0.2091 - acc: 0.9387\n",
      "30000/30000 [==============================] - 6s 192us/step\n",
      "30000/30000 [==============================] - 1s 49us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.4, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd, total= 1.1min\n",
      "[CV] activation=relu, batch_size=200, dropout=0.4, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 12s 384us/step - loss: 1.8655 - acc: 0.4512\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.7412 - acc: 0.7992\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.5089 - acc: 0.8514\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.4405 - acc: 0.8698\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.4067 - acc: 0.8793\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.3803 - acc: 0.8874\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.3561 - acc: 0.8952\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.3365 - acc: 0.9006\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.3216 - acc: 0.9046\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.3059 - acc: 0.9113\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.2913 - acc: 0.9149\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.2804 - acc: 0.9188\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.2687 - acc: 0.9228\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.2558 - acc: 0.9245\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.2448 - acc: 0.9282\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.2354 - acc: 0.9309\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.2283 - acc: 0.9337\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.2192 - acc: 0.9367\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 2s 66us/step - loss: 0.2113 - acc: 0.9397\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 2s 65us/step - loss: 0.2044 - acc: 0.9398\n",
      "30000/30000 [==============================] - 4s 149us/step\n",
      "30000/30000 [==============================] - 1s 31us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.4, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd, total=  57.7s\n",
      "[CV] activation=relu, batch_size=200, dropout=0.4, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 11s 351us/step - loss: 0.3905 - acc: 0.8895\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.1262 - acc: 0.9619\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.0915 - acc: 0.9720\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 3s 86us/step - loss: 0.0701 - acc: 0.9781\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 3s 86us/step - loss: 0.0598 - acc: 0.9815\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 3s 86us/step - loss: 0.0491 - acc: 0.9848\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.0471 - acc: 0.9853\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 3s 86us/step - loss: 0.0388 - acc: 0.9879\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 3s 85us/step - loss: 0.0341 - acc: 0.9891\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 3s 85us/step - loss: 0.0287 - acc: 0.9906\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 3s 86us/step - loss: 0.0286 - acc: 0.9907\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.0250 - acc: 0.9911\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 3s 86us/step - loss: 0.0233 - acc: 0.9919\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 3s 86us/step - loss: 0.0194 - acc: 0.9938\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.0178 - acc: 0.9939\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 3s 88us/step - loss: 0.0169 - acc: 0.9947\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 3s 88us/step - loss: 0.0166 - acc: 0.9943\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 3s 86us/step - loss: 0.0151 - acc: 0.9947\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 3s 86us/step - loss: 0.0134 - acc: 0.9955\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.0136 - acc: 0.9958\n",
      "30000/30000 [==============================] - 5s 179us/step\n",
      "30000/30000 [==============================] - 1s 43us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.4, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=adam, total= 1.1min\n",
      "[CV] activation=relu, batch_size=200, dropout=0.4, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 12s 395us/step - loss: 0.3791 - acc: 0.8932\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 3s 85us/step - loss: 0.1224 - acc: 0.9640\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 3s 86us/step - loss: 0.0864 - acc: 0.9735\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 3s 89us/step - loss: 0.0667 - acc: 0.9799\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 3s 90us/step - loss: 0.0563 - acc: 0.9822\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 3s 86us/step - loss: 0.0496 - acc: 0.9847\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.0402 - acc: 0.9880\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.0355 - acc: 0.9886\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.0291 - acc: 0.9903\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.0258 - acc: 0.9920\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.0238 - acc: 0.9925\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.0228 - acc: 0.9928\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.0194 - acc: 0.9940\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.0169 - acc: 0.9942\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.0144 - acc: 0.9955\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.0148 - acc: 0.9955\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.0116 - acc: 0.9964\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.0122 - acc: 0.9963\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.0132 - acc: 0.9959\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.0099 - acc: 0.9968\n",
      "30000/30000 [==============================] - 5s 155us/step\n",
      "30000/30000 [==============================] - 1s 34us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.4, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=adam, total= 1.1min\n",
      "[CV] activation=relu, batch_size=200, dropout=0.4, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 11s 357us/step - loss: 1.8582 - acc: 0.4810\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.7456 - acc: 0.8089\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.5097 - acc: 0.8512\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.4438 - acc: 0.8667\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 3s 85us/step - loss: 0.4149 - acc: 0.8746\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.3855 - acc: 0.8849\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.3718 - acc: 0.8888\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.3580 - acc: 0.8925\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.3435 - acc: 0.8973\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 2s 83us/step - loss: 0.3260 - acc: 0.9019\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 2s 83us/step - loss: 0.3233 - acc: 0.9028\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.3077 - acc: 0.9068\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.2988 - acc: 0.9102\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.2899 - acc: 0.9113\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.2806 - acc: 0.9167\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.2739 - acc: 0.9182\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 2s 83us/step - loss: 0.2693 - acc: 0.9192\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.2585 - acc: 0.9232\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.2547 - acc: 0.9230\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.2487 - acc: 0.9253\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.2410 - acc: 0.9276\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.2346 - acc: 0.9308\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.2316 - acc: 0.9308\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.2248 - acc: 0.9325\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.2198 - acc: 0.9349\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 3s 90us/step - loss: 0.2140 - acc: 0.9368\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 2s 83us/step - loss: 0.2089 - acc: 0.9371\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.2061 - acc: 0.9392\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 3s 85us/step - loss: 0.2010 - acc: 0.9383\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 3s 85us/step - loss: 0.1984 - acc: 0.9412\n",
      "30000/30000 [==============================] - 5s 181us/step\n",
      "30000/30000 [==============================] - 1s 40us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.4, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd, total= 1.5min\n",
      "[CV] activation=relu, batch_size=200, dropout=0.4, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 12s 385us/step - loss: 2.0932 - acc: 0.4029\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.9669 - acc: 0.7713\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.5485 - acc: 0.8422\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.4618 - acc: 0.8629\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.4218 - acc: 0.8743\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.3957 - acc: 0.8807\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.3762 - acc: 0.8872\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.3594 - acc: 0.8938\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.3457 - acc: 0.8971\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.3322 - acc: 0.9019\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.3234 - acc: 0.9050\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.3110 - acc: 0.9076\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.2975 - acc: 0.9115\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.2929 - acc: 0.9137\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.2841 - acc: 0.9161\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.2767 - acc: 0.9200\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.2668 - acc: 0.9202\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.2581 - acc: 0.9230\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.2511 - acc: 0.9259\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.2422 - acc: 0.9284\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.2369 - acc: 0.9302\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.2337 - acc: 0.9304\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.2243 - acc: 0.9341\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 2s 83us/step - loss: 0.2206 - acc: 0.9337\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 2s 83us/step - loss: 0.2145 - acc: 0.9362\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.2092 - acc: 0.9390\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.2055 - acc: 0.9385\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.1996 - acc: 0.9403\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 3s 85us/step - loss: 0.1956 - acc: 0.9425\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 3s 85us/step - loss: 0.1906 - acc: 0.9444\n",
      "30000/30000 [==============================] - 6s 190us/step\n",
      "30000/30000 [==============================] - 1s 46us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.4, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd, total= 1.4min\n",
      "[CV] activation=relu, batch_size=200, dropout=0.4, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 13s 419us/step - loss: 0.4081 - acc: 0.8859\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 3s 92us/step - loss: 0.1528 - acc: 0.9557\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 3s 94us/step - loss: 0.1083 - acc: 0.9676\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 3s 96us/step - loss: 0.0848 - acc: 0.9742\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 3s 92us/step - loss: 0.0715 - acc: 0.9778\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 3s 93us/step - loss: 0.0608 - acc: 0.9817\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 3s 90us/step - loss: 0.0538 - acc: 0.9831\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 3s 88us/step - loss: 0.0489 - acc: 0.9847\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 3s 94us/step - loss: 0.0409 - acc: 0.9869\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 3s 92us/step - loss: 0.0378 - acc: 0.9876\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 3s 91us/step - loss: 0.0327 - acc: 0.9889\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 3s 92us/step - loss: 0.0290 - acc: 0.9903\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 3s 90us/step - loss: 0.0261 - acc: 0.9914\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 3s 92us/step - loss: 0.0257 - acc: 0.9916\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 3s 91us/step - loss: 0.0214 - acc: 0.9934\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 3s 90us/step - loss: 0.0197 - acc: 0.9940\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 3s 89us/step - loss: 0.0194 - acc: 0.9936\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 3s 91us/step - loss: 0.0166 - acc: 0.9947\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 3s 89us/step - loss: 0.0156 - acc: 0.9948\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.0142 - acc: 0.9958\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 3s 86us/step - loss: 0.0142 - acc: 0.9949\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 3s 85us/step - loss: 0.0112 - acc: 0.9966\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 3s 88us/step - loss: 0.0108 - acc: 0.9965\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.0124 - acc: 0.9958\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.0109 - acc: 0.9967\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.0106 - acc: 0.9970\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.0096 - acc: 0.9962\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.0096 - acc: 0.9969\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.0070 - acc: 0.9979\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.0068 - acc: 0.9978\n",
      "30000/30000 [==============================] - 5s 162us/step\n",
      "30000/30000 [==============================] - 1s 34us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.4, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=adam, total= 1.6min\n",
      "[CV] activation=relu, batch_size=200, dropout=0.4, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 11s 373us/step - loss: 0.4108 - acc: 0.8819\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.1510 - acc: 0.9566\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 3s 95us/step - loss: 0.1031 - acc: 0.9690\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 3s 94us/step - loss: 0.0816 - acc: 0.9756\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 3s 93us/step - loss: 0.0673 - acc: 0.9788\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 3s 95us/step - loss: 0.0574 - acc: 0.9827\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 3s 94us/step - loss: 0.0497 - acc: 0.9845\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 3s 94us/step - loss: 0.0419 - acc: 0.9872\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 3s 95us/step - loss: 0.0397 - acc: 0.9871\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 3s 94us/step - loss: 0.0319 - acc: 0.9901\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 3s 93us/step - loss: 0.0292 - acc: 0.9903\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 3s 96us/step - loss: 0.0265 - acc: 0.9914\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 3s 94us/step - loss: 0.0239 - acc: 0.9928\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 3s 96us/step - loss: 0.0203 - acc: 0.9941\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 3s 95us/step - loss: 0.0187 - acc: 0.9937\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 3s 92us/step - loss: 0.0178 - acc: 0.9946\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 3s 93us/step - loss: 0.0150 - acc: 0.9956\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 3s 95us/step - loss: 0.0134 - acc: 0.9961\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 3s 91us/step - loss: 0.0139 - acc: 0.9959\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 3s 92us/step - loss: 0.0117 - acc: 0.9965\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 3s 93us/step - loss: 0.0123 - acc: 0.9957\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 3s 91us/step - loss: 0.0107 - acc: 0.9965\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 3s 93us/step - loss: 0.0104 - acc: 0.9970\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 3s 93us/step - loss: 0.0094 - acc: 0.9967\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 3s 92us/step - loss: 0.0082 - acc: 0.9975\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 3s 93us/step - loss: 0.0076 - acc: 0.9976\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 3s 92us/step - loss: 0.0066 - acc: 0.9978\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 3s 90us/step - loss: 0.0079 - acc: 0.9974\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 3s 92us/step - loss: 0.0070 - acc: 0.9977\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 3s 92us/step - loss: 0.0062 - acc: 0.9980\n",
      "30000/30000 [==============================] - 6s 192us/step\n",
      "30000/30000 [==============================] - 2s 55us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.4, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=adam, total= 1.6min\n",
      "[CV] activation=relu, batch_size=200, dropout=0.4, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 11s 375us/step - loss: 1.7564 - acc: 0.4876\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.6841 - acc: 0.8066\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.4965 - acc: 0.8510\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.4309 - acc: 0.8695\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.4000 - acc: 0.8786\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.3733 - acc: 0.8864\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.3553 - acc: 0.8937\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.3401 - acc: 0.8961\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.3216 - acc: 0.9039\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.3101 - acc: 0.9064\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.2968 - acc: 0.9126\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.2880 - acc: 0.9138\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.2760 - acc: 0.9177\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.2664 - acc: 0.9204\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.2611 - acc: 0.9226\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.2498 - acc: 0.9256\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.2431 - acc: 0.9277\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.2337 - acc: 0.9304\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.2252 - acc: 0.9328\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.2211 - acc: 0.9352\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.2161 - acc: 0.9361\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 2s 83us/step - loss: 0.2102 - acc: 0.9373\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.2032 - acc: 0.9396\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.1950 - acc: 0.9423\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.1899 - acc: 0.9437\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.1867 - acc: 0.9446\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.1837 - acc: 0.9463\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.1793 - acc: 0.9465\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.1730 - acc: 0.9498\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.1673 - acc: 0.9508\n",
      "30000/30000 [==============================] - 5s 173us/step\n",
      "30000/30000 [==============================] - 1s 35us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.4, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd, total= 1.3min\n",
      "[CV] activation=relu, batch_size=200, dropout=0.4, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 11s 373us/step - loss: 1.7714 - acc: 0.4961\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.6737 - acc: 0.8127\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.4917 - acc: 0.8542\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.4343 - acc: 0.8691\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.4001 - acc: 0.8804\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.3770 - acc: 0.8877\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.3525 - acc: 0.8957\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.3386 - acc: 0.8986\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.3188 - acc: 0.9053\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.3069 - acc: 0.9070\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.2931 - acc: 0.9144\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.2821 - acc: 0.9164\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.2696 - acc: 0.9215\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.2579 - acc: 0.9237\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.2468 - acc: 0.9262\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.2371 - acc: 0.9306\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.2306 - acc: 0.9324\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.2212 - acc: 0.9348\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.2124 - acc: 0.9371\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.2072 - acc: 0.9387\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.2003 - acc: 0.9416\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.1928 - acc: 0.9434\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.1882 - acc: 0.9444\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.1824 - acc: 0.9464\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.1764 - acc: 0.9484\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.1690 - acc: 0.9503\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.1641 - acc: 0.9514\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.1605 - acc: 0.9534\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.1577 - acc: 0.9543\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.1540 - acc: 0.9551\n",
      "30000/30000 [==============================] - 5s 166us/step\n",
      "30000/30000 [==============================] - 1s 33us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.4, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd, total= 1.3min\n",
      "[CV] activation=relu, batch_size=200, dropout=0.4, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 11s 381us/step - loss: 0.3915 - acc: 0.8836\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.1280 - acc: 0.9614\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.0895 - acc: 0.9732\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.0709 - acc: 0.9782\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.0590 - acc: 0.9816\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 2s 83us/step - loss: 0.0503 - acc: 0.9837\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.0415 - acc: 0.9863\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.0400 - acc: 0.9872\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.0351 - acc: 0.9886\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.0306 - acc: 0.9901\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.0254 - acc: 0.9914\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.0229 - acc: 0.9919\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.0200 - acc: 0.9934\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.0196 - acc: 0.9938\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.0155 - acc: 0.9950\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.0161 - acc: 0.9949\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.0161 - acc: 0.9948\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.0131 - acc: 0.9961\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.0129 - acc: 0.9955\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.0111 - acc: 0.9967\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.0111 - acc: 0.9962\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.0089 - acc: 0.9969\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.0090 - acc: 0.9975\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.0090 - acc: 0.9972\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.0077 - acc: 0.9974\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.0077 - acc: 0.9975\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.0080 - acc: 0.9976\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.0068 - acc: 0.9981\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.0061 - acc: 0.9984\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 3s 86us/step - loss: 0.0068 - acc: 0.9982\n",
      "30000/30000 [==============================] - 5s 177us/step\n",
      "30000/30000 [==============================] - 1s 32us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.4, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=adam, total= 1.4min\n",
      "[CV] activation=relu, batch_size=200, dropout=0.4, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 12s 400us/step - loss: 0.3849 - acc: 0.8874\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.1223 - acc: 0.9647\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.0844 - acc: 0.9760\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.0654 - acc: 0.9800\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.0548 - acc: 0.9834\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.0478 - acc: 0.9850\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.0415 - acc: 0.9870\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.0364 - acc: 0.9883\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.0300 - acc: 0.9903\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.0266 - acc: 0.9911\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.0256 - acc: 0.9913\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.0219 - acc: 0.9929\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.0197 - acc: 0.9935\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.0192 - acc: 0.9938\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.0151 - acc: 0.9952\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.0140 - acc: 0.9955\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.0152 - acc: 0.9947\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.0133 - acc: 0.9954\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.0106 - acc: 0.9965\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.0103 - acc: 0.9964\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.0094 - acc: 0.9970\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.0080 - acc: 0.9972\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.0090 - acc: 0.9971\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.0067 - acc: 0.9979\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.0069 - acc: 0.9979\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.0062 - acc: 0.9979\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.0071 - acc: 0.9975\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.0065 - acc: 0.9981\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.0065 - acc: 0.9979\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.0055 - acc: 0.9980\n",
      "30000/30000 [==============================] - 5s 164us/step\n",
      "30000/30000 [==============================] - 1s 32us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.4, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=adam, total= 1.4min\n",
      "[CV] activation=relu, batch_size=200, dropout=0.5, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 11s 383us/step - loss: 2.0788 - acc: 0.3837\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.9773 - acc: 0.7577\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.5854 - acc: 0.8273\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.4945 - acc: 0.8510\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.4534 - acc: 0.8621\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.4204 - acc: 0.8733\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.3981 - acc: 0.8790\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.3800 - acc: 0.8858\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 3s 85us/step - loss: 0.3672 - acc: 0.8882\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.3532 - acc: 0.8945\n",
      "30000/30000 [==============================] - 5s 178us/step\n",
      "30000/30000 [==============================] - 1s 36us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.5, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd, total=  39.4s\n",
      "[CV] activation=relu, batch_size=200, dropout=0.5, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 12s 391us/step - loss: 1.8782 - acc: 0.4670\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.7809 - acc: 0.7881\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.5344 - acc: 0.8411\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.4673 - acc: 0.8573\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.4354 - acc: 0.8673\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.4122 - acc: 0.8754\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.3900 - acc: 0.8819\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 2s 83us/step - loss: 0.3771 - acc: 0.8862\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.3666 - acc: 0.8912\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.3535 - acc: 0.8957\n",
      "30000/30000 [==============================] - 6s 190us/step\n",
      "30000/30000 [==============================] - 1s 41us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.5, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd, total=  39.0s\n",
      "[CV] activation=relu, batch_size=200, dropout=0.5, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 13s 425us/step - loss: 0.4217 - acc: 0.8792\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 3s 91us/step - loss: 0.1663 - acc: 0.9506\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 3s 85us/step - loss: 0.1185 - acc: 0.9654\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 3s 93us/step - loss: 0.0991 - acc: 0.9696\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 3s 90us/step - loss: 0.0838 - acc: 0.9745\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 3s 88us/step - loss: 0.0733 - acc: 0.9769\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 3s 92us/step - loss: 0.0659 - acc: 0.9796\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 3s 88us/step - loss: 0.0578 - acc: 0.9815\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.0519 - acc: 0.9831\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 3s 89us/step - loss: 0.0461 - acc: 0.9854\n",
      "30000/30000 [==============================] - 6s 185us/step\n",
      "30000/30000 [==============================] - 1s 39us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.5, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=adam, total=  43.1s\n",
      "[CV] activation=relu, batch_size=200, dropout=0.5, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 11s 382us/step - loss: 0.4235 - acc: 0.8756\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.1616 - acc: 0.9522\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.1126 - acc: 0.9655\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.0902 - acc: 0.9731\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.0747 - acc: 0.9763\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.0670 - acc: 0.9798\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 3s 89us/step - loss: 0.0564 - acc: 0.9820\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 3s 89us/step - loss: 0.0505 - acc: 0.9838\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 3s 100us/step - loss: 0.0455 - acc: 0.9854\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 3s 95us/step - loss: 0.0415 - acc: 0.9869\n",
      "30000/30000 [==============================] - 6s 201us/step\n",
      "30000/30000 [==============================] - 1s 45us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.5, epochs=10, filter_size=(3, 3), no_filters=32, optimizer_algo=adam, total=  41.1s\n",
      "[CV] activation=relu, batch_size=200, dropout=0.5, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 13s 437us/step - loss: 1.8839 - acc: 0.4468\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.7677 - acc: 0.7891\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.5306 - acc: 0.8405\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.4624 - acc: 0.8598\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 3s 83us/step - loss: 0.4245 - acc: 0.8719\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 3s 85us/step - loss: 0.3940 - acc: 0.8809\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 3s 86us/step - loss: 0.3713 - acc: 0.8884\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.3520 - acc: 0.8940\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.3350 - acc: 0.8987\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.3216 - acc: 0.9046\n",
      "30000/30000 [==============================] - 6s 207us/step\n",
      "30000/30000 [==============================] - 1s 47us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.5, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd, total=  42.5s\n",
      "[CV] activation=relu, batch_size=200, dropout=0.5, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 12s 415us/step - loss: 1.8714 - acc: 0.4684\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.7833 - acc: 0.7816\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.5408 - acc: 0.8378\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.4695 - acc: 0.8572\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.4348 - acc: 0.8679\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.4061 - acc: 0.8777\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.3832 - acc: 0.8835\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.3628 - acc: 0.8921\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.3461 - acc: 0.8955\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.3338 - acc: 0.9007\n",
      "30000/30000 [==============================] - 6s 187us/step\n",
      "30000/30000 [==============================] - 1s 46us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.5, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd, total=  37.0s\n",
      "[CV] activation=relu, batch_size=200, dropout=0.5, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 13s 439us/step - loss: 0.4023 - acc: 0.8799\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 3s 86us/step - loss: 0.1364 - acc: 0.9586\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 3s 86us/step - loss: 0.0990 - acc: 0.9700\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 3s 86us/step - loss: 0.0813 - acc: 0.9745\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 3s 85us/step - loss: 0.0717 - acc: 0.9771\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 3s 85us/step - loss: 0.0617 - acc: 0.9801\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 3s 85us/step - loss: 0.0532 - acc: 0.9829\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 2s 83us/step - loss: 0.0479 - acc: 0.9841\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.0419 - acc: 0.9861\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 3s 89us/step - loss: 0.0373 - acc: 0.9876\n",
      "30000/30000 [==============================] - 6s 197us/step\n",
      "30000/30000 [==============================] - 1s 45us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.5, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=adam, total=  43.0s\n",
      "[CV] activation=relu, batch_size=200, dropout=0.5, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 13s 448us/step - loss: 0.4161 - acc: 0.8802\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 3s 91us/step - loss: 0.1366 - acc: 0.9593\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.0949 - acc: 0.9717\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 3s 85us/step - loss: 0.0762 - acc: 0.9768\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.0630 - acc: 0.9809\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.0519 - acc: 0.9843\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.0452 - acc: 0.9853\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.0412 - acc: 0.9866\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.0379 - acc: 0.9880\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.0330 - acc: 0.9893\n",
      "30000/30000 [==============================] - 6s 190us/step\n",
      "30000/30000 [==============================] - 1s 35us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.5, epochs=10, filter_size=(5, 5), no_filters=32, optimizer_algo=adam, total=  42.8s\n",
      "[CV] activation=relu, batch_size=200, dropout=0.5, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 13s 443us/step - loss: 2.0085 - acc: 0.4164\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 3s 89us/step - loss: 0.8704 - acc: 0.7717\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 3s 88us/step - loss: 0.5423 - acc: 0.8409\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 3s 91us/step - loss: 0.4685 - acc: 0.8597\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 3s 91us/step - loss: 0.4251 - acc: 0.8707\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 3s 89us/step - loss: 0.4014 - acc: 0.8779\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 3s 88us/step - loss: 0.3836 - acc: 0.8840\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.3646 - acc: 0.8891\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 3s 85us/step - loss: 0.3510 - acc: 0.8938\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 3s 86us/step - loss: 0.3377 - acc: 0.8972\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 3s 86us/step - loss: 0.3290 - acc: 0.9025\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 3s 88us/step - loss: 0.3201 - acc: 0.9049\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.3083 - acc: 0.9081\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 3s 88us/step - loss: 0.2983 - acc: 0.9104\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.2929 - acc: 0.9114\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 3s 88us/step - loss: 0.2847 - acc: 0.9138\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.2789 - acc: 0.9171\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.2713 - acc: 0.9188\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.2679 - acc: 0.9203\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 3s 86us/step - loss: 0.2585 - acc: 0.9211\n",
      "30000/30000 [==============================] - 6s 206us/step\n",
      "30000/30000 [==============================] - 1s 46us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.5, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd, total= 1.2min\n",
      "[CV] activation=relu, batch_size=200, dropout=0.5, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 13s 425us/step - loss: 1.8356 - acc: 0.4846\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.7756 - acc: 0.7859\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.5377 - acc: 0.8405\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.4695 - acc: 0.8587\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.4337 - acc: 0.8705\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.4121 - acc: 0.8767\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.3986 - acc: 0.8817\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.3784 - acc: 0.8874\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.3670 - acc: 0.8904\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.3532 - acc: 0.8938\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.3455 - acc: 0.8979\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.3358 - acc: 0.8988\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.3250 - acc: 0.9052\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.3167 - acc: 0.9065\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.3070 - acc: 0.9088\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.3011 - acc: 0.9104\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.2920 - acc: 0.9138\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.2875 - acc: 0.9162\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.2784 - acc: 0.9182\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.2719 - acc: 0.9190\n",
      "30000/30000 [==============================] - 5s 181us/step\n",
      "30000/30000 [==============================] - 1s 34us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.5, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd, total= 1.0min\n",
      "[CV] activation=relu, batch_size=200, dropout=0.5, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 12s 415us/step - loss: 0.4344 - acc: 0.8744\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 3s 94us/step - loss: 0.1617 - acc: 0.9522\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 3s 93us/step - loss: 0.1159 - acc: 0.9656\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 3s 95us/step - loss: 0.0926 - acc: 0.9726\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 3s 92us/step - loss: 0.0795 - acc: 0.9755\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 3s 93us/step - loss: 0.0693 - acc: 0.9777\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 3s 91us/step - loss: 0.0621 - acc: 0.9807\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 3s 92us/step - loss: 0.0531 - acc: 0.9830\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 3s 91us/step - loss: 0.0469 - acc: 0.9856\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 3s 91us/step - loss: 0.0434 - acc: 0.9859\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 3s 93us/step - loss: 0.0403 - acc: 0.9873\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 3s 92us/step - loss: 0.0353 - acc: 0.9887\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 3s 94us/step - loss: 0.0319 - acc: 0.9894\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 3s 91us/step - loss: 0.0305 - acc: 0.9901\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 3s 92us/step - loss: 0.0272 - acc: 0.9911\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 3s 92us/step - loss: 0.0239 - acc: 0.9925\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 3s 92us/step - loss: 0.0230 - acc: 0.9921\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 3s 98us/step - loss: 0.0207 - acc: 0.9931\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 3s 97us/step - loss: 0.0201 - acc: 0.9933\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 3s 96us/step - loss: 0.0176 - acc: 0.9941\n",
      "30000/30000 [==============================] - 6s 215us/step\n",
      "30000/30000 [==============================] - 1s 45us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.5, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=adam, total= 1.2min\n",
      "[CV] activation=relu, batch_size=200, dropout=0.5, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 13s 442us/step - loss: 0.4455 - acc: 0.8708\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 3s 88us/step - loss: 0.1734 - acc: 0.9480\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.1195 - acc: 0.9644\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 2s 83us/step - loss: 0.0941 - acc: 0.9718\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.0786 - acc: 0.9764\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.0677 - acc: 0.9789\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.0596 - acc: 0.9806\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.0542 - acc: 0.9827\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.0476 - acc: 0.9856\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.0437 - acc: 0.9869\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.0406 - acc: 0.9869\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.0333 - acc: 0.9896\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.0331 - acc: 0.9897\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.0300 - acc: 0.9902\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.0245 - acc: 0.9924\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 3s 102us/step - loss: 0.0250 - acc: 0.9919\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 3s 97us/step - loss: 0.0242 - acc: 0.9920\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 3s 96us/step - loss: 0.0215 - acc: 0.9928\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 3s 96us/step - loss: 0.0191 - acc: 0.9940\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 3s 97us/step - loss: 0.0195 - acc: 0.9936\n",
      "30000/30000 [==============================] - 7s 223us/step\n",
      "30000/30000 [==============================] - 1s 49us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.5, epochs=20, filter_size=(3, 3), no_filters=32, optimizer_algo=adam, total= 1.1min\n",
      "[CV] activation=relu, batch_size=200, dropout=0.5, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 14s 463us/step - loss: 1.7935 - acc: 0.4977\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.7148 - acc: 0.8003\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 2s 83us/step - loss: 0.5125 - acc: 0.8464\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 2s 83us/step - loss: 0.4465 - acc: 0.8631\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.4118 - acc: 0.8763\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 3s 85us/step - loss: 0.3844 - acc: 0.8841\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 3s 89us/step - loss: 0.3646 - acc: 0.8905\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 3s 88us/step - loss: 0.3468 - acc: 0.8949\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 3s 91us/step - loss: 0.3287 - acc: 0.9031\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 3s 91us/step - loss: 0.3187 - acc: 0.9047\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 3s 88us/step - loss: 0.3009 - acc: 0.9091\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.2890 - acc: 0.9137\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.2782 - acc: 0.9171\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.2669 - acc: 0.9218\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.2598 - acc: 0.9235\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.2487 - acc: 0.9267\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.2411 - acc: 0.9283\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.2311 - acc: 0.9315\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.2255 - acc: 0.9331\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.2157 - acc: 0.9362\n",
      "30000/30000 [==============================] - 5s 183us/step\n",
      "30000/30000 [==============================] - 1s 33us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.5, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd, total= 1.1min\n",
      "[CV] activation=relu, batch_size=200, dropout=0.5, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 12s 416us/step - loss: 1.8948 - acc: 0.4244\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.7902 - acc: 0.7775\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.5432 - acc: 0.8370\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 2s 83us/step - loss: 0.4756 - acc: 0.8566\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.4406 - acc: 0.8668\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.4155 - acc: 0.8779\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.3937 - acc: 0.8811\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.3772 - acc: 0.8866\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 3s 91us/step - loss: 0.3560 - acc: 0.8931\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 3s 89us/step - loss: 0.3459 - acc: 0.8982\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 3s 92us/step - loss: 0.3300 - acc: 0.9010\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 3s 88us/step - loss: 0.3186 - acc: 0.9074\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.3039 - acc: 0.9100\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.2939 - acc: 0.9130\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.2809 - acc: 0.9174\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.2729 - acc: 0.9196\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.2604 - acc: 0.9238\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 3s 86us/step - loss: 0.2537 - acc: 0.9259\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 2s 83us/step - loss: 0.2454 - acc: 0.9299\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.2399 - acc: 0.9289\n",
      "30000/30000 [==============================] - 6s 215us/step\n",
      "30000/30000 [==============================] - 1s 45us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.5, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd, total= 1.1min\n",
      "[CV] activation=relu, batch_size=200, dropout=0.5, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 14s 460us/step - loss: 0.3758 - acc: 0.8926\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.1234 - acc: 0.9634\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.0894 - acc: 0.9729\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.0714 - acc: 0.9773\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.0621 - acc: 0.9807\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.0538 - acc: 0.9825\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.0482 - acc: 0.9847\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.0408 - acc: 0.9869\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.0373 - acc: 0.9880\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.0325 - acc: 0.9894\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.0312 - acc: 0.9896\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.0259 - acc: 0.9910\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.0244 - acc: 0.9913\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 3s 92us/step - loss: 0.0248 - acc: 0.9918\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 3s 91us/step - loss: 0.0221 - acc: 0.9928\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 3s 89us/step - loss: 0.0184 - acc: 0.9942\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 3s 92us/step - loss: 0.0191 - acc: 0.9934\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 3s 92us/step - loss: 0.0169 - acc: 0.9942\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 3s 89us/step - loss: 0.0150 - acc: 0.9951\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 3s 91us/step - loss: 0.0158 - acc: 0.9951\n",
      "30000/30000 [==============================] - 7s 225us/step\n",
      "30000/30000 [==============================] - 1s 47us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.5, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=adam, total= 1.1min\n",
      "[CV] activation=relu, batch_size=200, dropout=0.5, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 15s 487us/step - loss: 0.3925 - acc: 0.8863\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 3s 89us/step - loss: 0.1320 - acc: 0.9604\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 3s 88us/step - loss: 0.0941 - acc: 0.9717\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 3s 90us/step - loss: 0.0729 - acc: 0.9776\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 3s 89us/step - loss: 0.0614 - acc: 0.9801\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 3s 90us/step - loss: 0.0510 - acc: 0.9840\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 3s 90us/step - loss: 0.0468 - acc: 0.9856\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 3s 94us/step - loss: 0.0403 - acc: 0.9877\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 3s 90us/step - loss: 0.0371 - acc: 0.9877\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.0324 - acc: 0.9899\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 3s 93us/step - loss: 0.0308 - acc: 0.9901\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 2s 83us/step - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.0239 - acc: 0.9918\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.0215 - acc: 0.9930\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.0194 - acc: 0.9930\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 3s 90us/step - loss: 0.0178 - acc: 0.9939\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.0165 - acc: 0.9945\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.0150 - acc: 0.9953\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.0150 - acc: 0.9949\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 3s 83us/step - loss: 0.0123 - acc: 0.9959\n",
      "30000/30000 [==============================] - 6s 192us/step\n",
      "30000/30000 [==============================] - 1s 34us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.5, epochs=20, filter_size=(5, 5), no_filters=32, optimizer_algo=adam, total= 1.2min\n",
      "[CV] activation=relu, batch_size=200, dropout=0.5, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 15s 486us/step - loss: 1.9570 - acc: 0.4161\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 3s 89us/step - loss: 0.8335 - acc: 0.7813\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.5411 - acc: 0.8392\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 3s 88us/step - loss: 0.4609 - acc: 0.8603\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 3s 88us/step - loss: 0.4303 - acc: 0.8684\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 3s 88us/step - loss: 0.4059 - acc: 0.8772\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 3s 88us/step - loss: 0.3855 - acc: 0.8848\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.3699 - acc: 0.8877\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 3s 86us/step - loss: 0.3590 - acc: 0.8915\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.3479 - acc: 0.8949\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 3s 85us/step - loss: 0.3390 - acc: 0.8957\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 3s 86us/step - loss: 0.3247 - acc: 0.9021\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 3s 89us/step - loss: 0.3193 - acc: 0.9043\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.3090 - acc: 0.9055\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.3014 - acc: 0.9083\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.2951 - acc: 0.9097\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.2842 - acc: 0.9140\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.2797 - acc: 0.9153\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.2762 - acc: 0.9155\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 3s 90us/step - loss: 0.2661 - acc: 0.9183\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 3s 94us/step - loss: 0.2612 - acc: 0.9205\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 3s 93us/step - loss: 0.2571 - acc: 0.9224\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 3s 93us/step - loss: 0.2490 - acc: 0.9245\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 3s 96us/step - loss: 0.2471 - acc: 0.9256\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 3s 93us/step - loss: 0.2416 - acc: 0.9263\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.2361 - acc: 0.9283\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.2330 - acc: 0.9291\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.2289 - acc: 0.9306\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.2209 - acc: 0.9331\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.2191 - acc: 0.9342\n",
      "30000/30000 [==============================] - 6s 184us/step\n",
      "30000/30000 [==============================] - 1s 34us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.5, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd, total= 1.6min\n",
      "[CV] activation=relu, batch_size=200, dropout=0.5, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 12s 407us/step - loss: 1.9677 - acc: 0.4244\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.8504 - acc: 0.7770\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.5483 - acc: 0.8376\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 3s 85us/step - loss: 0.4741 - acc: 0.8585\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 2s 83us/step - loss: 0.4383 - acc: 0.8667\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 2s 83us/step - loss: 0.4168 - acc: 0.8753\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.3946 - acc: 0.8819\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 3s 85us/step - loss: 0.3816 - acc: 0.8851\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 3s 85us/step - loss: 0.3718 - acc: 0.8873\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.3599 - acc: 0.8895\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.3448 - acc: 0.8963\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 3s 89us/step - loss: 0.3362 - acc: 0.9002\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 3s 90us/step - loss: 0.3256 - acc: 0.9021\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.3147 - acc: 0.9077\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 3s 86us/step - loss: 0.3070 - acc: 0.9081\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.3022 - acc: 0.9104\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 3s 89us/step - loss: 0.2937 - acc: 0.9141\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.2859 - acc: 0.9122\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 3s 88us/step - loss: 0.2749 - acc: 0.9179\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 3s 90us/step - loss: 0.2715 - acc: 0.9187\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.2632 - acc: 0.9232\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 3s 88us/step - loss: 0.2568 - acc: 0.9239\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 3s 88us/step - loss: 0.2528 - acc: 0.9256\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 3s 91us/step - loss: 0.2471 - acc: 0.9268\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.2400 - acc: 0.9277\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.2350 - acc: 0.9302\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.2296 - acc: 0.9324\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 3s 85us/step - loss: 0.2250 - acc: 0.9333\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.2193 - acc: 0.9348\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.2169 - acc: 0.9359\n",
      "30000/30000 [==============================] - 6s 196us/step\n",
      "30000/30000 [==============================] - 1s 34us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.5, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=sgd, total= 1.5min\n",
      "[CV] activation=relu, batch_size=200, dropout=0.5, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 13s 433us/step - loss: 0.4199 - acc: 0.8790\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.1462 - acc: 0.9573\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.1065 - acc: 0.9682\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 3s 86us/step - loss: 0.0874 - acc: 0.9733\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 3s 93us/step - loss: 0.0750 - acc: 0.9763\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 3s 97us/step - loss: 0.0683 - acc: 0.9782\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 3s 96us/step - loss: 0.0583 - acc: 0.9814\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 3s 94us/step - loss: 0.0529 - acc: 0.9836\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 3s 94us/step - loss: 0.0471 - acc: 0.9846\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 3s 94us/step - loss: 0.0421 - acc: 0.9864\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 3s 94us/step - loss: 0.0383 - acc: 0.9884\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 3s 95us/step - loss: 0.0330 - acc: 0.9900\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 3s 92us/step - loss: 0.0316 - acc: 0.9901\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 3s 94us/step - loss: 0.0290 - acc: 0.9906\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 3s 92us/step - loss: 0.0263 - acc: 0.9914\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 3s 91us/step - loss: 0.0241 - acc: 0.9925\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 3s 92us/step - loss: 0.0234 - acc: 0.9930\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 3s 91us/step - loss: 0.0211 - acc: 0.9938\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 3s 94us/step - loss: 0.0189 - acc: 0.9941\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 3s 93us/step - loss: 0.0193 - acc: 0.9939\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 3s 92us/step - loss: 0.0154 - acc: 0.9948\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 3s 94us/step - loss: 0.0174 - acc: 0.9944\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 3s 93us/step - loss: 0.0138 - acc: 0.9961\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 3s 93us/step - loss: 0.0147 - acc: 0.9950\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 3s 92us/step - loss: 0.0136 - acc: 0.9958\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 3s 92us/step - loss: 0.0140 - acc: 0.9952\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 3s 90us/step - loss: 0.0117 - acc: 0.9964\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 3s 92us/step - loss: 0.0111 - acc: 0.9966\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 3s 89us/step - loss: 0.0121 - acc: 0.9959\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.0114 - acc: 0.9964\n",
      "30000/30000 [==============================] - 6s 194us/step\n",
      "30000/30000 [==============================] - 1s 35us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.5, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=adam, total= 1.7min\n",
      "[CV] activation=relu, batch_size=200, dropout=0.5, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 13s 437us/step - loss: 0.4413 - acc: 0.8759\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 2s 83us/step - loss: 0.1570 - acc: 0.9532\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 2s 83us/step - loss: 0.1103 - acc: 0.9664\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.0901 - acc: 0.9731\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.0740 - acc: 0.9772\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.0652 - acc: 0.9794\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 3s 86us/step - loss: 0.0586 - acc: 0.9819\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 3s 86us/step - loss: 0.0527 - acc: 0.9832\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 2s 83us/step - loss: 0.0455 - acc: 0.9850\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.0413 - acc: 0.9867\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.0379 - acc: 0.9887\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.0339 - acc: 0.9885\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.0303 - acc: 0.9901\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.0289 - acc: 0.9903\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.0251 - acc: 0.9918\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.0211 - acc: 0.9932\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.0215 - acc: 0.9930\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 3s 94us/step - loss: 0.0190 - acc: 0.9933\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 3s 95us/step - loss: 0.0175 - acc: 0.9941\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 3s 94us/step - loss: 0.0165 - acc: 0.9945\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 3s 95us/step - loss: 0.0169 - acc: 0.9942\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 3s 94us/step - loss: 0.0144 - acc: 0.9951\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 3s 94us/step - loss: 0.0134 - acc: 0.9960\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 3s 95us/step - loss: 0.0152 - acc: 0.9950\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 3s 97us/step - loss: 0.0120 - acc: 0.9961\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 3s 96us/step - loss: 0.0105 - acc: 0.9965\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 3s 97us/step - loss: 0.0108 - acc: 0.9966\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 3s 98us/step - loss: 0.0101 - acc: 0.9968\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 3s 98us/step - loss: 0.0128 - acc: 0.9951\n",
      "30000/30000 [==============================] - 7s 230us/step\n",
      "30000/30000 [==============================] - 1s 47us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.5, epochs=30, filter_size=(3, 3), no_filters=32, optimizer_algo=adam, total= 1.6min\n",
      "[CV] activation=relu, batch_size=200, dropout=0.5, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 14s 461us/step - loss: 1.8434 - acc: 0.4566\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.7352 - acc: 0.7931\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.5171 - acc: 0.8447\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.4496 - acc: 0.8651\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.4147 - acc: 0.8747\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.3860 - acc: 0.8827\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.3663 - acc: 0.8889\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.3460 - acc: 0.8939\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.3287 - acc: 0.8999\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.3151 - acc: 0.9069\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.3024 - acc: 0.9088\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.2878 - acc: 0.9157\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.2750 - acc: 0.9184\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.2658 - acc: 0.9209\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.2590 - acc: 0.9244\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.2443 - acc: 0.9285\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.2350 - acc: 0.9315\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.2286 - acc: 0.9333\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.2218 - acc: 0.9351\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.2119 - acc: 0.9382\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.2078 - acc: 0.9391\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.2013 - acc: 0.9416\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 2s 83us/step - loss: 0.1918 - acc: 0.9439\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.1867 - acc: 0.9440\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.1832 - acc: 0.9462\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.1784 - acc: 0.9474\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.1733 - acc: 0.9485\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 3s 83us/step - loss: 0.1686 - acc: 0.9501\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 3s 86us/step - loss: 0.1666 - acc: 0.9518\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.1598 - acc: 0.9534\n",
      "30000/30000 [==============================] - 7s 233us/step\n",
      "30000/30000 [==============================] - 1s 49us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.5, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd, total= 1.5min\n",
      "[CV] activation=relu, batch_size=200, dropout=0.5, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 15s 490us/step - loss: 1.9351 - acc: 0.4139\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 2s 83us/step - loss: 0.7994 - acc: 0.7730\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 3s 86us/step - loss: 0.5472 - acc: 0.8380\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 3s 85us/step - loss: 0.4700 - acc: 0.8586\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.4317 - acc: 0.8699\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.3985 - acc: 0.8800\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.3784 - acc: 0.8861\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.3563 - acc: 0.8924\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 2s 72us/step - loss: 0.3415 - acc: 0.8974\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.3216 - acc: 0.9031\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.3068 - acc: 0.9079\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.2908 - acc: 0.9138\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.2787 - acc: 0.9175\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 2s 67us/step - loss: 0.2682 - acc: 0.9191\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.2530 - acc: 0.9265\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.2449 - acc: 0.9273\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 2s 70us/step - loss: 0.2344 - acc: 0.9300\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.2265 - acc: 0.9346\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 2s 69us/step - loss: 0.2190 - acc: 0.9350\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.2123 - acc: 0.9369\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 2s 68us/step - loss: 0.2046 - acc: 0.9399\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.1966 - acc: 0.9412\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.1906 - acc: 0.9441\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.1847 - acc: 0.9451\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.1801 - acc: 0.9467\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.1743 - acc: 0.9479\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.1679 - acc: 0.9501\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 2s 83us/step - loss: 0.1646 - acc: 0.9510\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.1615 - acc: 0.9526\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.1556 - acc: 0.9544\n",
      "30000/30000 [==============================] - 7s 227us/step\n",
      "30000/30000 [==============================] - 1s 49us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.5, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=sgd, total= 1.5min\n",
      "[CV] activation=relu, batch_size=200, dropout=0.5, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 15s 509us/step - loss: 0.4047 - acc: 0.8826\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 3s 95us/step - loss: 0.1431 - acc: 0.9571\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 3s 94us/step - loss: 0.1023 - acc: 0.9693\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 3s 94us/step - loss: 0.0798 - acc: 0.9765\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 3s 94us/step - loss: 0.0662 - acc: 0.9790\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 3s 94us/step - loss: 0.0577 - acc: 0.9819\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 3s 93us/step - loss: 0.0492 - acc: 0.9836\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 3s 91us/step - loss: 0.0448 - acc: 0.9850\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 3s 91us/step - loss: 0.0391 - acc: 0.9869\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.0340 - acc: 0.9894\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.0295 - acc: 0.9903\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.0296 - acc: 0.9907\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 2s 75us/step - loss: 0.0244 - acc: 0.9919\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.0241 - acc: 0.9921\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 2s 73us/step - loss: 0.0220 - acc: 0.9927\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.0204 - acc: 0.9937\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.0191 - acc: 0.9936\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.0182 - acc: 0.9940\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 2s 77us/step - loss: 0.0163 - acc: 0.9946\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.0146 - acc: 0.9952\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 2s 74us/step - loss: 0.0148 - acc: 0.9952\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 2s 76us/step - loss: 0.0129 - acc: 0.9962\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 3s 93us/step - loss: 0.0119 - acc: 0.9962\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 3s 94us/step - loss: 0.0115 - acc: 0.9964\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 3s 87us/step - loss: 0.0122 - acc: 0.9960\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 3s 94us/step - loss: 0.0113 - acc: 0.9964\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 3s 94us/step - loss: 0.0100 - acc: 0.9965\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 3s 92us/step - loss: 0.0109 - acc: 0.9963\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 3s 93us/step - loss: 0.0095 - acc: 0.9970\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 3s 92us/step - loss: 0.0099 - acc: 0.9965\n",
      "30000/30000 [==============================] - 7s 227us/step\n",
      "30000/30000 [==============================] - 1s 47us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.5, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=adam, total= 1.6min\n",
      "[CV] activation=relu, batch_size=200, dropout=0.5, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=adam \n",
      "Epoch 1/30\n",
      "30000/30000 [==============================] - 15s 489us/step - loss: 0.4040 - acc: 0.8821\n",
      "Epoch 2/30\n",
      "30000/30000 [==============================] - 3s 94us/step - loss: 0.1375 - acc: 0.9598\n",
      "Epoch 3/30\n",
      "30000/30000 [==============================] - 3s 99us/step - loss: 0.0932 - acc: 0.9725\n",
      "Epoch 4/30\n",
      "30000/30000 [==============================] - 3s 98us/step - loss: 0.0780 - acc: 0.9769\n",
      "Epoch 5/30\n",
      "30000/30000 [==============================] - 3s 95us/step - loss: 0.0625 - acc: 0.9803\n",
      "Epoch 6/30\n",
      "30000/30000 [==============================] - 3s 97us/step - loss: 0.0550 - acc: 0.9837\n",
      "Epoch 7/30\n",
      "30000/30000 [==============================] - 3s 95us/step - loss: 0.0462 - acc: 0.9856\n",
      "Epoch 8/30\n",
      "30000/30000 [==============================] - 3s 91us/step - loss: 0.0386 - acc: 0.9875\n",
      "Epoch 9/30\n",
      "30000/30000 [==============================] - 3s 88us/step - loss: 0.0363 - acc: 0.9883\n",
      "Epoch 10/30\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.0332 - acc: 0.9897\n",
      "Epoch 11/30\n",
      "30000/30000 [==============================] - 2s 83us/step - loss: 0.0280 - acc: 0.9908\n",
      "Epoch 12/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.0282 - acc: 0.9905\n",
      "Epoch 13/30\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.0245 - acc: 0.9917\n",
      "Epoch 14/30\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.0235 - acc: 0.9927\n",
      "Epoch 15/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.0202 - acc: 0.9932\n",
      "Epoch 16/30\n",
      "30000/30000 [==============================] - 3s 85us/step - loss: 0.0176 - acc: 0.9943\n",
      "Epoch 17/30\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.0169 - acc: 0.9943\n",
      "Epoch 18/30\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.0151 - acc: 0.9951\n",
      "Epoch 19/30\n",
      "30000/30000 [==============================] - 2s 82us/step - loss: 0.0149 - acc: 0.9950\n",
      "Epoch 20/30\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.0133 - acc: 0.9955\n",
      "Epoch 21/30\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.0137 - acc: 0.9955\n",
      "Epoch 22/30\n",
      "30000/30000 [==============================] - 2s 83us/step - loss: 0.0121 - acc: 0.9959\n",
      "Epoch 23/30\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.0107 - acc: 0.9963\n",
      "Epoch 24/30\n",
      "30000/30000 [==============================] - 2s 79us/step - loss: 0.0100 - acc: 0.9966\n",
      "Epoch 25/30\n",
      "30000/30000 [==============================] - 2s 80us/step - loss: 0.0113 - acc: 0.9959\n",
      "Epoch 26/30\n",
      "30000/30000 [==============================] - 3s 83us/step - loss: 0.0091 - acc: 0.9970\n",
      "Epoch 27/30\n",
      "30000/30000 [==============================] - 2s 83us/step - loss: 0.0088 - acc: 0.9969\n",
      "Epoch 28/30\n",
      "30000/30000 [==============================] - 2s 78us/step - loss: 0.0079 - acc: 0.9971\n",
      "Epoch 29/30\n",
      "30000/30000 [==============================] - 2s 81us/step - loss: 0.0079 - acc: 0.9974\n",
      "Epoch 30/30\n",
      "30000/30000 [==============================] - 3s 84us/step - loss: 0.0069 - acc: 0.9977\n",
      "30000/30000 [==============================] - 6s 202us/step\n",
      "30000/30000 [==============================] - 1s 33us/step\n",
      "[CV]  activation=relu, batch_size=200, dropout=0.5, epochs=30, filter_size=(5, 5), no_filters=32, optimizer_algo=adam, total= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 144 out of 144 | elapsed: 132.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 16s 265us/step - loss: 0.2690 - acc: 0.9227\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.0968 - acc: 0.9705\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.0721 - acc: 0.9772\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.0579 - acc: 0.9818\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.0467 - acc: 0.9850\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.0401 - acc: 0.9872\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.0358 - acc: 0.9888\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.0309 - acc: 0.9898\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.0286 - acc: 0.9905\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.0251 - acc: 0.9916\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.0230 - acc: 0.9920\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.0207 - acc: 0.9930\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.0187 - acc: 0.9939\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.0171 - acc: 0.9939\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.0161 - acc: 0.9947\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.0156 - acc: 0.9946\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.0153 - acc: 0.9947\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.0124 - acc: 0.9958\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.0125 - acc: 0.9957\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.0111 - acc: 0.9962\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.0107 - acc: 0.9966\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.0099 - acc: 0.9964\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.0095 - acc: 0.9969\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.0086 - acc: 0.9968\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.0083 - acc: 0.9973\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.0084 - acc: 0.9972\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.0079 - acc: 0.9972\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.0064 - acc: 0.9979\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.0081 - acc: 0.9972\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.0074 - acc: 0.9976\n"
     ]
    }
   ],
   "source": [
    "grid_search_fit = grid_search_result.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "MiKAPMbatCTn",
    "outputId": "cf5a5819-4b88-4aa0-b37c-206067a79e49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Validation Accuracy Score from CV: 98.78% using {'activation': 'relu', 'batch_size': 200, 'dropout': 0.5, 'epochs': 30, 'filter_size': (5, 5), 'no_filters': 32, 'optimizer_algo': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best Validation Accuracy Score from CV: %.2f%% using %s\" % ((100*grid_search_fit.best_score_), grid_search_fit.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1075
    },
    "colab_type": "code",
    "id": "m1lsoOFZlfHX",
    "outputId": "31bb40d7-4751-478b-9190-b86e2d4cd25c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 20s 331us/step - loss: 0.2686 - acc: 0.9218 - val_loss: 0.0857 - val_acc: 0.9743\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 0.0910 - acc: 0.9721 - val_loss: 0.0555 - val_acc: 0.9820\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.0680 - acc: 0.9789 - val_loss: 0.0401 - val_acc: 0.9870\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.0554 - acc: 0.9821 - val_loss: 0.0365 - val_acc: 0.9880\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0470 - acc: 0.9853 - val_loss: 0.0342 - val_acc: 0.9879\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.0404 - acc: 0.9872 - val_loss: 0.0324 - val_acc: 0.9891\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.0364 - acc: 0.9880 - val_loss: 0.0311 - val_acc: 0.9891\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0324 - acc: 0.9893 - val_loss: 0.0289 - val_acc: 0.9901\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0274 - acc: 0.9908 - val_loss: 0.0285 - val_acc: 0.9909\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0249 - acc: 0.9922 - val_loss: 0.0269 - val_acc: 0.9914\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0229 - acc: 0.9925 - val_loss: 0.0283 - val_acc: 0.9908\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.0212 - acc: 0.9930 - val_loss: 0.0317 - val_acc: 0.9898\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.0186 - acc: 0.9937 - val_loss: 0.0280 - val_acc: 0.9905\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0169 - acc: 0.9940 - val_loss: 0.0291 - val_acc: 0.9911\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.0156 - acc: 0.9951 - val_loss: 0.0276 - val_acc: 0.9911\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0147 - acc: 0.9946 - val_loss: 0.0312 - val_acc: 0.9903\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.0141 - acc: 0.9953 - val_loss: 0.0325 - val_acc: 0.9906\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.0118 - acc: 0.9961 - val_loss: 0.0312 - val_acc: 0.9907\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.0114 - acc: 0.9961 - val_loss: 0.0280 - val_acc: 0.9912\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.0119 - acc: 0.9959 - val_loss: 0.0304 - val_acc: 0.9914\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.0113 - acc: 0.9963 - val_loss: 0.0323 - val_acc: 0.9901\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.0106 - acc: 0.9963 - val_loss: 0.0323 - val_acc: 0.9906\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.0098 - acc: 0.9965 - val_loss: 0.0312 - val_acc: 0.9911\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.0088 - acc: 0.9971 - val_loss: 0.0345 - val_acc: 0.9900\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.0088 - acc: 0.9970 - val_loss: 0.0335 - val_acc: 0.9916\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0078 - acc: 0.9974 - val_loss: 0.0334 - val_acc: 0.9897\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.0077 - acc: 0.9974 - val_loss: 0.0326 - val_acc: 0.9914\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.0075 - acc: 0.9974 - val_loss: 0.0327 - val_acc: 0.9908\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.0067 - acc: 0.9980 - val_loss: 0.0349 - val_acc: 0.9907\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0060 - acc: 0.9981 - val_loss: 0.0298 - val_acc: 0.9915\n",
      "10000/10000 [==============================] - 2s 208us/step\n",
      "CNN Error: 0.85%\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = CNN_model(no_filters = grid_search_fit.best_params_[\"no_filters\"],\\\n",
    "                  filter_size=grid_search_fit.best_params_[\"filter_size\"],\\\n",
    "                  activation = grid_search_fit.best_params_[\"activation\"],\\\n",
    "                  optimizer_algo = grid_search_fit.best_params_[\"optimizer_algo\"],\\\n",
    "                  dropout=grid_search_fit.best_params_[\"dropout\"])\n",
    "# Fit the model \n",
    "fit_model_final = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=grid_search_fit.best_params_[\"epochs\"], batch_size=200, verbose=1)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QaJv_d_Dp7OM"
   },
   "source": [
    "### 2.3.4: Evaluation\n",
    "\n",
    "Evaluate your model.\n",
    "\n",
    "When possible, you should have:\n",
    "  * Loss curves: Plot epoch (# passes over training data) and loss\n",
    "  * Accuracy curves: Plot epoch and accuracy over val/test set\n",
    "  * Final numbers: Report final accuracy numbers for your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IyyNyRn1lhem"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_label = np.argmax(y_pred, axis=1)\n",
    "y_test_label = np.argmax(y_test, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "colab_type": "code",
    "id": "RD0kcdlttD1J",
    "outputId": "f7e8a4ba-67d7-4107-ddc3-cf43fe15638b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFnCAYAAAC/5tBZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7eff7a532ac8>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_context(\"notebook\")\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "plt.plot(range(1,epochs[-1]+1),fit_model_final.history['loss'],label='Training Loss',linewidth=2.0)\n",
    "plt.plot(range(1,epochs[-1]+1),fit_model_final.history['val_loss'],label='Validation Loss',linewidth=2.0)\n",
    "plt.xticks(range(1,epochs[-1]+1,2));\n",
    "plt.legend(loc='best')\n",
    "plt.title('Loss vs Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "colab_type": "code",
    "id": "yByb07JjljSz",
    "outputId": "8acc804b-e69b-447a-b325-8844513938af"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFnCAYAAAC/5tBZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqAMA0EtQ1AEA6CX+AzNH0Icwj67BAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7eff7a481630>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_context(\"notebook\")\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "plt.plot(range(1,epochs[-1]+1),fit_model_final.history['acc'],label='Training Accuracy',linewidth=2.0)\n",
    "plt.plot(range(1,epochs[-1]+1),fit_model_final.history['val_acc'],label='Validation Accuracy',linewidth=2.0)\n",
    "plt.xticks(range(1,epochs[-1]+1,2));\n",
    "plt.legend(loc='best')\n",
    "plt.title('Accuracy vs Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 846
    },
    "colab_type": "code",
    "id": "NiLNTBwdllE6",
    "outputId": "7ab3a96f-85bc-44fd-fa61-1963118a4539"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 99.15%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99       980\n",
      "          1       1.00      1.00      1.00      1135\n",
      "          2       0.99      0.99      0.99      1032\n",
      "          3       0.99      0.99      0.99      1010\n",
      "          4       0.99      0.99      0.99       982\n",
      "          5       0.99      0.99      0.99       892\n",
      "          6       0.99      0.99      0.99       958\n",
      "          7       0.99      0.99      0.99      1028\n",
      "          8       0.99      0.99      0.99       974\n",
      "          9       0.99      0.98      0.98      1009\n",
      "\n",
      "avg / total       0.99      0.99      0.99     10000\n",
      "\n",
      "Confidence Matrix:\n",
      " [[ 976    0    0    0    0    0    2    1    1    0]\n",
      " [   1 1131    1    0    0    0    2    0    0    0]\n",
      " [   0    0 1024    0    1    0    0    5    2    0]\n",
      " [   0    0    0 1004    0    4    0    0    1    1]\n",
      " [   0    0    0    0  976    0    1    0    0    5]\n",
      " [   1    0    0    6    0  884    1    0    0    0]\n",
      " [   3    2    0    0    2    1  947    0    3    0]\n",
      " [   0    1    4    0    0    0    0 1019    1    3]\n",
      " [   2    0    1    1    0    2    0    1  964    3]\n",
      " [   0    0    0    0    8    3    0    4    4  990]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdUAAAFnCAYAAADwu9OJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3XlYVfXa//HPBkQTUQHZKo5NasfI\nMK0cEMfA7CjmhAjmdXw6mpia5ESmPkfj5FQ5oFlWkuWRRyy1UqE6aaZEGT5m5djgcURQFBUnZP/+\n6Nd+IhVpu5cLlu9X174u9tp7r/teEtzc3/Vd32VzOBwOAQCAG+ZhdgIAAFgFRRUAADehqAIA4CYU\nVQAA3ISiCgCAm1BUAQBwE4oq/rTGjRvr6NGjxba99957GjRo0A3td+3atTpz5swN7cMVsbGxatu2\nrSIiIhQeHq5HH31UycnJN7zfrVu3qmPHjpKk2bNn61//+leJ79+0aZMOHz5c6vcb6cCBA+rSpYt6\n9Ohx1de3b9+uQYMG6ZFHHlHnzp31xBNPKCsry/l648aNlZCQUOwzmZmZio2NdX7duHFjrVq1qth7\n5s2bp3nz5rn5aICbh6KKMmPu3LmmFFVJGjNmjNavX6+0tDQlJycrOTlZn3/+udv2Hx8fr/79+5f4\nniVLljiLamneb6RvvvlGgYGBWr169RWv7dy5U3//+98VExOj9PR0ffLJJxo4cKCefPJJ7d271/m+\nr7/+Wj/88MM1Y9SqVUtz585VQUGBIccAmIGiCrdzOByaP3++wsPD1aFDB02bNk2XL1+WJP3000/q\n37+/unbtqi5duujDDz+UJE2YMEE///yzYmNjtXXrVo0fP14vv/yyYmNj9fDDD+ull17SihUr9Ne/\n/lUdO3bUt99+K0nKzc3V4MGDFRERoY4dO+qtt95y5tG4cWO9/fbb6tGjh1q1alXqzi8wMFARERHa\nvHmzJKljx47O4zl8+LCOHj2qoUOHKjw8XOHh4dq4caPzswsWLFBYWJgiIyO1ZcsW5/bx48drwYIF\nkqTvvvtOjz/+uMLDwxUTE6MDBw7olVde0ZdffqkxY8Zo7dq1xd6/a9cuRUVFKSIiQj169NCmTZsk\n/drt9evXT7Nnz1bXrl3VsWNHffXVV5KkPXv2qF+/furWrZseeeQRvfPOO1c91nXr1umxxx5TRESE\nBg4cqP/85z/atm2bZs2apR9++EHdu3e/4jMLFy5Uv3791LlzZ+e2Tp06af78+QoICHBuGz16tBIT\nE6/571y/fn2FhYXp9ddfL/kbApQjFFW43erVq7V+/Xqlpqbq448/1oEDB5wFbcaMGerQoYPWrVun\nxMREPffcc7p06ZL++c9/SpKWLl2qFi1aSJI+//xzLVq0SG+//bYWL16sEydO6IMPPlB4eLiWLl0q\n6ddf8HXr1tX69euVnJys2bNn68iRI85c9u/fr9WrV+vdd99VYmKi8vLySnUMhYWF8vb2dj7Pzs5W\nWlqagoKCNG7cODVp0kRpaWl67bXXNHbsWOXl5Wnfvn1asmSJVq5cqZUrV2r37t1X3ffo0aM1cuRI\npaWlqXPnzpo6dapGjRqlmjVraubMmXr00Ued7y0qKtLo0aMVExOj9evXa9q0aYqPj3d29D/88IOa\nNWumdevWKTo6WgsXLpQkzZ8/X1FRUfroo4+0fPlybdmyRRcvXiyWx+HDh/X8888rKSlJ69evV/v2\n7TVp0iSFhIRo9OjRuv/++7VmzZor8v/6668VFhZ2xfZWrVrJ39/f+bxr165yOBxav379Nf+dR4wY\nodTU1GLfM6A8o6jCJbGxsYqIiHA+XnrpJedrn332mXr16iVfX195eXmpT58+Sk9Pl/RrJzd48GBJ\n0gMPPKALFy4oJyfnqjFat26typUr6+6771ZRUZE6dOggSWrUqJGOHTsmSZo4caKef/55SVK9evUU\nGBiogwcPOvfRq1cvSdIdd9yh22+/3dnhluTAgQNav369unTp4tzWvn17SVJBQYEyMzOd548bNGig\nBx54QBs3btTXX3+tli1bqkaNGvL09Lxql/fzzz8rLy/PWZRiYmJKPId48OBB5ebmqlu3bpKk4OBg\nBQUFaceOHZIkHx8fZ8fYtGlT5/BxQECA0tLS9P3338vPz08LFiwo9keCJG3evFkPPfSQGjRoIEnq\n06ePMjMzVVhYWOK/z6lTp1SjRo0S3/ObhIQEzZo1SxcuXLjq635+fho8eLBmzpxZqv0BZZ2X2Qmg\nfFq6dKlq1arlfP7ee+85u5rTp0/rjTfeUEpKiiTp8uXLzg5m06ZNWrhwofLy8mSz2eRwOFRUVHTV\nGD4+PpIkm80mDw8PVa5cWZLk4eHh/MyOHTuc3amHh4dycnKK7a9atWrFvs7Pz79qrJkzZ2rhwoVy\nOByqWrWqxo8fr/vuu++K/Zw+fVoOh0NRUVHO1woKCvTwww+roKBAvr6+zu1Vq1a9Ik5eXl6x93h5\necnL69o/hidOnJCvr69sNlux/Z44cUI1atQotq/f/7s8++yzWrRokUaNGqULFy5oyJAhGjBgwBW5\n/D5HX19fORyO63bzfn5+ys7OdhbjkjRt2lQtW7bUW2+9pZCQkKu+Z8CAAVq+fHmxiU5AeUVRhdvZ\n7XZ17NhRMTExxbZfunRJo0aN0iuvvKKwsDBdvHixWOFyxZgxY/TEE0+of//+stlsCg0NLfZ6Xl6e\n6tSpI0k6efJksSL7x/1ca6br7wUEBMjT01MrV650Fv3fLFu2TKdPny4W+4/8/Px08uRJFRUVycPD\nQ5cuXVJ2drbq1q17zXinTp2Sw+FwFtaTJ08WO3d5NT4+Pho9erRGjx6tb7/9Vk8++aRat26t22+/\nvdi+t23b5nx+6tQpeXh4yM/Pr8R9P/TQQ0pPT9eDDz5YbPvKlSvVqFEjBQcHF9v+zDPP6PHHH7/m\nMVaoUEFjx45VYmKi2rVrV+wPCKC8YfgXbtepUyetXr1a586dkyQtX75c77//vs6dO6eCggLde++9\nkqTk5GRVqFDBOfvTy8vrmp3ktRw/flz33nuvbDZbsRi/+eijjyRJP/74o/bv369mzZrd0LF5eXkp\nLCxMy5cvlySdO3dOEyZM0JEjRxQSEqJvvvlGJ06c0OXLl696PrJhw4aqVauWczg8NTVVkyZNcu77\n90VZkurWratatWpp7dq1kqSsrCzl5uZe94+RoUOHOmfiNmrUSFWqVLmiWLVp00Zbt27VgQMHJP36\nfWrTpk2JnbMkPfXUU1qzZo3ef/9957aPP/5Ys2fPVpUqVa54v91u14ABA0oc5u7YsaN8fX2d3y+g\nvKJThdt17txZe/fuVc+ePSX9OsvzhRdeUNWqVfVf//VfioyMVEBAgJ566il17txZQ4cO1YcffqiI\niAhFRUVp2rRppY41cuRIxcXFqXr16oqKilK/fv30/PPPa9myZZIkf39/9ejRQ9nZ2Zo4ceI1O9U/\nY8qUKZo8ebJWrFghSerevbtq166t2rVrKyoqSj179lT16tXVrVs37dmzp9hnbTab5syZozFjxuil\nl15SYGCgc5JWeHi4Ro8erREjRhR7/0svvaTJkydr/vz5uu222zRnzhznUPi1xMTEKD4+XpcuXZIk\nRUdHq2HDhsXeU6tWLU2bNk3Dhg3TpUuXVLduXU2dOvW6x3/33XfrzTff1OzZszV//nx5e3urQYMG\nWrJkSbFO+Pf+9re/Of+9rmXChAmKjIy8bnygLLNxP1VYVePGjbVx48Zi534BwEgM/wIA4CYUVQAA\n3IThXwAA3IROFQAAN6GoAgDgJmX2kpq+Lf5mdgpO7/ybJdQA3Nq8q5a84MiNuK/BlWtJl9a3+zde\n/003UZktqgCAW4OVVtFi+BcAADehUwUAmMpms05/Z50jAQDAZHSqAABTecg651QpqgAAU1lpohJF\nFQBgKg8LnVOlqAIATGWlTtU6fx4AAGAyiioAAG7C8C8AwFQ2Zv+WztmzZ5WbmytJCgwMVOXKlY0M\nBwAoh5iodB07duzQCy+8oPz8fPn5+cnhcOjYsWOqWbOmJk2apMaNGxsRFgBQDllpopIhRTUxMVEv\nvPCC7rzzzmLbv//+e/3jH//Qu+++a0RYAEA55GGhompIz+1wOK4oqJLUtGlTXb582YiQAACYzpBO\ntVmzZho6dKg6d+4sf39/SVJubq7S0tL04IMPGhESAADTGVJUJ0yYoK+//loZGRn69ttvJUl2u13D\nhw9XSEiIESEBAOWUzUJXdxo2+7dly5Zq2bKlUbsHAFgEE5UAAHATK01UoqgCAExlpcUfrDOQDQCA\nySiqAAC4CcO/AABTsUwhAABuwuxfAADchNm/AAC4CbN/AQDAFehUAQCmstJEJescCQAAJiuzneo7\n/55pdgpOLYIfNzuFYrbueM/sFADAbaw0+5dOFQBgKg+bzeXH9ezZs0edO3fWO++8I0k6cuSIYmNj\nFR0drZEjR+rixYuSpDVr1qhXr17q06ePVqxYIUm6dOmS4uPj1b9/f8XExOjAgQPXP5Yb+HcAAOCG\n2W7gv5IUFBRo6tSpatWqlXPb3LlzFR0drWXLlqlBgwZKTU1VQUGBkpKStGTJEi1dulTJyck6efKk\nPvzwQ1WtWlX/+te/NHToUM2ePfu6x0JRBQBYkre3t15//XXZ7XbntszMTHXq1EmS1KFDB2VkZGj7\n9u0KDg6Wr6+vKlWqpObNmysrK0sZGRnq0qWLJKl169bKysq6bswye04VAHBrMOqcqpeXl7y8ipe5\nc+fOydvbW5IUEBCgnJwc5ebmyt/f3/kef3//K7Z7eHjIZrPp4sWLzs9fNaYBxwEAQKmZtaKSw+Fw\ny/bfY/gXAHDLqFy5ss6fPy9Jys7Olt1ul91uV25urvM9x44dc27PycmR9OukJYfDUWKXKlFUAQAm\nM2qi0tW0bt1aaWlpkqT09HSFhoaqWbNm2rFjh/Lz83X27FllZWWpRYsWatOmjdavXy9J+uyzz/TQ\nQw9dd/8M/wIATGXUikrfffedpk+frkOHDsnLy0tpaWmaNWuWxo8fr5SUFAUFBSkyMlIVKlRQfHy8\nBg8eLJvNpri4OPn6+urRRx/Vli1b1L9/f3l7e+vFF1+8bkybozSDxCa4mH/c7BScWPwBwK3Ou2qA\nYfvu1XyQy59dmbXEbXm4A50qAMBUVlpRiaIKADCVle6netMnKuXn59/skACAMuxmTlQy2k0vqsOH\nD7/ZIQEAuCkMGf599913r/ladna2ESEBAOWUlYZ/DSmqS5YsUatWrYqtt/ibwsJCI0ICAGA6Q4pq\nUlKSpk2bpokTJ16x+kRmZqYRIQEA5RSzf6+jUaNGWrRo0RULGUvS+PHjjQgJACinGP4thdtuu+2q\n25s2bWpUSABAOVQWZ/G6iutUAQCmslKnyoL6AAC4CUUVAAA3YfgXAGAqZv8CAOAmVjqnSlEFAJiK\n2b8AALiJlTpVJioBAOAmFFUAANyE4V8AgKmY/QsAgJtY6ZwqRbUUtu54z+wUiunRJs7sFIpZvTnJ\n7BRQXjkcZmfwfyz0i728oVMFAMBNrHRJDROVAABwEzpVAICpPKzTqNKpAgDgLnSqAABTMVEJAAA3\n4ZIaAADcxEqdKudUAQBwEzpVAICpPCx0nSpFFQBgKoZ/AQDAFQwtqo6rrOt59OhRI0MCAMoZD5vN\n5UdZY0hR/fjjj9WhQwe1atVK48aN05kzZ5yvjR071oiQAIByymZz/VHWGFJUX3vtNb3//vvasmWL\nmjdvrsGDB+v06dOSrt69AgBgBYZMVPL09FT16tUlSf369VNAQIAGDx6sV1991VInpAEAN64sDuO6\nypCi2rx5cw0ZMkRz5sxRpUqV1LlzZ1WsWFGDBg3SyZMnjQgJACinrHTrN0OK6tixY5WZmamKFSs6\nt4WGhiokJERr1641IiQAoJyy0gimYdepPvTQQ1dsq1Klivr27WtUSAAATMXiDwAAU3FOFQAAN7FQ\nTWVFJQAA3IVOFQBgKoZ/AQBwEy6pAQDATYzqVM+ePatx48bp1KlTunTpkuLi4hQYGKgpU6ZIkho3\nbqz//u//liQtXrxY69evl81m0/DhwxUWFuZSTIoqAMCS3n//fd1+++2Kj49Xdna2nnjiCQUGBioh\nIUH33Xef4uPjtXHjRt1xxx1au3atli9frjNnzig6Olpt27aVp6fnn47JRCUAgKmMWlDfz8/PuYpf\nfn6+qlevrkOHDum+++6TJHXo0EEZGRnKzMxUaGiovL295e/vrzp16mjfvn0uHQtFFQBgSd26ddPh\nw4fVpUsXxcTEaOzYsapatarz9YCAAOXk5Cg3N1f+/v7O7f7+/srJyXEpJsO/AABTGbVM4erVqxUU\nFKQ33nhDu3btUlxcnHx9fZ2vX+uuaTdyNzWKKgDAVEZNVMrKylLbtm0lSU2aNNGFCxdUWFjofD07\nO1t2u112u10///zzFdtdQVEth1ZvTjI7hWJ6hY4wO4ViVm6aa3YKKC0LXZ8I1xn1v0GDBg20fft2\nhYeH69ChQ/Lx8VGdOnW0detWtWjRQunp6YqNjVXDhg311ltv6emnn1ZeXp6OHTumu+66y6WYFFUA\ngKmM6lT79eunhIQExcTEqLCwUFOmTFFgYKAmTZqkoqIiNWvWTK1bt5Yk9e3bVzExMbLZbJoyZYo8\nPFybckRRBQBYko+Pj+bMmXPF9mXLll2xLTY2VrGxsTcck9m/AAC4CZ0qAMBULFMIAICbGHVJjRko\nqgAAU3lYp6ZSVAEA5rJSp8pEJQAA3ISiCgCAmzD8CwAwFcO/Ljhx4sTNCgUAKEc8bK4/yhpDiuqG\nDRsUHh6uQYMGac+ePerevbtiY2PVsWNHbdy40YiQAIByymazufwoawwZ/l24cKHeeustHT58WEOH\nDtWCBQvUpEkT5ebmaujQoQoLCzMiLACgHCqDtdFlhhRVb29vBQUFKSgoSHa7XU2aNJEk1ahRQxUr\nVjQiJAAApjNk+DcgIEBvvPGGJGn58uWSpKNHjyoxMVG1atUyIiQAoJzysNlcfpQ1hhTVF198UbVr\n1y627fjx4woKClJiYqIRIQEAMJ0hw7+VKlXSo48+Wmxb06ZN1bRpUyPCAQDKMRbUBwDATcrgKK7L\nKKoAAFOVxXOjrmKZQgAA3IROFQBgqrK4iIOrKKoAAFNZqKYy/AsAgLvQqQIATMXwLwAAblIW7zbj\nKoZ/AQBwEzpVAICpGP4FAMBNLFRTKaoAAHNZaUUliipu2MpNc81OoZiYjmPMTsHpnX/PNDsFlFcO\nh9kZwAUUVQCAqax0TpXZvwAAuAmdKgDAVBZqVCmqAABzWWn4l6IKADCVhWoqRRUAYC4rXVLDRCUA\nANyEogoAgJsw/AsAMJWFRn8pqgAAc1lp9u9NGf7NyMi4GWEAAOWQzeb6o6xxe6e6atWqYs8dDocW\nLlyoYcOGSZIiIyPdHRIAUI5ZqVN1e1FNSkpS9erVFRYW5tx24cIFHTx40N2hAAAoU9xeVD/88EMt\nWLBAu3fv1vjx41WnTh1t2rRJw4cPd3coAADKFLcX1YoVK+qZZ57RTz/9pH/84x8KCQlRUVGRu8MA\nACzCQqO/xk1UuuOOO7Ro0SLVqlVLdevWNSoMAKCc87DZXH6UNYZfUhMZGcnkJADANRlZG9esWaPF\nixfLy8tLI0aMUOPGjTV27FhdvnxZgYGBmjlzpry9vbVmzRolJyfLw8NDffv2VZ8+fVyKV+pO9cyZ\nM5Kk3Nxcbd26lSFdAIBb2Gw2lx8lycvLU1JSkpYtW6ZXX31Vn376qebOnavo6GgtW7ZMDRo0UGpq\nqgoKCpSUlKQlS5Zo6dKlSk5O1smTJ106llIV1alTp2rdunU6efKkoqKitHTpUk2ZMsWlgAAA3AwZ\nGRlq1aqVqlSpIrvdrqlTpyozM1OdOnWSJHXo0EEZGRnavn27goOD5evrq0qVKql58+bKyspyKWap\niuoPP/ygPn36aN26derZs6fmzJmj/fv3uxQQAIDfM2rxh4MHD+r8+fMaOnSooqOjlZGRoXPnzsnb\n21uSFBAQoJycHOXm5srf39/5OX9/f+Xk5Lh0LKU6p+pwOCRJGzZs0KhRoyRJFy9edCkgAAA3y8mT\nJzV//nwdPnxYAwcOdNYzScW+/r1rbS+NUnWqDRs2VLdu3XT27Fndc889WrVqlapVq+ZyUAAAfmPU\nOdWAgACFhITIy8tL9evXl4+Pj3x8fHT+/HlJUnZ2tux2u+x2u3Jzc52fO3bsmOx2u0vHUqqiOnbs\nWM2aNUtvvvmmJOmuu+7SiBEjXAoIAMDvGTX827ZtW3355ZcqKipSXl6eCgoK1Lp1a6WlpUmS0tPT\nFRoaqmbNmmnHjh3Kz8/X2bNnlZWVpRYtWrh0LNcd/i0qKtLIkSP19ttvy+FwqKioSHfffbd69+6t\nDz74wKWgAAD8xqi1f2vWrKnw8HD17dtXkjRx4kQFBwdr3LhxSklJUVBQkCIjI1WhQgXFx8dr8ODB\nstlsiouLk6+vr0sxSyyqH374oebNm6f9+/frnnvucW738PBQ27ZtXQoIAMDNEhUVpaioqGLb3nrr\nrSveFxERoYiIiBuOV2JRfeyxx/TYY49p3rx5evrpp284GAAAf1QGF0ZyWYlFdePGjQoLC1OtWrWU\nmpp6xeu9e/c2LDEAwK3hlrn12+7duxUWFnbNi2ApqgAA/J8Si+rf//53SdI///nPm5IMAODWY6FG\ntXSLP4SFhV3Rnnt6eur222/XuHHjdPfddxuSHMqJG7hQ2gjv/Hum2Sk4xXefZnYKxcxeM9HsFFBa\nVqo011EW7zbjqlIV1QEDBujMmTMKDw+Xp6en0tPT5e3trTvvvFNTpkzRu+++a3SeAACLslBNLd3i\nD5s3b9bo0aPVtGlTNWnSRCNGjNDWrVvVpUsXeXgYdktWAADKlVJVxJMnT2rPnj3O57/88osOHz6s\nQ4cOOW8JBwCAK4xaptAMpRr+HT16tIYMGaKCggLZbDZ5enpqwoQJ2rVrl4YNG2Z0jgAACyuDtdFl\npZ6o9NlnnykvL08Oh0N+fn5l8i8EAADMVGJRXbRokYYMGaIxY8ZctYjOmDHDsMQAALcGm4d1mrQS\ni+pf/vIXSVJISIjOnj0rLy8vVatWjS4VAOA2ViopJRbVli1bKi4uTjt37tS9996rM2fOaOfOnWrT\npo0SExNvVo4AAJQLJc7+XbBggWrWrKn09HTNnTtXb775pv7973+rUqVKevnll29WjgAAC7PS7N8S\ni+rWrVs1fvx4eXn9X0N72223afLkyfriiy8MTw4AYH1G3aTcDCUWVU9PT3l7e1+xvUKFCqpatWqp\ngxQWFurQoUMqLCz88xkCACztlulUS0rY09Pzmq9Nm/Z/651u2bJFXbp00ahRo/TII49o06ZNLqQJ\nAEDZV+JEpW3btql9+/ZXbHc4HMrLy7vm53bv3u38OikpSW+//bbq1aunnJwcDR8+XKGhoa5nDACw\nlDLYcLqsxKK6fv16l3b6+w63WrVqqlevniQpMDCw2PlZAACspMQKV6dOHZd2unfvXo0cOVIOh0P7\n9+/XunXr1LVrV7355pvy9fV1aZ8AAIuyUKtqSNs4Z86cYs8bNGgg6ddOdfbs2UaEBACUU2VxwpGr\nDCmqDz744FW3//WvfzUiHACgHLNQTTWmqAIAUFpWWvuXO4wDAOAmFFUAANyE4V8AgKk4pwoAgJsw\n+xcAADexUE2lqAIAzGWlTpWJSgAAuAlFFQAAN2H4FwBgKguN/lJUAQDmstI5VYoqAMBcFjoRSVHF\njbPQX5nuNnvNRLNTKGZwlwSzUyjmjY8TzU4BZYCVOlUL/X0AAIC5KKoAALgJw78AAFNZaPSXogoA\nMJeVzqlSVAEAprJQTaWoAgBMZqGqykQlAADchE4VAGAqmwedKgAA5cL58+fVuXNnvffeezpy5Ihi\nY2MVHR2tkSNH6uLFi5KkNWvWqFevXurTp49WrFjhciyKKgDAVDab64/SWLhwoapVqyZJmjt3rqKj\no7Vs2TI1aNBAqampKigoUFJSkpYsWaKlS5cqOTlZJ0+edOlYblpRPXHixM0KBQAoR2w2m8uP6/nx\nxx+1b98+tW/fXpKUmZmpTp06SZI6dOigjIwMbd++XcHBwfL19VWlSpXUvHlzZWVluXQshhTVjRs3\natKkSZKkjIwMdejQQQMHDlTHjh21YcMGI0ICAMopIzvV6dOna/z48c7n586dk7e3tyQpICBAOTk5\nys3Nlb+/v/M9/v7+ysnJcelYDJmoNHfuXC1atEiSlJSUpLffflv16tVTXl6ehgwZ4vyLAQAAo6xa\ntUr333+/6tWrd9XXHQ7Hn9peGoYU1cLCQvn4+EiSfH19VbduXUlS9erVbyhZAIAFGXSd6oYNG3Tg\nwAFt2LBBR48elbe3typXrqzz58+rUqVKys7Olt1ul91uV25urvNzx44d0/333+9STEOK6uDBgxUZ\nGak2bdqoevXqGjZsmEJCQpSZmak+ffoYERIAUE4ZdUnNK6+84vx63rx5qlOnjrZt26a0tDT16NFD\n6enpCg0NVbNmzTRx4kTl5+fL09NTWVlZSkhw7TaJhhTV7t27q127dtqyZYsOHTokh8OhGjVqKDEx\nUTVr1jQiJAAA1/X0009r3LhxSklJUVBQkCIjI1WhQgXFx8dr8ODBstlsiouLk6+vr0v7tznK6Hjs\nxfzjZqcAWA43KYervKsGGLbvH15f7vJn//JklBszuXGsqAQAMBdr/wIAgD+iUwUAmMpCjSpFFQBg\nListqE9RBQCYqjTLDZYXnFMFAMBN6FQBAOayTqNKpwoAgLvQqQIATGWlc6oUVQCAqSiqAAC4i4VO\nRFJUAQCmolMFUC6VtQXsI9sONzsFp1VfzDc7BViAhZpuAADMRacKADAVw78AALiLdWoqRRUAYC4W\n1AcAwF0sNPzLRCUAANyEogoAgJsw/AsAMJWFRn8pqgAAc3FJDQAA7sLsXwAA3MNKnaohE5WaN2+u\nqVOn6vjx40bsHgCAMsmQTrVp06aKiIhQfHy8ateurccff1whISHy8qIxBgD8gXUaVWOKqs1mU8uW\nLbVkyRLt2LFDK1as0PPPPy/wRoqcAAAOtUlEQVQfHx8FBATotddeMyIsAACmMqSoOhwO59fBwcEK\nDg6WJB07dkw5OTlGhAQAlFNWOqdqSFHt0aPHVbfb7XbZ7XYjQgIAyinW/r2O3r17G7FbAIAV0akC\nAOAeVhr+Ze1fAADchE4VAGAu6zSqdKoAALgLnSoAwFTM/gUAwF0sNFGJogoAMBWzfwEAwBXoVAEA\n5uKcKgAA7sHwLwAAuAKdKgDAXNZpVCmqAMyz6ov5Zqfg9ESncWanUEzyp9PNTuGmYfgXAABcgU4V\nAGAuA2f/zpgxQ998840KCws1ZMgQBQcHa+zYsbp8+bICAwM1c+ZMeXt7a82aNUpOTpaHh4f69u2r\nPn36uBSPogoAMJVRw79ffvml9u7dq5SUFOXl5alnz55q1aqVoqOj1bVrV7300ktKTU1VZGSkkpKS\nlJqaqgoVKqh3797q0qWLqlev/qdjMvwLADCXzeb6owQtW7bUnDlzJElVq1bVuXPnlJmZqU6dOkmS\nOnTooIyMDG3fvl3BwcHy9fVVpUqV1Lx5c2VlZbl0KBRVAIAleXp6qnLlypKk1NRUtWvXTufOnZO3\nt7ckKSAgQDk5OcrNzZW/v7/zc/7+/srJyXEpJkUVAGAqm83m8qM0PvnkE6WmpmrSpEnFtjscjqu+\n/1rbS4OiCgCwrE2bNunVV1/V66+/Ll9fX1WuXFnnz5+XJGVnZ8tut8tutys3N9f5mWPHjslut7sU\nj6IKADCXh831RwlOnz6tGTNmaNGiRc5JR61bt1ZaWpokKT09XaGhoWrWrJl27Nih/Px8nT17VllZ\nWWrRooVLh8LsXwCAqYya/bt27Vrl5eVp1KhRzm0vvviiJk6cqJSUFAUFBSkyMlIVKlRQfHy8Bg8e\nLJvNpri4OPn6+roU0+a4kcFjA13MP252CgBuIayoVDLvqgGG7Tsnc7PLnw18qI0bM7lxN61TdTgc\nllqKCgDgHjYL3frNkHOqX3zxhbp27aoBAwbo22+/Va9evdSuXTtFREToq6++MiIkAACmM6RTTUpK\nUnJysk6dOqXY2FgtWbJETZo00aFDhzRmzBgtW7bMiLAAAJjKkKJaoUIF5zTlqlWrqkmTJpKkOnXq\nyNPT04iQAIDyykKnBg0pqtWqVdPLL7+svLw81a9fX5MmTVJoaKj+93//VwEBxp3sBgCUP1aab2PI\nOdXp06fLbrfr4Ycf1uLFi9WiRQtt3rxZNWrUUGJiohEhAQDllUFr/5rBkE61cuXKGjBggPN59+7d\n1b17dyNCAQDKOWb/AgCAK1BUAQBwE5YpBACYqwyeG3UVRRUAYC6KKgAA7mGlS2ooqgAAczH7FwAA\n/BGdKgDAVDabdfo76xwJAAAmo1MFAJiLiUoAALiHlWb/2hwOh8PsJK7mYv5xs1NAeVWW/pe20C8L\n3Fz9wp4xO4Vi3t/2tmH7PrVnh8ufrdYo2I2Z3DjOqQIA4CYM/wIATGWl4V+KKgDAXBYqqgz/AgDg\nJnSqAABzWWjxB4oqAMBUNtb+BQAAf0SnCgAwl4UmKlFUAQCm4pIaAADcxUITlaxzJAAAmMzQTtXh\ncCgvL08Oh0MBAQFGhgIAlFNWmv1rSFH9+eefNX36dB06dEgHDx7UnXfeqVOnTqlp06aaMGGCatas\naURYAABMZcjw7+TJk/Xcc8/pgw8+0MqVKxUcHKyPP/5Yjz/+uJ599lkjQgIAyiubzfVHGWNIUb14\n8aLq1asnSWrYsKF2794tSWrXrp3Onz9vREgAQDlls9lcfpQ1hgz/NmrUSKNHj9Z9992nTZs26aGH\nHpIkJSQk6K677jIiJACgvLLQ7F9DblLucDj06aef6pdfflGjRo3Url07SdKuXbvUuHHjUv11wU3K\n4TJuUg4LuJVuUl6Q/R+XP1u5Zn03ZnLjDOlUbTabOnfufMX2Jk2aGBEOAIAywTo9NwAAJmNFJQCA\nqcrihCNXUVQBAOay0EQliioAwFR0qgAAuIuFOlXrHAkAACajqAIA4CYM/wIATGXkXWoSExO1fft2\n2Ww2JSQk6L777jMslkRRBQCYzaCJSl999ZX279+vlJQU/fjjj0pISFBKSoohsX5DUQUAmMpm0ESl\njIwM5+p+v92C9MyZM6pSpYoh8STOqQIAzGbQrd9yc3Pl5+fnfO7v76+cnBxDD6XMdqreVQPMTgEA\nTGPkAvZlzc36fW/A/WOuQKcKALAku92u3Nxc5/Njx44pMDDQ0JgUVQCAJbVp00ZpaWmSpO+//152\nu93Q86lSGR7+BQDgRjRv3lxNmzZVVFSUbDabJk+ebHhMQ25SDgDArYjhXwAA3ISiCgCAm1j6nOrN\nXp7qevbs2aNhw4Zp0KBBiomJMTWXGTNm6JtvvlFhYaGGDBmiRx55xLRczp07p/Hjx+v48eO6cOGC\nhg0bpg4dOpiWjySdP39ejz32mIYNG6bHH3/ctDwyMzM1cuRI3X333ZKkRo0a6fnnnzctH0las2aN\nFi9eLC8vL40YMULt27c3LZcVK1ZozZo1zuffffedtm3bZkouZ8+e1bhx43Tq1CldunRJcXFxCg0N\nNSUXSSoqKtLkyZO1d+9eVahQQVOmTNGdd95pWj63CssWVTOWpypJQUGBpk6dqlatWpmWw2++/PJL\n7d27VykpKcrLy1PPnj1NLaqfffaZ7r33Xj355JM6dOiQ/va3v5leVBcuXKhq1aqZmsNvHnzwQc2d\nO9fsNCRJeXl5SkpK0sqVK1VQUKB58+aZWlT79OmjPn36SPr1Z37dunWm5fL+++/r9ttvV3x8vLKz\ns/XEE09o/fr1puXz6aef6vTp01q+fLn+85//6IUXXtCiRYtMy+dWYdmiasbyVCXx9vbW66+/rtdf\nf92U+L/XsmVLZ9detWpVnTt3TpcvX5anp6cp+Tz66KPOr48cOaKaNWuaksdvfvzxR+3bt8/UYlFW\nZWRkqFWrVqpSpYqqVKmiqVOnmp2SU1JSkmbNmmVafD8/P+3evVuSlJ+fX2wlHzP88ssvzp/z+vXr\n6/Dhw6b+nN8qLHtO1YzlqUri5eWlSpUqmRb/9zw9PVW5cmVJUmpqqtq1a1cmftCioqL07LPPKiEh\nwdQ8pk+frvHjx5uaw+/t27dPQ4cOVf/+/bV582ZTczl48KDOnz+voUOHKjo6WhkZGabm85tvv/1W\ntWvXNvzC/pJ069ZNhw8fVpcuXRQTE6Nx48aZlov066mCL774QpcvX9ZPP/2kAwcOKC8vz9ScbgWW\n7VT/iCuHrvTJJ58oNTVVb775ptmpSJKWL1+unTt3asyYMVqzZo1sBt25oiSrVq3S/fffr3r16t30\n2FfTsGFDDR8+XF27dtWBAwc0cOBApaeny9vb27ScTp48qfnz5+vw4cMaOHCgPvvsM1O+V7+Xmpqq\nnj17mprD6tWrFRQUpDfeeEO7du1SQkKC3nvvPdPyCQsLU1ZWlgYMGKDGjRvrjjvu4PfgTWDZomrG\n8lTlyaZNm/Tqq69q8eLF8vX1NTWX7777TgEBAapdu7buueceXb58WSdOnFBAwM1f/3nDhg06cOCA\nNmzYoKNHj8rb21u1atVS69atb3ouklSzZk3n8Hj9+vVVo0YNZWdnm1b0AwICFBISIi8vL9WvX18+\nPj6mfa9+LzMzUxMnTjQ1h6ysLLVt21aS1KRJEx07dsz04dZnnnnG+XXnzp1N/z7dCiw7/GvG8lTl\nxenTpzVjxgwtWrRI1atXNzsdbd261dkt5+bmqqCgwLTzUa+88opWrlyp//mf/1GfPn00bNgw0wqq\n9OtM2zfeeEOSlJOTo+PHj5t6zrlt27b68ssvVVRUpLy8PFO/V7/Jzs6Wj4+Pqd27JDVo0EDbt2+X\nJB06dEg+Pj6mFtRdu3ZpwoQJkqTPP/9cf/nLX+ThYdlf+WWGZTtVM5anKsl3332n6dOn69ChQ/Ly\n8lJaWprmzZtnSlFbu3at8vLyNGrUKOe26dOnKygo6KbnIv16LvW5555TdHS0zp8/r0mTJvHD//91\n7NhRzz77rD799FNdunRJU6ZMMbV41KxZU+Hh4erbt68kaeLEiaZ/r3JycuTv729qDpLUr18/JSQk\nKCYmRoWFhZoyZYqp+TRq1EgOh0O9e/dWxYoVTZ3EdSthmUIAANyEdgAAADehqAIA4CYUVQAA3ISi\nCgCAm1BUAQBwE8teUgMY4eDBg4qIiFBISIgk6dKlS2rRooXi4uL09ddf6/vvv9dTTz11zc+/9tpr\natSokdq3b68PPvhA3bp1M/2SFADuwyU1wJ9w8OBBRUdH6/PPP5ckXbhwQS+++KKys7O1YMGCP7Wv\nRx55RGvXrpWXF3/bAlbBTzNwAypWrKiEhASFh4fr3Xff1bZt2zRr1ixt3LhRs2fPVrVq1RQaGqp3\n3nlHn3/+ucaPH68HHnhAR44c0f79+zVo0CDNmTNHM2fO1M8//yybzaZ77rnH9MVKALiGcSfgBlWo\nUEH33nuvzp49K+nXmzdMnjxZM2bM0NKlS3X69OkrPjNixAhJ0pIlS5Sdna3t27crJSVFy5cv1z33\n3HPVzwAo+yiqgBucPn3auc7rb2viNmnSRJIUHh5e4mfvvPNO+fn56cknn9SyZcvUpUsX029yAMA1\nFFXgBp07d047d+5UtWrVJP3aqf7+VmjXW1S9YsWKWrZsmUaNGqUTJ06od+/eOnbsmKE5AzAG51SB\nG3Dp0iVNmzZNbdq0cc7i9fPzk4eHh3766SfdcccdSk9Pv+pnbTabCgsLtXPnTu3bt089e/ZU06ZN\ntWfPHv3yyy+y2+0381AAuAFFFfiTTpw4odjYWF2+fFn5+flq06aNJk2apI8++kiS5OHhoYSEBMXF\nxSkoKEgtWrS46gzf0NBQ9erVS9OnT1daWppSUlLk7e2t+vXrq3nz5jf7sAC4AZfUAAb45JNP1Lhx\nY9WrV0/p6elKSUlx3hcVgHXRqQIGKCoq0tNPP60qVaro8uXLpt9bE8DNQacKAICbMPsXAAA3oagC\nAOAmFFUAANyEogoAgJtQVAEAcBOKKgAAbvL/AGyjJWjA9ZNMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7eff7a3aafd0>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_classification_results(y_test_label, y_pred_label,\"Heatmap Predictions of CNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DEQrdyLHsUIu"
   },
   "source": [
    "### 2.3.5: Summary\n",
    "\n",
    "Summarize your findings:\n",
    " * Which hyper-parameters were important and how did they influence your results?\n",
    " > *The hyperparameters for CNN classifier that were important were the paramaters number of epochs, filter size, optimizer algorithm, non-linear activation, and dropout rate.*\n",
    " * What were other design choices you faced?\n",
    " > *The other choices include the fact that we used only one CNN layer with Maxpool and Dropout. We also set the number of filters to 32. The CNN layer is followed by a Fully Connected layer with 128 neurons.*\n",
    " * Any other interesting insights...\n",
    " > *We actually saw that having Adam optimizer again improved the performance of the network.*<br>\n",
    " > *We also see that validation loss is actually increasing very slightly towards the end of the 30 epochs, whereas the validation accuracy is also fluctuating, but seems to have a slight positive trend. This could mean that if we applied a learning rate decay after some epochs, it might have helped in reaching a better local minima.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ex3qQp3JolD1"
   },
   "source": [
    "# 3. Summary\n",
    "\n",
    "Enter your final summary here.\n",
    "\n",
    "* You should now compare performance  on the three models [M1], [M2] and [M3]. Present this in a tabular format and/or using plots.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We plot the accuracies of the different models below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAHsCAYAAAB8GrGUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzt3XlcVnXex/83i0AI3smdeteIC1pC9jMT07SkRDQzyQW3LKiHlZXaBKYlirskKndpepdmYypjJmlWozM5aaa5pkPhEpaCC5kL444my8X390e/rl+OCzQD50vyev4lh+uc63NdHOPVOcdzeRhjjAAAAGCNp+0BAAAAqjqCDAAAwDKCDAAAwDKCDAAAwDKCDAAAwDKCDAAAwDKCDHCIy+XSu+++q549e6pbt27q0qWLpk2bpsLCQknSiBEj9Kc//alcn3PNmjWaNGmSJCkrK0tRUVHq2bOnFi5c6F7+70hKStKuXbskSaNGjdKmTZvKZd4PP/xQ4eHh6tatm7p3765u3bqpX79++vrrr3/ztjZs2KD27durV69eunjxYrnMVxmcPXtWkyZNUnR0tPt9+uCDD2yPdZlu3brp7NmztscAfje8bQ8AVBXjxo3TmTNntGDBAgUGBurChQsaNmyYRo0apWnTplXIc3bo0EEdOnSQ9HOctW7dWsnJyf/xdjdt2qS+fftKUrls79datmypOXPmuL/+/PPP9cILL+iLL76Qt3fZ/5O1cuVK9e7dW4MGDSrX+WwqKCjQ448/rujoaC1fvlze3t46fPiwnnzySUlS79697Q74Kx9//LHtEYDfFYIMcMAPP/ygv/zlL9qwYYMCAgIkSf7+/ho/frwyMjIue/zSpUu1ZMkSFRUV6cyZM3rmmWfUv39/5eXl6ZVXXtGpU6ckSffff7/i4+OvuvzDDz/UqlWr9PDDD2vx4sVyuVy6ePGi7r33Xq1atUpz5sxRXl6exo4dq5ycHHl6eqpfv36Ki4vTN9984z6Cl5eXp7Zt2+rVV1/V66+/ruPHj2vYsGGaOnWqUlNT9dhjj6lz585avXq1Zs2apZKSElWvXl2JiYlq1qyZZs6cqcOHDysvL0+HDx9WnTp1NG3aNNWuXbvU965NmzbKy8vT2bNnFRAQoNTUVG3btk0ul0u33367kpKSFBAQoMjISDVr1kzfffedYmJitGbNGvn6+urcuXMaOnSoUlJStHnzZnl5ealZs2ZKTEy8bL2hQ4dq8uTJ6tq1q7Zs2aIzZ87o6aefVkZGhnbv3i1vb2+99dZbqlOnjtauXas5c+aosLBQJ0+eVPfu3RUfH6+tW7fq9ddfV3BwsPbu3avi4mKNHz9e4eHhOn/+vCZNmqSMjAx5eXkpKipKCQkJKioquurr+rW//vWv8vf31zPPPONe9oc//EHTp09XUVGRJGnv3r2aMGGCTp8+LQ8PDw0YMEDdu3fX1q1b9dprr+nmm2/W/v37dcMNN2jgwIFKS0vT/v371alTJ40cOVJbt25VamqqbrnlFuXk5MjPz08pKSlq1KiR9u/frwkTJuj8+fPKy8tTaGiopk+fLl9fX91xxx3q0KGD9uzZo9TUVPXq1UubN2+Wy+W64r4pSf/3f/+nlStXysvLSw0bNtTo0aNVq1YtxcbGqnnz5srIyNCRI0fUpk0bTZw4UZ6enNTBdcwAqHCffvqpiYmJueZjXnnlFfPOO++Y/Px806dPH3Py5EljjDFff/21ad68uTHGmFmzZpnRo0cbY4w5f/68iY+PN2fPnr3q8mXLlpmBAwcaY4x54403zPjx440x5pLlgwcPNlOmTDHGGHP27Fnz8MMPmwMHDpiEhASzZcsWY4wx+fn5pnXr1mbnzp3GGGPat29vduzYYYwx5vHHHzd/+9vfzL59+0zbtm3NoUOHjDHGbNq0ydx7773m3Llz5o033jAdOnQw586dM8YY8+yzz5oZM2Zc9h78ei5jjCkpKTHvvvuu6dq1qzHGmJkzZ5qUlBRTUlJijDHmf//3f83YsWPdM82aNeuy99MYY2bMmGGGDBliCgsLjcvlMiNGjHC/X/+6Xvv27c2rr75qjDFm5cqVJjQ01GRlZRljjBk0aJB56623TElJiXn88cfN/v37jTHGHD161ISFhZkTJ06YLVu2mLCwMPPtt98aY4z505/+ZB577DFjjDGvvvqqSUhIMMXFxaagoMA89thjZsuWLdd8Xb82YcIE98/qSoqKikyHDh3MqlWr3HO1a9fOZGRkuOfavXu3McaYp556yvTt29cUFBSYEydOmKZNm5qjR4+aLVu2mNDQULNt2zZjjDHvvfee6dGjhzHGmJSUFPPRRx8ZY4wpLCw0Xbt2NZ9++qkxxpjbbrvNLF++3D3LbbfdZk6cOHHVfXPp0qWmb9++5vz588aYn/fPAQMGGGN+3qf++Mc/GpfLZc6dO2fuu+8+s3nz5qu+buB6wBEywAGenp4qKSkp02OrV6+u2bNna926dTpw4ID27NmjCxcuSJLatWungQMH6siRI2rbtq1eeuklBQYGXnV5WWzatEnDhw+XJAUGBmrFihWSpJSUFK1fv16zZ89WTk6OCgoK3HNcyZYtW3TPPfcoODhY0s9HtoKCgtzXmrVq1cp9xOf222/XmTNnrrid7du3q1u3bvLw8FBhYaFCQkL0xhtvSJK++OILnTt3zn3NWlFRkf77v//bvW7Lli2vuM3169crISFB1apVkyTFxsZq8ODBV12vU6dOkqTg4GDddNNNCg0NlSTVq1dPZ86ckYeHh2bPnq0vvvhCK1asUHZ2towx+umnnyRJt9xyi8LCwtyvdfny5e73OjExUV5eXvLy8tKf//xnSdK0adOu+bp+4eHhIXONT7s7cOCACgoK3PPXqVNHnTp10pdffqnWrVurbt26uv32292vJTAwUD4+PgoKClL16tXdP5PQ0FD3exITE6MJEybo1KlTGj58uDZu3Ki5c+fqwIEDOn78+CX7xJXe/6vtm+vXr1fPnj3l7+8vSYqLi9Ps2bPd11S2b99enp6eCggIUP369a+6vwDXC4IMcECzZs2Uk5Oj/Pz8S05DHTt2TKNHj3YHhyQdPXpUffv2VZ8+fRQeHq7OnTtr7dq17u2sWbNGmzdv1pYtW9S7d2/NnTv3qsvLwtvbWx4eHu6vc3NzVbNmTQ0YMEBNmjRRu3bt9NBDDykzM/OaMVBSUnLJdiTJGKPi4mJJkp+fn3v5tcLiX68h+9fnGDlypO6//35J0vnz51VQUOD+/i+/3EubraSkxH2K70rr+fj4uP/8S8T92oULF9SjRw9FRUWpZcuWiomJ0erVq92v6Wqv9V/f6yNHjsjPz6/U1/WL5s2ba9GiRZctX7NmjbZv367u3btf82fw69f1yzxX4uXldcVlQ4cOlcvl0kMPPaQHHnhAR44cueTneKX3/2r75pV+Jr/MKZV9fwGuF5yQBxxQp04dRUdHa+TIkcrPz5ck5efna9y4cbrxxhsv+eWza9cuBQUFadCgQbrvvvvcMeZyuZSamqo333xTUVFRGjVqlBo3bqy9e/dedXlZtGnTRsuWLZMknTt3Tk888YQOHDignTt3atiwYerUqZOOHj2qQ4cOuY/yeXl5XfLL85ftbNiwQbm5uZKkzZs368iRI7rzzjv/szfvV+677z4tWrRIhYWFKikp0ejRo/Xaa6+Vul67du20ePFiFRUVqaSkRIsWLdK99977b89x8OBB5efnKz4+XpGRkdq6dat7pmtp06aNli9frpKSEhUWFuqPf/yjtm3bVubX1alTJ+Xn52vu3LlyuVySfg7oX67xCgkJkbe3t/7+979L+jn4V61apbZt2/6m17dnzx7t2bNHkrRkyRLdddddqlGjhjZs2KDBgwerS5cukqTMzEz3HFdztX2zXbt2WrZsmfsIW1pamu6+++7LohGoKjhCBjhk7NixevPNN9WvXz95eXmpsLBQUVFReuGFFy553L333qulS5eqc+fO8vDwUKtWrRQUFKSDBw/qiSee0IgRI9S1a1f5+PioSZMmevjhh3XmzJkrLv/l9OO1jBkzRuPGjVN0dLSMMXr22Wd1xx13aODAgerRo4f8/f1Vp04dtWjRQgcPHlSbNm3UsWNHDR8+XOPGjXNvp3Hjxho7dqyGDBkil8slPz8/zZ49u8ynTsti0KBBmjJlinr06CGXy6WwsDCNGDGi1PWef/55TZkyRd27d1dxcbGaNWum0aNH/9tzNGnSRA888IAeeugh+fj46LbbblPjxo118ODBawbFkCFDlJycrG7dusnlcqlLly7q1KmTIiIiyvS6fHx89O6772ratGmKjo52n/p8/vnn1bNnT0nSm2++qUmTJmnmzJlyuVwaPHiw7rnnHm3durXMr++mm27S9OnTdfjwYQUFBWnq1KmSpISEBA0ePFj+/v4KCAjQ3XffrUOHDl1zW1fbZ729vXXkyBH17t1bJSUlql+/vlJTU8s8I3C98TAcBwYA/H+2bt2qiRMnlinmAZQfTlkCAABYxhEyAAAAyyrsCFlmZqZiY2Ml/XwB7KOPPqr+/ftr7Nix7gtfZ82apV69eqlfv37asWNHRY0CAABQqVVIkM2dO1dJSUnuf7Y9efJkxcfH67333pMxRmvWrNHu3bv11Vdf6YMPPtBrr72m8ePHV8QoAAAAlV6FBFm9evU0c+ZM99e7d+9Wq1atJEkRERHatGmT/vGPf+i+++6Th4eHbrnlFrlcLp08ebIixgEAAKjUKuS2Fw8++KB++OEH99fGGPcNAKtXr65z584pPz9fN954o/sxvywPCgq65rYzMjIuu/EhAABAZeTh4aHmzZuX+jhH7kP26w+EPX/+vGrUqKGAgACdP3/+kuVluV/RDTfc4P5IEgAAgMosKyurTI9z5LYXt99+u/umhOvXr1fLli3VokULbdiwQSUlJfrxxx9VUlJS6tExAACA65EjR8heeeUV90eBhISE6MEHH5SXl5datmypvn37qqSkRGPGjHFiFAAAgErnd3cfsqysLE5ZAgCA34Wydgt36gcAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMA/K4VFBfYHgHXGRv7lLfjzwgAQDny9fbVvTPvtT0GriMbX9jo+HNyhAwAAMAyggwAAMAyggwAAMAyggwAAMAyggwAAMAyggwAAMAyggwAAMAyggwAAMAyx24MW1hYqMTEROXm5iogIEBjxozRDz/8oNTUVN1www1q166dBg0a5NQ4AAAAlYZjQZaeni5/f3+lp6crJydH48eP1/79+5WWlqbg4GANGzZM27dvV8uWLZ0aCQAAoFJw7JTlvn37FBERIUkKCQlRRkaGatSooeDgYElSixYtlJGR4dQ4AAAAlYZjR8jCwsK0du1aRUVFKTMzU4WFhbp48aKys7PVoEEDrV+/XqGhoaVup6CgQFlZWQ5MDAD4PQgLC7M9Aq5DTreGY0EWExOj7OxsxcXFqUWLFmratKmSkpI0btw41ahRQw0bNlTNmjVL3Y6vry9/+QAAQIUqr9Yoa9g5dspy586dCg8PV1pamqKiohQcHKz169drzpw5mjVrlg4dOqS2bds6NQ4AAECl4dgRsvr162vGjBmaN2+eAgMDlZycrHXr1unRRx+Vn5+foqOjdeuttzo1DgAAQKXhWJAFBQVp/vz5lyzr06eP+vTp49QIAAAAlRI3hgUAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAMAALCMIAOuY6a4wPYIuM6wTwEVw9v2AAAqjoe3rw5N+H9sj4HrSL0xO22PAFyXOEIGAABgGUEGAABgGUEGAABgGUEGAABgGUEGAABgGUEGAABgGUEGAABgGUEGAABgGUEGAABgGUEGAABgGUEGAABgGUEGAABgGUEGAABgmbdTT1RYWKjExETl5uYqICBAY8aM0Y8//qjU1FR5e3urTZs2SkhIcGocAACASsOxIEtPT5e/v7/S09OVk5OjiRMn6sSJE0pNTVWjRo3Uv39/fffdd2rSpIkj8xQUueRbzcuR50LVwD4FAPh3ORZk+/btU0REhCQpJCRE2dnZatOmjU6fPq2ioiIVFBTIy8u5X2a+1bwUPnyhY8+H698/psXZHgEA8DvlWJCFhYVp7dq1ioqKUmZmpo4dO6Zbb71Vzz33nG688UY1adJEISEhpW6noKBAWVlZ5TIPUN7KY98sT+znqAjs56gKnN7PHQuymJgYZWdnKy4uTi1atFC9evU0d+5crVy5UnXq1NHUqVM1b948Pf3009fcjq+vL3/5UGmxb6IqYD9HVVBe+3lZw86xf2W5c+dOhYeHKy0tTVFRUWrcuLH8/f3l7+8vSapdu7bOnj3r1DgAAACVhmNHyOrXr68ZM2Zo3rx5CgwMVHJysnbs2KEBAwbI19dXgYGBSklJcWocAACASsOxIAsKCtL8+fMvWdaxY0d17NjRqREAAAAqJW4MCwAAYBlBBgAAYBlBBgAAYBlBBgAAYBlBBgAAYBlBBgAAYBlBBgAAYBlBBgAAYBlBBgAAYBlBBgAAYBlBBgAAYBlBBgAAYBlBBgAAYBlBBgAAYBlBBgAAYBlBBgAAYBlBBgAAYBlBBgAAYFmpQVZUVOTEHAAAAFVWqUHWs2dPJScn6/vvv3diHgAAgCrHu7QHfPzxx/ryyy81a9YsnTp1So888oi6dOmi6tWrOzEfAADAda/UI2Senp6KiIhQTEyMbrzxRqWlpempp57SkiVLnJgPAADgulfqEbKpU6dqzZo1atWqlZ555hk1a9ZMJSUl6tmzp/r27evEjAAAANe1UoOsQYMGWr58ufz9/d0X+Ht6emrWrFkVPhwAAEBVUOopS2OMpk+fLkl69tln9dFHH0mS6tatW7GTAQAAVBGlBtn777+vl156SZI0Z84cLV68uMKHAgAAqErKdFG/r6+vJKlatWry8PCo8KEAAACqklKvIevQoYP69++vZs2aaffu3YqMjHRiLgAAgCqj1CAbNGiQ2rdvr/3796t79+4KDQ11Yi4AAIAqo9RTlgcPHtT69euVk5Oj1atXa8yYMU7MBQAAUGWUGmSvvPKKJCkjI0M//PCDTp8+XeFDAQAAVCWlBpmfn5+effZZ1alTRykpKfrnP//pxFwAAABVRpnuQ5aXl6cLFy7owoULOnPmjBNzAQAAVBmlBtmQIUO0evVqPfLII+rQoYMiIiKcmAsAAKDKKPVfWe7YsUNPPfWUpJ9vgQEAAIDyVeoRsnXr1snlcjkxCwAAQJVU6hGyU6dOqV27dqpbt648PDzk4eGh999/34nZAAAAqoRSg2z27NlOzAEAAFBllRpky5cvv2zZkCFDKmQYAACAqqjUILvpppsk/Xz7i2+//VYlJSUVPhQAAEBVUmqQ9evX75Kvn3766QobBgAAoCoqNcj279/v/nNeXp6OHDlSoQMBAABUNaUG2ZgxY+Th4SFjjPz8/PTyyy87MRcAAECVUWqQvfPOO8rOztbtt9+u1atXq23btk7MBQAAUGWUemPY4cOHKzMzU9LPpy9HjBhR4UMBAABUJaUG2bFjx/Too49Kkp555hkdP368wocCAACoSkoNMun/v7D/0KFD3PYCAACgnJV6DdnIkSMVHx+vEydOqHbt2ho/frwTcwEAAFQZpQZZWFiYJk+e7L6oPzQ01Im5AAAAqoxST1kOGzaMi/oBAAAqEBf1AwAAWPabLuo/ePAgF/UDAACUs990Ub+fn5969OjhxFwAAABVRqlHyO68805NnDhRbdu21U8//aQTJ044MRcAAECVcdUjZIWFhVq5cqUWLVokHx8f5efna82aNfLz83NyPgAAgOveVY+QRUZG6rvvvlNqaqree+891a5dmxgDAACoAFc9QhYXF6cVK1bo8OHD6tWrl4wxTs4FAABQZVz1CNnAgQP1ySefKDY2VitWrNCuXbs0bdo0ff/9907OBwAAcN0r9aL+Vq1aadq0afrss8/0P//zP3r55ZedmAsAAKDKKNN9yCSpRo0aio2N1UcffVSR8wAAAFQ5ZQ4yAAAAVAyCDAAAwDKCDAAAwDKCDAAAwDKCDAAAwDKCDAAAwDKCDAAAwDKCDAAAwDKCDAAAwDKCDAAAwDKCDAAAwDKCDAAAwDKCDAAAwDKCDAAAwDKCDAAAwDKCDAAAwDKCDAAAwDKCDAAAwDKCDAAAwDJvp56osLBQiYmJys3NVUBAgMaMGaPRo0e7v5+Tk6MePXpo2LBhTo0EAABQKTgWZOnp6fL391d6erpycnI0ceJEpaWlSZJyc3P14osv6vnnn3dqHAAAgErDsVOW+/btU0REhCQpJCRE2dnZ7u8lJydr+PDhql69ulPjAAAAVBqOHSELCwvT2rVrFRUVpczMTB07dkwul0t79+7V+fPn1aZNmzJtp6CgQFlZWeUyD1DeymPfLE/s56gI7OeoCpzezx0LspiYGGVnZysuLk4tWrRQ06ZN5eXlpU8++US9e/cu83Z8fX35y4dKi30TVQH7OaqC8trPyxp2jp2y3Llzp8LDw5WWlqaoqCgFBwdLkrZs2aJ27do5NQYAAECl49gRsvr162vGjBmaN2+eAgMDlZycLEnKy8tTzZo1nRoDAACg0nEsyIKCgjR//vzLln/55ZdOjQAAAFApcWNYAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAywgyAAAAy7ydeqLCwkIlJiYqNzdXAQEBGjNmjDw8PDR27FgVFRXJx8dHr732mmrWrOnUSAAAAJWCY0GWnp4uf39/paenKycnRxMnTlRRUZGGDh2q5s2ba9WqVTpw4ABBBgAAqhzHTlnu27dPERERkqSQkBDt3r1bJ0+e1Nq1axUbG6tvvvlGzZo1c2ocAACASsOxI2RhYWFau3atoqKilJmZqVOnTunUqVNKSkpSfHy8Ro0apeXLl6tXr17X3E5BQYGysrLKZR6gvJXHvlme2M9REdjPURU4vZ87FmQxMTHKzs5WXFycWrRooTvuuEP79+/XPffcI0lq3769Nm7cWGqQ+fr68pcPlRb7JqoC9nNUBeW1n5c17Bw7Zblz506Fh4crLS1NUVFRqlevnho0aKDt27dLkrZt26Zbb73VqXEAAAAqDceOkNWvX18zZszQvHnzFBgYqOTkZJ06dUrjx4+Xy+VS3bp1NWzYMKfGAQAAqDQcC7KgoCDNnz//kmV16tTR4sWLnRoBAACgUuLGsAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJb4T4mNAAAMa0lEQVQRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJYRZAAAAJZ5O/VEhYWFSkxMVG5urgICAjRmzBh9//33mjp1qm6++WZJ0gsvvKBWrVo5NRIAAECl4FiQpaeny9/fX+np6crJydHEiRN1xx13aPjw4XrwwQedGgMAAKDScSzI9u3bp4iICElSSEiIsrOz5eHhoaysLC1YsEDNmjXTsGHD5O3t2EgAAACVgocxxjjxREuWLFFmZqaSk5OVmZmpRx99VMOHD1fHjh1Vt25djR07Vrfddpsef/zxa27nm2++ka+vrxMjAwAA/EcKCgrUvHnzUh/n2OGomJgYZWdnKy4uTi1atFDTpk3Vq1cv1ahRQ5LUoUMHrVq1qtTtlOVFAQAA/J449q8sd+7cqfDwcKWlpSkqKkp169bVI488oqNHj0qSNm/erKZNmzo1DgAAQKXh2CnLkydPaujQofrpp58UGBio5ORk7d27V9OnT5efn58aNWqkpKQkVatWzYlxAAAAKg3HggwAAABXxo1hAQAALCPIAAAALCPIqrC3335bTz75pAYMGKCnnnpKu3btUmRkpH59FruoqEiRkZE6d+6cmjRporFjx16yjUmTJikyMtLp0YEy27p1q5o0aaK//vWvlyyPjo7WiBEjFBkZqYKCgku+9+GHH+qBBx5QbGysYmNj1bdv38vWByqbvXv3auDAgYqNjVVMTIzeeOMN5ebmqmnTptq1a5f7cYsXL9bMmTMlSZGRkVq4cKH7e9nZ2YqNjXV8djh42wtULvv27dPnn3+uxYsXu2/Q+8orr6hevXr66quv1Lp1a0nS559/rtatWyswMFA33nijtm3bpuLiYnl7e8vlcl3ylxyorEJCQrRixQp16dJFkvTdd9/pp59+uuY6Xbt21bBhwyRJp0+f1iOPPKKHHnpIHh4eFT4v8FudPXtWQ4cO1cyZM9WgQQO5XC69+OKL2rBhgwICApSYmKhly5bJx8fnsnXnz5+v++67TyEhIRYmxy84QlZFBQUF6ccff9TSpUt17NgxhYWFaenSperTp48++ugj9+OWLVumvn37SpK8vb3VqlUrbdy4UZK0YcMGtWnTxsr8wG8RGhqqI0eO6OzZs5KkTz75RNHR0WVe/9y5c/Lz8yPGUGmtWbNGrVu3VoMGDSRJXl5emjJliu655x7Vr19f7dq10+uvv37FdUeMGKERI0bI5XI5ODH+FUFWRQUFBemtt95SRkaG+vbtq86dO2vt2rWKiorStm3bdPHiRR0/flz//Oc/L7kZb9euXd2nblasWPGbfqkBNnXs2FGfffaZjDHasWOH7rrrrms+fsWKFYqNjVVcXJwmTZqkqVOnOjQp8NsdP35cwcHBlyyrXr26+1ZS8fHx2rhxo7Zv337Zuvfff79uu+02zZ0715FZcWWcsqyiDh48qICAAE2ePFnSzzfuHThwoFq3bq2oqCitXr1aP/74o2JiYi5ZLzw8XOPHj9epU6d0+vRp/eEPf7AxPvCbRUdHa9y4cQoODlbLli1LffyvT1kCld0tt9yib7/99pJlubm57puv+/j4aPLkyXrppZfUp0+fy9YfMWKEYmJiVK9ePUfmxeU4QlZFfffddxo3bpz7YuaGDRsqMDBQXl5e6t27t1asWKHVq1frkUceuWQ9Dw8P3X///Ro3bpyioqJsjA78W4KDg3XhwgWlpaVdtl8Dv3ft27fXl19+qUOHDkn6+R9kpaSk6Pvvv3c/pmnTpuratesVj4QFBARowoQJSk5OdmxmXIojZFVUp06dlJ2drd69e8vf31/GGL388ssKDAxUYGCgLly4oEaNGikwMPCydaOjoxUTE6MJEyZYmBz493Xp0kUff/yxGjZsqNzcXPfyRx991P3n6Oho/dd//ZeN8YB/W0BAgFJSUpSUlCRjjM6fP6/27dsrIiJCH3/8sftxzz33nNauXXvFbbRu3VoPP/ywsrKynBobv8Kd+gEAACzjlCUAAIBlBBkAAIBlBBkAAIBlBBkAAIBlBBkAAIBlBBmACnGlDzo2xmjr1q1KSEj4j7efl5encePGSZJWr16trl27auHChRoyZMhv3taSJUtUVFSkrKwszZo16z+aKzIyUk8//fQly9599101adKkzNtISEjQ1q1br/kc//qB6AB+37gPGYByd7UPOn7//ffL7QOMa9Wq5Q6ytWvXaujQoYqMjFRcXNxv3tacOXPUvXt3hYWFKSws7D+e7dixYzp58qSCgoIkSevWrePeZgCuiSADUO6u9kHH1apV09dff+1+3J///Gf9/e9/V3FxsQIDAzVz5kwdPnxYiYmJ8vb2lpeXl6ZOnapq1aopPj5exhgVFRVp/Pjxql69uoYOHapnn31WX3zxhXbs2KGaNWtqyJAh2rhxozIzM5WcnCxjjOrUqaPU1FTt2LHDfQTs4sWLmjJlirZv3668vDwlJCToiSee0Pvvv6/XX39dn3zyiRYsWCAfHx81aNBAEyZM0F/+8hetW7dOFy9e1KFDh/TMM8+oZ8+el73+Bx98UJ9++qn69++v7Oxs1atXT3v37pUk/fDDDxo1apSKi4vl4eGhpKQkhYaGatGiRfrggw9Uq1YtnThxQtLPd1sfO3asDh48qJKSEsXHx6t169YV/NMDYAOnLAGUu6t90LGPj4/765KSEp0+fVrz58/Xe++9p+LiYu3cuVObNm1S06ZN9e677+q5557TmTNntGPHDgUGBmru3LlKSkpSfn6+ezsdOnRQu3btNHz48Es+MHz06NGaPHmyPvjgA7Vp00bZ2dnau3evpk2bpoULFyoyMlKffvqpevfurVq1aun11193r3vq1CnNnDlTCxYs0OLFixUYGKglS5ZIkvLz8zVnzhy99dZbevvtt6/4+rt27aq//e1vkqRPPvlE0dHR7u9NnTpVsbGxWrRokUaNGqWRI0fq3LlzWrhwodLT0/Xmm2+qqKhIkvTBBx+oZs2aWrRokd58800+HQO4jnGEDEC5K+2DjiXJ09NT1apV09ChQ+Xv76+jR4+quLhYvXr10ty5c/X0008rMDBQCQkJioiI0IEDBzRo0CB5e3vr+eefL3WGEydOqFGjRpKkxx57TJJ05MgRJScny9/fX8eOHVOLFi2uuG5ubq4aN26sgIAASdLdd9+tDRs26M4771RoaKgk6eabb1ZhYeEV17/55pvdz5eRkaH4+Hj397Kzs3X33XdLksLCwnT06FHl5OSocePG7mBt1qyZJOn777/XP/7xD+3YsUOSVFxcrFOnTpX62gH8/nCEDEC5K8sHHe/Zs0erV6/W9OnTNXr0aJWUlMgYozVr1ig8PFwLFixQ586d9c4772jr1q2qXbu25s2bp+eff16vvfZaqTPUrl1bBw4ckCS9/fbb+uyzz5SUlKRXX31VKSkpql27tn755DgPDw+VlJS4161bt66ys7N14cIFSdJXX32lhg0buh9bFl26dFFKSoruuuuuS9Zp1KiRtm/fLknKysrSTTfdpODgYO3bt08XL16Uy+Vyf5ZgSEiIHn74YaWlpWnu3Lnq3Lkz16IB1ymOkAEod1f7oOP+/fvrq6++kiTVr19fN9xwg3r27CkfHx/VqlVLx48fV/PmzTV8+HDNnDlTnp6eSkxM1C233KKEhAQtWLBAnp6eGjx4cKkzjB8/XiNHjpSnp6dq1aqlJ598Ut26dVOfPn1Uo0YN3XTTTTp+/LgkqWXLlho4cKB7u0FBQXrhhRcUFxcnT09P1atXT8OGDdPKlSvL/B507txZycnJ+uijjy5Z/vLLL2v06NGaN2+eiouLlZycrKCgIL344ovq16+fgoKCdMMNN0iS+vXrp6SkJD3++OPKz89X//795enJ/0cD1yM+XBwAAMAy/lcLAADAMoIMAADAMoIMAADAMoIMAADAMoIMAADAMoIMAADAMoIMAADAMoIMAADAsv8XBqHaqq/rsAQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style('whitegrid')\n",
    "ax = sns.barplot(['SVM','MLP','CNN'],[98.02,98.21,99.15]);\n",
    "ax.set(title=\"Classification Performance Comparison\", xlabel=\"Classification Model\", ylabel=\"Accuracy\",ylim=(95,100));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  Which model do you recommend to perform digit classification and why?\n",
    "\n",
    "> According to the performance, as well as training time required, CNN provided the best balance. Not only did it give the highest accuracy (99.15%), but the training time required was less compared to the MLP. SVM also took a long time to train, and it also gave the lowest score. Hence, CNN would be our classifier of choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Feel free to discuss other insightful observations.\n",
    "\n",
    "> We realized that some learning rate decay mechanism might have helped the models even further. A more exhaustive hyperparamter search can also be performed to get even better hyperparameter set."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Project_1_-_Template_hand-out.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
