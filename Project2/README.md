This project explores Adversarial Attacks in Machine Learning Models, pertaining to image classification. The project had 3 sub-tasks.
1. Implement an attack algorithm without using any libraries. We implemented an iterative gradient-based attack for this part. We crafted adversarial examples and show if it can fool a CNN model.
2. Use CleverHans to implement two attack algorithms. We chose FGSM and Momentum based attack and generated 1000 examples to attack the model. Both the attacks were untargeted.
3. Use CleverHans to perform adversarial training to defend the model.
